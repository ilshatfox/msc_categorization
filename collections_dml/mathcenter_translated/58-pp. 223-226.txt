PLACES : DEEP CONVOLUTIONAL NETWORKS FOR PLACES DETECTION F.P.B. Dossou1  1 femipancrace.dossou@gmail.com; Kazan Federal Unirersity  The geolocation services thanks to the precious tool called GPS, are nowadays very present and important in our daily life activities: taxi ordering, place tagging, address finding etc. However, this identification is not always easy because it strongly depends on the activation of this GPS services on the user’s phone settings and also a good internet connection to ensure high efficiency and accuracy in determining the geographical location coordinates of the user. In recent years, with the dazzling advance of Artificial Intelligence, the human being has been able to achieve excellent and unimaginable progresses. This research paper introduces BD97 Places, an ongoing research project to develop a powerful artificial intelligence system for places detection and GPS Services helper using deep convolutional neural networks.  Keywords: Places Detection, Convolutional Neural Networks, Artificial Intelligence, Deep Learning  Introduction to BD97 Places  Our current task is a computer vision task because we have to teach our Artificial Neural Network how to analyze a picture and how to be able to identify probable places where the picture has been taken as we, humans could simply do by using our memory and our eyes. For that, Convolutional Neural Networks architecture has been preferred and used since they are able to successfully establish dependencies between patterns in the image through the use of appropriate filters. The proposed model is called BD-97 Places and at the currently is made of two convolutional layers with precised numbers of filters.  BD97 Places Architecture  The input to BD-97 Places is a picture. In order to get good results from our model, we applied some preliminary transformations to the input data. Firstly, we resized the picture at the input, because we needed to get it shaped so that the model could efficiently extract very important properties from them. We get another array that contains numbers, each of which respectively characterizes each pixel of the input. This last array that we got is a matrix, where height is the number of rows and width is the number of columns. Along the input image, we have a third axis called the channel axis, which corresponds to the RGB (red-green-blue) values of the image. While performing transformations on the input data, the data along that third axis can be easily compressed in quality and as a result we could most likely get very poor data quality. In order to maintain good data quality as in the input data, we performed the zero-padding operation: it consists in adding the maximum possible number of zeros along all axes of our input data matrix. After the zero-padding, the input data is sent to convolutional layers, where the model start filtering the input data. The filtration is performed by taking each of the submatrices with a predetermined size and multiply by the filter matrix to obtain a convoluted matrix of features. These submatrices are called kernels, and    224 «ЛОБАЧЕВСКИЕ ЧТЕНИЯ - 2019»  their size is called kernel’s size. However instead of multiplying each elementary single submatrix by the filter matrices, we can specifically decide which submatrices we need. This is possible thanks to the stride: the stride is the distance between each linear pattern along the axes. For example, stride 2 means that we must go from 2 rows and 2 columns along the axes of our pixel array, moving from one kernel to another. By default, its value is 1. The convoluted matrix of features is the result of the input through the filter obtained after performing multiplication between the kernel and the filter matrix taking into account the value of the stride parameter. If W is the width of the input image, the number of columns of the array of our input image, H is the height of the input image, the number of lines of the array of our input image, D is the input depth that determines the size of the axes of the channels (here the size is 3, since we are working on the RGB system), F - kernel size, S - stride, K - number of filters, P - size of the zero-padding.  Then the output size will be W ′∗H ′∗D, where:  W ′ = (W −F +2∗P )/S +1; H ′ = (H −F +2∗P )/S +1.  The convoluted matrix of features needs to be passed through an activation function, which gives an array essentially characterizing abstract patterns of the input data with pixels. There are many activation functions but in the structure of our model we used reLu and softmax as activation functions. By definition reLu function is a semi-linear function with saturation which has been proven to give very good experimental results. ReLU is simply defined as f (x) = max(0, x) and the Softmax function, also known as the normalized exponential function, calculates the probability distribution of an event over “n” different events. In this case, the events here are the diff