LAGRANGEAN DUAL PROBLEMS OF VARIATIONAL INEQUALITIES 1  I.V. Konnov Kazan State University  We consider properties of Lagrangean dual problems of variational inequalities with nonlinear constraints. In general, this problem is also a variational inequality. At the same time, we show that such a dual can be formulated as a concave maximization problem.  1 Introduction  Let Q be a convex and closed subset of a real n-dimensional Euclidean space Rn, G : Rn → Rn a continuous mapping and hi : Q → R, i = 1, . . . ,m be convex continuous functions. Then one can define the variational inequality problem (VI) as follows: Find a point u∗ ∈ U such that  〈G(u∗), u− u∗〉 ≥ 0 ∀u ∈ U, (1.1) where  U = {u ∈ Q | hi(u) ≤ 0 i = 1, . . . ,m}. (1.2) It is well known that in the case where G is the gradient map of a convex function f , VI (1.1), (1.2) is equivalent to the problem of minimizing f over U , or briefly,  min u∈U → f(u). (1.3)  One of the most powerful and popular approaches to solving nonlinearly constrained optimization problems consists in exploiting duality relationships. In fact, consider the following constraint qualification (C) Either hi, i = 1, . . . ,m are affine, or there exists a point ū ∈ Q such that hi(ū) < 0 for all i = 1, . . . ,m.  Then we can state the following Kuhn-Tucker saddle point theorem (e. g. see [1, 2]).  1This work is supported in part by RFBR Project No. 01-01-0068 and by the  Academy of Sciences of the Republic of Tatarstan  84    I.V. Konnov  Proposition 1.1. (i) If u∗ is a solution to problem (1.3), (1.2) and (C) holds, then there exists an element v∗ ∈ Rm+ such that w∗ = (u∗, v∗) is a saddle point of the Lagrange function  L(u, v) = f(u) + 〈v, h(u)〉, (1.4)  i. e.,  L(u∗, v) ≤ L(u∗, v∗) ≤ L(u, v∗) ∀u ∈ Q, ∀v ∈ Rm+ , (1.5)  where h(u) = (h1(u), . . . , hm(u)). (ii) If w∗ = (u∗, v∗) is a saddle point of the Lagrange function L  defined in (1.4), then u∗ solves problem (1.3), (1.2).  We also recall that the initial (or primal) problem is equivalent to  min u∈Q → sup  v∈Rm +  L(u, v),  whereas the dual problem can be formulated as follows  max v∈Rm  +  → ψ(v), where ψ(v) = inf u∈Q  L(u, v). (1.6)  Note that the dual problem (1.6) is also an optimization problem, more precisely, it is a concave maximization problem. Thus, the initial problem (1.3), (1.2) can be in principle reduced to the simply constrained problem (1.6) which in fact is a composition of such problems. A great number of works were devoted to this approach in optimization; see e. g. [1] - [3].  It is natural to extend this approach to variational inequality problems. Clearly, we can also use the corresponding version of the Kuhn-Tucker theorem as a basis. We now recall one of such results from [4, Proposition 1].  Proposition 1.2. (i) If u∗ is a solution to VI (1.1), (1.2) and (C) holds, then there exists a point v∗ ∈ Rm+ such that  〈G(u∗), u− u∗〉+ 〈v, h(u)− h(u∗)〉 ≥ 0 ∀u ∈ Q, (1.7) 〈−h(u∗), v − v∗〉 ≥ 0 ∀v ∈ Rm+ . (1.8)  (ii) If w∗ = (u∗, v∗) solves VI (1.7), (1.8), then u∗ solves VI (1.1), (1.2).  85    A note on lagrangean dual problems. . .  Note that VI (1.7), (1.8) coincides with the saddle point problem (1.5) if G = ∇f where f is a convex function. By analogy with the previous case, we can replace VI (1.1), (1.2) with the dual problem, which can be formulated as follows: find v∗ ∈ Rm+ such that  sup t∗∈T (v∗)  〈t∗, v − v∗〉 ≥ 0 ∀v ∈ Rm+ , (1.9)  where  T (v) = {t ∈ Rm | t = −h(ũ), ũ ∈ Q(v)}, (1.10) Q(v) = {ũ ∈ Q | 〈G(ũ), u− ũ〉  +〈v, h(u)− h(ũ)〉 ≥ 0 ∀u ∈ Q}. (1.11)  Of course, both mappings Q and T , defined in (1.10), (1.11), are in general multivalued. Moreover, although T is monotone if G is so, T need not be the subdifferential map of a convex function as the following example illustrates. For simplicity, consider the problem of finding an element u∗ ∈ Ũ such that  〈Mu∗ + q, u− u∗〉 ≥ 0 ∀u ∈ Ũ ,  where Ũ = {u ∈ Rn | Au = b},  M is an n× n nonsymmetric positive definite matrix, A is an m× n matrix, q ∈ Rn, b ∈ Rm. Then Q(v) can be determined explicitly as follows:  Q(v) = −M−1(q +AT v), hence T (v) = AM−1(q+AT v), and the Jacobian of T is asymmetric in general. Therefore, VI (1.9) does not coincide with the problem (1.6).  In this work, we show that it is possible to reduce monotone VIs to dual convex maximization problems under certain additional assumptions. This approach is described in the next section.  2 Problems with a single constraint  For simplicity, we consider the strictly monotone case.  86    I.V. Konnov  Proposition 2.1. Suppose G is strictly monotone. Then the mapping Q and T , defined in (1.11), (1.10), are single-valued, and T is monotone.  The proof follows e. g. from [4, Corollary 1]. Let X be a subset in Rm and let S : X → Rm be a mapping.  The mapping S is said to be locally bounded, if it maps each bounded set into a bounded set. Next, the mapping S is said to be cyclically monotone, if for arbitrary points x0, x1, . . . , xN in X one has  〈S(x0), x1 − x0〉+ 〈S(x1), x2 − x1〉+ . . .+ 〈S