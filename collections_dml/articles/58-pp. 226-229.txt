 «ЛОБАЧЕВСКИЕ ЧТЕНИЯ - 2019»  or bypass GPS services while trying to identity the probable places where a given picture has been taken. To solve this problem, we used a special type of architecture of neural networks called Convolutional Neural Networks. To train our network, it was necessary first of all to write a python script that helped to automatically download images from Google with the given keywords because we couldn’t find any ready dataset, we had to create our own. After the data collection, cleaning and processing, the data were still not enough and then we had to apply the data-augmentation technique. After the dataaugmentation, the data increased and we could then train our network. We made two convolutional neural network models and we established a voting classifier: this made and helped us to obtain great results. For future references, in order to get a more general and better performing network for recognizing more places, we will need to collect more data and train the network with very fined-tuned parameters and look for an effective way to use the models that we would get.  References  1. Chollet, F., Deep Learning with Python / F. Chollet. — Manning Shelter Island, 2018. — 362p  2. Cornelisse D. - Apr 24: An intuitive guide to Convolutional Neural Networks 2018  3. Abdellatif Abdelfattah - 2017, Jul 28: Image Classification using Deep Neural Network – A beginner friendly approach using TensorFlow  UDC 004.85  SEEGAAI : DEEP REINFORCEMENT LEARNING IN SEEGA C.C. Emezue1, F.P.B. Dossou2  1 chris.emezue@gmail.com; Kazan Federal University 2 femipancrace.dossou@gmail.com; Kazan Federal University  This research paper introduces SeegaAI, a research project to develop a powerful artificial intelligence bot for the game of Seega using deep reinforcement learning. Researchers have long been working on embedding human-like behavior in computers: a field of research popularly called artificial intelligence (hereafter called AI). With the advent of personal, faster and more efficient computers in our present generation, it has become easy to create powerful AIs that can play (and beat humans) at various games like checkers, backgammon, chess, and Go[1]. As a result, several resources concerning the implementation of AI in these gamesresearch papers, python libraries, game bots online, project codes, etc. – are available and easily accessible online. On the contrary, only few resources from African indigenous games (Ayo, Seega, Abula) can be found because little research has beenmade on them. These games are however unique because they involve a complex combination of strategy, psychology, and quick decision making. For example, playing Seega involves two stages: placing the players and moving the players, which both need strategy to win, unlike chess (which only requires strategy in moving the players as they have a fixed position) and Go (which involves only placing the player). It is for this complex gaming structure of Seega that we chose it for our AI project. We hope to achieve two things with this project: successfully implement deep    C.C. Emezue, F.P.B. Dossou 227  reinforcement learning in Seega and provide research materials for implementing machine learning in African indigenous board games.  Keywords: seega, reinforcement learning, artificial intelligence  Introduction  Seega is a board battle game played in Egypt, Ethiopia and especially in Somalia. It became popular in the 19th century. The aim of the game is to capture as many of the opponent’s pieces as possible. The winner is the player with the most captured pieces. Seega is a game with complete and perfect information[3]. In November 2018, Seega was selected for the annual MIFY Artificial Intelligence contest[2]. This was the first (as far as we know) approach to designing a sophisticated AI for Seega  Previous research done and what makes SeegaAI unique  The contestants designed their AI using various methods: from coding of complex logical decision making processes, minimax, to implementing alpha-beta pruning and other advanced gaming optimization methods. All their AI algorithms had one common feature: the game decisions were hard-coded into the AI (through gaming optimization techniques and perhaps expert knowledge of the game of Seega). SeegaAI explores a different approach: where the AI learns, through trial and error, about the game: the strategy of the game, how to make winning moves. This approach, called Reinforcement learning (hereafter called RL), is akin to the way a child learns to walk in its environment, by trying many times, failing and learning from experience. Over the years, using reinforcement learning to train computers to play games has produced far better results. DeepMind’s AlphaZero, which is considered unbeatable in chess, shogi and Go, taught itself to play these games from scratch through reinforcement learning. AlphaZero beat all the then powerful computer AIs in these games: it beat Elmo in a shogi match, Stockfish in a chess match and AlphaGo in a Go match. That is why we are exploring using reinforcement learning to teach SeegaAI to play Seega.  Work Objective and Process  Although computer programs have been trained to play Seega in the past, SeegaAI is the first ever attempt to implement deep reinforcement learning in Seega. The stages involved in this project can be summarized as follows[4]:  Defining the environment: This involves encoding the game state: encoding the board for each move. This is a very important stage in implementing RL in any game, because the way you present the game environment (the game state and everything going on in the game) to the neural network will affect how it learns and performs. Seega is unique because it has two stages which are both strategic and paramount to winning the game: placing the players on the board and moving the players on the board. Numerous encoding strategies are possible, depending on the game and objective. We have explored a 9-layer encoding system of the form:  Table 1. Feature planes used in SeegaAI    228 «ЛОБАЧЕВСКИЕ ЧТЕНИЯ - 2019»  Feature Name No of planes  Description  Player color 3 Three feature planes indicating the player color one each for the current player, the opponent and the empty points on the board  Player’s turn 1 This one layer gets 1 if it’s black player’s turn and 0 if it’s white’s turn.  Step 1 One layer to encode the step of the game - 0 if step is zero and 1 if step is one  Number Can capture 1 This encodes the possible number of pieces that can be captured by the player  Number Captured 1 A one-layer encoding that computes the number of opponent’s captured pieces for all possible moves  Legal move 1 If it’s a legal move, that plane gets 1, and 0 otherwise.  isPiece 1 This checks if the particular point on the board has a player piece. 1 if True and 0 if False.  Then, we get a tensor of shape (x,5,5,9), where x is the number of game moves made in a game played from the beginning to the end. We are also working on another idea: recording all the moves made in the game by taking pictures of them. This method, although requiring much computation, could help SeegaAI get more information about the game, thereby improving its performance.  Choosing the action space The action space, X , is a set of all possible actions that can be made in the game. The model learns to take in an encoded board state and produce a probability space, P , for the different actions in the action space.  X = {x1, x2, x3, x4, x5, ..., xn}, P = {p1, p2, p3, p4, p5, . . . pn}  where ∀i , pi is the probability of choosing the action xi In our first experiment, we developed two models for the action space, A, in a 5x5 board:  A = bH t ∗bW h A = (i , j ) ∪ (k, l ,m,n) where bH t = height of the board, where (i , j ) is the index of the board and bW h = width of the board ∀(k, l ), (k, l ,m,n) = all possible destinations for (k, l ) l en(A) = 25 len(A) = 105  Choosing the policy and algorithm to train the model: A policy is a function to choose the action to take at each game state, from the action space and their probabilities. The RL model learns this function during training. There are different algorithms for training an RL model: from policy optimization methods, like policy gradient, A2C /A3C , PPO, T RPO, to Q-learning methods like DQN [5]. Deep Q-learning involves using deep learning methods in Q-learning algorithm. Due to the constraint on the number of pages for this paper, we cannot go on to discuss these learning algorithms in detail. Choosing the right algorithm involves making extensive research on the mathematical modelling of the game of Seega: the strategies and psychology in winning or losing the game, how each learning algorithm influences SeegaAI’s understanding of the game, as    C.C. Emezue, F.P.B. Dossou 229  well as carrying out numerous experiments: training SeegaAI on the different algorithms and comparing the performance.  Conclusion and results of first experiment  As of writing this paper, SeegaAI is still being trained on thousands of gameplays. In  (a). Accuracy of training and validation data  (b). Loss of training and validation data  Fig. 1. Accuracy and loss plot for SeegaAI pre-training.  the beginning, we created a database from about 80,000 gameplays of a random Seegaplaying computer program. Then we trained a normal convolution neural network on this data with 300 epochs. Fig 1(a) and 1(b) show the training and loss accuracy respectively. This gave us an idea on what we need to improve SeegaAI, which we are currently working on. Such improvements include improving the board encoding, implementing RL algorithms to SeegaAI and training SeegaAI on millions of gameplay. Considering the intricacies involved in developing SeegaAI, including our currently available computing power (the CPU/GPU power we have), we estimate that SeegaAI will be ready for launching on or before January, 2020.  References  1. Max Pumperia, Kevin Ferguson. Deep learning and the game of Go.  2. Seega: The MAIC 2018 Game: https://maic.mify-ai.com/maic2018  3. All about the game of Seega: http://www.cyningstan.com/game/120/seega  4. Sterling Osborne, Reinforcement Learning from Scratch: Designing and Solving a Task All Within a Python Notebook, December, 2018.  5. SmartLab AI Reinforcement Learning algorithms — an intuitive overview   