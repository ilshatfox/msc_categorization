)  РЕЛАКСАЦИОННЫЕ МЕТОДЫ РЕШЕНИЯ УРАВНЕНИЙ С СЕДЛОВЫМ ОПЕРАТОРОМ 1  Введение  Применение различных приближенных методов для отыскания решений уравнений математической физики, как правило, приводит к необходимости решать системы линейных алгебраических уравнений, обладающих следующей спецификой: большая размерность вектора неизвестных, плохая обусловленность и ленточная структура матрицы системы. Отмеченные свойства порождают приоритетное развитие итерационных методов решения таких систем, называемых сеточными. Библиография работ по этой тематике не поддается учету, однако достаточно полное представление о современном состоянии теории итерационных методов решения сеточных уравнений можно получить из следующих изданий: Young D.M. Iterative Solution of Lager Linear Systems (1971) [60], Марчук Г.И. Методы вычислительной математики (1977) [17], Самарский А.А., Николаев Е.С. Методы решения сеточных уравнений (1978) [24], Hackbusch W. Multi – Grid Methods and Applications. (1985) [51], Дьяконов Е.Г. Минимизация вычислительной работы. Асимптотически оптимальные алгоритмы для эллиптических задач (1989) [7].  Решение сеточных уравнений с седловым оператором привлекло внимание исследователей в области численного анализа относительно недавно (с начала 70-х годов) и поэтому нашло отражение только в последней из указанных книг. Такие системы  1Работа выполнена при поддержке РФФИ, проект N 99-01-01146  44    в приложениях возникают достаточно часто, например, при численном решении линейных стационарных и нестационарных задач в гидродинамике и теории упругости, а также в смешанном подходе при решении эллиптических уравнений второго порядка и др. При этом сам термин “cедловой оператор”, или “оператор с седловой точкой”, видимо, был заимствован из теории математического программирования [18].  Следует отметить, что большинство существующих итерационных методов решения предназначено для систем со знакоопределенными симметричными матрицами. Специфика же симметричных матриц седловых систем состоит в незнакоопределенности, т.е. в наличии собственных значений разных знаков. Поэтому традиционные подходы для решения систем с такими матрицами, вообще говоря, не применимы.  Отметим в условно-хронологическом порядке авторов, внесших заметный вклад в построение и исследование алгоритмов решения седловых задач : Arrow K., Hurwicz L., Uzawa H., Crouzeix M., Temam R., Girault V., Raviart P.A., Langer U., Queck W., Bank R.E., Welfert B.D., Yserentant H., Bramble J.H., Pasciak J.E., Elman H., Golub G., Silvester D.J., Wathen A. за рубежом, Кобельков Г.М., Дьяконов Е.Г., Бахвалов Н.С., Пальцев Б.В., Ольшанский М.А. в нашей стране. Однако, несмотря на представительность библиографии, следует обратить внимание на отсутствие до настоящего времени в литературе сколь-нибудь систематического изложения теории итерационных методов решения седловых систем, содержащей как анализ сходимости, так и сравнение вычислительной эффективности различных алгоритмов. Кроме того, отметим чрезвычайную редкость не только решений, но и самих постановок задач асимптотической оптимизации для этого случая.  Приведем краткое изложение основных идей построения алгоритмов в этой области, для единообразия будем использовать алгебраическую терминологию. Рассмотрим вещественную систему линейных алгебраических уравнений Lεz = F с параметром ε ≥ 0 следующего вида  Lεz ≡ ( A B BT −εC  )( u p  ) =  ( f g  ) ≡ F , (0.1)  где A = AT > 0, C = CT > 0 — квадратные матрицы размеров  45    Nu×Nu и Np×Np , а B — прямоугольная, в общем случае, матрица размера Nu×Np . Предполагается невырожденность матрицы Lε при любом ε ≥ 0 , что делает ее седловым оператором [7]. Системой типа Стокса будем называеть наиболее важный частный случай задачи (0.1) — L0z = F (ε = 0). Ограничимся при перечислении библиографии только им, как наиболее сложным и принципиальным (т.к. из ε > 0 немедленно следует det(Lε) 6= 0).  С точки зрения приложений самым распространенным подходом к решению задачи L0z = F является построение алгоритмов типа Удзавы (Uzawa). В самой простой форме [35] его можно записать следующим образом:      Auk+1 +B pk = f,  − p k+1 − pk τk  +BT uk+1 = g. (0.2)  Здесь τk — вещественный переменный итерационный параметр. Для случая постоянного параметра τk = τ R.Temam [26] по лучил достаточное условие сходимости метода (0.2) в дифференциальной форме:  0 < τ < 2 .  Наличие здесь абсолютной постоянной, равной двум, связано с тем, что в дифференциальном случае спектр оператора BTA−1B принадлежит отрезку [γ, 1], γ > 0 .  Этот результат улучшил M.Crouzeix [45], получив в дифференциальном случае достаточное условие сходимости следующего вида:  0 < inf k (τk) ≤ sup  k (τk) < 2 .  В этой же работе, видимо впервые, было отмечено, что алгоритм Удзавы (0.2) эквивалентен методу простой итерации для системы уравнений с симетричной положительно определенной матрицей A0 = B  TA−1B :  pk+1 − pk τk  +A0 p k = BTA−1f + g ≡ f̃ . (0.3)  Такая форма записи позволяет использовать результаты общей теории итерационных методов для знакоопределенных матриц:  46    выбор оптимальных последовательностей параметров и соответствующие оценки скорости сходимости. В частности, в [45] приведены формулы для параметров и оценки погрешностей для оптимального одношагового метода, циклического k -шагового метода и полуитерационного метода Чебышева.  Далее V.Girault и P.A.Raviart в книге [49] доказали сходимость методов наискорейшего спуска и сопряженных градиентов для решения системы  A0 p = f̃ (0.4)  в абстрактном банаховом пространстве, а U.Langer и W.Queck [53] получили оценки их скоростей сходимости для сеточных систем, возникающих при аппроксимации задачи Стокса в гидродинамике.  Дальнейшее развитие этого подхода заключается в построении различными способами для конкретных сеточных систем операторов предобусловливания C , таких, что отношение констант эквивалентности Γ/γ в матричном неравенстве γ C ≤ A0 ≤ ΓC минимально. Следует отметить, что здесь в полной мере используется специфика конкретных задач, и поэтому эта тематика неисчерпаема. Приведем несколько примеров. Для задачи Стокса с параметром  −∆u + grad p+ αu = f в Ω, divu = 0 в Ω,  u = 0 на ∂Ω, (0.5)  возникающей при неявной дискретизации по времени нестационарной первой краевой задачи Стокса, J.Cahouet и J.P.Chabart [42] предложили, а M.А.Ольшанский [20] обосновал использование оператора предобусловливания с постоянными эквивалентности γ и Γ , не зависящими как от шагов сетки, так и от параметра α . Для различных дискретизаций классической задачи Стокса (α = 0) H.C.Elman и G.H.Golub [47] проанализировали диагональные и трехдиагональные операторы предобусловливания. Для классической задачи Стокса в области типа вытянутого прямоугольника M.А.Ольшанский [54] предложил оператор предобусловливания с постоянными, не зависящими ни от шагов сетки, ни от отношения сторон прямоугольника. Различные варианты  47    операторов предобусловливания многосеточного типа в сочетании с вариационными методами решения возникающих систем рассматривали R.Verfurth [57] и H.C.Elman [46].  Несмотря на успешное практическое использование, в теории алгоритмов типа Удзавы имеются, как минимум, две серьезные проблемы. Первая — связана с обобщением этого подхода на близкие, возможно нелинейные, задачи. Типичным примером здесь является первая краевая задача для уравнений Навье-Стокса при малых числах Рейнольдса. Даже при решении линеаризованной задачи оператор перехода является несимметризуемым [48], и вся имевшаяся ранее теория выбора итерационных параметров и получения оценок скорости сходимости становится неприменимой. Вторая проблема связана с необходимостью обращения на каждой итерации оператора A . Хотя здесь трудность носит другой характер (трудоемкость этой операции может быть сравнима с трудоемкостью решения исходной задачи в целом, например, когда матрица A возникает при дискретизации бигармонического оператора), попытка ее преодоления за счет обращения спектрально-эквивалентного оператора также приводит к несимметризуемости оператора перехода в методах типа Удзавы. Наиболее продвинутые результаты в этих направлениях получили J.H.Bramble, J.E.Pasciak и A.T.Vassilev [39], [40], работы которых служат наилучшей иллюстрацией к сказанному. Приведенные в них оценки скорости сходимости получены в несколько искусственной метрике и весьма далеки от предельных.  Для преодоления первой из указанных проблем еще в книге K.Arrow, L.Hurwicz, H.Uzawa [35] был предложен алгоритм Эрроу-Гурвица      A uk+1 − uk  τ + Auk + B pk = f,  −α p k+1 − pk  τ + BT uk+1 = g,  (0.6)  содержащий два итерационных параметра и являющийся обобщением алгоритма Удзавы на случай τ 6= 1 . Оператор перехода в этом методе является несимметризуемым, зависимость его собственных значений от итерационных параметров — нелинейной. Следствием этого является чрезвычайно малое количество работ по исследованию этого метода, при этом использование  48    в них энергетического подхода приводит к сильно завышенным оценкам.  Одним из первых M.Crouzeix [45] доказал в дифференциальном случае достаточное условие сходимости следующего вида:  0 < τ ≤ 1, 0 < τ/α < 2 .  Далее R.Temam [26] получил другое достаточное условие сходимости метода (0.6) в дифференциальной форме:  0 < τ < 2α/(α+ 1) , ∀α > 0 .  Наконец, W.Queck [55] попытался минимизировать оценку сверху для скорости сходимости в предобусловленном методе Эрроу– Гурвица. В наших обозначениях оптимальные параметры выглядят так:  τopt = 1/2 , αopt = 1 .  Если обозначить погрешность решения на k -й итерации через yk = (vk, rk) = (uk−u, pk−p) , где (u, p) — точное решение задачи L0z = F , и определить норму погрешности как ‖y‖2 = (v, v)/4 + (r, r) , то метод (0.6) будет сходиться с оценкой погрешности  ‖yk‖ ≤ (√  1− γ 8  )k ‖y0‖ ,  если спектр оператора BTA−1B принадлежит отрезку [γ, 1], γ > 0 .  Важным направлением исследований является также построение операторов предобусловливания для матрицы исходной системы L0 . Диагональное и блочное предобусловливание анализировали в своих работах A.Wathen и D.Silvester [58], [59]. Многосеточный метод с диагональным предобуславливанием рассматривал В.В.Шайдуров [34]. В этом же ряду следует отметить работу J.H.Bramble, J.E.Pasciak [38], в которой для предобусловленной системы уравнений, равносильной исходной, удалось ввести искусственную метрику, такую, что полученная матрица стала в ней симметричной и знакоопределенной.  Предпринимались попытки построения итерационных методов с модельными седловыми операторами. Видимо, впервые оценки скорости для их сходимости получены Е.Г.Дьяконовым [8].  49    Аналогичные исследования провели позднее R.E. Bank, B.D.Welfert, H.Yserentant H. [37]. Сочетание модельных седловых операторов с итерациями в подпространстве и методом фиктивных областей изучено в работах Н.С.Бахвалова [2], [36].  По-видимому, первым удачным алгоритмом, допускающим обобщения на близкие, даже нелинейные, задачи, был предложенный Г.М.Кобельковым (β, τ)-метод, использующий блочнотреугольную факторизацию оператора исходной задачи [12], [13]. К сожалению, даже в линейном случае условия сходимости этого алгоритма носили неконструктивный характер, хотя эффективность этого метода при решении сложных с вычислительной точки зрения задач была впечатляющей [4], [10]. Позднее Е.Г.Дьяконов получил для такого рода методов оценки погрешности [7], но численные эксперименты в этом случае не проводились.  Самостоятельное значение для решения задач с седловыми операторами имеет идея сочетания симметризации и предобусловливания, предложенная Е.Г.Дьяконовым [8]. Ценой увеличения спектрального числа обусловлености, уже не зависящего от сеточных параметров, здесь получается система с симметричной положительно определенной матрицей, для решения которой применяются хорошо известные алгоритмы. Оптимизация одного обобщения такого алгоритма была проведена П.П.Аристовым [1]. Позднее Е.Г.Дьяконовым [9] было предложено обобщение подхода на нелинейные задачи.  Существуют также методы, основанные на расщеплении граничных условий для исходных дифференциальных задач (в первую очередь, для задачи Стокса). Алгоритмы получения краевого условия для давления весьма эффективны, но сильно используют специфику задачи. Наиболее продвинутые результаты в этом направлении получил Б.В.Пальцев [21] - [22], построив в декартовых и сферических координатах в дифференциальном и конечномерном случаях методы полного и неполного расщепления граничных условий. Граничные значения для гармонической составляющей скорости предложили находить В.Д.Валединский и Е.В.Чижонков [56]. Сходимость итерационного метода в подпространстве гармонических функций для давления в дифференциальном случае обосновал А.Кожевников [52].  50    1. Общие сведения и вспомогательные результаты  1.1. Краткие сведения о методах релаксации  Приведенные материалы цитируются по книгам [6],[60].  Общие понятия  Методы релаксации решения невырожденной системы Au = f относятся к классу линейных стационарных одношаговых итерационных методов, для записи которых используется формула  B uk+1 − uk  τ +Auk = f ,  где B — невырожденная матрица, а τ — числовой параметр. Пусть I — единичная матрица, тогда матрица T = I−τB−1A  называется матрицей (оператором) перехода итерационного метода, а величина ρ(T ) , равная максимальному по модулю собственному значению матрицы T , — ее спектральным радиусом.  Условие ρ(T ) < 1  необходимо и достаточно для сходимости линейного стационарного одношагового итерационного метода.  Асимптотическая скорость сходимости линейного стационарного одношагового итерационного метода с матрицей перехода T , для которой ρ(T ) < 1 , определяется формулой  r∞ = − ln ρ(T ) .  Пусть оператор перехода T непрерывно зависит (как от параметров) от компонент вектора γ = (γ1, . . . , γp) ∈ Rp (при некотором p ≥ 1), т.е. T = T (γ) ; и Gγ ⊆ Rp — множество векторов γ ∈ Rp , для которых ρ(T ) < 1 . Тогда задача асимптотической оптимизации метода эквивалентна максимизации его асимптотической скорости сходимости и заключается в нахождении такого вектора γopt ∈ Gγ , чтобы  ρ(T (γopt)) = min γ∈Gγ  ρ(T (γ)) ,  51    и является минимаксной задачей вида  min γ∈Gγ  max λ∈σ(T (γ))  |λ| .  Здесь было использовано обозначение спектра матрицы σ(T ) — множества из n собственных значений матрицы T порядка n (каждое собственное значение берется столько раз, какова его кратность). Отметим, что решение задачи асимптотической оптимизации метода тесно связано с условием его сходимости, и поэтому в дальнейшем эти две проблемы будут рассматриваться одновременно.  Метод Якоби  Пусть A = (aij) — некоторая невырожденная (n × n)матрица с ненулевыми диагональными элементами и Λ = diag(a11, . . . , ann) . Тогда итерационный метод  Λ (uk+1 − uk) +Auk = f (1.1)  называется точечным методом Якоби решения системы Au = f . Пусть  A =    A11 . . . A1s . . . . . . . . . As1 . . . Ass     — блочная матрица с квадратными невырожденными блоками Aii , i = 1, . . . , s , и  Λ = A11 ⊕A22 ⊕ . . .⊕Ass .  В этом случае итерационный метод (1.1) называется блочным методом Якоби.  Пусть Λ — матрица какого-либо из вариантов метода Якоби и ω — некоторый числовой параметр. Тогда итерационный метод  Λ uk+1 − uk  ω +Auk = f (1.2)  называется экстраполированным методом Якоби (JOR).  52    Пусть s = 2 и ω1, ω2 — некоторые числовые параметры. Тогда блочный вариант метода (1.2)      A11 uk+11 − uk1  ω1 + A11 u  k 1 + A12 u  k 2 = f1  A22 uk+12 − uk2  ω2 + A21 u  k 1 + A22 u  k 2 = f2  (1.3)  называется модифицированным экстраполированным методом Якоби (MJOR).  Пусть A = AT > 0 . Экстраполированный метод Якоби (1.2) сходится тогда и только тогда, когда ω ∈ (0, 2/ρ(Λ−1A)) . При этом оптимальное значение параметра (в смысле максимума асимптотической скорости сходимости) вычисляется по формуле  ω0 = 2/(γ + Γ) ,  где γ = 1/ρ(A−1Λ) — минимальное собственное значение матрицы Λ−1A , и Γ = ρ(Λ−1A) .  Пусть s = 2 и A = AT > 0 . Тогда, если величина µ является собственным значением оператора перехода Tω в блочном экстраполированном методе Якоби (1.2) при ω = 1 , то и величина −µ также является собственным значением Tω=1 . Отсюда, в частности, следует, что оптимальное значение параметра ω (в смысле максимума асимптотической скорости сходимости) определяется формулой ω0 = 1 . В свою очередь, для модифицированного метода (1.3) это влечет за собой неравенство  ρ(Tω1,ω2) ≥ ρ(Tω0,ω0) = ρ(Tω=1) .  Таким образом, в случае блочных (2 × 2) линейных алгебраических систем с симметричной положительно определенной матрицей A оптимальным вариантом модифицированного экстраполированного метода Якоби является выбор ω1 = ω2 = 1 , и, следовательно, не имеет смысла вводить в классический вариант блочного метода Якоби итерационные параметры.  Метод SOR  Пусть A = (aij) — некоторая невырожденная (n×n) – матрица с ненулевыми (невырожденными) диагональными элементами  53    (блоками), Λ = diag(a11, . . . , ann) , (или Λ = A11⊕A22⊕ . . .⊕Ass ), L — строго нижняя треугольная матрица, U — строго верхняя треугольная матрица, так что A = Λ+L+U . Тогда итерационный метод (  1  ω Λ + L  ) (uk+1 − uk) +Auk = f (1.4)  называется методом последовательной верхней релаксации решения системы Au = f , а ω — релаксационным параметром. В зарубежной литературе для метода последовательной верхней релаксации принято обозначение SOR (successive overrelaxation method). Если все блоки матрицы имеют порядок единица, метод называется точечным, в противном случае — блочным.  Метод Гаусса-Зейделя является частным случаем метода последовательной верхней релаксации при ω = 1 .  Пусть s = 2 и ω1, ω2 — некоторые числовые параметры. Тогда блочный вариант метода (1.4)      A11 uk+11 − uk1  ω1 + A11 u  k 1 + A12 u  k 2 = f1,  A22 uk+12 − uk2  ω2 + A21 u  k+1 1 + A22 u  k 2 = f2  (1.5)  называется модифицированным методом последовательной верхней релаксации (MSOR).  Пусть A = AT > 0 . Метод последовательной верхней релаксации (1.4) сходится тогда и только тогда, когда ω ∈ (0, 2) .  Пусть s = 2 и A = AT > 0 . Тогда собственные значения λ оператора перехода Tω1,ω2 в методе (1.5) связаны с собственными значениями µ оператора перехода T1 в блочном методе (1.1) соотношением  (λ+ ω1 − 1)(λ+ ω2 − 1) = ω1ω2µ2λ . Более того, если µ 6= 0 является собственным значением матрицы T1 , то оба корня этого уравнения являются собственными значениеми матрицы Tω1,ω2 , в противном случае либо одна из величин ω1−1 и ω2−1 является собственным значением матрицы Tω1,ω2 , либо обе величины.  Пусть s = 2 и A = AT > 0 . Модифицированный метод последовательной верхней релаксации (1.5) сходится тогда и только тогда, когда ω1, ω2 ∈ (0, 2) .  54    Пусть s = 2 , A = AT > 0 и ω1 = ω2 = ω . Тогда оптимальное значение параметра ω (в смысле максимума асимптотической скорости сходимости) вычисляется по формуле  ω0 = 2/ ( 1 +  √ 1− ρ2(T1)  ) .  При этом ρ(Tω0) = ω0 − 1 , и, соответственно,  r∞ = − ln(ω0 − 1) .  Для модифицированного метода (1.5) это влечет за собой неравенство  ρ(Tω1,ω2) ≥ ρ(Tω0,ω0) = ρ(Tω0) . Таким образом, в случае блочных (2 × 2) линейных алгеб раических систем с симметричной положительно определенной матрицей A оптимальным вариантом модифицированного метода верхней релаксации является выбор ω1 = ω2 = ω0 и, следовательно, не имеет смысла вводить в блочный метод верхней релаксации дополнительные итерационные параметры.  1.2. Задачи, приводящие к системе сеточных уравнений с седловым оператором  Обобщенная задача Стокса  Рассмотрим в области Ω ⊂ Rs(s = 2, 3) нестационарную первую краевую задачу для уравнений Стокса в переменных скорость-давление [15]  ∂u  ∂t − ν∆u + grad p = f в Ω,  divu = 0 в Ω, u = 0 на ∂Ω,  u(x, 0) = u0(x) в Ω.  (1.6)  Уравнения (1.6) описывают движение вязкой (ν — постоянный коэффициент кинематической вязкости), несжимаемой, однородной и изотропной жидкости при малых скоростях под воздействием внешних сил. Неизвестными здесь являются вектор-функция  55    u = (u1(x, t), . . . , us(x, t)) (скорость жидкости) и скалярная функция p = p(x, t) (давление), определенная с точностью до константы. Нулевые граничные условия означают, как правило, что движение происходит в некотором неподвижном объеме с твердыми стенками, полностью заполненном жидкостью.  Произвольная неявная по времени дискретизация после соответствующей перенормировки приводит к обобщенной задаче Стокса с параметром α ≥ 0 :  −∆u + αu + grad p = f , divu = 0, u|∂Ω = 0.  (1.7)  Случай α = 0 соответствует классической задаче Стокса, нестационарные же уравнения порождают большой параметр α ∼ (ν δt)−1 , где δt — шаг интегрирования по времени.  Пусть  P =  { q|q ∈ L2(Ω),  ∫  Ω  qdΩ = 0  } , U =  ( ◦  W 12 (Ω)  )s .  Определим обобщенное решение задачи (1.7) следующим образом: найти u ∈ U и p ∈ P , удовлетворяющие системе интегральных тождеств  (gradu, gradv) + α (u,v)− (p, divv) = (f,v) ∀v ∈ U, −(q, divu) = 0 ∀q ∈ P. (1.8)  Для дискретизации задачи (1.8) по пространственным переменным необходимо ввести конечномерные подпространства Uh ⊂ U и Ph ⊂ P , приводящие к задаче: найти uh ∈ Uh и ph ∈ Ph , такие, что  (graduh, gradv) + α (uh,v)− (ph, divv) = (f,v) ∀v ∈ Uh, −(q, divuh) = 0 ∀q ∈ Ph.  (1.9) При этом независимо от конкретного выбора Uh и Ph система сеточных уравнений (1.9) может быть переписана в матричной блочной (2× 2) форме  L0z ≡ ( A B BT 0  )( u p  ) =  ( f 0  ) ≡ F , (1.10)  56    где u — дискретный аналог вектора скорости, а p — дискретный аналог функции давления, порожденные разложениями искомых неизвестных по базисам пространств Uh и Ph соответственно.  Уравнения Ламе в теории упругости и слабосжимаемая жидкость  Рассмотрим в области Ω ⊂ Rs(s = 2, 3) стационарную первую краевую задачу для линейных уравнений теории упругости с постоянными коэффициентами Ламе — µ, λ , записанную относительно вектора перемещений u [25]:  µ∆u + (λ+ µ) grad divu = f в Ω, u = 0 на ∂Ω.  (1.11)  Неизвестной здесь является вектор-функция u = (u1(x), . . . , us(x)) . Нулевые граничные условия означают, как правило, что форма тела остается неизменной.  Введем новую переменную  p = − λ+ µ µ  divu (1.12)  и обозначение ε =  µ  λ+ µ .  Тогда задачу (1.11) после соответствующей перенормировки можно записать в виде  −∆u + grad p = f , − divu− ε p = 0,  u|∂Ω = 0. (1.13)  К такому же виду приводятся линеаризованные уравнения слабосжимаемой жидкости [26]  −ν∆uε − ε−1 grad divuε = f в Ω, u = 0 на ∂Ω.  Здесь ε > 0 — малый параметр. Пусть, как и в предыдущем случае,  P =  { q|q ∈ L2(Ω),  ∫  Ω  qdΩ = 0  } , U =  ( ◦  W 12 (Ω)  )s .  57    Определим обобщенное решение задачи (1.13) следующим образом: найти u ∈ U и p ∈ P , удовлетворяющие системе интегральных тождеств  (gradu, gradv)− (p, divv) = (f,v) ∀v ∈ U, −(q, divu)− ε (p, q) = 0 ∀q ∈ P. (1.14)  Для дискретизации задачи (1.14) по пространственным переменным необходимо ввести конечномерные подпространства Uh ⊂ U и Ph ⊂ P , приводящие к задаче: найти uh ∈ Uh и ph ∈ Ph , такие, что  (graduh, gradv)− (ph, divv) = (f,v) ∀v ∈ Uh, −(q, divuh)− ε (ph, q) = 0 ∀q ∈ Ph.  (1.15)  При этом независимо от конкретного выбора Uh и Ph система сеточных уравнений (1.15) может быть переписана в матричной блочной (2× 2) форме  Lεz ≡ ( A B BT −εC  )( u p  ) =  ( f 0  ) ≡ F , (1.16)  где u — дискретный аналог вектора перемещений, а p — дискретный аналог введенной функции, порожденные разложениями искомых неизвестных по базисам пространств Uh и Ph соответственно.  Смешанный подход при решении эллиптических уравнений  Рассмотрим в области Ω ⊂ Rs(s = 2, 3) первую краевую задачу для эллиптического уравнения второго порядка  − div K grad p = f в Ω, p = 0 на ∂Ω ,  (1.17)  где K = {kij}s ′  i,j=1 — симметричная положительно определен ная матрица, элементы которой являются ограниченными функциями пространственных переменных (значения s и s′ не обязательно совпадают). Такая постановка является традиционной модельной задачей в механике сплошных сред или гидродинамике пористых областей [16], [25].  58    Введем новую переменную u следующим образом:  u = K grad p . (1.18)  Тогда задачу (1.17) можно записать в виде  K −1  u− grad p = 0 в Ω, divu = −f в Ω, p = 0 на ∂Ω.  (1.19)  Наиболее типичными случаями модели являются случаи, когда K определяет тензор упругости/проницаемости, u представляет вектор напряжений/скорости, а p — функция смещения/давления.  Пусть  P = L2(Ω), U = { v|v ∈  ( L2(Ω)  )s , div v ∈ L2(Ω)  } .  Определим обобщенное решение задачи (1.19) следующим образом: найти u ∈ U и p ∈ P , удовлетворяющие системе интегральных тождеств  ( K −1  u,v ) + (p, divv) = 0 ∀v ∈ U,  (divu, q) = − (f, q) ∀q ∈ P. (1.20)  Для дискретизации задачи (1.20) по пространственным переменным необходимо ввести конечномерные подпространства Uh ⊂ U и Ph ⊂ P , приводящие к задаче: найти uh ∈ Uh и ph ∈ Ph , такие, что  ( K −1  uh,v ) + (ph, divv) = 0 ∀v ∈ Uh,  (divuh, q) = − (f, q) ∀q ∈ Ph. (1.21)  При этом независимо от конкретного выбора Uh и Ph система сеточных уравнений (1.21) может быть переписана в матричной блочной (2× 2) форме (1.10).  Несколько другой способ сведения исходной задачи (1.20) к равносильной системе уравнений, а также алгоритмы для ее решения были рассмотрены в [5], [14].  59    1.3. Вспомогательные утверждения  Две задачи на собственные значения  Рассмотрим связанные с (0.1) обобщенные задачи на собственные значения  A0 p ≡ BTA−1B p = t C p , (1.22) B0u ≡ BC−1BTu = ωAu , (1.23)  где t, ω — спектральные параметры, и проанализируем их решения. Имеет место  Теорема 1.3.1. Пусть det(Lε) 6= 0 для любого ε ≥ 0 . Тогда 1) все собственные значения задачи (1.22) положительны; 2) ненулевые собственные значения задачи (1.23) положи тельны и совпадают с учетом кратностей с собственными значениями задачи (1.22);  3) задача (1.23) имеет ровно Nu−Np ≥ 0 нулевых собственных значений;  4) каждому решению (ti, pi) задачи (1.22) можно поставить в соответствие единственное (с точностью до постоянного множителя) решение (ωi, ui) задачи (1.23) по следующему правилу  ti = ωi, pi = C −1BTui, i = 1, . . . , Np .  Доказательство. Из явного представления матрицы A0 = BTA−1B следует A0 = A  T 0 ≥ 0 . Напомним, что C = CT > 0 ,  поэтому [23] задача (1.22) имеет Np действительных собственных значений 0 ≤ t1 ≤ . . . ≤ tNp вместе с соответствующими C ортогональными собственными векторами p1, . . . , pNp .  Для доказательства первого утверждения обратимся к факторизации матрицы Lε следующего вида  Lε =  ( A 0 BT I  )( A−1 0 0 −(BTA−1B + εC)  )( A B 0 I  ) ,  где I – единичная матрица. Из условия теоремы сразу следует невырожденность матрицы A0 = B  TA−1B , т.е. ее положительная определенность. Следовательно, имеем ti > 0, i = 1, . . . , Np , и, кроме того, имеет место ограничение на размерности подсистем: Nu −Np ≥ 0 (в противном случае ker(B) не пусто).  60    Если ввести обозначения R = C−1BT , S = A−1B , то матрицы C−1A0 и A  −1B0 представимы в виде RS и S R соответственно. В терминах характеристического многочлена ΦT (λ) = det(λ I − T ) квадратной матрицы T это приводит к равенству  ΦA−1B0(λ) = λ Nu−NpΦC−1A0(λ)  на основании теоремы 1.3.20 из [27]. Поскольку собственные значения задачи (1.22) положительны, то отсюда следуют второе и третье утверждения теоремы.  Отметим теперь свойства решений задачи (1.23). Поскольку B0 = B  T 0 ≥ 0 , то задача (1.23) имеет Nu действительных соб ственных значений  0 = ω1 = . . . = ωNu−Np < ωNu−Np+1 ≤ . . . ≤ ωNu вместе с соответствующими A-ортогональными собственными векторами u1, . . . , uNu . Кроме того, векторы pi = C  −1BTui, i = 1, . . . , Nu , являются C -ортогональными. Действительно, в силу A-ортогональности системы векторов {ui}Nui=1 имеем при i 6= j :  0 = (uj , BC −1BTui) = (B  Tuj , C −1BTui) = (Cpj , pi) ,  где pi = C −1BTui , причем некоторые из них могут быть нулевы ми. Рассмотрим теперь некоторый вектор ui , соответствующий  ненулевому собственному значению ωi :  BC−1BT ui = ωiAui .  Применим к этому равенству последовательно операторы A−1 и BT , будем иметь  BTA−1BC−1BT ui = ωiB Tui .  Вводя обозначения ti = ωi, pi = C −1BT ui , можно переписать  последнее соотношение в виде  A0pi = ti C pi .  Учитывая, что ненулевые собственные значения задачи (1.23) совпадают с учетом кратностей с собственными значениями задачи (1.22) и преобразование C−1BT переводит A-ортогональные  61    векторы u в C -ортогональные векторы p , можем положить в последнем равенстве i = Nu − Np + 1, . . . , Nu , что и завершает доказательство последнего утверждения. Теорема доказана.  Из полученного результата следует существование такого отрезка [γ,Γ], γ > 0 , что спектры операторов C−1A0 и A  −1B0 принадлежат соответственно множествам  σ(C−1A0) ⊂ [γ,Γ], σ(A−1B0) ⊂ {0} ⋃  [γ,Γ],  причем без ограничения общности можно считать, что границы собственных значений совпадают с границами указанного отрезка. Подчеркнем важную роль этого вывода: в дальнейшем собственные значения всех интересующих нас матриц будут представлены в виде, зависящем от параметра t , где t ∈ [γ,Γ] (или [γ+ε,Γ+ε], ε ≥ 0), γ > 0 . Оценки спектральных радиусов операторов перехода и нормы разрешающих операторов также будут сформулированы в терминах границ этого отрезка.  Базис специального вида из собственных векторов  Пусть U и P — евклидовы пространства векторов размерностей Nu и Np соответственно. Поскольку в общем случае Nu ≥ Np , то удобно обозначить ker(A−1B0) за H (множество векторов размерности dim(H) = Nu −Np ). Заметим, что  H = {u ∈ U : BTu = 0} . Далее будем использовать разложение пространства U в прямую сумму — U = H ⊕G , где G есть обозначение ортогонального дополнения к H (в смысле скалярного произведения, порожденного матрицей A).  Разложим базис пространства U , состоящий из собственных векторов задачи (1.23), на два подмножества: базис пространства H и базис его ортогонального дополнения G , так что  {ui}Nui=1 = {hi} Nu−Np i=1  ⋃ {gi}Npi=1 .  Отметим, что каждую из подсистем векторов можно считать ортонормированной в метрике, порождаемой матрицей A , в силу B0 = B  T 0 , A = A  T > 0 . Аналогично будем считать C ортонормированными собственные векторы pi задачи (1.22) в силу A0 = A  T 0 > 0, C = C  T > 0 .  62    Введем в пространстве Z = U × P скалярное произведение  (z1, z2)Z = χ1(Au1, u2) + χ2(C p1, p2), zi = (ui, pi) ∈ Z, χi > 0, i = 1, 2,  и построим в нем базис специального вида, используя собственные векторы задач (1.22) и (1.23). Имеет место  Теорема 1.3.2. Система векторов {zi}Nu+Npi=1 следующего вида  z (1) i = (hi, 0), i = 1, . . . , Nu −Np ,  z (2,3) j = (gj , γ  (2,3) j pj), j = 1, . . . , Np ,  где pj = C −1BT gj , образует базис в пространстве Z , если при  фиксированном значении j конечные коэффициенты γ (2,3) j раз личны. Доказательство. Проверим сначала ортогональность в мет рике пространства Z таких векторов из множества {zi}Nu+Npi=1 , у которых первые компоненты различны. Действительно, при любых k, j векторы hk, gj принадлежат множеству {ui}Nui=1 собственных векторов задачи (1.23), для которых справедливо при n 6= k :  (Aun, uk) = 0 .  Для вторых компонент векторов zi — решений задачи (1.22) — при этом справедливо при n 6= k :  (Cpn, pk) = 0 .  Пусть теперь некоторый ненулевой вектор z = (u, p) ∈ Z ортогонален произвольному вектору из множества {zi}Nu+Npi=1 . Тогда, поскольку системы {hi}Nu−Npi=1 ,{gi}  Np i=1 и {pi}  Np i=1 являются бази сами в пространствах H , G и P соответственно, получаем, что он может иметь только следующий вид  u =  Np∑  i=1  c (1) i gi, p =  Np∑  i=1  c (2) i pi .  Но для каждого фиксированного gi имеется пара различных век торов z (2,3) i вида (gi, γ  (2,3) i pi) , откуда, предполагая наличие неко торого c (1) k (или c  (2) k , порознь или одновременно), не равного  63    нулю, получим после скалярного умножения z на z (2) k и z  (3) k  { c (1) k χ1(Agk, gk) + c  (2) k χ2(Cpk, pk) γ  (2) k = 0,  c (1) k χ1(Agk, gk) + c  (2) k χ2(Cpk, pk) γ  (3) k = 0.  Отличие от нуля определителя линейной системы (т.к. γ (2) k 6=  γ (3) k , gk, pk 6= 0) дает только тривиальное решение c  (1) k = c  (2) k =  0 , откуда и следует искомое утверждение. Теорема доказана. Это утверждение играет важную роль как для самого отыс кания собственых векторов операторов перехода в различных алгоритмах, так и для обоснования того факта, что предлагаемым способом находятся все собственные значения.  2. Модифицированные методы релаксации для системы типа Стокса  2.1. Модифицированный метод Якоби (MJOR)  Модифицированный экстраполированный метод Якоби (метод MJOR) для алгебраической системы типа Стокса имеет следующий вид:      A uk+1 − uk  τ + Auk + B pk = f,  −C α p k+1 − pk  τ + BT uk = g.  (2.1)  Здесь и далее верхний индекс обозначает номер итерации, τ, α — вещественные положительные итерационные параметры.  Построение метода  Пусть вектор z = (u, p) является решением невырожденной алгебраической системы типа Стокса L0z = F :  { Au +B p = f,  BT u = g.  64    Рассмотрим систему Lεz = F̃ , равносильную исходной и полученную с помощью параметра ε ≥ 0 и матрицы C = CT > 0 ,  { Au + B p = f,  BT u − εC p = g̃ ,  где g̃ = g − εC p . Запишем для нее модифицированный, т.е. с двумя итерационными параметрами ω1, ω2 , экстраполированный метод Якоби      A uk+1 − uk  ω1 + Auk + B pk = f,  −εC p k+1 − pk ω2  + BT uk− εC pk = g̃.  Положим далее ω2 = εω̃2 и перейдем к пределу при ε → 0 . В результате будем иметь      A uk+1 − uk  ω1 + Auk + B pk = f,  −C p k+1 − pk ω̃2  + BT uk = g.  Отсюда после формального переобозначения параметров  ω1 −→ τ, ω̃2 −→ τ/α  и следуют искомые соотношения (2.1).  Спектр оператора перехода  Обозначим через T оператор перехода в алгоритме (2.1) и рассмотрим спектральную задачу T z = λ z :  T z ≡ (  (1− τ) I − τA−1B τ  α C−1BT I  )( u p  ) = λ  ( u p  ) . (2.2)  Имеет место Теорема 2.1.1. Спектр σ(T ) оператора перехода T в мето де (2.1) принадлежит множеству Λ  Λ = {1− τ} ⋃{  1− τ 2 ± τ  2  √ 1− 4t/α, t ∈ [γ,Γ]  } .  65    Доказательство. Воспользуемся базисом пространства Z , построенным в теореме 1.3.2. Вначале для векторов вида  z (1) i = (hi, 0), i = 1, . . . , Nu −Np,  непосредственной подстановкой убедимся, что каждый из них  удовлетворяет соотношениям (2.2) с λ (1) i = 1−τ . Оставшиеся соб ственные векторы будем искать в виде zj = (gj ,−δ−1C−1BT gj) . После применения к первому уравнению (2.2) оператора C−1BT  и замены C−1BT gj = pj получим  { (1− τ) pj + τδ−1 C−1A0pj = λ pj ,  − τ α pj + δ  −1 pj = λ δ −1 pj .  Перепишем полученную систему в виде      A0 pj = δ(λ− 1 + τ)  τ C pj ,  pj  ( λ− 1 + δ τ  α  ) = 0.  Каждой собственной функции pj задачи A0p = t C p соответствует собственное значение tj , j = 1, . . . , Np . Зафиксировав его, из полученной системы для λ и δ имеем соотношения  tj = δ(λ− 1 + τ)  τ , λ− 1 + δ τ  α = 0 .  Исключая из этих уравнений δ , приходим к выражению  λ (2,3) j = 1−  τ  2 ± τ  2  √ 1− 4tj/α,  и, соответственно,  δ (2,3) j =  α  2  ( 1∓  √ 1− 4tj/α  ) .  Перейдем к обоснованию того факта, что указанным способом найдены все собственные значения задачи (2.2).  Рассмотрим вначале более простой случай — различных соб ственных значений λ (2,3) j при фиксированном j . Пусть парамет ры α и τ таковы, что выражение 1 − 4tj/α не обращается  66    в нуль ни при каком значении tj . Тогда величины δ (2) j и δ  (3) j  для любого j также будут различны, что следует из их явного представления. Это означает, что найденная система собственных  векторов {z1,2,3i } Nu+Np i=1 задачи (2.2) удовлетворяет теореме 1.3.2,  следовательно, все искомые собственные значения найдены. Обобщим доказательство на случай кратных собственных зна чений, т.е. обращения в нуль выражения 1 − 4tj/α при некотором tj . Сразу необходимо отметить, что при любых фиксированных α и τ таких различных значений tj существует не более одного, причем даже одинаковым значениям tj соответствуют различные C -ортогональные векторы pj . Пусть в рас сматриваемом случае λ (2) j = λ  (3) j = λj имеется только один соб ственный вектор z (2) j оператора T с первой компонентой gj .  Тогда для построения полной в Z системы векторов достаточно добавить к нему в пару корневой вектор высоты два следующего  вида z (3) j = (gj ,−pj (λj + τ)/tjτ ) , удовлетворяющий уравнению  (T − λjI)2z(3)j = 0 , и, очевидно, линейно независимый с соответствующим собственным. Теперь уточненная система собственных  векторов {z(1,2,3)i } Nu+Np i=1 удовлетворяет теореме 1.3.2.  Таким образом, полнота найденной системы векторов в пространстве Z , состоящей либо только из собственных векторов оператора T , либо с добавлением к ним корневых по указанной схеме, дает основание утверждать, что других собственных значений в задаче (2.2) , отличных от указанных, не существует. Это дает возможность сделать вывод о том, что σ(T ) – спектр оператора перехода T в методе (2.1) – может быть параметризован с помощью спектра оператора C−1A0 . Действительно, пусть σ(C−1A0) ∈ [γ,Γ] , тогда σ(T ) принадлежит множеству  Λ = {1− τ} ⋃{  1− τ 2 ± τ  2  √ 1− 4t/α, t ∈ [γ,Γ]  } .  Теорема доказана.  Необходимое и достаточное условие сходимости  Полученное представление спектра оператора перехода дает возможность выяснить условия сходимости метода (2.1). Основной результат о сходимости метода формулируется следующим образом.  67    Теорема 2.1.2. При любом α > 0 и произвольном начальном приближении z0 ∈ Z необходимым и достаточным условием сходимости метода (2.1) является выполнение неравенства  0 < τ < min (2, α/Γ) . (2.3)  Доказательство. Введем следующие обозначения для элементов множества Λ :  λ1 = 1− τ , λ2,3 = 1−  τ  2 ± τ  2  √ 1− 4t/α .  Знак “+” здесь и далее относится к λ2 . Достаточность. Отметим, что ограничение |λ1| < 1 дает  0 < τ < 2 . Рассмотрим теперь некоторую фиксированную точку t ∈ [γ,Γ] и выясним соотношение между параметрами τ и α , при котором |λ2,3| < 1 .  Проанализируем сначала случай различных вещественных значений λ2,3 ( 1 − 4t/α > 0) . Так как λ2 > λ3 , достаточно исследовать неравенства  −1 < λ3 < λ2 < 1 .  Условие λ2 < 1 выполнено всегда, так как √  1− 4t/α < 1 . Очевидные преобразования выражения λ3 > −1 приводят к неравенству  −τ2 t α < 2(2− τ) ,  которое также справедливо при любом 0 < τ < 2 . Таким образом, условие (3) гарантирует выполнение неравенства  max t |λ1,2,3| < 1  в случае различных вещественных λ . Рассмотрим далее случай комплексных (или кратных) зна чений λ при некотором t ∈ [γ,Γ] : 1 − 4t/α ≤ 0 . При этом |λ2,3|2 = 1 − τ + τ2t/α . Неравенство |λ2,3|2 < 1 в силу положительности параметра τ равносильно следующему: τ < α/t ,  68    откуда следует, что для нахождения комплексных и кратных значений λ ∈ Λ внутри единичного круга достаточно выполнения неравенства 0 < τ < α/Γ .  Завершение доказательства достаточности следует из объединения двух рассмотренных выше случаев.  Необходимость. Доказательство будем проводить от противного. Пусть условие (3) не выполнено. Возможны два варианта. В первом, при α/Γ ≥ 2 , положим τ = 2 , при этом |λ1| = 1 , и метод не будет сходиться при любом начальном приближении вида z0 = (u0, p0), u0 ∈ H .  Во втором варианте, при α/Γ < 2 , покажем, что даже для единственной точки отрезка [γ,Γ] , а именно, t = Γ , невыполнение (3) приводит к неравенству |λ2,3| ≥ 1 . Пусть  τ = α  Γ + ε1 < 2, 0 ≤ ε1 < 2−  α  Γ .  При этом λ2 и λ3 будут комплексно сопряженными, так как дискриминант — 1− 4Γ/α < −1 — отрицателен.  Далее рассмотрим изменение определяющей величины  |λ2,3|2 = 1− τ + τ2Γ/α  в зависимости от параметра ε1 :  |λ2,3|2 = 1 + ε1 + ε21 Γ  α ≥ (1 + ε1/2)2 + ε21/4 ,  поскольку α/Γ < 2 . Последнее неравенство приводит к условию  |λ2,3| ≥ 1 при 0 ≤ ε1 < 2− α  Γ .  Напомним, что t = Γ является собственным значением оператора C−1A0 и, следовательно, λ2,3 при t = Γ — собственным значением оператора T в (2.2) . Отсюда следует, что при невыполнении условия (3) существует собственный вектор оператора T , такой, что отвечающее ему одно из собственных значений λ2,3 по модулю не меньше единицы. С учетом этого замечания и теоремы о необходимом и достаточном условии сходимости метода простой итерации (см., например, [3]) получаем, что выполнение неравенства (3) является необходимым и достаточным для сходимости метода (2.1). Теорема доказана.  69    Задача асимптотической оптимизации  Обозначим погрешность решения на k -й итерации через yk = (vk, rk) = (uk − u, pk − p) , где (u, p) — точное решение задачи L0z = F , и выберем начальное приближение z  0 = (u0, p0) из условия  Au0 +B p0 = f (2.4)  (например, возьмем произвольный вектор p0 и положим u0 = A−1(f −B p0)). Для такого начального приближения имеем  v1 = v0 , (2.5)  r1 = ( I − τ  α C−1A0  ) r0 , (2.6)  и, кроме того, справедлива  Лемма 2.1.1. Для любой итерации k первая компонента vk  погрешности yk итерационного метода (2.1), стартующего с начального приближения вида (2.4), является элементом подпространства G (т.е. (Avk, h) = 0 для ∀h ∈ H ).  Доказательство. Из соотношения (2.4) следует, что начальная погрешность y0 = (v0, r0) удовлетворяет равенству  Av0 +B r0 = 0 ,  и, следовательно, v0 является элементом G . Действительно, для произвольного элемента h ∈ H справедливо BTh = 0 , поэтому  (Av0, h) = −(Br0, h) = −(r0, BTh) = 0 .  Далее покажем, что если vk ∈ G , то и vk+1 ∈ G . Компонента vk удовлетворяет соотношению  vk+1 = (1− τ)vk − τA−1Brk ,  поэтому для любого h ∈ H имеем  (Avk+1, h) = ( (1− τ)Avk − τBrk, h  ) = (1− τ)(Avk, h) .  Таким образом, индуктивный переход и начальное условие гарантируют, что для любой итерации k вектор vk ∈ G . Лемма доказана.  70    Из леммы 2.1.1 и теоремы 1.3.2 вытекает покомпонентное разложение погрешности следующего вида  vk =  Np∑  i=1  c (k) i gi, r  k =  Np∑  i=1  d (k) i pi .  Поэтому для определения асимптотически оптимальных параметров в методе (2.1), стартующим с начального приближения (2.4), достаточно рассмотреть следующую задачу: найти положительные значения τ0 и α0 , доставляющие минимум функции q :  q = max t∈[γ,Γ]  {∣∣∣1− τ/2± τ/2 √  1− 4t/α ∣∣∣ } . (2.7)  Имеет место Теорема 2.1.3. При выборе начального приближения, удо влетворяющего условию (2.4), спектральный радиус q0 оператора перехода и асимптотически оптимальные параметры τ0, α0 в итерационном методе (2.1) определяются по формулам  q0 =  √ 1− ξ 1 + ξ  , τ0 = 2, α0 = 2 (γ + Γ),  где ξ = γ/Γ . Доказательство. Рассмотрим вспомогательную задачу для  подкоренного выражения в (2.7) :  q̃ = min α  max t∈[γ,Γ]  |1− 4t/α| .  Ее решение ([3], стр.278) имеет вид  q̃ = q20 = 1− ξ 1 + ξ  , α0 = 2 (γ + Γ), ξ = γ/Γ .  Теперь на отрезке γ ≤ t ≤ (γ +Γ)/2 подкоренное выражение при α = α0 неотрицательно, и поэтому на нем задачу (2.7) можно переформулировать в виде  q1 = min τ  max s∈[−q0,q0]  ∣∣∣1− τ  2 + τ  2 s ∣∣∣ .  71    В силу линейности по τ решение этой подзадачи очевидно: q1 = q0, τ = 2 . Для завершения доказательства достаточно заметить, что на отрезке (γ + Γ)/2 ≤ t ≤ Γ величина  max s∈[−q0,q0]  ∣∣∣1− τ  2 + i  τ  2 s ∣∣∣  при τ = 2 не превосходит q0 . Теорема доказана.  2.2. Модифицированный метод SOR (MSOR)  Модифицированный метод SOR (метод MSOR) для алгебраической системы типа Стокса имеет следующий вид      A uk+1 − uk  τ + Auk + B pk = f,  −C α p k+1 − pk  τ + BT uk+1 = g.  (2.8)  Спектр оператора перехода  Обозначим через T оператор перехода в алгоритме (2.8) и рассмотрим спектральную задачу T z = λ z :  T z ≡ (  (1− τ) I − τA−1B τ(1− τ)  α C−1BT I − τ  2  α C−1A0  )( u p  ) = λ  ( u p  ) .  (2.9) Имеет место  Теорема 2.2.1. Спектр σ(T ) оператора перехода T в методе (2.8) принадлежит множеству  Λ = {1− τ} ⋃ {1− τθ ± τ  √ θ2 − t/α, θ = (1 + τt/α)/2, t ∈ [γ,Γ]} .  Доказательство. Воспользуемся базисом пространства Z , построенным в теореме 1.3.2. Вначале для векторов вида  z (1) i = (hi, 0), i = 1, . . . , Nu −Np  непосредственной подстановкой убедимся, что каждый из них  удовлетворяет соотношениям (2.9) с λ (1) i = 1−τ . Оставшиеся соб ственные векторы будем искать в виде zj = (gj ,−δ−1C−1BT gj) .  72    После применения к первому уравнению (2.9) оператора C−1BT  и замены C−1BT gj = pj получим      (1− τ) pj + τδ−1 C−1A0pj = λ pj , τ(τ − 1)  α pj + δ  −1  ( I − τ  2  α C−1A0  ) pj = λ δ  −1 pj .  Перепишем полученную систему в виде     A0 pj = δ(λ− 1 + τ)  τ C pj ,  A0 pj = α(1− λ)− δτ(1− τ)  τ2 C pj .  Каждой собственной функции pj задачи A0p = t C p соответствует собственное значение tj , j = 1, . . . , Np . Зафиксировав его, из полученной системы для λ и γ имеем соотношения  tj = δ(λ− 1 + τ)  τ = α(1− λ)− δτ(1− τ)  τ2 .  Исключая из этих уравнений δ , приходим к выражению  λ (2,3) j = 1− τθj ± τ  √ θ2j − tj/α ,  где θj = (1 + tj τ/α)/2, и, соответственно,  δ (2,3) j =  α  λ 2,3 j  ( θj ∓  √ θ2j − tj/α  ) .  Перейдем к обоснованию того факта, что указанным способом найдены все собственные значения задачи (2.9).  Рассмотрим вначале более простой случай — различных соб ственных значений λ (2,3) j при фиксированном j . Пусть парамет ры α и τ таковы, что выражение θ2j − tj/α не обращается в нуль ни при каком значении tj . Тогда величины δ  (2) j и δ  (3) j  для любого j также будут различны, что следует из их явного представления. Это означает, что найденная система собственных  векторов {z1,2,3i } Nu+Np i=1 задачи (2.9) удовлетворяет теореме 1.3.2,  следовательно, все искомые собственные значения найдены. Обобщим доказательство на случай кратных собственных зна чений, т.е. обращения в нуль выражения θ2j−tj/α при некоторых  73    tj . Сразу необходимо отметить, что при любых фиксированных α и τ таких различных значений tj – не более двух, причем даже одинаковым tj соответствуют различные pj . Пусть в рассматри ваемом случае λ (2) j = λ  (3) j = λj имеется только один собствен ный вектор z (2) j оператора T с первой компонентой gj . Тогда  для построения полной в Z системы функций достаточно доба вить к нему в пару корневой вектор z (3) j высоты два следующего  вида z (3) j = (gj ,−pj (λj + τ)/tjτ ), удовлетворяющий уравнению  (T − λjI)2z(3)j = 0 , и, очевидно, линейно независимый с соответствующим собственным. Теперь уточненная система собственных  векторов {z(1,2,3)i } Nu+Np i=1 удовлетворяет теореме 1.3.2.  Таким образом, полнота найденной системы векторов в пространстве Z , состоящей либо только из собственных векторов оператора T , либо с добавлением к ним корневых по указанной схеме, дает основание утверждать, что других собственных значений в задаче (2.9), отличных от указанных, не существует. Это дает возможность сделать вывод о том, что σ(T ) – спектр оператора перехода T в методе (2.8) – может быть параметризован с помощью спектра оператора C−1A0 . Действительно, пусть σ(C−1A0) ∈ [γ,Γ] , тогда σ(T ) принадлежит множеству  Λ = {1− τ} ⋃ {1− τθ ± τ  √ θ2 − t/α, θ = (1 + τt/α)/2, t ∈ [γ,Γ]} .  Теорема доказана.  Необходимое и достаточное условие сходимости  Найденное представление дает возможность выяснить условия сходимости метода (2.8). Основной результат о сходимости метода формулируется следующим образом.  Теорема 2.2.2. При любом α > 0 и произвольном начальном приближении z0 ∈ Z необходимым и достаточным условием сходимости метода (2.8) является выполнение неравенства  0 < τ < √ α2/Γ2 + 4α/Γ− α/Γ . (2.10)  74    Доказательство. Введем следующие обозначения для элементов множества Λ :  λ1 = 1− τ, λ2,3 = 1− τθ ± τ  √ θ2 − t/α.  Знак “+” здесь и далее относится к λ2 . Достаточность. Рассмотрим некоторую фиксированную точ ку t ∈ [γ,Γ] и выясним соотношение между параметрами τ и α , при котором |λ2,3| < 1 .  Проанализируем сначала случай различных вещественных значений λ2,3 ( θ  2 − t/α > 0) . Так как λ2 > λ3 , достаточно исследовать неравенства  −1 < λ3 < λ2 < 1.  Условие λ2 < 1 выполнено всегда, так как √ θ2 − t/α < θ. Оче видные преобразования неравенства λ3 > −1 приводят к выражению  0 < τ < √ α2/t2 + 4α/t− α/t ,  из монотонности по t правой части которого следует неравенство (2.10).  Ограничение |λ1| < 1 дает 0 < τ < 2 . Поскольку правая часть (2.10) монотонно возрастает по α и ограничена величиной 2, получим, что условие (2.10) гарантирует выполнение неравенства  max t |λ1,2,3| < 1  в случае различных вещественных λ . Рассмотрим далее случай комплексных (или кратных) зна чений λ при некотором t ∈ [γ,Γ] : θ2 − t/α ≤ 0 . При этом |λ2,3|2 = 1− τ, откуда в силу положительности параметра τ следует, что комплексные и кратные значения λ ∈ Λ всегда лежат внутри единичного круга.  Завершение доказательства достаточности следует из объединения двух рассмотренных выше случаев.  Необходимость. Доказательство проведем от противного. Покажем, что даже для единственной точки отрезка [γ,Γ] , а именно, t = Γ , невыполнение (2.10) приводит к неравенству |λ3| ≥ 1 . Пусть  τ = √ α2/Γ2 + 4α/Γ− α/Γ + ε1α/Γ, ε1 ≥ 0.  75    При этом λ2 и λ3 будут вещественны, так как дискриминант — θ2 − Γ/α > 1/4 — положителен для любого ε1 ≥ 0 . Далее рассмотрим изменение определяющей величины  λ3 = 1− τθ − τ √ θ2 − Γ/α  в зависимости от параметра θ :  ∂λ3 ∂θ  = −τ ( 1 +  θ√ θ2 − Γ/α  ) < 0.  В свою очередь, ∂θ/∂ε1 > 0 , и при ε1 = 0 имеем λ3 = −1 . Последние два неравенства для производных приводят к условию λ3 ≤ −1 при ε1 ≥ 0 .  Напомним, что t = Γ является собственным значением оператора C−1A0 и, следовательно, λ3 при t = Γ — оператора T в (2.9). Отсюда следует, что при невыполнении условия (2.10) существует собственный вектор оператора T , такой, что отвечающее ему собственное значение λ3 по модулю не меньше единицы. С учетом этого замечания и теоремы о необходимом и достаточном условии сходимости метода простой итерации (см., например, [3]) получаем, что выполнение неравенства (2.10) является необходимым и достаточным для сходимости метода (2.8). Теорема доказана.  Задача асимптотической оптимизации  Для определения асимптотически оптимальных параметров в методе (2.8) рассмотрим следующую задачу: найти положительные значения τ0 и α0 , доставляющие минимум функции q :  q = max t∈[γ,Γ]  { |1− τ |,  ∣∣∣1− τθ ± τ √ θ2 − t/α  ∣∣∣ } , (2.11)  где, как и ранее, θ = (1 + τt/α)/2 . Задачу асимптотической оптимизации метода (2.8) решает  Теорема 2.2.3. Спектральный радиус q0 оператора перехода T и асимптотически оптимальные параметры τ0, α0 в итерационном методе (2.8) определяются по формулам  q0 = 1− √ ξ  1 + √ ξ , τ0 =  4 √ ξ  (1 + √ ξ)2  , α0 = 4γ  (1 + √ ξ)2  ,  76    где ξ = γ/Γ . Доказательство. Рассмотрим выражение для q . Второй ар гумент в процедуре max — это корни следующего уравнения:  λ2 − λ(2− τ − τ2t/α) + 1− τ = 0. (2.12)  Пусть 0 < τ < 1 . Тогда максимальный по модулю корень уравнения (2.12), очевидно, удовлетворяет оценке  |λmax| ≥ √ 1− τ ,  причем равенство достигается в случае комплексных или кратных корней. Изучим подробнее этот предельный случай неположительного дискриминанта (2.12) для всех t ∈ [γ,Γ] —  θ2 − t/α ≤ 0.  Преобразования последнего неравенства приводят к выражению  τ ≤ min{2 √ α/Γ− α/Γ, 2  √ α/γ − α/γ} ,  откуда максимально возможное значение τ достигается при  α0 = 4γ  (1 + √ ξ)2  и равно  τ0 = 4 √ ξ  (1 + √ ξ)2  .  При этом все корни уравнения (2.12) лежат на окружности:  |λ | = q0 = 1− √ ξ  1 + √ ξ .  Неулучшаемость полученной оценки при 0 < τ < 1 следует из наличия двух двухкратных вещественных корней и непрерывности корней многочлена в зависимости от коэффициентов. Действительно, при τ > τ0 немедленно получаем |λmax | > q0 , причем максимум достигается на одном из вещественных корней.  Рассмотрим далее значение τ = 1 . Максимальный по модулю корень (2.12) имеет вид λ = 1−t/α , и решение следующей задачи (см. [3])  q1 = min α  max t∈[γ,Γ]  |1− t/α| = 1− ξ 1 + ξ  ,  77    очевидно, для любых γ < Γ больше, чем q0 . Осталось рассмотреть интервал τ ∈ (1, 2) , поскольку ограни чение τ < 2 следует из явного вида первого аргумента в процедуре max в (2.11). В этом случае при любых положительных α и τ корни (2.12) вещественны и имеют различные знаки, что дает возможность записать (2.11) в следующем виде  q2 = max t {τ − 1, τ  √ θ2 − t/α+ 1− τθ, τ  √ θ2 − t/α+ τθ − 1}  = max t {τ − 1, τ  √ θ2 − t/α+ |1− τθ|} .  Теперь приведем цепочку неравенств  min α q2 ≥ min  α max t {τ − 1, τ  √ θ2 − t/α+ |1− τθ|} >  (в первом слагаемом под знаком радикала учтем, что τ > 0)  min α  max t  { τ  2  ∣∣∣∣1− t  α  ∣∣∣∣+ ∣∣∣∣1−  τ  2 − τ  2  2α t  ∣∣∣∣ }  =  (во втором слагаемом вынесем положительный множитель за знак модуля)  min α  max t  { τ  2  ∣∣∣∣1− t  α  ∣∣∣∣+ ( 1− τ  2  ) ∣∣∣∣1− t  α  τ2  2(1− τ/2)  ∣∣∣∣ } ≥  (расширим область минимизации, введя во втором слагаемом вместо α параметр κ)  min α,κ  max t  { τ  2  ∣∣∣∣1− t  α  ∣∣∣∣+ ( 1− τ  2  ) ∣∣∣∣1− t  κ  τ2  2(1− τ/2)  ∣∣∣∣ }  =  min α  max t  { τ  2  ∣∣∣∣1− t  α  ∣∣∣∣ } +min  κ max t  {( 1− τ  2  ) ∣∣∣∣1− t  κ  τ2  2(1− τ/2)  ∣∣∣∣ }  =  τ  2  1− ξ 1 + ξ  + ( 1− τ  2  ) 1− ξ 1 + ξ  = 1− ξ 1 + ξ  .  Таким образом, при τ ∈ (1, 2) имеем q2 > q1 . Теорема доказана.  78    3. Оценки погрешности методов MJOR и MSOR  Обозначим погрешность решения на k -й итерации через yk = (vk, rk) = (uk − u, pk − p) , где (u, p) — точное решение задачи L0z = F , введем операторы Du = D  T u > 0 и Dp = D  T p > 0 , такие,  что  DuA −1B0 = (DuA  −1B0) T , DpC  −1A0 = (DpC −1A0)  T ,  и определим норму погрешности в пространстве Z как  ‖y‖2D = (Duv, v) + (Dpr, r), y = (v, r) ∈ Z .  3.1. Оценки погрешности из общей теории итерационных методов  Напомним формулы и оценки погрешностей из общей теории итерационных методов решения линейных систем с симметричными положительно определенными матрицами  Au = f , A = AT > 0 . (3.1)  Рассмотрим следующие обобщенные алгоритмы: оптимальный одношаговый метод и трехслойный метод с постоянными параметрами. Приводимые данные цитируются по [24], носят вспомогательный характер и используются в следующих разделах.  Оптимальный одношаговый метод  Рассмотрим для решения задачи (3.1) обобщенный метод простой итерации  B uk+1 − uk  τ +Auk = f (3.2)  с симметричным положительно определенным (здесь и далее в настоящем разделе) оператором B : B = BT > 0 . Пусть оператор D = DT > 0 таков, что DB−1A = (DB−1A)T , и имеет место матричное неравенство  γ D ≤ DB−1A ≤ ΓD  79    с постоянными γ, Γ . Тогда при τ = 2/(γ + Γ) метод (3.2) называется оптимальным одношаговым методом, который сходится к решению u с оценкой погрешности  ‖uk − u‖D ≤ qk1 ‖u0 − u‖D, q1 = 1− ξ 1 + ξ  , ξ = γ  Γ . (3.3)  Стационарный трехслойный метод  Рассмотрим для решения задачи (3.1) трехслойный итерационный метод с постоянными параметрами α, τ  B uk+1 = α(B − τA)uk + (1− α)Buk−1 + ατf , Bu1 = (B − τA)u0 + τf , (3.4)  где  τ = 2  γ + Γ , α = 1 + q20 q0 =  1− √ ξ  1 + √ ξ , ξ =  γ  Γ . (3.5)  Такой алгоритм сходится к решению u с оценкой погрешности  ‖uk − u‖D ≤ qk0 ( 1 + k  1− q20 1 + q20  ) ‖u0 − u‖D (3.6)  и называется стационарным трехслойным методом.  3.2. Оценка погрешности для метода MJOR  Преобразование формул  Сначала из формул (2.1) выводятся раздельные трехслойные соотношения для компонент погрешности vk, rk . Имеет место  Лемма 3.2.1. Компоненты погрешности vk+1, rk+1 при k ≥ 1 удовлетворяют соотношениям  vk+1 = (2− τ)vk − [ (1− τ)I + τ2/αA−1B0  ] vk−1,  rk+1 = (2− τ)rk − [ (1− τ)I + τ2/αC−1A0  ] rk−1.  80    Доказательство. Запишем соотношения метода (2.1) для погрешности yk = (vk, rk)      A vk+1 − vk  τ + Avk + B rk = 0,  −C α r k+1 − rk  τ + BT vk = 0.  Отсюда имеем  vk+1 = (1− τ)vk − τA−1Brk, (3.7)  rk+1 = rk + τ/αC−1BT vk. (3.8)  Увеличим в выражении (3.8) индекс k на единицу и заменим в полученном — vk+1 c помощью соотношения (3.7). В результате получим  rk+2 = rk+1 − τ2/αC−1A0rk + τ/α(1− τ)C−1BT vk . (3.9)  Теперь выразим из (3.8) величину  τ/αC−1BT vk = rk+1 − rk  и подставим ее в (3.9):  rk+2 = (2− τ)rk+1 − [ (1− τ)I + τ2/αC−1A0  ] rk .  Искомое соотношение для второй компоненты погрешности получено. Аналогичным образом получается трехслойное соотношение и для первой. Увеличим в выражении (3.7) индекс k на единицу и заменим в полученном — rk+1 c помощью соотношения (3.8). В результате получим  vk+2 = (1− τ)vk+1 − τ2/αA−1B0vk − τA−1Brk (3.10)  Теперь выразим из (3.7) величину  −τA−1Brk = vk+1 − (1− τ)vk  и подставим ее в (3.10):  vk+2 = (2− τ)vk+1 − [ (1− τ)I + τ2/αA−1B0  ] vk .  81    Лемма доказана.  Начальное приближение  Выберем начальное приближение (u0, p0) из условия (2.4)  Au0 +B p0 = f .  Для такого начального приближения имеем  v1 = v0, (3.11)  r1 = ( I − τ  α C−1A0  ) r0 (3.12)  и, кроме того, справедлива (см. раздел 2.1)  Лемма 2.1.1. Для любой итерации k первая компонента vk  погрешности yk итерационного метода (2.1), стартующего с начального приближения вида (2.4), является элементом подпространства G (т.е. (Avk, h) = 0 для ∀h ∈ H ).  Из леммы 2.1.1 и теоремы 1.3.2 вытекает покомпонентное разложение погрешности следующего вида  vk =  Np∑  i=1  c (k) i gi, r  k =  Np∑  i=1  d (k) i pi .  Оценка погрешности  Теорема 3.2.1. Метод (2.1) с асимптотически оптимальными параметрами τ0, α0 и спектральным радиусом операто ра перехода q0 =  √ 1− ξ 1 + ξ  , ξ = γ  Γ , стартующий с начального  приближения вида (2.4), сходится с оценкой погрешности при четных k  ‖yk‖D ≤ qk0 ‖y0‖D .  Доказательство. Пусть τ0, α0 — асимптотически оптимальные итерационные параметры, а q0 — соответствующий им спектральный радиус оператора перехода из теоремы 2.1.3. Напомним, что  τ0 = 2, α0 = 2 (γ + Γ).  82    Если ввести обозначение  τ̃ = 2  γ + Γ ,  то полученные трехслойные соотношения для погрешности метода (2.1) можно переписать в более удобном виде  vk+1 = (I − τ̃A−1B0)vk−1, (3.13)  rk+1 = (I − τ̃C−1A0)rk−1. (3.14) С помощью этих выражений можно оценить компоненты погрешности vk и rk порознь. Поскольку из теоремы 1.3.1 следует, что спектральный параметр t ∈ [γ,Γ] (область изменения собственных значений матриц A−1B0 и C  −1A0 ) в соотношениях (3.13), (3.14) одинаков, то в силу определения величины τ̃ имеем  ‖yk+2‖D ≤ q20‖yk‖D,  откуда и следует искомая оценка. Теорема доказана. Следует отметить, что при нечетных k оценка немного ухуд шается за счет выражения (3.11) (показатель степени уменьшается на единицу).  3.3. Оценка погрешности для метода MSOR с постоянными параметрами  Получим оценку погрешности yk = (vk, rk) метода MSOR с асимптотически оптимальными параметрами.  Преобразование формул  Сначала из формул (2.8) выводятся раздельные трехслойные соотношения для компонент погрешности vk, rk . Имеет место  Лемма 3.3.1. Компоненты погрешности vk+1, rk+1 при k ≥ 1 в области сходимости метода удовлетворяют соотношениям  vk+1 = α̃(I − τ̃A−1B0)vk + (1− α̃)vk−1 , (3.15)  rk+1 = α̃(I − τ̃C−1A0)rk + (1− α̃)rk−1 , (3.16)  83    где новые параметры определяются формулами  α̃ = 2− τ, τ̃ = τ 2  α(2− τ) .  Доказательство. Запишем соотношения метода (2.8) для погрешности yk = (vk, rk) :      A vk+1 − vk  τ + Avk + B rk = 0,  −C α r k+1 − rk  τ + BT vk+1 = 0,  откуда имеем vk+1 = (1− τ)vk − τA−1Brk, (3.17)  rk+1 = rk + τ/αC−1BT vk+1 = (I − τ2/αC−1A0)rk  +τ/α(1− τ)C−1BT vk. (3.18) Увеличим в выражении (3.18) индекс k на единицу  rk+2 = (I − τ2/αC−1A0)rk+1 + τ/α(1− τ)C−1BT vk+1, (3.19)  выразим из левого равенства (3.18) величину  τ/αC−1BT vk+1 = rk+1 − rk  и подставим ее в (3.19):  rk+2 = (2− τ)(I − τ 2  α(2− τ)C −1A0)r  k+1 + (1− (2− τ))rk .  Теперь после замены при 0 < τ < 2 (в области сходимости метода)  α̃ = 2− τ, τ̃ = τ 2  α(2− τ) искомое соотношение для второй компоненты погрешности получено. Аналогичным образом получается трехслойное соотношение и для первой. Увеличим в выражении (3.17) индекс k на единицу и заменим в полученном — rk+1 c помощью левой части соотношения (3.18). В результате получим  vk+2 =  ( 1− τ − τ  2  α A−1B0  ) vk+1 − τA−1Brk . (3.20)  84    Теперь выразим из (3.17) величину  −τA−1Brk = vk+1 − (1− τ)vk  и подставим ее в (3.20):  vk+2 = (2− τ) ( I − τ  2  α(2− τ)A −1B0  ) vk+1 + (1− (2− τ))vk .  Теперь после замены при 0 < τ < 2 (в области сходимости метода)  α̃ = 2− τ, τ̃ = τ 2  α(2− τ) искомое соотношение и для первой компоненты погрешности получено. Лемма доказана.  Начальное приближение  Выберем начальное приближение (u0, p0) из условия (2.4):  Au0 +B p0 = f .  Для такого начального приближения имеем  v1 = v0, (3.21)  r1 =  ( I − τ̃ 2− τ  τ C−1A0  ) r0, (3.22)  и, кроме того, справедлива  Лемма 3.3.2. Для любой итерации k первая компонента vk  погрешности yk итерационного метода (2.8), стартующего с начального приближения вида (2.4), является элементом подпространства G (т.е. (Avk, h) = 0 для ∀h ∈ H ).  Доказательство. Первая компонента vk погрешности решения в методе MSOR удовлетворяет точно такому же соотношению, что и в методе MJOR. Поэтому сформулированный результат следует из леммы 2.1.1. Лемма доказана.  Из леммы 3.3.2 и теоремы 1.3.2 вытекает покомпонентное разложение погрешности следующего вида  vk =  Np∑  i=1  c (k) i gi, r  k =  Np∑  i=1  d (k) i pi .  85    Полином ошибки  Положим в формулах для α̃, τ̃ асимптотически оптимальные значения α0, τ0 . Теперь для получения оценок каждой из компонент погрешности достаточно найти алгебраический полином Pk(t) , определяемый соотношениями  Pk+1(t) = α̃(1− τ̃ t)Pk(t) + (1− α̃)Pk−1(t), P1(t) = 1− κτ̃t, P0(t) = 1.  (3.23)  (параметр κ может принимать значения 0 или 2− τ0 τ0  ), и опре делить его норму  ‖Pk(t)‖ = max t∈[γ,Γ]  |Pk(t)| .  Для этого нам потребуются многочлены Чебышева первого Tk(x) и второго Uk(x) рода [24]. Имеет место  Лемма 3.3.3. Многочлен Pk(t) , определяемый соотношениями (3.23), имеет вид  Pk(t) = q k 0  {( 2− κq1  q0  ) Tk(x) +  ( κq1 q0 − 1 ) Uk(x) +  1− κ q0  Uk−1(x)  } ,  (3.24)  где x = 1− τ̃ t q1  ∈ [−1, 1], q1 = 1− ξ 1 + ξ  , q0 = 1− √ ξ  1 + √ ξ , ξ = γ/Γ .  Доказательство. Полагая t = 1− q1x  τ̃ , отобразим отрезок  [γ,Γ] на [−1, 1] . Тогда  Pk(t) = Qk(x), x ∈ [−1, 1].  Учитывая явные формулы для параметров α̃, τ̃ , получим рекуррентные соотношения для многочленов Qk(x) :  Qk+1(x) = 2 q0xQk(x)− q20Qk−1(x), Q1(x) = 1− κ+ κ q1x, Q0(x) = 1.  Отсюда при помощи замены Qk(x) = q k 0Rk(x) имеем  Rk+1(x) = 2xRk(x)−Rk−1(x), R1(x) =  1− κ q0  + κ q1 q0  x, R0(x) = 1 .  86    Полученному рекуррентному соотношению удовлетворяют многочлены Чебышева первого и второго рода, поэтому методом неопределенных коэффициентов несложно определить  Rk(x) =  ( 2− κq1  q0  ) Tk(x) +  ( κq1 q0 − 1 ) Uk(x) +  1− κ q0  Uk−1(x) ,  откуда и следует формула (3.24). Лемма доказана.  Оценка погрешности  Теорема 3.3.1. Метод (2.8) с асимптотически оптимальными параметрами τ0, α0 и спектральным радиусом оператора  перехода q0 = 1− √ ξ  1 + √ ξ , ξ =  γ  Γ , стартующий с начального при ближения вида (2.4), сходится с оценкой погрешности  ‖yk‖D ≤ qk0 (c1 + c2k) ‖y0‖D,  где постоянные c1 ≥ 1, c2 > 0 не зависят от номера итерации. Доказательство. Обозначим многочлен Pk(t) при κ = 0 за  P vk (t) , тогда из (3.15), (3.21) следует v k = P vk (A  −1B0)v 0, vk ∈ G и  (Duv k, vk) ≤ ‖P vk (t)‖2 (Duv0, v0) .  Оценим величину ‖P vk (t)‖ . В данном случае из (3.24) имеем  P vk (t) = q k 0  { 2Tk(x)− Uk(x) +  1  q0 Uk−1(x)  } , x =  1− τ̃ t q1  ∈ [−1, 1] .  Поэтому  ‖P vk (t)‖ ≤ qk0 { 2‖Tk(x)‖+ ‖Uk(x)−  1  q0 Uk−1(x)‖  } .  Учитывая свойства многочленов Чебышева  max x∈[−1,1]  |Tk(x)| = 1, Uk(−x) = (−1)kUk(x), max  x∈[−1,1] |Uk(x)| = U(1) = k + 1 ,  из последнего неравенства получим  ‖P vk (t)‖ ≤ qk0 { 2 +  ( k + 1 +  1  q0 k  )} = qk0  { 3 + k  ( 1 +  1  q0  )} .  87    Аналогично введем обозначение P rk (t) для многочлена Pk(t)  при κ = 2− τ0 τ0  > 1 . Тогда из (3.16), (3.22) следует rk =  P rk (C −1A0)r  0 и  (Dpr k, rk) ≤ ‖P rk (t)‖2 (Dpr0, r0) .  Оценим величину ‖P rk (t)‖ . Проводя те же рассуждения, что и выше, получим  ‖P rk (t)‖ ≤ qk0 {∣∣∣∣2−  κq1 q0  ∣∣∣∣+ ( κq1 q0 − 1 )  (k + 1) + κ− 1 q0  k  } =  qk0  {∣∣∣∣2− κq1 q0  ∣∣∣∣+ κq1 q0 − 1 + k  ( κ(q1 + 1)− 1  q0 − 1 )}  .  Теперь, определяя постоянные c1, c2 как  c1 = max  { 3,  ∣∣∣∣2− κq1 q0  ∣∣∣∣+ κq1 q0 − 1 } ,  c2 = max  { 1 +  1  q0 , κ(q1 + 1)− 1  q0 − 1 } ,  несложно получить искомую оценку погрешности  ‖yk‖2D = (Duvk, vk) + (Dprk, rk) ≤ q2k0 (c1 + c2k)2‖y0‖2D .  Теорема доказана. Прокомментируем полученный результат. Из доказательства  теоремы 2.2.3 следует, что при оптимальных значениях итерационных параметров жорданова форма оператора перехода в методе (2.8) содержит клетки второго порядка, поэтому множитель qk0 (c1 + c2k) в полученной оценке является асимптотически правильным. Кроме того, в доказательстве теоремы 3.3.1 при получении оценок для норм многочленов P vk (t), P  r k (t) множители при  k определялись точно, а завышались только слагаемые нулевого порядка. Поэтому постоянная c2 , вообще говоря, неулучшаема.  Литература  [1] Аристов П.П. Об ускорении сходимости одного итерационного метода решения задачи Стокса// Известия вузов. Математика. – 1994. – No. 9. – С. 3–10.  88    [2] Бахвалов Н.С. Эффективный итерационный метод решения уравнений Ламе для почти несжимаемых сред и уравнений Стокса. // Доклады АН СССР. – 1991. – Т. 319. – No. 1. – С. 13-17.  [3] Бахвалов Н.С., Жидков Н.П., Кобельков Г.М. Численные методы. – М.: Наука, 1987.  [4] Бахвалов Н.С., Кобельков Г.М., Чижонков Е.В. Эффективные методы решения уравнений Навье-Стокса. Численное моделирование в аэрогидродинамике. – М.: Наука, 1986, С. 37–45.  [5] Бахвалов Н.С., Кобельков Г.М., Чижонков Е.В. Итерационный метод решения эллиптических задач со скоростью сходимости, не зависящей от разброса коэффициентов. – Препринт ОВМ АН СССР. – М., 1988, N. 190.  [6] Воеводин В.В., Кузнецов Ю.А. Матрицы и вычисления. – М.: Наука, 1984.  [7] Дьяконов Е.Г. Минимизация вычислительной работы. Асимптотически оптимальные алгоритмы для эллиптических задач. – М.: Наука, 1989.  [8] Дьяконов Е.Г. О некоторых классах седловых градиентных методов// Вычислительные процессы и системы. – М.,1987. – Вып.5. С. 101–115.  [9] Дьяконов Е.Г. О некоторых итерационных методах для нелинейных сеточных систем// Вычислительные процессы и системы. – М., 1991. – Вып.8. – С. 95–115.  [10] Исаков А.Б., Кобельков Г.М. К численному решению задачи о движении вязкой несжимаемой жидкости в кубической каверне. – М.: Препринт ОВМ АН СССР, 1987 – N 179.  [11] Кобельков Г.М. О численных методах решения уравнений Навье–Стокса в переменных скорость–давление// Вычислительные процессы и системы. – М., 1991. – Вып.8. – С. 204–236.  [12] Кобельков Г.М. О методах решения уравнений Навье – Стокса// Доклады АН СССР. – 1978. – Т. 243. – N 4. – С. 843-846.  89    [13] Кобельков Г.М. Решение задачи о стационарной свободной конвекции// Доклады АН СССР. – 1980. – Т. 255. – N 2. – С. 277-282.  [14] Кобельков Г.М. О решении эллиптических уравнений с сильно меняющимися коэффициентами. – Препринт ОВМ АН СССР. – М., 1987. – N 145.  [15] Ладыженская О.А. Математические вопросы динамики вязкой несжимаемой жидкости. – М.: Наука, 1970.  [16] Лойцянский Л.Г. Механика жидкости и газа. – М.: Наука, 1973.  [17] Марчук Г.И. Методы вычислительной математики. – М.: Наука, 1977.  [18] Математическая энциклопедия. – М.: Советская энциклопедия, 1984. – Т.3.  [19] Ольшанский М.А. Задача Стокса с модельными краевыми условиями// Матем. Сборник.– 1997. – Т. 188.– N 4.– C. 127– 144.  [20] Ольшанский М.А. Об одной задаче типа Стокса с параметром// ЖВМ и МФ. – 1996. – Т. 36. – N 2. – С. 75-86.  [21] Пальцев Б.В. О быстросходящихся итерационных методах с расщеплением граничных условий для многомерной системы типа Стокса. Периодические “течения” между параллельными стенками// Доклады Академии Наук. – 1992. – Т. 325. – N 5. – С. 926-931.  [22] Пальцев Б.В. Об условиях сходимости итерационных методов с полным расщеплением граничных условий для системы типа Стокса в шаре и шаровом слое// ЖВМ и МФ. – 1995. – Т. 35. – N 6. – С. 935-963.  [23] Парлетт Б. Симметричная проблема собственных значений. – М.: Мир, 1983.  [24] Самарский А.А., Николаев Е.С. Методы решения сеточных уравнений. – М.: Наука, 1978.  [25] Седов Л.И. Механика сплошной среды. – М.: Наука, 1973. – Т. 1.  90    [26] Темам Р. Уравнения Навье-Стокса. Теория и численный анализ. – М: Мир, 1981.  [27] Хорн Р., Джонсон Ч. Матричный анализ. – М.: Мир, 1989.  [28] Чижонков Е.В. О сходимости одного алгоритма для решения задачи Стокса// Вестник Моск. Ун-та, – Сер.15. Вычисл. матем. и киберн. – 1995. – N 2. – С. 12 – 17.  [29] Чижонков Е.В. К оптимизации алгоритмов решения задачи Стокса// Вестник Моск. Ун-та. – Сер. 1. Математика. Механика. – 1995. – No.6. – C. 93 – 96.  [30] Чижонков Е.В. К сходимости метода искусственной сжимаемости// Вестник Моск. Ун-та. – Сер. 1. – Математика. Механика.–1996. – N 2. – С. 13 – 20.  [31] Чижонков Е.В. О сходимости алгоритма Эрроу-Гурвица для алгебраической системы типа Стокса// Доклады Академии Наук. – 1998. – Т.361. – N5. – C. 1–3.  [32] Чижонков Е.В. О сходимости модифицированного метода SSOR для алгебраической системы типа Стокса// Численный анализ: методы и программы. – М.: Издательство Московского университета. – 1998. – С. 83-91.  [33] Чижонков Е.В. Некоторые результаты о сходимости алгоритма Эрроу – Гурвица для алгебраической системы типа Стокса// ЖВМ и МФ. – 1999. – Т. 39. – N 3. – С. 521-531.  [34] Шайдуров В.В. Многосеточные методы конечных элементов. – М.: Наука, 1989.  [35] Arrow K., Hurwicz L., Uzawa H. Studies in Nonlinear Programming. – Stanford, CA: Stanford University Press, 1958.  [36] Bakhvalov N.S. Solution of the Stokes nonstationary problems by the fictitious domain method// Russ. J. Numer. Anal. Math. Modelling. – 1995. – V.10. – No.3. – P. 163-172.  [37] Bank R.E., Welfert B.D., Yserentant H. A class of iterative methods for solving saddle point problems// Numer. Math. – 1990. – No 56. – P. 645–666.  [38] Bramble J.H., Pasciak J.E. A Preconditioning technique for indefinite systems resulting from mixed approximations of elliptic problems // Math. Comp. – 1988. – V.50. – No.181. – P. 1-17.  91    [39] Bramble J.H., Pasciak J.E., Vassilev A.T. Analysis of the inexact Uzawa algorithm for saddle point problems // SIAM. – Numer. Anal. – 1997. – V.33. – No.4. – P. 1072-1092.  [40] Bramble J.H., Pasciak J.E., Vassilev A.T. Inexact Uzawa algorithms for nonsymmetric saddle point problems // Math. Comp. – 1999 (to appear).  [41] Brezzi F., Fortin M. Mixed and Hybrid Finite Element Methods.– New York: Springer – Verlag, 1991.  [42] Cahouet J., Chabart J.P. Some fast 3D finite element solvers for the generalized Stokes problem// Int. J. Numer. Methods Fluid. – 1988. – V.8. – P. 869-895.  [43] Chizhonkov E.V. Application of the Cossera spectrum to the optimization of a method for solving the Stokes Problem // Russ. J. of Numer. Analysis and Math.Modelling. – 1994. – V.9. – N 3. – P. 191 – 199.  [44] Chizhonkov E.V. On Methods for Solving the Stokes Problem for a Weakly-Compressible and Incompressible Fluids. In “Advanced Mathematics: Computations and Applications” (Editors: A.S.Alekseev, N.S.Bakhvalov). – Proceedings of AMCA-95. NCC Publisher, Novosibirsk. – 1995. – P. 167 – 171.  [45] Crouzeix M. Etude d’une methode de linearisation. Resolution des equations de Stokes stationaries. Application aux equations des Navier-Stokes stationares. – Cahiere de l’IRIA. – 1974. – N 12. – P. 139–244.  [46] Elman H.C. Multigrid and Krylov subspaces methods for the discrete Stokes equations // Int. J. Numer. Methods Fluids. – 1996. – V.22. – P. 755-770.  [47] Elman H.C., Golub G.H. Inexact and preconditioned Uzawa algorithms for saddle point problems// SIAM J. Numer. Anal. – 1994. – V.31. – N.6. – P. 1645-1661.  [48] Elman H.C., Silvester D. Fast nonsymmetric iterations and preconditioning for Navier-Stokes Equations// SIAM J. Sci. Comput. – 1996. – V.17. – N.1. – P. 33-46.  [49] Girault V., Raviart P.A. Finite element methods for NavierStokes equations. – Springer, Berlin, 1986. – 375 p.  92    [50] Gunzburger M. Finite element methods for viscous incompressible flow: a guide to theory, practice and alghorithms. Academic Press, Boston, 1989.  [51] Hackbusch W. Mult-Grid Methods and Applications. Springer, Berlin, 1985.  [52] Kozhevnikov A. The basic boundary value problems of static elasticity theory and their Cosserat spectrum// Mathematische Zeitschrift. – 1993. – V.213. – P. 241-274.  [53] Langer U., Queck W. On the convergence factor of Uzawa’s algorithm// J. Comp. Appl. Math. – 1986. – V.15. – P. 191202.  [54] Ol’shanskii M.A. On numerical solution of nonstationary Stokes equations// Russ. J. Numer. Anal. Math. Modelling. – 1995. – V.10. – N 1.– P. 81-92.  [55] Queck W. The convergence factor of preconditioned algorithms of the Arrow-Hurwicz type// SIAM J. Numer. Anal. – 1989. – V.26.– No. 4. – P. 1016-1030.  [56] Valedinsky V.D., Chizhonkov E.V. Structure of Solution to Stokes Problem and Efficient Numerical Method// Sov. J. of Numer. Analysis and Math. Modelling. – 1990. – V.5. – N 4/5. – P. 419-423.  [57] Verfurth R. A combined conjugate gradient-multigrid algorithm for the numerical solution of the Stokes problem// IMA J. Numer. Anal. – 1984. – V.4. – P. 441-455.  [58] Wathen A., Silvester D. Fast iterative solution of stabilized Stokes systems. Part I: using simple diagonal preconditioners// SIAM J. Numer. Anal. 1993. – V.30. – No. 3. – P. 630-649.  [59] Wathen A., Silvester D. Fast iterative solution of stabilized Stokes systems. Part II: using general block preconditioners// SIAM J. Numer. Anal. – 1994. – V.31.– No. 5. – P. 1352-1367.  [60] Young D.M. Iterative Solution of Lager Linear Systems. – New York: Academic Press, 1971.  93   