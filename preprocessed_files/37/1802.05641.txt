the underlying connections between identifiability active subspaces and parameter space dimension reduction andrew f brouwer and marisa c eisenberg co corresponding brouweaf umich edu marisae umich edu department of epidemiology departments of complex systems and mathematics university of michigan ann arbor abstract the interactions between parameters model structure and outputs can determine what inferences predictions and control strategies are possible for a given system pa rameter space reduction and parameter estimation and more generally understand ing the shape of the information contained in models with observational structure are thus essential for many questions in mathematical modeling and uncertainty quantifi cation as such different disciplines have developed methods in parallel for approach ing the questions in their field many of these approaches including identifiability sloppiness and active subspaces use related ideas to address questions of parameter dimension reduction parameter estimation and robustness of inferences and quanti ties of interest in this paper we show that active subspace methods have intrinsic connections to methods from sensitivity analysis and identifiability and indeed that it is possible to frame each approach in a unified framework a particular form of the fisher infor mation matrix fim which we denote the sensitivity fim is fundamental to all three approaches active subspaces identifiability and sloppiness through a series of ex amples and case studies we illustrate the properties of the sensitivity fim in several contexts these initial examples show that the interplay between local and global and linear and non linear strongly impact the insights each approach can generate these observations underline that one s approach to parameter dimension reduction should be driven by the scientific question and also open the door to using tools from the other approaches to generate useful insights 1 ar x iv 1 80 2 05 64 1 v 1 m at h d s 1 5 f eb 2 01 8 introduction both parameter space dimension reduction and parameter identifiability are fundamen tally a pursuit of the underlying structure of a map from an input space to an output space this pursuit is an essential aspect of mathematical modeling where a model is the map of interest indeed different disciplines have developed methods in parallel for approaching dimension reduction each with their own emphasis depending on the important questions of the parent field although much dimension reduction work has been done in the con text of dynamical systems many of the concepts and techniques apply to a wide range of models identifiability which emphasizes questions of parameter estimation i e which parameters or parameter combinations can be uniquely determined from observed data primarily grew out of statistics and engineering starting in the 1940 s and 50 s with applications particularly focused in pharmacokinetics 22 32 33 48 since then periods of renewed and more generalized interest have followed in the 70 s and after 2000 particularly with advent of the differential algebra method for identifiability of dynamical systems 2 6 15 19 29 31 35 38 40 45 47 50 52 these methods often include parameter reduction approaches often by either combining or fixing estimated parameters to ensure model identifiability more recently in the early 2000 s the concept of model sloppiness was developed by re searchers investigating dynamical systems in biology and physics with the goal of devel oping reduced models with nearly the same dynamical properties by using differential ge ometry methods like the manifold boundary approximation method mbam 9 24 56 60 sloppiness concepts and techniques are closely related to the parameter reduction approaches seen in the identifiability literature and seek to identify sloppy insensitive and stiff sensitive directions in parameter space moreover the reduced models identi fied by the methods should be able to generate the same overall input output behavior as the original i e given the same inputs it generates the same outputs thereby seeming to indicate that the original model was unidentifiable and potentially that the reduced model is identifiable or closer to it these connections have been explored in several pa pers which have shown that while connections to identifiability may not be one to one sloppiness is a closely related concept 13 18 active subspaces is a relatively new approach that came out of uncertainty quantification and that seeks to reduce the number of parameters needed to approximate a quantity 2 of interest particularly in the case of large models 16 54 larger models often exhibit challenges that may make more standard identifiability and sloppiness approaches difficult to implement particularly when running the model is computationally intensive similar to both identifiability and sloppiness active subspaces methods focus on understanding input output relationships how the model output changes as a function of its inputs or parameters and on developing reduced models which generate a similar input output structure as the original model in the case of active subspaces these ideas are framed around the idea of active sensitive directions in parameter space versus inactive in sensitive directions in parameter space the inactive directions would seem to naturally correspond to compensation between parameters potentially in an identifiable combina tion while active directions might correspond to changing the value of the identifiable combination itself in this paper we will examine this potential connection further each of these methods has close connections to ideas of parameter sensitivities which will form the basis of the links we will draw out in this paper indeed some links along these lines have been drawn out in varying levels of detail for all three methods 16 29 31 57 unidentifiability sloppiness and inactive directions in parameter space are each manifes tations of insensitivity of the model output to changes along some direction in parameter space sensitivity analysis methods often focus on determining which individual param eters are sensitive or insensitive but the generalization of this idea to a multi parameter case can lead one to any of the three approaches mentioned here for more comprehensive reviews of these approaches to dimension reduction and tech niques popular in each field we refer the reader to 12 16 20 24 43 57 here we examine some of the underlying connections between identifiability and parameter reduc tion methods in particular focusing on active subspaces and sloppiness we show that some of the main objects and concepts in active subspaces and other parameter space reduction approaches can be framed in terms of a commonly used form of the fisher infor mation matrix which we will term the sensitivity fisher information matrix sfim while much of the material we present is a review or reframing of existing approaches we hope that the translation dictionary developed here will facilitate cross talk between these sim ilar approaches finally we illustrate how these concepts and approaches may interact in practice with a series of examples and case studies 3 framework and notation we begin by setting up the framework and notation we will use throughout we will consider primarily either algebraic equations or ordinary differential equations odes of the form x w x t y v x 1 where t is time w and v are functions and represents the vector of parameters which may in some cases include initial conditions input variables or other quantities affecting the model behavior here x is the unobserved state variable vector and y represents the measured observed outputs or quantities of interest in many cases one might also have known inputs or forcing functions which drive the model and be included in f these would typically be denoted u for non differential algebraic models we will also use the same notation of state variables x observed variables y and parameters more generally our notation will follow the following conventions parameters input variables initial conditions or other varied quantities these are often denoted x in the active subspace literature 16 and p or in the identifiability literature here n is the length of the parameter vector 1 n x model state variables unobserved a vector q y model output observed or quantity or quantities of interest qoi a qoi can often be viewed as the output of the model and is a function of x and potentially time or other independent variables in the active subspace literature this is typically viewed as a scalar 16 and is denoted q in the identifiability and parameter estimation literature the qoi might be a scalar in the form of the likelihood or sum of squares or potentially a vector of model measurements or an observed trajectory of some function of the model variables e g one of the variables scaled by a constant if the qoi is a vector of measurements or an observed trajectory it would more typically be denoted y in the identifiability literature we will thus use q to represent a scalar qoi and y to represent a vector or continuous qoi f model map from the model parameters to the model output q or y f rn rm for scalar q m 1 in an identifiability context f is the model map used when evaluating injectivity which the input output equations represent implicitly described further in the next section 4 concepts in identifiability and parameter space reduction a model parameter is said to be identifiable if it can be uniquely determined from the model output and a model is identifiable if all of its parameters are identifiable if a parameter is not identifiable then the model output is either insensitive to that parameter or the parameter is part of an identifiable parameter combination meaning that while the value of the parameter itself is not fixed by the model output some function of it and other parameters is for example in the model y m 1 m 2 x b with x y pairs as the observed model output parameter b is identifiable and while parameters m 1 and m 2 are individually unidentifiable the sum m 1 m 2 is an identifiable parameter combination a common distinction in examining identifiability is between structural versus practical identifiability structural identifiability focuses purely on identifiability issues inherent to the model structure such as in the linear example described above while practical iden tifiability considers the estimation issues that come with real data such as error number or timing of samples taken etc in some cases these two categories are denoted iden tifiability and estimability in the ode case structural identifiability is often framed as a best case scenario wherein the data are assumed to be known completely i e smooth noise free and continuously sampled although one can also consider structural identi fiability when particular measurement times are specified structural identifiability of a model is a necessary condition but not sufficient condition for parameter estimation with real world data 15 since failure to recover parameters in the ideal case implies failure in the imperfect i e real world data case as well more formally we can define structural identifiability as follows definition 1 an individual parameter i in eq 1 is globally also termed uniquely structurally identifiable if for almost all values i and initial conditions the observation of an output y y uniquely determines the parameter value i i i i e if only one value of i could have resulted in the observed output similarly a parameter i is said to be locally also termed non uniquely structurally identifiable if there are a finite number of parameter values which can generate the observed output similarly a model is said to be globally respectively locally structurally identifiable if ev ery parameter is globally at least locally structurally identifiable in subsequent sections structurally identifiable will be understood to mean globally structurally identifiable unless otherwise indicated if a model is not structurally identifiable it is unidentifiable and there exists a set of identifiable combinations of parameters that represents the para metric information available in the data except in degenerate cases where the model is 5 reducible or has insensitive parameters 15 such a set is not unique any set of combi nations that generates the same field is an equivalent set of identifiable combinations e g 1 2 3 2 and 1 2 1 3 are equivalent sets of identifiable parameter combinations many different analytical approaches to structural identifiability have been developed 11 12 15 43 45 61 however analytical methods for identifiability can be compu tationally intensive making applications beyond relatively simple models challenging 12 45 52 61 of these techniques differential algebra has gained significant traction and has been the source of a range of recent advances the field of identifiability 5 7 25 26 36 37 41 42 53 by contrast while most numerical approaches to identifiability pro vide only local rather than global information about the parameters they are often more computationally tractable 27 many of these methods can be used to address both struc tural and practical identifiability often by using simulated data either without noise or with a range of different noise assumptions depending on whether structural or practical identifiability is considered 19 46 both structural and practical identifiability are often used in to inform parameter space reduction one simplistic approach is to fix the values of individual parameters until the identifiable parameter combinations uniquely determine the remaining parameters e g in the example with identifiable combinations 1 2 and 1 3 fixing 1 1 would allow 2 and 3 to be uniquely determined from the identifiable parameters another more elegant approach is to restructure and reparameterize the model in terms of its identifiable combi nations yielding an identifiable form of the model 8 11 in the structural identifiability case this is often termed a identifiable reparameterization for example a simple identi fiable reparameterization would be to take the y m 1 m 2 x b example above and define m m 1 m 2 so that our model is now the identifiable equation y mx b with two parameters identifiable from x y data m and b an example of a practical parameter reduction is the linear approximation of a hill function 28 where y v x x k if all x y data is in the region where x k then this model becomes practically unidentifiable and can be approximated by the identifiable linear model y mx where m v k these ex amples are extremely simple compared to most models used in practice but they illustrate the concepts parameter space dimension reduction based on structural identifiability takes advantage of the inherent structure of the model by reparameterizing only in terms of the structurally identifiable parameter combinations the dimension of the parameter space is reduced but no information is lost viewing the model as a map from parameter space to output space we can consider the fibers of this map i e the sets of all input values that correspond to 6 each output value or trajectory if the fibers contain only one or finitely many elements i e only one or finitely many parameter values can generate a given output then the model is identifiable or equivalently cannot be structurally reduced in dimension how ever if the fibers contain infinitely many elements the model is unidentifiable or put in a dimension reduction framework these fibers represent opportunities for dimension reduction as they all yield the same output the dimension reduction process can then be viewed as collapsing taking a set of representatives of the equivalence classes generated by the model map from parameters to output these reduced dimension models would be termed identifiable reparameterizations of the model in an identifiability context practical dimension reduction whether based on practical identifiability approaches or more general numerical approaches to the problem identifies lower dimensional models with output that is nearly indistinguishable but not necessarily equivalent to the output of the original higher dimensional model in the parameter estimation context this might occur because the collected data cannot distinguish for some level of significance be tween similar output trajectories associated with different parts of parameter space such problems can arise for example from excessive noise or measurement error or because of insufficiently generic measurement times for instance if one measures the value of a periodic function only once per period the amount of information in the data for a pe riodic model is limited of course this may be framed as a problem or an opportunity depending on the question at hand as for structural identifiability practical identifiability approaches to dimension reduction can find practically identifiable parameter combina tions although there may not exist reparameterizations of the original model in terms of these practical parameter combinations the scientific and philosophical implications of practical dimension reduction particularly in biological models have been a focus the sloppiness literature among others 60 63 practical dimension reduction is also used as in the active subspace literature to find computationally tractable approximations to to computationally intensive models the focus in this context is usually not on the scientific implications but rather on the effective outcomes dimension reduction depends not only the model but also on the output considered parameters that are identifiable for one kind of observed output may not be for another this observed output might be a single quantity of interest qoi as is typical in the active subspaces literature among the mathematical biology dynamical systems literature on the other hand the output is typically a trajectory measured over time if one observes a trajectory over time then each data point could be considered its own qoi alternatively one can aggregate the fit of the model output to all data points simultaneously in one cost 7 function as in the case of maximum likelihood estimation the dimension reduction tech niques will only identify parameter combinations that are common to all qois considered hence which qois to consider in one s analysis should be driven by one s question in a periodic model for example do you want to find the parameter space that closely matches the observed output or do you simply want to match the period and amplitude the sensitivity fisher information matrix next we introduce the sensitivity matrix formulation of the fisher information matrix fim which will underpin our development of the connections between parameter space reduction methods this formulation of the fim has useful identifiability properties 50 and has like sensitivity analysis more generally a long history of use in identifiability and parameter space reduction 3 4 10 14 15 29 31 49 50 64 definition 2 for a vector valued function f rn rm the sensitivity fisher information matrix sfim denoted f f is the symmetric n n matrix whose i j th element is given by fij f m k 1 fk i fk j 2 remark although f is often simply called the fisher information matrix in the literature we want to distinguish between this object and the expected fisher information matrix we compare and contrast these objects in a later section the entries of f are the sensitivity coefficients 17 54 of our quantity of interest f i e the partial derivatives of f with respect to each parameter sensitivity coefficients are the core objects of local sensitivity analysis and they link naturally to questions of param eter space reduction and identifiability if a parameter is insensitive it is practically or structurally unidentifiable and the model can be reduced note that the reverse is not true individual parameters may be highly sensitive but also unidentifiable for a univariate i e m 1 qoi q f as in the active subspaces literature f f can be conveniently written as f f f f t 3 8 where f is the column gradient vector of sensitivities f f 1 f n 4 for a multivariate qoi y f it is convenient to use the jacobian j f f 1 1 f 1 n fm 1 fm n 5 which is often called the sensitivity matrix in this context 15 and write f f t 6 remark depending on the context an analytic formula for f may or may not be available and so the derivatives are often calculated numerically constantine 16 discusses some practical considerations in gradient calculation remark we note that the forms given for and f assume a vector of discrete qois form ing y while many definitions of structural identifiability use the full trajectory of the model as the output or qoi i e with complete continuous temporal and or spatial information for the model in such cases we can typically approximate the full trajectory by taking very frequent samples as would be generated in most numerical solvers allowing us to numerically evaluate local structural identifiability alternatively we may also define the output as being measured at specific times to understand why f is an important object we first consider the linear approximation of the change in the output f as a function of the change in the parameters can be written as f 7 in the early identifiability literature f was said to be sensitivity identifiable if was locally recoverable from f 15 47 more generally it has been shown that the rank of or equivalently f is the number of locally identifiable combinations so that the model is locally identifiable when or f has full rank 17 30 31 50 here it is useful to think of as a map from rn to rm the nullspace of at any point in parameter space gives the linearization of the structures along which parameters can move without changing f indicating the identifiable combinations so characterizing the nullspace of 9 is one approach to the goal of dimension reduction alternatively we could characterize the coimage of that is the quotient space rn ker also called the orthogonal comple ment of the kernel or the row space in the language of linear algebra the rank of this space which is at most m is the number of identifiable parameter combinations and finding a basis for this space identifies the linearizations of the parameter combinations hence from the perspective of parameter reduction we hope that does not have full rank however from the perspective of parameter estimation we hope that it does in practice it is easier to work with the map f t which has the same nullspace and coimage as but also is square symmetric positive semi definite and if full rank invertible and positive definite as noted above if f has full rank at then we say that f is locally structurally identifiable at in many situations f is nearly rank deficient with one or more eigenvalues close to zero near rank deficiency is an indication of practical unidentifiability and an opportunity for practical dimension reduction the slop piness literature has called models sloppy when max min is large in this situation certain directions in parameter space corresponding the eigenvectors of the small eigenvalues do not greatly affect the value of f at least relative to the change along the directions of the eigenvectors of the large eigenvalues the notion of large vs small eigenvalues is ill defined which is a common complaint about the notion of sloppiness e g 13 the sensitivity fim f f is a local object as it depends on it can be full rank in some regions of parameter space but nearly rank deficient in others that is practical identifi able parameter combinations in one region might be resolved into individually identifiable parameters elsewhere for example when measuring the sum of two periodic functions the amplitudes of two functions may be difficult to distinguish if their periods are similar but easy to distinguish if their periods are very different the expected and sensitivity fims although we developed the sfim above in the parameter sensitivity context it is closely related to and can be viewed as a special case of a similar object encountered in the parameter estimation context namely the expected fisher information matrix in pa rameter estimation the fit of a model to the available data z is usually measured by a cost function often a statistical likelihood l z least squares fitting falls into this category since it is equivalent to maximum likelihood assuming gaussian measurement error in this context we do not consider the fit to each point individually but rather to all points 10 as a whole here we are interested in shape of information near some parameter vector typically the maximum likelihood estimate arg max l z arg min logl z 8 the expected fisher information matrix is an important information theoretic object asso ciated with a likelihood function l z and is given by i logl z logl z t l z dz ez logl z logl z t 9 because i is integrated over the data z it is dependent only on the parameters the sensitivity fim f logl is a special case of expected fim i when z has gaussian error with mean zero and variance one 15 given sufficient regularity the entries of i can be written iij ez 2 i j logl z 10 thus the negative hessian matrix of logl evaluated at the maximum likelihood estimate also called the observed information matrix is sometimes used to assess parameter sensitivity and identifiability 34 the underlying connection between active subspaces and the sensitivity fim with the sfim introduced we now present the main objects used in active subspaces framed around the sfim unlike the local sfim the active subspace approach is more interested in the behavior of a function over large regions of parameter space the active subspace approach thus integrates f over the parameter space with respect to some density on often uniform or gaussian to create a global object denoted c in 16 in our more general notation we can write c as c f f d 11 11 this matrix c then is average sensitivity fim over parameter space and is a global object unlike f which has rank at most m c is not similarly constrained and can have rank up to n active subspace analysis using c will capture unidentifiable parameters that are linear or nearly so over the whole space but will not find more non linear parameter combinations as we will see in the examples eigendecomposition of local and average sensitivity fims because local and average sensitivity fims f and c are symmetric real matrices they have orthogonal eigendecompositions q qt 12 the active subspace and sloppiness literatures have used the eigendecomposition of what we call the average and local sensitivity fims respectively to designate the directions spanned by eigenvectors corresponding to large eigenvalues as active stiff and those cor responding to zero or small eigenvalues as inactive sloppy one could also call these direc tions identifiable and unidentifiable whether practically or structurally so although we will use the active subspace notation here again the designation of eigenvalues as large or small has largely been relatively ad hoc and driven by the questions of the investigators denote qa as the matrix whose columns are the active eigenvectors of c and qi as the matrix whose columns are the inactive eiegenvectors then qa which is called the active variables in the active subspace literature are the linearized identifiable parameter combinations taking advantage of the decomposition 16 i qqt qaq t a qiq t i 13 one can approximate f as g f qaq t a f 14 though in practice creating a response surface approximation for f through regression on the active directions may be a more robust and less computationally intensive choice 16 if all identifiable combinations are linear then f and c will have the same eigenvectors if there are non linear identifiable combinations then the two matrices will have different eigenspaces and accordingly different approximations of f the approach one uses should be directed by the scientific question 12 the cost function as a link between scalar and vector qois both of the sensitivity fim objects f and c introduced thus far can be considered in either the scalar or vector case although researchers using active subspaces have reported difficulty or the need for further examination of using active subspace methods for vector valued qois 1 16 however the framing of c in terms of f suggests one possible option for a scalar summary qoi to be used when we are considering a relatively local analysis the cost function e g least squares or other norms and likelihood functions in the case of the local sfim f there is a natural link between the vector qoi where y is a vector of measurements and a cost function as the analogous scalar qoi as follows let fy be the sfim for a vector of measurements y and suppose we evaluate fy at a point then let us consider q m 1 y y 2 to be the least squares cost function using y as the data although we note a range of other cost functions would also work the qoi q is zero at and will remain roughly zero if we perturb in an insensitive inactive unidentifiable direction for y conversely it will increase as we move in a sensitive active identifiable direction for y thus when evaluated at fq should broadly be sensitive insensitive in the same similar directions as fy then if we are considering examining c using a vector qoi in a region around some nominal set of parameters the cost function or likelihood may provide a useful way to generate a scalar summary qoi although it does then tie one s qoi to a specific local area of parameter space a similar approach could also be applied if one is working in a parameter estimation context where the y might be replaced with the data set used for estimation visual tools for parameter space reduction there are several visual tools used to assess the parameter identifiability or opportunities for parameter space reduction parameter profile plots developed to assess identifiability is the gold standard for determining practical identifiability and is not based on the sfim sufficient summary plots on the other hand are used to visualize results of active subspace analysis and are thus based on the average sfim 13 parameter profiles the profile likelihood is a visual tool in assessing parameter identifiability 44 46 62 that we will generalize here as the parameter profile conceptually one tries to identify ridges and other structures in the response surface this approach profiles a single parameter i by fixing the value of i across a range of values and fitting all remaining parameters for each fixed value of i either to data or to a model trajectory the optimal cost function value at each value of i constitutes the likelihood profile for the fixed parameter the first step in profiling a parameter is to select a point in parameter space in some contexts this point will be the maximum likelihood estimate though this may be general ized for broader parameter reduction questions to simply be a set of nominal parameters around which we plan to profile then to profile a parameter i we fix i at a value i define j 6 i j j 6 i and c j 6 i f i j 6 i f 2 15 remark this definition of a cost function is useful for profiling parameters in the dimen sion reduction context in the parameter estimation context on the other hand the cost function will be an assessment of fit to the data typically a likelihood and this profile is called a profile likelihood the cost function c is a map rn 1 r 0 although we ve defined c here to correspond to minmization of the l 2 norm other metrics might be appropriate depending on the context let j 6 i argmin c j 6 i 16 that is in the dimension reduction context we are looking for the values of all parameters excluding i which is fixed at i that make the function as close as possible to f the plot of c j 6 i vs i is called a parameter profile the shape of this profile is informative as shown in figure 1 if the shape is concave i e trough shaped the parameter is practi cally identifiable if the profile is flat or flat on one side the parameter is at least practically and potentially structurally unidentifiable in the practical identifiability literature one defines a threshold value and a confidence interval for j i c j 6 i 17 14 figure 1 example profile likelihoods and parameter relationship contour plots for structural unidenti fiabilty practical unidentifiability and identifiability top row profile likelihoods solid line showing negative log likelihood ll or goodness of fit values dashed line shows a confidence interval thresh old e g for 95 confidence bounds which is infinite finite on one side or bounded respectively left to right bottom row corresponding parameter relationship plots to the top row contours indicate goodness of fit with the best fit value of p 2 parameter 2 for each fixed value of p 1 parameter 1 shown as a black line the structurally unidentifiable case illustrates a combination of the form p 1 p 2 the parameter is said to be practically identifiable if the confidence interval is finite 8 46 whether or not the parameter is practically identifiable can depend on the threshold chosen much like the designation of active or inactive subspaces depends on the eigenvalue cut off when the cost function is a relative negative log likelihood 2 is given by the chi squared distribution 2 1 n where is the level of significance 0 05 for 95 confidence intervals and n is the number of parameters 46 but the choice of in other contexts is more heuristic perhaps more useful in considering parameter space reduction often one uses plots of j 6 i vs i to identify the relationship between parameters in identifiable parameter combina tions 19 bottom row of figure 1 by examining how the estimates of the remaining parameters change as we profile a particular parameter j we can trace out the form of the identifiable combinations as developed in 46 for example if we have a combination 1 2 then when profiling 1 we would expect 2 to change in a compensatory way which preserves the sum 1 2 as this will preserve the value of identifiable combination at or fit to the data however as noted in 19 46 this approach is ill conditioned when there are multiple parameters in a combination or multiple combinations any extra degree of freedom in a combination allows the fitted parameters to compensate for one another and 15 avoid tracing out the form of the identifiable combination with the profiled parameter for example when profiling 1 if our combination is 1 2 3 then there are infinitely many ways that 2 and 3 can compensate to maintain the sum 1 2 3 and thus maintain the same fit to the data the resulting profiled parameter relationships are often noisy or arbitrary as there is a range of values for the unidentifiable parameters which will yield the same output in the profile these issues can be addressed by restricting the set of parameters used for profiling to maintain appropriate degrees of freedom such as using an sfim based approach 19 as well as other methods 27 ultimately one can plot the value of f against the identifiable parameter combinations when they are determined sufficient summary plots a related figure is the sufficient summary plot which is a plot of a single qoi versus one row of qta that is an informative linear combination of parameters input variables 16 this plot can be conceptualized as a rotation of a surface plot of the function q f to reveal a potentially lower dimensional structure by viewing it edge on in practice one may generate points by sampling from the parameter space e g latin hypercube sampling or using the density and computing q at each point 16 because each row of qta is a linearized identifiable combination the relationship between q t a and q should be nearly one dimensional a sufficient summary plot is typically used as validation tool to confirm that the active subspace adequately captures the desired variation in the data the sufficient summary plot can also be generalized to include multiple rows of qta by using 3 d plots or heatmaps in general if there is a sizable eigenvalue gap after the first eigenvalue one might expect a single row sufficient summary plot to capture a univariate trend while if the gap comes after the second eigenvalue a two row plot may be useful examples and case studies we illustrate the definitions and techniques with three simple analytic examples where we begin to explore the strengths and weaknesses of the local and global techniques for linear and non linear identifiable combinations then we consider two real world case studies to highlight the importance of tailoring the technique to the scientific question code for each of these examples and case studies is provided on github https github com epimath sfim param reduction 16 https github com epimath sfim param reduction https github com epimath sfim param reduction example 1 linear identifiable combination the first example f 1 2 exp 1 2 18 has a linear structural identifiable parameter combination this two parameter function is univariate so a priori its inputs cannot be uniquely determined from its output because the identifiable parameter combination 1 2 is linear we will be able to reconstruct it with these linear techniques here exp 1 2 exp 1 2 19 and f exp 2 1 2 exp 2 1 2 exp 2 1 2 exp 2 1 2 20 because f is univariate the local sensitivity fim f can have rank at most 1 indeed the eigenvalues of f are 1 2 exp 2 1 2 and 2 0 with eigenvectors 1 1 2 1 1 2 1 2 1 1 21 as seen in figure 2 a the rank deficiency of f indicates that f is not structurally identifi able and 1 correctly identifies the identifiable combination 1 2 to find the active subspaces we must define a parameter region and density let us take 1 and 2 uniformly distributed on 0 1 0 2 the choice of domain here is meant to remove symmetry that could result in non generalizable results then c 2 0 1 0 exp 2 1 2 exp 2 1 2 exp 2 1 2 exp 2 1 2 d 1 d 2 1 4 e 2 1 e 2 1 1 1 1 1 22 like the local f the average sensitivity fim c is not full rank because the identifi able parameter combination is linear the local and global techniques identify the same directions the stiff active identifiable direction corresponds to the parameter combina tion 1 2 given by 1 while kernel is spanned by 2 the sloppy inactive unidentifiable 17 direction corresponding to compensation between 1 and 2 moreover the approxima tion g 1 2 f qaq t a 1 2 f 1 2 1 1 1 1 1 2 23 is in fact equal to f 1 2 figure 2 b here with a linear parameter combination the active subspace gives the same answer as the local identifiability analysis both identify the linear structural parameter combination and we can successfully make a low rank approximation of f 0 0 0 5 1 0 1 5 2 0 0 00 0 25 0 50 0 75 1 00 1 2 5 10 15 20 f 1 2 a 5 10 15 5 10 15 g 1 2 f 1 2 b figure 2 a heat map of f 1 2 exp 1 2 with the eigenvector directions of the sensitivity fim evaluated at 0 3 1 0 the gray contour is the set of points 1 2 f 1 2 f 0 3 1 0 if we were to profile on 1 we would find that this contour is also 1 argmin c 2 and since min c 2 0 along this profile the parameter profile would be flat b the approximation g 1 2 is identical to f 1 2 because the identifiable combination is linear 18 example 2 non linear identifiable combination now consider an example with a structural non linear identifiable parameter combina tion f 1 2 exp 1 2 24 again this function is necessarily not identifiable because the number of parameters n 2 is greater than the number of outputs m 1 here 2 exp 1 2 1 exp 1 2 25 and f 22 exp 2 1 2 1 2 exp 2 1 2 1 2 exp 2 1 2 2 1 exp 2 1 2 26 again for any 1 2 the local sensitivity f is not full rank it has eigenvalues 1 21 2 2 exp 2 1 2 and 2 0 with corresponding eigenvectors 1 2 1 2 1 2 27 as seen in figure 3 a for any particular 1 2 this analysis will suggest that 2 1 1 2 is a linearized identifiable combination in this situation we can recover the true identifiable combina tion through profiling that is we fix 1 at a series of values 1 and determine the value of 2 such that c 2 f 1 2 f 1 2 2 28 is minimized in this case profiling reveals a linear relationship between 1 and arg min c 2 when plotted on a log log scale figure 3 b demonstrating that arg min c 2 1 1 29 i e 1 2 is an identifiable combination 19 now we consider whether we can create a one dimensional global approximation for f using the average sensitivity fim we again assume that 1 and 2 are uniformly distributed on 0 1 0 2 then c 2 0 1 0 22 exp 2 1 2 1 2 exp 2 1 2 1 2 exp 2 1 2 2 1 exp 2 1 2 d 1 d 2 4 89983 8 9827 8 9827 19 5993 30 the average sensitivity fim c has the eigendecomposition c 0 428222 0 903673 0 903673 0 428222 23 8559 0 0 0 64321 0 428222 0 903673 0 903673 0 428222 31 in this calculation c is full rank but there is a small eigenvalue gap between 1 23 8559 and 2 0 64321 raising the possibility of a one dimensional approximation the active subspace is the span of qa 0 428222 0 903673 32 the sufficient summary plot for the active subspace figure 3 c indicates that although there is some sort of structure most of the variance is not captured by the active subspace alone indeed the approximation g 1 2 f qaq t a 1 2 f 0 183374 1 0 386973 2 2 11029 0 183374 1 0 386973 2 33 deviates a great deal from f figure 3 d in contrast to example 1 both the local and global sensitivity fim analyses had difficulty because we are applying linear methods to a non linear problem profiling can determine the form of the non linear combination locally but the global analysis was unable to find the low dimensional approximation 20 0 0 0 5 1 0 1 5 2 0 0 00 0 25 0 50 0 75 1 00 1 2 2 4 6 f 1 2 a 0 1 1 0 0 1 1 0 1 log scale a rg m in c 2 lo g sc a le b 2 4 6 0 25 0 50 0 75 qa t f 1 2 c 2 4 6 2 3 4 5 6 g 1 2 f 1 2 d figure 3 a heat map of f 1 2 exp 1 2 with the eigenvector directions of the sensitivity fim evaluated at 0 3 1 0 the gray contour is the set of points 1 2 f 1 2 f 0 3 1 0 as in example 1 if we were to profile on 1 we would find that this contour is also 1 argmin c 2 and since min c 2 0 along this profile the likelihood profile would be flat b we plot this contour on the log log scale and the linear relationship indicates that the parameter combination is a product the value of 2 minimizes the squared difference of f 1 2 and f 0 3 1 c sufficient summary plot of the first eigenvector of the average sensitivity fim a nearly linear relationship would indicate that a lower dimensional structure is present d the approximation g 1 2 deviates from f 1 2 because the identifiable combination is non linear 21 example 3 nearly rank deficient sfim now we consider an example with a nearly rank deficient sensitivity fim let f 1 2 1 log 1 2 1 2 34 this function has a two dimensional output so unlike the previous examples it could be identifiable and in fact is structurally identifiable because f is injective but because log 1 2 2 for 2 near zero we expect to find that 1 2 is a practically identifiable combination when 2 is small computing 1 1 1 1 2 1 35 and f 1 1 1 2 2 1 1 1 2 1 1 1 2 2 36 the ratio of the eigenvalues of this matrix varies widely depending on the value of 2 let us consider two points 1 2 1 95 0 05 and 0 05 1 95 at the first point the eigenvalues are 1 3 91 and 2 5 80 e 4 with eigenvectors 1 0 699 0 715 2 0 715 0 699 37 the matrix is nearly rank deficient at this point and the eigenvectors suggest that we can only practically identify 1 2 from the value of f at this point at 0 05 1 95 on the other hand the eigenvalues are much closer with eigenvalues 1 2 96 and 2 0 15 indicating that the values of both 1 and 2 can be identified as a global measure active subspaces will not identify local opportunities for dimension reduction on the other hand making system simplifications and creating a function ap proximation based on the local practical identifiability near the first point would not be useful for global approximation 22 case study cell cycle model in this case study we consider a cell cycle model developed by gerard and goldbeter 23 dmd dt vsd gf kgf gf vdd md kdd md de 2 f dt vle 2 f e 2 ftot e 2 f kle 2 f e 2 ftot e 2 f md me v 2 e 2 f e 2 f k 2 e 2 f e 2 f ma dme dt vse e 2 f vde ma me kde me dma dt vsa e 2 f vda cdc 20 ma kda ma dmb dt vsb ma vdb cdc 20 mb kdv mb dcdc 20 dt v 1 cdc 20 mb cdc 20 tot cdc 20 k 1 cdc 20 cdc 20 tot cdc 20 v 2 cdc 20 cdc 20 k 2 cdc 20 cdc 20 38 reduced from their original model of thirty nine variables this skeleton model qualita tively reproduces cell cycle behavior in six variables and twenty four parameters figure 4 see 23 for variable and parameter definitions cyclins are a family of proteins that in complex with cyclin dependent kinases cdk drive a cell through the g 1 s g 2 and m phases of the cell cycle transcription factor e 2 f and protein cdc 20 help regulate this cell cycle progression here we consider one quantity of interest the period of the cell cycle and we ask whether we can find a lower dimensional structure in parameter space that predicts it although our question is a global one the model does not exhibit periodic dynamics ev erywhere in parameter space hence we restrict our analysis to parameter values between 50 150 of the default parameters of gerard and goldbeter 23 we sample 1 000 points from this restricted parameter space and calculate the period and estimate the gradient at each point we compute the global sensitivity fim c although the eigenvalues of c do not display a large eigenvalue gap at the top of the eigenvalue ladder figure 5 a sufficient summary plots of the first figure 5 b and first two figure 5 c eigenvectors demonstrate that most of the variance in the period is controlled by a subset of parame ters considering the parameter loadings of these eigenvectors figure 5 d we see that 23 cyclin d cdk 4 6 cyclin e cdk 2 cyclin a cdk 2 cyclin b cdk 1 active e 2 f inactive e 2 f active cdc 20 inactive cdc 20 a 0 1 2 3 0 25 50 75 100 time hours c o n ce n tr a tio n m cyclin e cdk 2 cyclin a cdk 2 cyclin b cdk 1 b figure 4 a a skeleton model of the cell cycle developed by gerard and goldbeter 23 b the cell progresses from g 1 to s to g 2 to m phases as cyclins e a and b in complex with their cyclin dependent kinases cdk wax and wane periodically the synthesis and degradation of the cyclin cdk complexes have the greatest effect on the period exact computation of identifiable combinations for observing output trajectories becomes increasing computationally intensive for even moderately sized models moreover there is no clear way to formulate the period as a rational function of an output trajectory as would be required for differential algebra method parameter profiling here would be computationally intensive and it may be difficult glean useful information about the likely complex practical identifiable combinations without an involved analysis fixing different combinations of parameters local sensitivity fim may be useful but as a first pass it will be insufficient for understanding which parameters are important over a wide range of parameters global sensitivity fim analysis active subspaces is useful in this instance because we i have a single quantity of interest that cannot be analytically expressed as a function of the output trajectories and ii are interested in determining which parameters would be needed to develop a low dimensional computationally fast approximation to the period that does not require solving a system of odes or numerically estimating the period 24 1 e 05 1 e 04 1 e 03 1 e 02 1 e 01 1 e 00 1 e 01 1 e 02 1 e 03 1 e 04 1 e 05 1 e 06 1 e 07 e ig e n va lu e s a 15 20 25 30 35 0 30 0 25 0 20 0 15 0 10 qa 1 t p e ri o d h o u rs 20 25 30 35 period b 0 20 0 25 0 30 0 35 0 30 0 25 0 20 0 15 0 10 qa 1 t q a 2 t 20 25 30 35 period c degredation of cycb cdk 1 degredation of cyce cdk 2 synthesis of cyca cdk 2 synthesis of cyce cdk 2 activation of cdc 20 0 0 0 2 0 4 0 6 parameter m a g n itu d e in f ir st e ig e n ve ct o r degredation of cyca cdk 2 degredation of cycd cdk 4 6 synthesis of cycb cdk 1 synthesis of cycd cdk 4 6 0 0 0 2 0 4 0 6 parameterm a g n itu d e in s e co n d e ig e n ve ct o r d figure 5 a global sensitivity fim analysis of the period of the cell cycle model finds that eigenvalues cluster near the top of the ladder suggesting that only a few of the variables do not impact the period nevertheless the sufficient summary plot of the first b and first two eigenvectors c demonstrate that the period is determined by a low dimensional structure in parameter space d analysis of the parameter loadings of the first two eigenvectors highlight the importance of the synthesis and degredation of the cyclin cdk complexes 25 susceptible s recovered r infectious i environment w s ii ww infection recovery shedding pathogen decay figure 6 the susceptible infectious water recovered siwr model of infectious disease transmission with direct and indirect transmission pathways case study infectious disease transmission model we finally illustrate sensitivity fim techniques on a ordinary differential equation model of infectious disease transmission with two pathways a direct person to person route and an indirect environmental route shown in figure 6 this example will allow us to illustrate two points how different identifiable combinations active inactive directions may be present in different parts of parameter space and how one might examine vectors of qois in the form of a time series the model we consider is often referred to as the siwr model as an initialism of the com partments susceptible infectious water and recovered 21 55 infectious people infect susceptible people directly with rate i recover from infection at rate and pathogens in the water infect susceptible people with rate w and decay at rate we note also that w has been re scaled by the pathogen shedding rate and decay rate which is why does not appear in the equations see 21 55 the units for all human compartments s i and r are assumed to be as fractions of the total population at risk a schematic of this 26 system shown in figure 6 and the system of equations is s s ii ww i s ii ww i r i w i w 39 for our qoi output we take in this case the vector of measured cases over time y i where is the reporting rate multiplied by the size of the at risk population following eisenberg et al 21 we define k 1 and work with k so that y i k as it is often easier to estimate k is bounded generally between 0 and 1 while is typically a large number ranging from the hundreds to the millions using the differential algebra method eisenberg et al 21 previously showed that the scaled form of the model given in eq 39 is structurally identifiable and used the model to demonstrate that both a direct and indirect pathway was needed to explain the ob served transmission dynamics for the 2006 cholera epidemic in angola however while the model is structurally identifiable they also observed that there are often issues of prac tical unidentifiability between w and 21 when noisy data is considered further in the limit as w and i become indistinguishable forming an identifiable combina tion w i as this happens the model may also become insensitive to relatively small changes in in practice these issues mean that depending on where one is in parame ter space and the data quality level of noise variance frequency of samples the model may be practically identifiable or unidentifiable in different ways depending on which dependencies between w and i dominate we implemented the model using the parameter estimates given in 21 for the 2006 angola epidemic shown in figure 7 a with parameter set i 0 256 w 1 21 0 00756 k 1 1212 e 5 as in 21 we let 0 25 be a fixed not estimated or varied value we let the initial conditions be determined by the data taking i 0 y 0 k and set the remainder of the population to be susceptible to simplify our example somewhat we use simulated data without noise this can also potentially be useful in illustrating the more general aim of parameter reduction from a time series qoi even if not working with data to illustrate the issues of unidentifiability as we profiled the parameters in both regimes we first profile using the above parameters as our i e the model trajectory y is treated as the data in the cost function and used for profiling we then profiled 27 0 2000 4000 6000 0 50 100 150 time days c a se s a 0 0 2 5 5 0 7 5 10 0 12 5 1 150 1 175 1 200 1 225 1 250 1 275 w n l l b 0 20 0 24 0 28 0 32 1 150 1 175 1 200 1 225 1 250 1 275 w i c figure 7 a model fit to data from the 2006 angola epidemic using parameters estimated in 21 b profile likelihoods for w using simulated noise free data generated in two parameter regimes dashed line the parameters used to generate panel a see example text for values and solid line the same parameters but with multiplied by 5000 the red dotted line indicates the threshold for the 95 confidence interval once is large the model becomes unidentifiable flat profile with an infinite confidence interval c corresponding parameter relationship plot showing how i varies as w is profiled in the unidentifiable case for panel b as becomes large the two transmission pathways can no longer be distinguished with the total i w forming an identifiable combination in active subspaces parlance the direction along the line would be considered inactive sloppy while the normal direction to the line corresponding to changing the value of the identifiable combination would be considered active stiff the model with our nominal value for 5000 times higher equal to 37 8 in both cases we took 20 data points spread evenly between the start and approximate end of the epidemic as shown in figure 7 b the model becomes unidentifiable with an combination that has begun to approximate w i figure 7 c indeed as increases the rank of the sfim falls from full rank of 4 to 3 and finally to 2 once is approximately four orders of magnitude larger indicating increasing dependencies between parameters next we consider how we might apply more general sfim techniques beyond rank given that we are considering a vector of qois the time series y we can evaluate the eigenval ues and eigenvectors of f and c in the vector case however the vector form of our qoi y makes examining sufficient summary plots which are typically defined for scalar qoi more complicated however as we are partially localizing our analyses we will define a single summary qoi q to be the cost function minimizing the sum of squares l 2 norm between the current parameters and our trajectory at a set of nominal parameter values 28 at the center of our parameter regime denoted this allows us to examine which di rections in parameter space tend to maintain the same goodness of fit or the same model behavior as the nominal values inactive sloppy versus tend to alter the model behav ior fit however we note that once away from there will be many ways to attain the same cost function value that do not necessarily represent the same model behavior still this qoi may allow us to use sufficient summary plots to examine the overall impact of the parameters across the time series we restrict our analysis to parameter values between 50 150 of sampling 500 points using latin hypercube sampling lhs we note that while it is often preferable for suffi cient summary plots to rescale the parameters to be within 1 1 16 we found that the identifiability relationships in the eigenvectors were better visualized if we took symmetric ranges but left the parameters unscaled this was likely due to the fact that the identifi able combination sum between the two parameters is more easily captured without any multiplicative scaling on the parameters we first take to be the default parameters described above from these default param eters and our lh sample we calculated four sfim related quantities two local and two global fy the sfim at calculated using our qoi y time series vector fq the sfim at calculated using the summary qoi q sum of squares using y as the data cy the average sfim calculated using our qoi y time series vector cq the average sfim calculated using the summary qoi q sum of squares using y as the data figure 8 shows the eigenvalues and eigenvector component magnitudes for each sfim type for all four quantities the four eigenvalues were fairly evenly spaced apart in terms of eigenvectors the four sfim versions agreed quite closely with each eigenvector corresponding largely to a single parameter the sufficient summary plots do not show any cohesive patterns not shown consistent with the profile likelihood results that the model is identifiable in this region of parameter space next we ran the same analyses but with the larger value of 37 8 used in figure 7 c shown in figures 9 and a 1 the eigenvector directions are similarly consistent across all four sfim quantities appendix figure a 1 the first two eigenvectors capture the sensi tive directions for the model approximately matching k and w i the main identifiable 29 fy 1 e 04 1 e 06 1 e 08 1 e 10 1 e 12 1 e 14 1 e 16 1 e 18 e ig e n va lu e s 0 00 0 25 0 50 0 75 1 00 i w k parameter m a g n itu d e in t h e f ir st e ig e n ve ct o r 0 00 0 25 0 50 0 75 1 00 i w k parameter m a g n itu d e in t h e s e co n d e ig e n ve ct o r 0 00 0 25 0 50 0 75 1 00 i w k parameter m a g n itu d e in t h e t h ir d e ig e n ve ct o r 0 00 0 25 0 50 0 75 1 00 i w k parameter m a g n itu d e in t h e f o u rt h e ig e n ve ct o r fq 1 e 24 1 e 21 1 e 18 1 e 15 1 e 12 1 e 09 e ig e n va lu e s 0 00 0 25 0 50 0 75 1 00 i w k parameter m a g n itu d e in t h e f ir st e ig e n ve ct o r 0 00 0 25 0 50 0 75 1 00 i w k parameter m a g n itu d e in t h e t h ir d e ig e n ve ct o r 0 00 0 25 0 50 0 75 1 00 i w k parameter m a g n itu d e in t h e s e co n d e ig e n ve ct o r 0 00 0 25 0 50 0 75 1 00 i w k parameter m a g n itu d e in t h e f o u rt h e ig e n ve ct o r cy 1 e 08 1 e 10 1 e 12 1 e 14 1 e 16 1 e 18 e ig e n va lu e s 0 00 0 25 0 50 0 75 1 00 i w k parameter m a g n itu d e in t h e f ir st e ig e n ve ct o r 0 00 0 25 0 50 0 75 1 00 i w k parameter m a g n itu d e in t h e s e co n d e ig e n ve ct o r 0 00 0 25 0 50 0 75 1 00 i w k parameter m a g n itu d e in t h e t h ir d e ig e n ve ct o r 0 00 0 25 0 50 0 75 1 00 i w k parameter m a g n itu d e in t h e f o u rt h e ig e n ve ct o r cq 1 e 16 1 e 18 1 e 20 1 e 22 e ig e n va lu e s 0 00 0 25 0 50 0 75 1 00 i w k parameter m a g n itu d e in t h e f ir st e ig e n ve ct o r 0 00 0 25 0 50 0 75 1 00 i w k parameter m a g n itu d e in t h e s e co n d e ig e n ve ct o r 0 00 0 25 0 50 0 75 1 00 i w k parameter m a g n itu d e in t h e t h ir d e ig e n ve ct o r 0 00 0 25 0 50 0 75 1 00 i w k parameter m a g n itu d e in t h e f o u rt h e ig e n ve ct o r figure 8 eigenvalues leftmost column and eigenvector magnitudes for the four sfim based quantities for all four versions the four eigenvalues were fairly evenly spaced apart note that for fq the second and third eigenvalues were very close and so appear as one bar in the eigenvalue plot second row eigenvectors for all four sfims each captured one main parameter with largely the same order except for fq where the third eigenvector was primarily and the second was i because the two associated eigenvalues were so close for clarity we swapped the order of the two eigenvectors in the plot 30 1 e 04 1 e 06 1 e 08 1 e 10 1 e 12 1 e 14 1 e 16 1 e 18 1 e 20 e ig e n va lu e s 1 00 0 75 0 50 0 25 0 00 i w k parameter f ir st e ig e n ve ct o r 0 6 0 4 0 2 0 0 i w k parameter s e co n d e ig e n ve ct o r 0 4 0 0 0 4 i w k parameter t h ir d e ig e n ve ct o r 0 00 0 25 0 50 0 75 1 00 i w k parameter f o u rt h e ig e n ve ct o r figure 9 eigenvalues leftmost panel and eigenvectors for the four cy the average sfim evaluated for the full vector qoi y in the fast case the first two eigenvectors capture the active directions corresponding to identifiable combinations k and w i the third and fourth eigenvectors correspond to the inactive or unidentifiable directions corresponding to compensation between w and i and parameters the lower two eigenvalues capture the inactive unidentifiable directions rep resenting compensation between the two transmission routes and for both the fast and slow regimes the similarity of eigenvectors with all four quantities local global vector scalar qois highlights how active subspaces can be used to explore different regions of parameter space and also how for more regional analyses a cost function based scalar qoi can be useful as a way of summarizing a vector or time series of qoi s lastly we ran the same four metrics but with the parameters scaled and translated to be centered at zero with a range of 1 1 in order to examine the sufficient summary plots 16 shown in figure 10 the resulting plots show a much stronger univariate relationship in the unidentifiable fast case than the default parameter case consistent with the larger gap after the first eigenvalue in the fast case shown in appendix figures a 2 and a 3 additionally we generated sufficient summary plots by plotting qta for cy versus q our least squares cost function while q was not the quantity used to generate cy the sufficient summary plots looked quite similar to those generated with cq sufficient summary plots for the subsequent eigenvectors showed no clear trend in any of the cases not shown the associated eigenvalues and eigenvectors for the scaled versions of the parameters are given in figures a 2 and a 3 31 0 e 00 2 e 08 4 e 08 6 e 08 0 8 0 4 0 0 0 4 qa 1 t c o st f u n ct io n v a lu e 2 e 08 4 e 08 6 e 08 cost function value a cq normal 0 e 00 5 e 06 1 e 07 0 6 0 3 0 0 0 3 0 6 qa 1 t c o st f u n ct io n v a lu e 5 e 06 1 e 07 cost function value b cq fast 0 e 00 2 e 08 4 e 08 6 e 08 0 4 0 0 0 4 qa 1 t c o st f u n ct io n v a lu e 2 e 08 4 e 08 6 e 08 cost function value c cy normal 0 e 00 5 e 06 1 e 07 0 6 0 3 0 0 0 3 0 6 qa 1 t c o st f u n ct io n v a lu e 5 e 06 1 e 07 cost function value d cy fast figure 10 sufficient summary plots for the first active eigenvector with the average sfim c calculated using either the scalar qoi q top row or the vector qoi y bottom row in both cases the cost function scalar qoi q is used as the y value in the plot left column panels show the normal case which shows a somewhat unclear relationship between the first eigenvector and the cost function q while the right column panels show the fast case where the relationship with the cost function q is close to one dimensional 32 conclusions and future directions to conclude in this paper we have examined the relationships between identifiability ac tive subspaces and sloppiness using the sensitivity fim as a common framework across each approach by framing the active subspaces quantity c as the average sensitivity fim over the parameter space of interest we were able to examine how local global and linear nonlinear identifiability and parameter reduction tools can each generate useful in sights into a range of real world applications the framing of these parameter reduction tools in a parameter estimation context also let us examine the potential use of cost func tions such as least squares and likelihood functions as a summary qoi when dealing with vector qois such as for time series we hope that the sensitivity fim based frame work developed here will facilitate further cross talk between different areas of identifia bility uncertainty quantification and parameter space reduction 33 appendix fy 1 e 02 1 e 04 1 e 06 1 e 08 1 e 10 1 e 12 1 e 14 1 e 16 1 e 18 1 e 20 e ig e n va lu e s 0 00 0 25 0 50 0 75 1 00 i w k parameter m a g n itu d e in t h e f ir st e ig e n ve ct o r 0 00 0 25 0 50 0 75 1 00 i w k parameter m a g n itu d e in t h e s e co n d e ig e n ve ct o r 0 00 0 25 0 50 0 75 1 00 i w k parameter m a g n itu d e in t h e t h ir d e ig e n ve ct o r 0 00 0 25 0 50 0 75 1 00 i w k parameter m a g n itu d e in t h e f o u rt h e ig e n ve ct o r fq 1 e 21 1 e 18 1 e 15 1 e 12 1 e 09 1 e 06 e ig e n va lu e s 0 00 0 25 0 50 0 75 1 00 i w k parameter m a g n itu d e in t h e f ir st e ig e n ve ct o r 0 00 0 25 0 50 0 75 1 00 i w k parameter m a g n itu d e in t h e s e co n d e ig e n ve ct o r 0 00 0 25 0 50 0 75 1 00 i w k parameter m a g n itu d e in t h e t h ir d e ig e n ve ct o r 0 00 0 25 0 50 0 75 1 00 i w k parameter m a g n itu d e in t h e f o u rt h e ig e n ve ct o r cy 1 e 04 1 e 06 1 e 08 1 e 10 1 e 12 1 e 14 1 e 16 1 e 18 1 e 20 e ig e n va lu e s 0 00 0 25 0 50 0 75 1 00 i w k parameter m a g n itu d e in t h e f ir st e ig e n ve ct o r 0 00 0 25 0 50 0 75 1 00 i w k parameter m a g n itu d e in t h e s e co n d e ig e n ve ct o r 0 00 0 25 0 50 0 75 1 00 i w k parameter m a g n itu d e in t h e t h ir d e ig e n ve ct o r 0 00 0 25 0 50 0 75 1 00 i w k parameter m a g n itu d e in t h e f o u rt h e ig e n ve ct o r cq 1 e 14 1 e 16 1 e 18 1 e 20 1 e 22 1 e 24 1 e 26 e ig e n va lu e s 0 00 0 25 0 50 0 75 1 00 i w k parameter m a g n itu d e in t h e f ir st e ig e n ve ct o r 0 00 0 25 0 50 0 75 1 00 i w k parameter m a g n itu d e in t h e s e co n d e ig e n ve ct o r 0 00 0 25 0 50 0 75 1 00 i w k parameter m a g n itu d e in t h e t h ir d e ig e n ve ct o r 0 00 0 25 0 50 0 75 1 00 i w k parameter m a g n itu d e in t h e f o u rt h e ig e n ve ct o r figure a 1 eigenvalues leftmost column and eigenvector loads for the four sfim based quantities in the fast case the first two eigenvectors capture the active directions corresponding to identifiable combinations k and w i the lower two eigenvectors correspond to the inactive or unidentifiable directions corresponding to compensation between w and i and 34 cq normal 1 e 16 1 e 17 e ig e n va lu e s 0 00 0 25 0 50 0 75 1 00 i w k parameter m a g n itu d e in t h e f ir st e ig e n ve ct o r 0 00 0 25 0 50 0 75 1 00 i w k parameter m a g n itu d e in t h e s e co n d e ig e n ve ct o r 0 00 0 25 0 50 0 75 1 00 i w k parameter m a g n itu d e in t h e t h ir d e ig e n ve ct o r 0 00 0 25 0 50 0 75 1 00 i w k parameter m a g n itu d e in t h e f o u rt h e ig e n ve ct o r cq fast 1 e 10 1 e 11 1 e 12 1 e 13 1 e 14 e ig e n va lu e s 0 00 0 25 0 50 0 75 1 00 i w k parameter m a g n itu d e in t h e f ir st e ig e n ve ct o r 0 00 0 25 0 50 0 75 1 00 i w k parameter m a g n itu d e in t h e s e co n d e ig e n ve ct o r 0 00 0 25 0 50 0 75 1 00 i w k parameter m a g n itu d e in t h e t h ir d e ig e n ve ct o r 0 00 0 25 0 50 0 75 1 00 i w k parameter m a g n itu d e in t h e f o u rt h e ig e n ve ct o r figure a 2 eigenvalues leftmost column and eigenvector component magnitudes for the average sfim in both the normal and fast cases using the least squares cost function q as the qoi and with parameters translated and scaled to be within 1 1 cy normal 1 e 08 1 e 09 e ig e n va lu e s 0 00 0 25 0 50 0 75 1 00 i w k parameter m a g n itu d e in t h e f ir st e ig e n ve ct o r 0 00 0 25 0 50 0 75 1 00 i w k parameter m a g n itu d e in t h e s e co n d e ig e n ve ct o r 0 00 0 25 0 50 0 75 1 00 i w k parameter m a g n itu d e in t h e t h ir d e ig e n ve ct o r 0 00 0 25 0 50 0 75 1 00 i w k parameter m a g n itu d e in t h e f o u rt h e ig e n ve ct o r cy fast 1 e 03 1 e 04 1 e 05 1 e 06 1 e 07 e ig e n va lu e s 0 00 0 25 0 50 0 75 1 00 i w k parameter m a g n itu d e in t h e f ir st e ig e n ve ct o r 0 00 0 25 0 50 0 75 1 00 i w k parameter m a g n itu d e in t h e s e co n d e ig e n ve ct o r 0 00 0 25 0 50 0 75 1 00 i w k parameter m a g n itu d e in t h e t h ir d e ig e n ve ct o r 0 00 0 25 0 50 0 75 1 00 i w k parameter m a g n itu d e in t h e f o u rt h e ig e n ve ct o r figure a 3 eigenvalues leftmost column and eigenvector component magnitudes for the average sfim in both the normal and fast cases using the time series vector y as the qoi and with parameters translated and scaled to be within 1 1 35 references 1 active subspaces faq http activesubspaces org faq accessed 2018 01 30 2 s audoly g bellu l d angio m p saccomani and c cobelli global identifiability of nonlinear models of biological systems ieee transactions on bio medical engineering 48 2001 pp 55 65 https doi org 10 1109 10 900248 http www ncbi nlm nih gov pubmed 11235592 3 e balsa canto a a alonso and j r banga an iterative identification proce dure for dynamic modeling of biochemical networks bmc systems biology 4 2010 p 11 4 h banks s dediu and s l ernstberger sensitivity functions and their uses in inverse problems journal of inverse and ill posed problems jiip 15 2007 pp 683 708 5 d j bearup n d evans and m j chappell the input output relationship approach to structural identifiability analysis computer methods and programs in biomedicine 109 2013 pp 171 181 6 r bellman and k a stro m on structural identifiability mathematical biosciences 7 1970 pp 329 339 https doi org 10 1016 0025 5564 70 90132 x http linkinghub elsevier com retrieve pii 002555647090132 x 7 a f brouwer r meza and m c eisenberg a systematic approach to deter mining the identifiability of multistage carcinogenesis models risk analysis 2016 https doi org 10 1111 risa 12684 8 a f brouwer r meza and m c eisenberg parameter estimation for mul tistage clonal expansion models from cancer incidence data a practical identifia bility analysis plos computational biology 13 2017 pp 1 18 https doi org 10 1371 journal pcbi 1005431 http dx doi org 10 1371 2 fjournal pcbi 1005431 9 k s brown and j p sethna statistical mechanical approaches to models with many poorly known parameters physical review e 68 2003 p 021904 https doi org 10 1103 physreve 68 021904 https link aps org doi 10 1103 physreve 68 021904 36 http activesubspaces org faq https doi org 10 1109 10 900248 http www ncbi nlm nih gov pubmed 11235592 https doi org 10 1016 0025 5564 70 90132 x http linkinghub elsevier com retrieve pii 002555647090132 x http linkinghub elsevier com retrieve pii 002555647090132 x https doi org 10 1111 risa 12684 https doi org 10 1371 journal pcbi 1005431 https doi org 10 1371 journal pcbi 1005431 http dx doi org 10 1371 2 fjournal pcbi 1005431 http dx doi org 10 1371 2 fjournal pcbi 1005431 https doi org 10 1103 physreve 68 021904 https link aps org doi 10 1103 physreve 68 021904 https link aps org doi 10 1103 physreve 68 021904 10 a capaldi s behrend b berman j smith j wright and a l lloyd pa rameter estimation and uncertainty quantication for an epidemic model mathematical biosciences and engineering 2012 p 553 11 m j chappell and r n gunn a procedure for generating locally identifiable repa rameterisations of unidentifiable non linear systems by the similarity transformation approach mathematical biosciences 148 1998 pp 21 41 12 o t chis j r banga and e balsa canto structural identifiability of systems biology models a critical comparison of methods plos one 6 2011 p e 27755 13 o t chis a f villaverde j r banga and e balsa canto on the relationship between sloppiness and identifiability mathematical biosciences 282 2016 pp 147 161 https doi org 10 1016 j mbs 2016 10 009 http dx doi org 10 1016 j mbs 2016 10 009 14 a cintro n arias h t banks a capaldi and a l lloyd a sensitivity ma trix based methodology for inverse problem formulation journal of inverse and ill posed problems 17 2009 pp 545 565 https doi org 10 1515 jiip 2009 034 http www degruyter com view j jiip 2009 17 issue 6 jiip 2009 034 jiip 2009 034 xml 15 c cobelli and j j distefano parameter and structural identifiability concepts and ambiguities a critical review and analysis the american journal of physiology 239 1980 pp r 7 24 http www ncbi nlm nih gov pubmed 7396041 16 p g constantine active subspaces emerging ideas for dimension reduction in pa rameter studies siam 2015 17 j distefano iii dynamic systems biology modeling and simulation academic press 2015 18 e dufresne h a harrington and d v raman the geometry of sloppiness arxiv preprint arxiv 1608 05679 2016 19 m c eisenberg and m a hayashi determining identifiable param eter combinations using subset profiling mathematical biosciences 256 2014 pp 116 126 https doi org 10 1016 j mbs 2014 08 008 http linkinghub elsevier com retrieve pii s 0025556414001631 37 https doi org 10 1016 j mbs 2016 10 009 http dx doi org 10 1016 j mbs 2016 10 009 http dx doi org 10 1016 j mbs 2016 10 009 https doi org 10 1515 jiip 2009 034 https doi org 10 1515 jiip 2009 034 http www degruyter com view j jiip 2009 17 issue 6 jiip 2009 034 jiip 2009 034 xml http www degruyter com view j jiip 2009 17 issue 6 jiip 2009 034 jiip 2009 034 xml http www ncbi nlm nih gov pubmed 7396041 https doi org 10 1016 j mbs 2014 08 008 http linkinghub elsevier com retrieve pii s 0025556414001631 20 m c eisenberg and h v jain a confidence building exercise in data and identifi ability modeling cancer chemotherapy as a case study journal of theoretical biology 431 2017 pp 63 78 21 m c eisenberg s l robertson and j h tien identifiability and estimation of multiple transmission pathways in cholera and waterborne disease journal of the oretical biology 324 2013 pp 84 102 https doi org 10 1016 j jtbi 2012 12 021 http www ncbi nlm nih gov pubmed 23333764 22 r c geary inherent relations between random variables in proceedings of the royal irish academy section a mathematical and physical sciences vol 47 jstor 1941 pp 63 76 23 c gerard and a goldbeter a skeleton model for the network of cyclin dependent kinases driving the mammalian cell cycle interface focus 1 2011 pp 24 35 https doi org 10 1098 rsfs 2010 0008 24 r n gutenkunst j j waterfall f p casey k s brown c r myers and j p sethna universally sloppy parameter sensitivities in systems biology models plos computational biology 3 2007 pp 1871 1878 https doi org 10 1371 journal pcbi 0030189 https arxiv org abs 0701039 25 b haffke r mo ller t melz and j strackeljan validation of simulation mod els without knowledge of parameters using differential algebra mathematical problems in engineering 2015 2015 26 h a harrington k l ho and n meshkat differential algebra for model com parison arxiv preprint arxiv 1603 09730 2016 27 s hengl c kreutz j timmer and t maiwald data based identifiability anal ysis of non linear dynamical models bioinformatics 23 2007 pp 2612 2618 28 a holmberg on the practical identifiability of microbial growth models incorporating michaelis menten type nonlinearities mathematical biosciences 62 1982 pp 23 43 https doi org 10 1016 0025 5564 82 90061 x 29 j a jacquez identifiability and parameter estimation jpen journal of par enteral and enteral nutrition 15 1991 pp 55 s 59 s https doi org 10 1177 014860719101500355 s 38 https doi org 10 1016 j jtbi 2012 12 021 https doi org 10 1016 j jtbi 2012 12 021 http www ncbi nlm nih gov pubmed 23333764 https doi org 10 1098 rsfs 2010 0008 https doi org 10 1098 rsfs 2010 0008 https doi org 10 1371 journal pcbi 0030189 https doi org 10 1371 journal pcbi 0030189 https arxiv org abs 0701039 https doi org 10 1016 0025 5564 82 90061 x https doi org 10 1177 014860719101500355 s https doi org 10 1177 014860719101500355 s 30 j a jacquez and p greif numerical parameter identifiability and estimability integrating identifiability estimability and optimal sampling design mathematical biosciences 77 1985 pp 201 227 https doi org 10 1016 0025 5564 85 90098 7 31 j a jacquez and t perry parameter estimation local identifiability of parameters the american journal of physiology 258 1990 pp e 727 36 32 t c koopmans identification problems in economic model construction economet rica journal of the econometric society 1949 pp 125 144 33 t c koopmans and o reiersol the identification of structural characteristics the annals of mathematical statistics 21 1950 pp 165 181 34 m p little w f heidenreich and g li parameter identifiability and redun dancy theoretical considerations plos one 5 2010 pp 1 6 https doi org 10 1371 journal pone 0008915 https arxiv org abs 0812 4701 35 l ljung and t glad on global identifiability for arbitrary model parametrizations automatica 30 1994 pp 265 276 https doi org 10 1016 0005 1098 94 90029 9 36 a mahdi n meshkat and s sullivant structural identifiability of viscoelastic mechanical systems plos one 9 2014 p e 86411 37 b merkt j timmer and d kaschek higher order lie symmetries in identifia bility and predictability analysis of dynamic models physical review e 92 2015 p 012920 38 n meshkat c anderson and j j distefano finding identifiable parameter combinations in nonlinear ode models and the rational reparameterization of their input output equations mathematical biosciences 233 2011 pp 19 31 https doi org 10 1016 j mbs 2011 06 001 http dx doi org 10 1016 j mbs 2011 06 001 39 n meshkat c anderson and j j distefano alternative to ritt s pseudodi vision for finding the input output equations of multi output models mathematical biosciences 239 2012 pp 117 123 https doi org 10 1016 j mbs 2012 04 008 http dx doi org 10 1016 j mbs 2012 04 008 39 https doi org 10 1016 0025 5564 85 90098 7 https doi org 10 1016 0025 5564 85 90098 7 https doi org 10 1371 journal pone 0008915 https doi org 10 1371 journal pone 0008915 https arxiv org abs 0812 4701 https doi org 10 1016 0005 1098 94 90029 9 https doi org 10 1016 0005 1098 94 90029 9 https doi org 10 1016 j mbs 2011 06 001 https doi org 10 1016 j mbs 2011 06 001 http dx doi org 10 1016 j mbs 2011 06 001 http dx doi org 10 1016 j mbs 2011 06 001 https doi org 10 1016 j mbs 2012 04 008 https doi org 10 1016 j mbs 2012 04 008 http dx doi org 10 1016 j mbs 2012 04 008 40 n meshkat m eisenberg and j j distefano an algorithm for finding globally identifiable parameter combinations of nonlinear ode models using gro bner bases mathematical biosciences 222 2009 pp 61 72 https doi org 10 1016 j mbs 2009 08 010 http www ncbi nlm nih gov pubmed 19735669 41 n meshkat and s sullivant identifiable reparametrizations of linear compartment models journal of symbolic computation 63 2014 pp 46 67 42 n meshkat s sullivant and m eisenberg identifiability results for several classes of linear compartment models bulletin of mathematical biology 77 2015 pp 1620 1651 43 h miao x xia a s perelson and h wu on identifiability of nonlinear ode models and applications in viral dynamics siam review 53 2011 pp 3 39 https doi org 10 1137 090757009 44 s a murphy and a w van der vaart on profile likelihood journal of the amer ican statistical association 95 2000 pp 449 465 45 h pohjanpalo system identifiability based on the power series expansion of the solu tion mathematical biosciences 41 1978 pp 21 33 https doi org 10 1016 0025 5564 78 90063 9 46 a raue c kreutz t maiwald j bachmann m schilling u klingmu ller and j timmer structural and practical identifiability analysis of partially observed dynamical models by exploiting the profile likelihood bioinformatics 25 2009 pp 1923 1929 https doi org 10 1093 bioinformatics btp 358 47 j g reid structural identifiability in linear time invariant systems ieee transac tions on automatic control 22 1977 pp 242 246 https doi org 10 1109 tac 1977 1101474 48 o reiers l identifiability of a linear relation between variables which are subject to error econometrica journal of the econometric society 1950 pp 375 389 49 m rodriguez fernandez p mendes and j r banga a hybrid approach for efficient and robust parameter estimation in biochemical pathways biosystems 83 2006 pp 248 265 50 t j rothenberg identification in parametric models econometrica 39 1971 pp 577 591 40 https doi org 10 1016 j mbs 2009 08 010 https doi org 10 1016 j mbs 2009 08 010 http www ncbi nlm nih gov pubmed 19735669 https doi org 10 1137 090757009 https doi org 10 1137 090757009 https doi org 10 1016 0025 5564 78 90063 9 https doi org 10 1016 0025 5564 78 90063 9 https doi org 10 1093 bioinformatics btp 358 https doi org 10 1109 tac 1977 1101474 https doi org 10 1109 tac 1977 1101474 51 m saccomani s audoly g bellu and l d angio a new differential al gebra algorithm to test identifiability of nonlinear systems with given initial condi tions in proceedings of the 40 th ieee conference on decision and control cat no 01 ch 37228 vol 4 ieee 2001 pp 3108 3113 https doi org 10 1109 2001 980295 http ieeexplore ieee org document 980295 52 m p saccomani s audoly and l d angio parameter identifiability of nonlinear systems the role of initial conditions automatica 39 2003 pp 619 632 https doi org 10 1016 s 0005 1098 02 00302 3 53 m p saccomani and k thomaseth structural vs practical identifiability of non linear differential equation models in systems biology in dynamics of mathematical models in biology springer 2016 pp 31 41 54 r c smith uncertainty quantification theory implementation and applications siam philadelphia 2014 55 j h tien and d j d earn multiple transmission pathways and disease dynam ics in a waterborne pathogen model bulletin of mathematical biology 72 2010 pp 1506 33 https doi org 10 1007 s 11538 010 9507 6 http www ncbi nlm nih gov pubmed 20143271 56 c to nsing j timmer and c kreutz cause and cure of sloppiness in ordinary differential equation models physical review e statistical nonlinear and soft mat ter physics 90 2014 pp 1 15 https doi org 10 1103 physreve 90 023303 https arxiv org abs 1406 1734 57 m k transtrum b b machta k s brown b c daniels c r myers and j p sethna perspective sloppiness and emergent theories in physics biology and beyond journal of chemical physics 143 2015 https doi org 10 1063 1 4923066 https arxiv org abs 1501 07668 58 m k transtrum b b machta and j p sethna geometry of nonlinear least squares with applications to sloppy models and optimization physical review e 83 2011 pp 1 35 https doi org 10 1103 physreve 83 036701 https arxiv org abs 1010 1449 59 m k transtrum and p qiu model reduction by manifold boundaries physical review letters 113 2014 pp 1 6 https doi org 10 1103 physrevlett 113 098701 41 https doi org 10 1109 2001 980295 https doi org 10 1109 2001 980295 http ieeexplore ieee org document 980295 https doi org 10 1016 s 0005 1098 02 00302 3 https doi org 10 1016 s 0005 1098 02 00302 3 https doi org 10 1007 s 11538 010 9507 6 http www ncbi nlm nih gov pubmed 20143271 http www ncbi nlm nih gov pubmed 20143271 https doi org 10 1103 physreve 90 023303 https arxiv org abs 1406 1734 https doi org 10 1063 1 4923066 https doi org 10 1063 1 4923066 https arxiv org abs 1501 07668 https doi org 10 1103 physreve 83 036701 https arxiv org abs 1010 1449 https arxiv org abs 1010 1449 https doi org 10 1103 physrevlett 113 098701 https doi org 10 1103 physrevlett 113 098701 60 m k transtrum and p qiu bridging mechanistic and phenomenological models of complex biological systems plos computational biology 12 2016 p e 1004915 61 s vajda k r godfrey and h rabitz similarity transformation approach to identifiability analysis of nonlinear compartmental models mathematical biosciences 93 1989 pp 217 248 https doi org 10 1016 0025 5564 89 90024 2 62 d venzon and s h moolgavkar a method for computing profile likelihood based confidence intervals applied statistics 1988 pp 87 94 63 a f villaverde and j r banga dynamical compensation and structural identifi ability of biological models analysis implications and reconciliation plos computa tional biology 13 2017 p e 1005878 64 h yue m brown j knowles h wang d s broomhead and d b kell insights into the behaviour of systems biology models from dynamic sensitivity and iden tifiability analysis a case study of an nf b signalling pathway molecular biosystems 2 2006 pp 640 649 42 https doi org 10 1016 0025 5564 89 90024 2