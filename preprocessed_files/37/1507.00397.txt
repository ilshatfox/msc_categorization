scaling limits of a model for selection at two scales shishi luo jonathan c mattingly abstract the dynamics of a population undergoing selection is a central topic in evolutionary biol ogy this question is particularly intriguing in the case where selective forces act in opposing directions at two population scales for example a fast replicating virus strain out competes slower replicating strains at the within host scale however if the fast replicating strain causes host morbidity and is less frequently transmitted it can be outcompeted by slower replicating strains at the between host scale here we consider a stochastic ball and urn process which models this type of phenomenon we prove the weak convergence of this process under two natural scalings the first scaling leads to a deterministic nonlinear integro partial differential equation on the interval 0 1 with dependence on a single param eter we show that the fixed points of this differential equation are beta distributions and that their stability depends on and the behavior of the initial data around 1 the second scaling leads to a measure valued fleming viot process an infinite dimensional stochastic process that is frequently associated with a population genetics 1 introduction we study the model introduced in 13 of a trait that is advantageous at a local or indi vidual level but disadvantageous at a larger scale or group level for example an infectious virus strain that replicates rapidly within its host will outcompete other virus strains in the host however if infection with a heavy viral load is incapacitating and prevents the host from transmitting the virus the rapidly replicating strain may not be as prevalent in the overall host population as a slow replicating strain a simple mathematical formulation of this phenomenon is as follows consider a popu lation of m n groups each group contains n n individuals there are two types of individuals type i individuals are selectively advantageous at the individual i level and type g individuals are selectively advantageous at the group g level replication and se lection occur concurrently at the individual and group level according to the moran process 6 and are illustrated in fig 1 type i individuals replicate at rate 1 s s 0 and type g individuals at rate 1 when an individual gives birth another individual in the same group is selected uniformly at random to die to reflect the antagonism at the higher level of selection groups replicate at a rate which increases with the number of type g indivduals they contain as a simple case we take this rate to be w 1 r k n where k n is the fraction of indivduals in the group that are type g r 0 is the selection coefficient at the group level and w 0 is the ratio of the rate of group level events to the rate of individual level events date september 26 2018 1 ar x iv 1 50 7 00 39 7 v 1 m at h p r 2 j ul 2 01 5 2 shishi luo jonathan c mattingly figure 1 schematic of the particle process a left a population of m 3 groups each with n 3 individuals of either type g filled small circles or type i open small circles middle a type i individual replicates in group 3 and a type g individual is chosen uniformly at random from group 3 to die right group 1 replicates and produces group 2 group 2 is chosen uniformly at random to die b the states in a mapped to a particle process left group 2 has no type g individuals represented by ball 2 in urn 0 similarly group 3 is represented by ball 3 in urn 2 and group 1 by ball 1 in urn 3 middle the number of type g individuals in group 3 decreases from two to one therefore ball 3 moves to urn 1 right a group with zero type g individuals dies while a group with three type g individuals is born therefore ball 2 leaves urn 0 and appears in urn 3 as ball 2 more general functions for the group replication rate are possible though the subsequent analysis of the model may be less tractable as with the individual level the population of groups is maintained at m by selecting a group uniformly at random to die whenever a group replicates the offspring of groups are assumed to be identical to their parent as illustrated in fig 1 this two level process is equivalent to a ball and urn or particle process where each particle represents a group and its position corresponds to the number of type g individuals that are in it let x it be the number of type g individuals in group i at time t then m n t 1 m m i 1 xit n is the empirical measure at time t for a given number of groups m and individuals per group n x y 1 if x y and zero otherwise the x i t are divided by n so that m n t is a probability measure on en 0 1 n 1 for fixed t 0 m n t d 0 t p en the set of ca dla g processes on 0 t taking values in p en where p s is the set of probability measures on a set s with the particle process described above m n t has generator lm n v i j r 1 wr 2 v vij vij v 1 scaling limits of a model for selection at two scales 3 where vij v 1 m j n i n cb p 0 1 are bounded continuous functions and v p en p 0 1 the transition rates r 1 wr 2 are given by r 1 v vij mv i n i 1 i n 1 s if j i 1 i n mv i n i 1 i n if j i 1 i 0 0 otherwise and r 2 v vij mv i n v j n 1 r j n r 1 represents individual level events while r 2 represents group level events acknowledgements the authors would like to thank mike reed and katia koelle for their roles in the collaboration out of which this paper s central model grew we would also like to thank rick durrett of a number of useful discussions jcm would like to thank the nsf for its support though dms 08 54879 sl would like to thank support from the nsf grants nsf ef 08 27416 and dms 0942760 nih grant r 01 gm 094402 and the simons institute for the theory of computing 2 main results we prove the weak convergence of this measure valued process as m n under two natural scalings the first scaling leads to a deterministic partial differential equation we derive a closed form expression for the solution of this equation and study its steady state behavior the second scaling leads to an infinite dimensional stochastic process namely a fleming viot process let us briefly introduce some notation by m n we mean a sequence mk nk k such that for any n there is an n 0 such that if k n 0 mk nk n we define f v 1 0 f x v dx where f is a test function and v a measure lastly x will denote the delta measure for both continuous and discrete state spaces to provide intuition for the two scalings and the corresponding limits take to be of the form v f g v where g is some suitable function on 0 1 and apply the generator in 1 to it lm n f 1 n g i n sg i n i n 1 i n i n wr i n g i n i n g i n i n j n j n 1 m wf g i n 2 i n g i n i n 2 1 2 r g j n g i n 2 j n j n i n o 1 m o 1 n this suggests two natural scalings the first is to take m n without rescaling any parameters the g and f terms vanish and we have a deterministic process the precise statement of the weak convergence of the finite state space system to the deterministic limit is in terms of a weak measure valued solution to a partial differential equation theorem 1 suppose the particles in the system described by m n t are initially independently and identically distributed according to the measure m n 0 where m n 0 0 p 0 1 as 4 shishi luo jonathan c mattingly m n then as m n m nt t d 0 t p 0 1 weakly where t solves the differential equation d dt f t x 1 x f t xf t f t x t 2 for any positive valued test function f c 1 0 1 and with initial condition f 0 here wr s and time has been sped up by a factor of s throughout we will denote the measure valued solutions to 2 by t dx we note that strong density valued solutions denoted by t x solve t t x x 1 x t t x 1 0 y t y dy 3 with initial density 0 x in this more transparent form one can see that the first term on the right is a flux term that transports density towards x 0 whereas the second term is a forcing term that increases the density at values of x above the mean of the density the flux corresponds to the individual level moves nearest neighbor moves in the particle system the forcing term corresponds to group level moves moves to occupied sites in the particle system we will see that if we start with an initial measure 0 which is the sum of delta measures then the solution t retains the same form more explicitly if 0 dx i ai 0 xi 0 dx where xi 0 0 1 ai 0 0 and ai 0 1 then we will see from lemma 5 that the solution t to 2 has the form t dx i ai t xi t dx moreover the parameters ai t xi t satisfy the following set of coupled equations 4 dxi dt xi 1 xi dai dt ai xi y t ai xi j ajxj notice that the positions of the delta masses change according to a negative logistic function independently of the other masses and the density the weight ai increases at time t if the position of the particle xi is above the mean ajxj and decreases if it is below the mean to build intuition it is instructive to consider some simple examples of this form example 1 according to 4 if 0 1 then t 0 this can also be seen directly from 2 in the case of an initial condition containing some delta mass at 1 all of the rest of the mass will migrate towards zero eventually all of the mass will be below the mean as the mass at one will not move and will ever be increasing its mass as it is always above the mean once this happens it is clear that all of the mass will drain from all of the points not at one and hence t 1 as t this reasoning holds in a more general setting and is included in theorem 3 scaling limits of a model for selection at two scales 5 example 2 according to 4 if 0 0 then t 0 this too can be seen directly from 2 in the case of an initial condition containing no mass at one and only finite number of masses total the mass will eventually all move towards zero and hence hence t 0 as t if an infinite number of masses are allowed the situation is not as simple theorem 3 hints at the possible complications by giving an example of a density which is invariant though 0 is a fixed point of the system attracting many initial configurations it is not lyapunov stable this means that even small perturbations of 0 can lead to an arbitrary large excursion away from 0 even though the system eventually returns to 0 rather than making a precise statement which would require quantifying the size of a perturbation consider the example of 0 1 0 1 as 0 the distance between 0 and 0 goes to zero in any reasonable metric if we write t 1 at 0 at xt then as 0 one can ensure that the system spends arbitrarily long time with xt 1 2 and hence at will grow to as close to one as one wants in this time thus the system could be described as making an an arbitrarily big excursion away from 0 even though t 0 as t it natural to ask if there are other fixed points beyond 0 and 1 lemma 2 fixed points the measures delta 0 1 and densities in the beta family of distributions 1 b x 1 1 x 1 with 0 are fixed points of 2 b is the normalizing constant that makes the density integrate to 1 over the interval 0 1 for measure valued initial data we show that the basins of attraction for the fixed points are determined by whether they charge the point x 1 and their ho lder exponent around x 1 theorem 3 steady state behavior consider measure valued solution t dx to 2 with initial probability measure 0 dx if 0 1 0 then t 1 as t and if 0 1 1 0 for some 0 then t 0 as t alternatively suppose that for some 0 and c 0 x 0 1 x 1 c as x 0 if then t dx beta as t otherwise if t dx 0 dx as t the results of theorem 3 should be contrasted with the original markov chain before taking the limit m n in the markov chain all individuals eventually become either entirely type g or type i these two homogeneous states are absorbing states for the individual level dynamics the population level state made of individuals that are all either homogeneous 6 shishi luo jonathan c mattingly of type g or i is absorbing for the group level dynamics hence the state of the system eventually becomes composed entirely of homogeneous groups of solely g or i and stays in that state for all future times these two absorbing states of the markov chain with finite m and n correspond to the states 0 and 1 in the scaling limit hence the natural discretization for the beta distribution to the lattice k n 0 k n given by 1 z m n k n 1 1 k n 1 cannot be invariant here z is the normalization constant which ensures the probabilities sum to one however for large m and n it is reasonable to expect it to be nearly invariant in the sense that if the initial states xi 0 1 i m are independent and distributed as the discrete beta distribution then the markov chain dynamics will keep the distribution close to the product of discretized beta distributions for a long time the expectation of this time will grow to infinity as m n we will not pursue a rigorous proof of this near or quasi invariance here nonetheless we now briefly sketch the argument as we understand it giving the central points if the distribution of the markov chain is close to a product of discretized beta distributions then the empirical mean will be highly concentrated around the mean of continuous beta when m and n are large hence the generator projected on to any xi is nearly decoupled from the other particles and close to being markovian more precisely the dynamics of any fixed xi is well approximated in this setting by the one dimensional markov chain obtained by replacing the mean of the empirical measure in the full generator with the mean of the beta distribution it is straightforward to see that for m and n large the discretized beta distribution is an approximate left eigenfunction of this one dimensional generator with an eigenvalue which goes to zero as m n all of these observations can be combined to show that if the systems starts in the product discretized beta distribution then it will say close to the product discretized beta distribution for a long time if m and n are large we now turn to the second scaling let s n r m and n m and let m nt denote the empirical measure under this scaling the terms f and g in the generator 1 no longer vanish and the process converges to a limit that is stochastic our weak convergence result is proved and stated in terms of a martingale problem theorem 4 suppose n m w o 1 s n r m and we speed up time by a factor of n suppose the particles in the rescaled m n t process are initially independently and identically distributed according to the measure m n 0 where m n 0 0 as m n then the rescaled process converges weakly to t as m n where t satisfies the following martingale problem nt f f t f 0 t 0 af z dz 5 w t 0 1 0 1 0 f x v z z y q z dx dy dz scaling limits of a model for selection at two scales 7 is a martingale with conditional quadratic variation n f t 2 w t 0 1 0 1 0 f x f y q dx dy d 6 where af x x 1 x d 2 dx 2 f x d dx f x v t x x q dx dy dx x dy dy and f c 2 0 1 the drift part of the martingale 5 comprises a second order partial differential operator a and the centering term from the global jump dynamics the expression in curly brackets the entire process is a fleming viot process 9 fleming viot processes frequently arise in models of population genetics see 8 for a review in these contexts the variable x can represent the geographical location of an individual or as in the original paper of fleming and viot 9 the genotype of an individual where genotype is a continuous instead of a discrete variable to our knowledge the specific form of the limiting fleming viot process above has not previously been studied in particular although infinite dimensional stochastic processes have been applied to multilevel population dynamics of a single type 5 this appears to be the first fleming viot process for the evolution of two types under opposing forces of selection at two population scales the dynamical properties of the deterministic partial differential equation 2 are the focus of the next section the proofs of weak convergence theorems 1 and 4 are deferred to section 4 3 properties of the deterministic limit we begin with a closed form expression for solutions to the deterministic partial differential equation 2 lemma 5 the solution to the deterministic partial differential equation 2 with initial measure 0 is given by t dx gt 0 dx 0 1 t dx wt x 7 where 1 t x x e t x 1 e t wt x e t x 1 e t et t 0 h z dz and h t satisfies h t x t remark 1 0 1 t dx 0 1 t dx captures the changes in the initial data that are solely due to the flux term this expression is also known as the push forward measure of 0 under the dynamics of as we will see in the proof t x is precisely the characteristic curve for the spatial variable x and includes a normalizing constant the multiplication by wt x captures the changes in the initial data that are due to the forcing term in 2 and includes a normalizing factor 8 shishi luo jonathan c mattingly remark 2 density valued solutions are given by t x 0 1 t x x 1 t x wt x 0 x e t x 1 e t e t x 1 e t 2 e 1 t t 0 h z dz 8 to see this suppose 0 dx 0 x dx then for any test function f 1 0 f x 0 1 t dx 1 0 f t x 0 dx 1 0 f y 0 1 t y y 1 t y dy the first equality follows from the change of variable property of push forward measures and the second from a standard change of variables the limits of integration do not change because 0 and 1 are fixed points of both t and 1 t proof of lemma 5 we apply the method of characteristics see for example 14 to obtain a formula for a density valued solution we then prove that the weak measure valued analog of this solution satisfies 2 consider the following modification of 3 t t x x x 1 x t x t x x h t 9 where h t is a general function in time and 0 c 1 0 1 note that when h t 1 0 y t y dy this differential equation is equivalent to 3 to be clear about which equation we are solving we use t x to denote solutions when h t is unspecified rewriting 9 t x 1 1 x 1 x 1 2 x x h t 0 the second vector is therefore tangent to the solution surface and gives the rates of change for the t x and coordinates let the initial condition be parameterized as 0 x 0 x 0 p 0 p the t x and coordinates change according to the characteristic equations dt dq 1 t 0 p 0 dx dq x 1 x x 0 p p d dq 1 2 x q p x q p h t q p 0 p 0 p where q is the parameter as we move through the solutions in time the first two ordinary differential equations have solutions t q p q x q p p p p 1 eq q p 10 from this the third differential equation can be solved exactly d dq 1 p p p 1 eq 2 h q q p 0 p exp q q 0 h z dz 2 q 0 p p p 1 ez dz 0 p e q q 0 h z dz p e q 1 1 2 scaling limits of a model for selection at two scales 9 next make the substitutions q t and p 1 t x from 10 to obtain in terms of t and x t x 0 1 t x e t x 1 e t 2 e 1 t t 0 h z dz 0 1 t x x 1 t x wt x 11 if h t satisfies h t 1 0 y t y dy then by definition t x solves the partial differential equation 3 conversely if t x solves the partial differential equation 3 it also solves the differential equation 9 with h t 1 0 y t y dy therefore this above expression along with the condition h t 1 0 y t y dy are equivalent to solutions of 3 to extend this result to measures suppose we have a strong solution t x with initial condition 0 t x 0 1 t x x 1 t x wt x using a similar calculation as that in remark 2 the measure t dx corresponding to t x is given by t dx 0 1 t dx wt x it remains to check that this satisfies the weak deterministic partial differential equation 2 with h t x t the left hand side of the equation is d dt f t ddt 1 0 f x wt x 0 1 t dx d dt 1 0 f t x wt t x 0 dx differentiating under the integral sign expanding out the expressions for t t and t wt t x and applying change of variables for push forward measures again we obtain d dt f t 1 0 x 1 x f x wt x 0 1 t dx 1 0 x h t f x wt x 0 1 t dx this matches right hand side of the weak deterministic partial differential equation 2 in practice the condition h t x t is difficult to use the following provides an equivalent and simpler condition lemma 6 conservation of measure condition suppose is a weak measure valued solution to the deterministic partial differential equation 9 with initial condition 1 0 0 dx 1 then h t 1 0 y t dy if and only if 1 0 t dy 1 t 0 proof direction suppose h t 1 0 y t dy then is a weak measure valued solution to 2 taking the test function f 1 we obtain d dt 1 0 x 1 x 0 thus if the initial data has total measure 1 1 remains constant at 1 for all t 0 direction suppose 1 0 t dx 1 for all t 0 again take the test function f 1 but this time with unspecified h t 0 d dt 1 0 x 1 h t x h t for this to hold we must have h t 1 0 x t dx 10 shishi luo jonathan c mattingly the above lemmas imply that solutions t dx to 2 can be obtained by using formula 7 from lemma 5 and imposing the conservation of measure condition 1 t 1 from lemma 6 we illustrate this with some examples of exactly solvable solutions for special choices of initial data we will see that the long time behavior of the examples is consistent with results stated in theorem 3 example 3 initial measure concentrated at x 0 0 1 i e 0 x 0 using formula 7 f x t dx f x wt x x 0 1 t dx f t x 0 wt t x 0 f x wt x t x 0 dx thus t dx wt x t x 0 dx imposing the conservation of measure condition gives t dx t x 0 dx in other words an initial delta measure at x 0 moves as a delta measure along the x axis with position given by t x 0 the solution to the negative logistic equation with initial position x 0 example 4 initial uniform density 0 x 1 i e 0 dx dx using formula 8 t x e 1 t t 0 h z dz e t x 1 e t 2 imposing conservation of measure e 1 t t 0 h z dz 1 0 e t x 1 e t 2 dx 1 1 1 e t 1 e 1 t if 6 1 1 e t t if 1 thus t x 1 1 e t 1 e 1 t e t x 1 e t 2 if 6 1 1 e t t e t x 1 e t 2 if 1 note that 0 1 corresponds to an initial condition satisfying the hypothesis of theorem 3 with 1 as predicted when 1 we obtain t x 1 x 2 beta 1 1 as t the following is an example with 1 example 5 if 0 x 2 1 x i e 0 1 x 1 x 2 then the corresponding from theorem 3 is 2 scaling limits of a model for selection at two scales 11 using formula 8 t x 2 e 2 t t 0 h z dz 1 x e t x 1 e t 3 imposing the condition in lemma 6 to solve for the h z term e 2 t t 0 h z dz 2 1 0 1 x e t x 1 e t 3 dx 1 2 1 e t 2 1 1 1 e t e 1 t 1 1 e t e 2 t 1 if 6 2 1 e t 2 2 te t if 2 as predicted by theorem 3 for 2 t x 12 2 1 1 x x 3 beta 2 2 as t example 6 0 x 1 c 1 0 c x with c 1 using formula 8 t x 1 c 1 x t c wt x x 1 t x since t c ce t 1 c ce t 0 as t t x 0 for any x 0 since must have total mass 1 it follows that regardless of the value of t x dx 0 dx for any c 1 this can also be seen by applying theorem 3 and noting that 0 1 c 1 1 1 c 0 x dx 0 we end these examples with solutions for 0 that are mixtures of delta measures and densities first note that it is straightforward to extend example 3 to the case where 0 dx ai xi dx is a linear combination of delta measures ai 0 for all i applying 7 we obtain t dx i aiwt x t xi dx i ai t xi t dx where xi t t xi and ai t aiwt x x xi t our earlier system of equations 4 is obtained from this and the definitions of t x and wt x second we consider a combination of a delta measure and a density 0 dx a x 0 dx 1 a v 0 x dx notice that the formula for the solution 7 at first seems linear in the initial condition f x t dx f x gt 0 dx f x wt x a t x 0 dx 1 a v 0 1 t x x 1 t x dx f x a gt x 0 dx 1 a gtv 0 dx this gives gt 0 dx a gt x 0 dx 1 a gtv 0 dx however this notation is mislead ing because implicit in the gt operator is the function h t the mean of the overall process over time here h t involves both the delta measure and the density the solution operator gt is therefore not linear for this reason 12 shishi luo jonathan c mattingly nevertheless we can still use this formula to obtain expressions for solutions we illustrate this with a concrete example example 7 take x 0 0 and v 0 x the density function for beta with 0 using the solution formula and direct calculation we obtain t dx awt 0 0 dx 1 a wt x v 0 1 t x x 1 t x dx e t 0 h z dz a 0 dx 1 a e tv 0 x dx note in particular that t remains a linear combination of 0 and the beta distribution the beta distribution ultimately dominates because we now use lemma 5 to show that beta distributions 0 and 1 are fixed points for the deterministic partial differential equation and thus provide a proof of lemma 2 announced earlier in this note proof of lemma 2 note that we could prove this lemma by substituting 0 1 and the beta distribution into the deterministic partial differential equation 2 and showing the right hand side equals zero instead we will show that these distribution are fixed points of the solution operator let v be the density of the beta distribution v x 1 b x 1 1 x 1 the mean of v is using 8 gtv x v x e t x 1 e t e t x 1 e t 2 e 1 t t v x v is therefore a fixed point of the solution operator and hence is a fixed point of the deter ministic partial differential equation for 0 and 1 we use example 3 above to obtain gt x 0 dx t x 0 dx since x 0 0 and x 0 1 are fixed points of t it follows that 0 and 1 are fixed points of gt we now prove when the fixed points are stable we begin with a lemma which gives more general conditions than those given in theorem 3 for the delta measure at zero to attract a given initial condition lemma 7 if for some 0 lim x 0 x 0 1 x 1 then t 0 as t in particular this condition holds if 0 1 1 0 for some 0 to prove this and subsequent results we will need the following technical lemma lemma 8 setting h t x t the following two implications hold 0 h t dt h t 0 as t 0 1 h t dt h t 1 as t scaling limits of a model for selection at two scales 13 proof of lemma 8 since h t 0 and 1 h t 0 the only obstruction to the implication is that h t or 1 h t could have ever shorter and shorter intervals were they return to an order one value before returning to a value close to zero this would require h t to have unbounded derivatives however this is not possible since dh dt t h x 2 t x 2 t h 2 from which one easily see that 1 dh dt t since 0 h x 2 t 1 and 0 x 2 t h 2 1 proof of lemma 7 as usual let h t x t we begin by observing that if 0 h t dt then h t 0 as t by lemma 8 and t 0 as we wish to prove thus we henceforth assume that 0 h t dt under this assumption we will show that for any continuous function f 1 0 f x t dx f 0 as t since f is continuous given any 0 there exists a 0 so that f x f 0 whenever x hence 12 1 0 f x t dx f 0 1 0 f x f 0 t dx 1 f x f 0 t dx now setting 1 f x f 0 t dx 1 1 t f t x f 0 wt t x 0 dx 2 f 1 1 t wt t y 0 dy since for all y 1 t 1 and t 0 we have wt t y e t t 0 h s ds we see that 1 f x f 0 t dx 2 f e t t 0 h s ds 0 1 t 1 now using the assumptions on 0 and that 1 t 1 de t for some d 0 and all t 0 one has that e t t 0 h s ds 0 1 t 1 d e t t 0 h s ds for some constant d and all t 0 since and 0 h s ds this bound converges to zero as t and the proof is complete as the in 12 was arbitrary 14 shishi luo jonathan c mattingly proof of theorem 3 we start with the setting when 0 1 0 and begin by writing t dx at 1 dx 1 at t dx for some time dependent process at 0 1 with a 0 0 and some probability measure valued process t dx as usual we define h t x t and using the representation given in 7 one sees that at solves dat dt at 1 h t at a 0 exp t 0 1 h s ds since 1 h t 0 we know that t 0 1 h s ds converges as t if it converges to then at also converges to since a 0 0 however this is impossible since at 0 1 for all t 0 thus we conclude that t 0 1 h s ds then lemma 8 implies that h t 1 which in turn implies that t 1 as t we know turn to the setting when x 0 1 x 1 c 0 as x 0 the case when is already handled by lemma 7 leaving only the case when 0 to be proven for x 0 1 define u x 0 0 x since 0 is a probability measure we know that u has finite variation and is regular in the sense that both the right limit u x and the left limit u x exist where u x limu y as y x at the extreme points only the limit obtained by staying in 0 1 is defined now for any smooth function f of 0 1 we have from 7 that 1 0 f x t dx zt 1 0 f x gt x 0 1 t dx zt 1 0 fgt t x 0 dx where wt x has been written as the product of gt x e t x 1 e t and zt some positive time dependent normalizing constant it is enough to show that for some time positive dependent constant kt 13 kt 1 0 fgt t x 0 dx 1 0 f x x 1 1 x 1 dx as t since x 7 f x gt x is continuous on 0 1 even if u x has discontinuities the integration by parts formula for lebesgue stieltjes integrals produces 1 0 fgt t x 0 dx fgtu 1 fgtu 0 1 0 x fgt t x u x dx fgt u 1 1 fgt 1 u 0 1 0 x fgt t x 1 u x dx here we have used that t is continuous with t 1 1 and t 0 0 first observe that 1 u 1 0 since 0 1 x 1 0 as x 0 by assumption and that gt 0 e t hence 14 fgt 1 u 1 fgt u 1 0 u 0 1 f 0 e t now turning to the integral term applying the chain rule and changing variables to y t x produces 1 0 x fgt t x 1 u x dx 1 0 x fgt t x 1 u x x t x dx 1 0 x fgt y 1 u 1 t y dy scaling limits of a model for selection at two scales 15 for any fixed x 0 1 by direct calculation and use of the assumption on 0 one sees that x fgt x x x f x e t 1 u 1 t x e t 0 1 t x 1 c 1 x x as t combining these facts with 14 and the fact that e t 0 as t since produces e t 1 0 fgt t x 0 dx c 1 0 x x f x 1 x x dx as t for some new positive constant c now since integration by parts implies that 1 1 0 x x f x 1 x x dx 1 0 f x x 1 1 x 1 dx the last part of the proof is complete 4 proofs of weak convergence the proofs of theorems 1 and 4 follow a standard procedure 11 10 3 both proofs require i tightness of the sequence of stochastic processes which implies a subsequential limit and ii uniqueness of this limit for the tightness of m nt m n on d 0 t p 0 1 it is sufficient by theorem 14 26 in kallenberg 12 to show that f m nt is tight on d 0 t r for any test function f from a countably dense subset of continuous positive functions on 0 1 for the uniqueness of solutions to the partial differential equation in theorem 1 we apply gronwall s inequality for uniqueness of solutions to the martingale problem in theorem 4 we apply a girsanov theorem by dawson 4 4 1 semimartingale property of multilevel selection process it will be useful for what follows to treat f m nt as a semimartingale below d x f is the first order difference quotient of f taken from the right d x f is the first order difference quotient of f taken from the left and dxxf is the second order difference quotient lemma 9 for f c 2 0 1 and m nt with generator lm n defined in 1 f m nt f m n 0 a m n t f m m n t f 15 where a m n t f is a process of finite variation a m n t f t 0 am nz f dz with a m n t f i m n t i n i n 1 i n 1 n dxxf i n sd x f i n 16 wr j m n t j n j n f j n i m n t i n f i n j m n t j n j n and m m n t f is a ca dla g martingale with conditional quadratic variation mm n f t 1 m t 0 1 n i m nz i n i n 1 i n d x f i n 2 1 s d x f i n 2 w i j m nz i n m nz j n 1 r j n f i n f j n 2 dz 17 16 shishi luo jonathan c mattingly proof by dynkin s formula see for example lemma 17 21 in 12 m n t m n 0 t 0 lm n m ns ds where dom lm n is a ca dla g martingale in particular this is true for m n t f f m n t where f c 2 0 1 and f r r setting f x x and plugging this f into 1 lm n f v i v i n i n 1 i n 1 n dxxf i n sd x f i n wr j v j n j n f j n i v i n f i n j v j n j n thus f m nt f m n 0 t 0 am nz f dz m m n t f 18 where m m n t f is some martingale and a m n t f l m n f m nt at f is a process of finite variation because for a given f a m n t f is uniformly bounded in t next setting f x x 2 and plugging this into 1 lm n f 2 v 2 f v am nt f 1 mn i v i n i n 1 i n d x f i n 2 1 s d x f i n 2 w m i j v i n v j n 1 r j n f i n f j n 2 thus f m nt 2 f m n 0 2 t 0 cm nz f dz martingale 19 where c m n t f l m n f 2 m nt alternatively take yt f m n t and apply ito s formula for example p 78 in 15 to y 2 t to obtain f m nt 2 f m n 0 2 2 t 0 f z am nz f dz m m n f t martingale 20 where mm n f t is the quadratic variation process of m m n t since mm n f t is the com pensator of mm n f t mm n f t mm n f t is a martingale thus f m nt 2 f m n 0 2 2 t 0 f m nz a m n z f dz m m n f t martingale 21 the compensator mm n f t is a predictable process of finite variation see p 118 in 15 by the doob meyer inequality p 103 in 15 the martingale in 21 is the same as the scaling limits of a model for selection at two scales 17 martingale in 19 equating these martingale parts we obtain 2 t 0 f m nz a m n z f dz m m n f t t 0 cm nz f dz 22 substituting in the expressions for am nz and c m n z then gives the explicit expression for the conditional quadratic variation 17 in the statement of the lemma 4 2 proof of deterministic limit to prove theorem 1 we need the two following lem mas the first uses criteria in billingsley 2 to show tightness of the sequence of processes f m nt the second uses gronwall s inequality to show uniqueness of solutions to the limiting system lemma 10 the processes f m nt as a sequence in m n is tight for all positive valued test functions f c 1 0 1 proof by theorem 13 2 in 2 a sequence of probability measures pn on d 0 t r is tight if and only if i for all 0 there exists a such that pn x sup t 0 t x t a for n 1 and ii for all 0 and 0 there exists 0 1 and n 0 such that pn x w x for all n n 0 where w is the modulus of continuity for ca dla g processes and is defined w x inf ti max 1 i v sup s t ti 1 ti x s x t where ti is a partition of 0 t such that max i ti ti 1 and x d 0 t r is distributed according to pn first note that since m n t is a probability measure we have f m nt f for all t m and n thus i holds for ii we have by markov s inequality pm n w 1 em n w 23 where w w f m nt we will use the fact that f m nt is a pure jump process to bound the right hand side the process f m nt has two types of jumps nearest neighbor and occupied site jumps nearest neighbor jumps occur at rate i m m n t i n i 1 i n 2 s mn 4 2 s and have magnitude f m nt f m n t f m nt 1 m i 1 n in f m nt 1 mn maxi d x f in occupied site jumps occur at rate i j m m n t i n m n t j n 1 r j n m 1 r 18 shishi luo jonathan c mattingly and have magnitude f m nt f m n t f m nt 1 m jn in f m nt 2 m f putting this together em n w em n number of nearest neighbor jumps in time 1 mn maxi d x f i n em n number of occupied site jumps in time 2 1 m f mn 4 2 s 1 mn max i d x f i n m 1 r 2 m f 2 s 4 max i d x f i n 2 1 r f because f c 1 0 1 the expression in curly brackets is uniformly bounded by cf a constant that depends on f but not on m nor n substituting the above into 23 we get that for cf pm n w for all m and n thus both conditions for tightness are satisfied and f m nt is tight lemma 11 the integro partial differential equation 2 in theorem 1 has a unique solution proof suppose t satisfies 2 fix t 0 and let t x be a function of time t and space x by the chain rule and the differential equation 2 d dt t t ddz z t z t d dz t z z t t t t sx 1 x t x t wr x t t t t x t t t 0 0 t 0 z z x g z x z dz 24 wr t 0 x z z z z x z dz where gf sx 1 x x f let pt be the semigroup operator associated with g in fact using the method of characteristics or lemma 5 with 0 ptf f xe st 1 x xe st 25 now set z x pt zf x for 0 z t where f c 1 0 1 is some test function substituting this into 24 we have p 0 f t ptf 0 t 0 z pt zf x gpt zf x z dz t 0 wr xpt zf z pt zf z x z dz f t ptf 0 t 0 wr xpt zf z pt zf z x z dz 26 since z pt zf gpt zf thus any t that satisfies 2 also satisfies 26 we show that 26 has a unique solution which in turn implies that 2 has a unique solution scaling limits of a model for selection at two scales 19 suppose t and t both satisfy 26 with 0 0 let t 0 t t tv sup f 1 f t f t sup f 1 t 0 wr xpt zf z z wr x z pt zf z x z pt zf z dz 27 we can bound the first term in the integrand by wr xpt zf z z wr z z tv because xpt zf pt zf f 1 where the first inequality follows from x 0 1 and the second from 25 for the second term in the integrand of 27 add and subtract x z pt zf z wr x z pt zf z x z pt zf z wr x z z pt zf z x z pt zf z z wr pt zf z z tv z z tv wr f 1 z z tv again the inequalities follow from x 0 1 ptf f and also that z and z are probability measures substituting this back into 27 t t tv t 0 3 wr z z tv dz by gronwall s inequality t t tv 0 so we have uniqueness proof of theorem 1 the uniqueness of the limit is given by lemma 11 and the tightness of the process by lemma 10 it remains to show that f m nt m n converges to the solution of 2 recall from lemma 9 that f m nt f m n 0 a m n t f m m n t f since tightness implies relative compactness prohorov s theorem there exists a subsequence of m n t that converges to a limit call it t thus f m n t f t we also have f m n 0 f 0 by assumption in addition a m n t f t 0 i m nz i n i n 1 i n 1 n dxxf i n sd x f i n wr j m nz j n j n f j n i m nz i n f i n j m nz j n j n dz t 0 x 1 x s df dx z wr xf x z f x z x z dz at f the factor of 1 m in the quadratic variation 17 implies that m m n t 0 as m n therefore f t f 0 at f or d dt f t x 1 x s dfdx t wr xf x t f x t x t 20 shishi luo jonathan c mattingly 4 3 proof of fleming viot limit the elementary proof for tightness in theorem 1 does not easily carry over for the case of theorem 4 we thus use a criterion by aldous 1 to prove tightness for the martingale part of the stochastic process first consider the semimartingale formulation of f m nt 15 with the rescaled param eters s n and r m let e m n t f t 0 em nz f dz and n m n t f denote the drift and martingale parts of f m nt the rescaled process then e m n t f t 0 i m nz i n i n 1 i n dxxf i n d x f i n 28 w n m j nz j n j n f j n i nz i n f i n j nz j n j n dz and nm n f t t 0 n m 2 i m nz i n i n 1 i n d x f i n 2 1 n d x f i n 2 29 w n m i j m nz i n m n t j n 1 m j n f i n f j n 2 dz lemma 12 the processes f m nt as a sequence in m n is tight for all f c 2 0 1 proof since f m nt e m n t f n m n t f it suffices by the triangle inequality applied to billingsley s tightness criterion theorem 13 2 in 2 to show tightness of em n f and nm n f separately for the tightness of the finite variation term e m n t f em nt f 1 4 i m nz i n dxxf in d x f in w n m j nz j n j n f j n i nz i n f i n j nz j n j n for a given 0 we can choose n and m sufficiently large such that n m dxxf in f and d x f i n f we thus obtain em nt f 1 4 f f 2 w f there are only a finite number of m and n for which this condition is not satisfied taking the maximum of the right hand side of the above equation with the value of em nt f for such m and n we obtain that for all m and n em nt f gf and therefore sup t 0 t em nt f gft where gf is a constant that depends on f using the same conditions for tightness as in the proof of theorem 1 condition i is satisfied because e m n t f is bounded uniformly in t m and n condition ii is satisfied because em nt e m n t gf for all t m and n and scaling limits of a model for selection at two scales 21 therefore we can always choose to be sufficiently small so that em nt e m n t for some prescribed we will show tightness for the martingale part nm nt f t using aldous tightness condition we use the result as stated in 7 first note that by equation 29 nm nt f t jf t for f c 2 0 1 where jf is a constant that depends on f thus for fixed t pm n n m n t f a 1 a em n n m n t f 1 a em n n m n t f 2 1 2 1 a em n n m n t f t 1 2 jf t a given 0 choose a jf t and we have that n m n t f is tight for each t next let be a stopping time bounded by t and let 0 for 0 pm n n m n f n m n f 1 em n n m n f n m n f now suppressing subscripts on expected value for clarity e nm n f n m n f e nm n f n m n f 2 1 2 e nm n f 2 nm n f 2 2 nm n f n m n f n m n f 1 2 e nm n f nm n f 1 2 jf hence pm n n m n f n m n f 1 jf by taking 4 jf we satisfy the conditions of aldous stopping criterion lemma 13 the martingale problem 5 and 6 has a unique solution proof the martingale problem with v t x 0 corresponds to a neutral fleming viot with linear mutation operator its uniqueness has previously been established see for exam ple 4 to show uniqueness for nontrivial v we use a girsanov type transform by dawson 4 it suffices to check that sup t x v t x v 0 a constant 30 in our case v t x x and since x 0 1 the condition is satisfied and the martingale problem has a unique solution proof of theorem 4 the uniqueness of the limit is given by lemma 13 and the tightness of the process by lemma 12 to see that the limit is the martingale problem stated in theorem 4 note that for a fixed t e m n t f t 0 1 0 x 1 x 2 x 2 f x s f x z dx w 1 0 xf x z dx 1 0 f x z dx 1 0 x z dx dz 22 shishi luo jonathan c mattingly as n m and nm n f t t 0 w 1 0 1 0 f x f y 2 z dx z dy dz finally notice that 1 0 1 0 f x f y 2 z dx z dy 2 1 0 1 0 f x 2 z dx z dy 2 1 0 1 0 f x f y z dx z dy 2 1 0 1 0 f x f y z dx x dy z dy and 1 0 xf x z dx 1 0 f x z dx 1 0 x z dx 1 0 1 0 f x y z dx x dy z dx satisfying the form of the martingale problem in the theorem scaling limits of a model for selection at two scales 23 references 1 david aldous stopping times and tightness the annals of probability 6 2 pp 335 340 1978 2 patrick billingsley convergence of probability measures wiley interscience 2 edition 1999 3 nicolas champagnat re gis ferrie re and sylvie me le ard unifying evolutionary dynamics from indi vidual stochastic processes to macroscopic models theor pop biol 69 3 297 321 2006 4 donald a dawson introductory leture on stochastic population systems technical report series of the laboratory for research statistics and probability technical report 451 carleton university university of ottawa 2010 5 donald a dawson and k j hochberg a multilevel branching model advances in applied probability 23 701 715 1991 6 richard durrett probability models for dna sequence evolution springer 2 nd edition 2008 7 alison etheridge an introduction to superprocesses american mathematical soc 2000 8 s n ethier and thomas g kurtz fleming viot processes in population genetics 31 2 42 1993 9 wendell h fleming and michel viot some measure valued markov processes in population genetics theory indiana university mathematics journal 28 5 817 843 1979 10 nicolas fournier and sylvie me le ard a microscopic probabilistic description of a locally regulated population and macroscopic approximations ann appl probab 14 4 1880 1919 2004 11 a joffe and m metivier weak convergence of sequences of semimartingales with applications to multi type branching processes advances in applied probability 18 20 65 1986 12 olav kallenberg foundations of modern probability springer 1 st edition 1997 13 shishi luo a unifying framework reveals key properties of multilevel selection j theor biol 341 41 52 2014 14 yehuda pinchover and jacob rubinstein an introduction to partial differential equations cambridge university press 2005 15 philip e protter stochastic integration and differential equations springer 2 nd edition 2004 abstract 1 introduction 2 main results 3 properties of the deterministic limit 4 proofs of weak convergence 4 1 semimartingale property of multilevel selection process 4 2 proof of deterministic limit 4 3 proof of fleming viot limit references