author guidelines for 8 weeping and gnashing of teeth teaching deep learning in image and video processing classes al bovik director laboratory for image and video engineering the university of texas at austin abstract in this rather informal paper and talk i will discuss my own experiences feelings and evolution as an image processing and digital video educator trying to navigate the deep learning revolution i will discuss my own ups and downs of trying to deal with extremely rapid technological changes and how i have reacted to and dealt with consequent dramatic changes in the relevance of the topics i ve taught for three decades i have arranged the discussion in terms of the stages over time of my progression dealing with these sea changes index terms image processing education digital video education deep learning machine learning 1 blissful ignorance in the year 2012 i had been giving undergrad classroom lectures on digital image and video processing for more than two decades my prepared course materials covered the essential topics of image formation sampling and fourier theory wavelets linear and nonlinear filtering image coding and feature detection using log and dog sift and surf using them for picture quality prediction texture analysis edge boundary and line detection visual search 3 d stereo ranging motion and optical flow i updated my topics as technology progressed but changes large enough to affect my courseware were easy to keep up with along with hundreds of powerpoint slides i had developed dozens of image processing programs with which i could demo the effects of varying algorithm parameters on visual outcomes in real time 1 i taught perceptual theory and showed dozens of visual illusions a hobby of mine which helped students understand how we see and even affect certain algorithms years later some students remembered these illusions when they chanced upon other ones which they passed to me often to join the others in class i used my own book as a supplement always had good attendance and great fun the topic sells itself received excellent course ratings and hardly had to prepare for each lecture i even wrote about my educational methods for image processing in ieee journals 2 3 overall teaching was a blissful experience and as i thought would be for decades longer 2 denial however also in 2012 the famous alexnet imagenet paper was published 4 needless to say a bomb had dropped on the machine learning and computer vision communities overnight the attentions of workers in those fields turned to deep models of anything with large data and spectacular results were obtained on natural language processing and most problems in computer vision chatting about this with an ml colleague i observed they sure are getting cited a lot aren t they to which he replied um they are the only papers being cited with a nervous smile well this wasn t the case in the field of image processing and i saw little need to worry much after all those researchers were primarily interested in classifying and identifying objects and words whereas we dealt with pictures intended for people to look at not robots why hop on the neural net bandwagon i was old enough to have already seen three or four machine learning waves perceptrons artificial neural nets convnets and support vector machines each accompanied by considerable hype and some degree of letdown at least in terms of real world applications yet it was at least worth chatting about the deep learning wave with my class usually accompanied by the observations just made and noting that well it is perhaps no surprise that incredibly powerful gpus crunching to optimize a model having 40 million free parameters might do pretty well and don t forget what von neuman said with four parameters i can fit an elephant and with five i can make him wiggle his trunk anyway i felt no need to start lecturing on these cumbersome algorithms that took days weeks or even months to train interesting yes but not very practical as a friend said who is a very notable neurobiologist and bioengineer deep learning bah glorified curve fitting well as my students would say he was not wrong but my work on the research side rather reinforced these rather negative viewpoints with an interest in its possibilities deepti ghadiyaram and i published one of the earliest papers if not the first on picture quality prediction using deep belief nets 5 unfortunately when trained and tested on the new live challenge picture quality database which was the largest database then available 6 but see 7 the deep models could not attain the performance of simple natural scene based models like brisque 8 and friquee 9 rigorous tests on other researchers deep models produced similar results 10 it was becoming clear that these deep models needed much more data than was available in the field of perceptual image processing where careful psychophysics experiments were required unlike human participation in crowdsourced picture labeling experiments like imagenet 11 where each human label might need only 0 5 1 0 sec to apply human quality judgments on pictures generally required 10 20 x that amount to time for a subject to feel comfortable in making their assessments on a likert scale 6 in other words i was able to hide behind a great wall of non existent perceptual data even if other areas of image processing were being infiltrated which they weren t yet after all popular picture and video quality algorithms still ruled the world jpeg and mpeg compressed most moving bits a figure that now approaches 75 of all internet data our own algorithms for picture and video quality were being used throughout industry and silicon valley was keeping my graduate students quite busy only deep learning papers were cited ours were doing pretty well what me worry 12 back in the classroom students still loved learning about image processing and i kept updating it with things like haar cascades for face detection natural scene statistics models and no reference picture quality and more deep networks well they hadn t impacted image processing much yet generative adversarial networks gans and all those synthetic people pictures hmmm seemed like learned database interpolation to me anyway the field had so expanded in terms of both material and student interest that in 2014 i created a new graduate class on digital video replete with hundreds of playable video examples showing every aspect of the various parameters loads of spatio temporal perceptual theory and a high level of math rigor for a video class however no deep learning at all why would i there wasn t any work to speak of on deep video analysis anyway what train a network for 6 months on what dataset what kind of hardware would this run on in the real work will there be gpus on the same soc as mpeg video decoders will they industry stack the chips surely not 3 realization anyway even if an old dog cannot easily learn new tricks s he can at least still watch the puppies play and master them researchers more perspicacious than i or at least readier to try the new thing began to apply deep learning models to practical problems of regression on images the results they obtained were provocative and often state of the art sota a good example is the simple residual based denoiser of my colleague lei zhang s group 13 a simple network and data handling process leading to exceptional results plenty of other researchers were getting great results on image processing problems using varieties of deep nets true they didn t operate in my space of perception based analysis where i had my great wall of non data but it was obvious that things were changing on the research side we were beginning to deploy more sophisticated machine learning models and especially methods of transfer learning exploiting the generalizability of deep networks perhaps their most amazing property and in the news there were stories of high school kagglers solving all kinds of interesting problems using ultra accessible new libraries devoted to making deep learning easy most disturbing of all were my students class projects in all my classes i assign a semester long class project with a possible reward of best project culminating in not having to take the final exam the projects that are produced to compete for an automatic a on the final are always amazing and are helped along by the class demos at the end of the semester where the students voted on the winners rather than a finicky professor what bothered me a bit was that the projects increasingly used deep learning none of which i taught in the class the solutions were better and the problems solved were more complex e g gesture recognition image compression style transfer and much more even as my own hairs were getting grayer i began to feel that my teaching of image processing an important part of my professional identity that i took very seriously was in danger of becoming obsolete soon i figured the students would be whispering old boomer he s still living in the past i d take the computer vision class over in cs instead 4 dispair sure enough by 2016 i was beginning to notice the effects on my teaching program attendance was noticeably dropping in my classes at first i attributed this to just part of the irrational rush into data science when in the fall attendance in my image processing class fell by 30 from the previous years even worse in the spring of 2017 a promising enrollment of 25 students in my advanced grad class digital video fell precipitously after the first week a couple of students asked me after class i didn t see deep learning on the syllabus will you be covering that i was a bit dismayed to tell them well not this time it hasn t really started to impact video yet which truth be told was not quite true anymore in any case a week later enrollment was at 14 while the new large scale optimization class being offered had to turn away students after reaching the room limit of 100 ok boomer it suddenly felt a bit odd trudging through the rather heavy math i offered throughout the early parts of the class once a highlight of the material developing high dimensional transforms and the theory of space time distributions but how can motion in videos be understood without covering singularity theory but of course parallel to my own woes things were changing everywhere one time high impact champion ieee transactions on information theory was beginning its descent to levels just above the ieee journal of oceanic engineering where it currently languishes i cast no aspersion on either and have published in both i would wince when i would read papers pronouncing new heights in deep network performance on problems old and new some unimaginable where the authors would inevitably compare their results with the handcrafted method of so and so not quite pejorative but getting there how brilliant to instead shovel data into a computing engine what of all those years of actually thinking of dissecting the little knowledge we had of brain function developing and deploying models of neural function to create amazing and useful picture processing algorithms i began to feel like an old wood carver slowly chipping away outside a great and shining high tech city creating interesting little doo dads watching each passerby hoping to catch someone s eye the less indelicate of these computer science authors would instead refer to anything using features no matter if derived from neurophysiological measurements statistical physics or mathematical deduction as engineered thanks for that this was mainly a concern in the classroom of course my course materials were clearly becoming obsolete at an astonishing pace on the research side my students were adaptive and adopting all kinds of machine learning methods into their creative efforts as always i learn more from them than they from i something had to change however in my teaching of image and video processing and soon 5 acceptance my method of instruction tends towards the exceedingly prepared each semester i charge through about 1000 powerpoint slides at a rate of 40 day showing live action visual examples throughout while i was once comfortable chalking away clouds of dust teaching dsp it isn t practical when students need to see the results and when the volume of material has become immense given the cross disciplinary nature of the field and the explosion of applications there is huge ground to cover in any case creating substantial modifications in a massively prepared class like mine is like steering a battleship nevertheless i steeled myself to do just that one class after the other beginning with the undergraduate image processing class to enable this i took a paid faculty leave in the spring of 2018 so that i could focus on recreating digital image processing in the deep learning age i did not suspect that i would need to do it again the following spring to be able to accomplish the same thing in the digital video class 6 action once resolved i eyeballed my notes and realized that the task ahead would require hundreds of hours of work i wanted the class to be special and complete as it had once been and in particular i wanted it to be immersively visual we are all visual creatures with about 50 of brain function implicated in sight but i think i am far more so so that is my preferred way of teaching as well wherever i travel my first stop is at the local gallery and visits to london paris and florence are tireless hikes to see every great work of art for me a week without visiting the cinema leads to withdrawal symptoms anyway the task ahead seemed daunting for the image processing class i wanted to immerse the students from beginning to end in both classical image processing as well as machine learning how to do both i decided that since many students would enter class without any exposure to machine learning as with many schools we are unprepared still to handle this cresting wave i would have to start at the beginning in this way i could also make my own command of the subject matter completer and more authoritative so i created hundreds of slides on machine learning beginning with the perceptron it took many months hundreds of hours of creating colorful slides diagrams and visual examples i covered multi layer perceptrons mlps and backprop radial basis functions and support vector machines arriving at convnets revealing the amazing vgg 16 14 which we would dissect in detail a wonderful exemplar of many of the principles of deep learning and still popular today as a deep feature model then on to resnet 15 the biggest advance since alexnet and imagenet autoencoders and the wonders of transfer learning i was determined to find and give instruction on the most interesting and important applications of deep learning in denoising image compression picture quality prediction recognition and computational stereopsis while retaining as much fundamental classic material as i could the problem was what to retain so much material had to be simply eliminated like the vacuum tube after much contemplation things began to be surgically excised like mathematical morphology except on binary pictures anisotropic diffusion order statistic filters and am fm image models i chewed my lip over edge detection and finally retained half of it if only to exemplify the utility of the image gradient and to explain connections between retinal processing dog log and image processing applications like ssim 16 brisque sift 17 and surf 18 finally this long process was over just as the fall 2019 semester was commencing i advertised the class as digital image processing in a flyer with a list the topics covered new and old emblazoned by with deep learning superimposed before long 100 students had signed onto the class and nearly all 90 of them stayed the course and i had more fun than i could have imagined both reveling in the magical results of deep models and as i discovered combining my teachings on old and new ideas to create a richer learning experience after all concepts like resnet can be understood not only from the data science perspective allowing very deep models to be built with better convergence and less overfitting or vanishing gradients but this is hardly a surprise to neuroscientists after all the neurovisual system has evolved not only to optimal filters like gabor functions similar to the early layers of an imagenet trained deep net but also to exploit the considerable redundancies in visual data via processes of normalization similar to residual coding from that perspective it all dates back to barlow s efficient coding hypothesis 19 in any case the course was successful the student projects were more amazing than ever the feedback i received was uniformly positive and all in all it was enormously satisfying to find myself once again teaching things that were sota and relevant to the moment of course i still had my graduate course to consider and so now emboldened i repeated the process once again wielding the scimitar but with even more energy as great swathes of mathematics and proofs sampling theory wavelet theory and filter theory were simply axed to preserve my dignity i kept much of this material linking it to the lectures where appropriate in case there were any students remaining who appreciated the analysis side of digital video yes but wavelet theory gone well yes after all neurophysiological systems like deep nets it seems seek efficient processing through massively overcomplete representations no need to discuss perfect reconstruction after all in addition to increasing the sophistication and timeliness of the deep learning material to include modern innovations like densenet 20 and resnext 21 i needed to also lecture on global to local networks like faster r cnns 22 space time networks like flownet 23 gans and how to use these in advanced applications in motion estimation video compression video quality prediction and more in fact it is mid semester into this class as i write this little paper and i have just finished placing the finishing touches on those notes and just in time as the class lectures are catching up to the notes i am having fun again i have 35 students in the class and i am very much looking forward to the class projects presentations and demonstrations on digital video most involving deep learning models in the final 2 3 days of the semester i am sure the students will surprise and amaze me as they always do 7 how i learned to stop worrying and love the bomb i have never actually been interested in the topic of neural networks other than long ago understanding the properties of mlps backpropagation and the universal approximation theorems i have largely ignored them sure i think everyone understood their eventual potential and that indeed one day they would become the key to artificial intelligence after all massive connectivity and all that right still they are nothing more than optimization machines with zillions of parameters why shouldn t they be able to learn just about any dataset indeed they are still boring to me in that way since i am generally only excited about things related to understanding visual processing and visual perception and a black box that generates high f 1 scores is not that however deep learning engines are definitely not boring in that they can be explained as achieving the optimizations that we have long taught of multiscale processing sparsity space frequency localization linear and nonlinear models of feature abstraction and adaptation to the natural statistics of the visual world even more so they are unlimited in their applications and in their ability to realize concepts that we have tried to solve for many years but have been only poorly implemented in the old ways in the future i think we will see deep networks being used to control the efficiency of most of the data being transported over the internet nearly all of which will be pictures and videos it will be exciting to be part of that for the few decades i have left conducting research and teaching and seeing the kinds of applications i have imagined for many years dating long before most people knew what a digital picture was realized at the largest scales it will be even more satisfying to lecture and teach these topics since this is why i come to the university far more so than to conduct research despite all the energy i put into that 8 nirvana i think that a lot of other professors of image and video processing as well as of computer vision must have had similar experiences as i have i haven t been able to fully express how much the deep learning revolution has affected me but i can say that it has substantially affected my professional life to a greater degree than anything since my assistant professor years 35 years ago it s also given me a sense of accomplishment to catch up to this wave in the classroom i hope to hear from others their own experiences and ways of dealing with these major changes as always all of my course materials are freely available for others to use you can preview the course notes in pdf form without links programs or visual illusions on the live website 24 and i am happy to share the powerpoints in their entirety on request after all teaching is blissful again 12 references 1 u rajashekar g panayi f baumgartner and a c bovik didactic tools for signal image and video processing education https live ece utexas edu class siva default htm 2 u rajashekar g panayi and f p baumgartner and a c bovik the siva demonstration gallery for signal image and video processing education ieee transactions on education vol 45 no 4 pp 323 335 nov 2002 3 a c bovik what you see is what you learn ieee signal processing magazine vol 27 no 5 pp 117 123 sept 2010 4 a krizhevsky i sutskever and g e hinton imagenet classification with deep convolutional neural networks advances in neural information processing systems nips 2012 5 d ghadiyaram and a c bovik blind image quality assessment on real distorted images using deep belief nets ieee global conference on signal and information processing globalsip 2014 6 d ghadiyaram and a c bovik massive online crowdsourced study of subjective and objective picture quality ieee transactions on image processing vol 25 no 1 pp 372 387 jan 2016 7 z ying h niu p gupta d mahajan d ghadiyaram and a c bovik from patches to pictures paq 2 piq mapping the perceptual space of picture quality arxiv 1912 10088 dec 2019 8 a mittal a k moorthy and a c bovik no reference image quality assessment in the spatial domain ieee transactions on image processing vol 21 no 12 pp 4695 4708 dec 2012 9 d ghadiyaram and a c bovik perceptual quality prediction on authentically distorted images using a bag of features approach journal of vision vol 17 no 1 art 32 doi 10 1167 17 1 32 pp 1 25 jan 2017 10 j kim h zeng d ghadiyaram s lee l zhang and a c bovik deep convolutional neural models for picture quality prediction ieee signal processing magazine special issue on deep learning for visual understanding vol 34 no 6 pp 130 141 nov 2017 11 j deng w dong r socher l j li k li and l fei fei imagenet a large scale hierarchical image database ieee international conference on computer vision and pattern recognition cvpr 2009 12 b sanders mad magazine in the remedial english class the english journal vol 59 no 2 pp 266 272 feb 1970 13 k zhang w zuo y chen d meng and l zhang beyond a gaussian denoiser residual learning of deep cnn for image denoising ieee transactions on image processing vol 26 no 7 pp 3142 3155 feb 2017 14 k simonyan and a zisserman very deep convolutional networks for large scale image recognition arxiv 1409 1556 2014 15 k he x zhang s ren and j sun deep residual learning for image recognition ieee international conference on computer vision and pattern recognition cvpr 2009 16 z wang a c bovik h r sheikh and e p simoncelli image quality assessment from error visibility to structural similarity ieee transactions on image processing vol 13 no 4 pp 600 612 apr 2004 17 d g lowe distinctive image features from scale invariant keypoints international journal of computer vision vol 60 no 2 pp 91 110 nov 2004 18 h bay t tuytelaars and l van gool surf speeded up robust features european conference on computer vision may 2006 19 h b barlow possible principles underlying the transformation of sensory messages in sensory communication w a rosenblith ed cambridge ma m i t press pp 217 234 1961 20 g huang z liu g pleiss l van der maaten and k weinberger k convolutional networks with dense connectivity ieee trans pattern anal machine intell may 2019 21 s xie r girshick p doll r z tu and k he aggregated residual transformations for deep neural networks ieee international conference on computer vision and pattern recognition cvpr 2017 22 s ren k he r girshick and j sun faster r cnn towards real time object detection with region proposal networks advances in neural information processing systems nips 2015 23 a dosovitskiy p fischer e ilg p hausser c hazirbas v golkov p van der smagt d cremers and t brox flownet learning optical flow with convolutional networks international conference on computer vision iccv 2015 24 laboratory for image and video engineering live https live ece utexas edu 2020 https live ece utexas edu class siva default htm https arxiv org abs 1912 10088 https live ece utexas edu weeping and gnashing of teeth teaching deep learning in image and video processing classes abstract