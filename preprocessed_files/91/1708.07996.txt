ar x iv 1 70 8 07 99 6 v 1 q fi n e c 2 6 a ug 2 01 7 a simple algorithm for solving ramsey optimal policy with exogenous forcing variables jean bernard chatelain and kirsten ralf june 20 2018 abstract this algorithm extends ljungqvist and sargent 2012 algorithm of stackelberg dynamic game to the case of dynamic stochastic general equilibrium models includ ing exogenous forcing variables it is based anderson hansen mcgrattan sargent 1996 discounted augmented linear quadratic regulator it adds an intermediate step in solving a sylvester equation forward looking variables are also optimally anchored on forcing variables this simple algorithm calls for already programmed routines for ricatti sylvester and inverse matrix in matlab and scilab a final step using a change of basis vector computes a vector auto regressive representa tion including ramsey optimal policy rule function of lagged observable variables when the exogenous forcing variables are not observable jel classification numbers c 61 c 62 c 73 e 47 e 52 e 61 e 63 keywords ramsey optimal policy stackelberg dynamic game algorithm forcing variables augmented linear quadratic regulator 1 introduction ljungqvist and sargent 2012 chapter 19 offer an elegant algorithm of stackelberg dy namic game used for ramsey optimal policy all dynamic stochastic general equilibrium dsge models include exogenous auto regressive forcing variables which are not in cluded in their algorithm this algorithm extends ljungqvist and sargent 2012 chapter 19 algorithm of dynamic stackelberg game to the case of dsge models including ex ogenous forcing variables we use anderson hansen mcgrattan sargent 1996 discounted augmented linear quadratic regulator after the usual algorithm for solving the riccati equation of the linear quadratic regulator amman 1996 this algorithm adds another step in solving a sylvester equation for completing the policy rule it also adds a term for the optimal initial anchor of forward looking variables on the predetermined forcing variables this algorithm is easy to code and check it is simple because it only calls already optimized routines solving ricatti and sylvester equations and inverse matrix in matlab paris school of economics universite paris i pantheon sorbonne pjse 48 boulevard jourdan 75014 paris email jean bernard chatelain univ paris 1 fr esce international business school 10 rue sextius michel 75015 paris email kirsten ralf esce fr 1 http arxiv org abs 1708 07996 v 1 and scilab a final step using a change of basis vector computes a vector auto regressive representation of ramsey optimal policy in this representation of the ramsey optimal policy rule policy instruments respond to lagged observable variables if all the exogenous forcing variables are not observable 2 a simple algorithm 2 1 the stackelberg problem we refer to ljungqvist and sargent 2012 chapter 19 step by step the stackelberg leader is the government and the stackelberg follower is the private sector let kt be an nk 1 vector of controllable predetermined state variables with initial conditions k 0 given xt an nx 1 vector of endogenous variables free to jump at t without a given initial condition for x 0 and ut a vector of government policy instruments let yt k t t x t t t be an nk nx 1 vector our only addition to sargent and ljungvist 2012 stackelberg problem is to include zt which an nz 1 vector of non controllable exogenous forcing state variables such as auto regressive shocks all variables are expressed as absolute or proportional deviations about a steady state subject to an initial condition for k 0 and z 0 but not for x 0 a government wants to maximize 1 2 t 0 t ytt qyyyt 2 y t t qyzzt u t t rut 1 where is the policy maker s discount factor and her policy preference are the relative weights included matrices q r qyy 0 is a nk nx nk nx positive symmetric semi definite matrix r 0 is a p p strictly positive symmetric definite matrix so that policy maker s has at least a very small concern for the volatility of policy instruments the cross product of controllable policy targets with non controllable forcing variables ytt qyzzt is introduced by anderson hansen mcgrattan and sargent 1996 to our knowledge it has always been set to zero qyz 0 so far in models of ramsey optimal policy this simplifies the sylvester equation in step 3 the policy transmission mechanism of the private sector s behavior is summarized by this system of equations written in a kalman controllable staircase form etyt 1 zt 1 ayy ayz 0 zy azz yt zt by 0 z ut 2 a is nk nx nz nk nx nz matrix b is the nk nx nz p matrix of the marginal effects of policy instruments ut on next period policy targets yt 1 the government minimizes his discounted objective function by choosing sequences ut xt kt 1 zt 1 t 0 subject to the policy transmission mechanism 2 and subject to 2 nx nk nz boundary conditions detailed below the certainty equivalence principle of the linear quadratic regulator simon 1956 allows us to work with a non stochastic model we would attain the same decision rule if we were to replace xt 1 with the forecast etxt 1 and to add a shock process c t 1 to the right hand side of the private sector policy transmission mechanism where t 1 is an 2 i i d random vector with mean of zero and identity covariance matrix ljungqvist and sargent 2012 p 767 the policy maker s choice can be solve with lagrange multipliers using bellman s method ljungqvist and sargent 2012 it is practical but not necessary to solve the policy maker s choice by attaching a sequence of lagrange multipliers 2 t 1 t 1 to the sequence of private sector s policy transmission mechanism constraints and then forming the lagrangian 1 2 t 0 t ytt qyyyt 2 y t t qyzzt u t t rut 2 t 1 t 1 ayyyt byut yt 1 3 the non controllable variables dynamics can be excluded from the lagrangian ander son hansen mcgrattan and sargent 1996 it is important to partition the lagrange multipliers t conformable with our partition of yt kt xt so that t k t x t where x t is an nx 1 vector of lagrange multipliers of forward looking variables the first order conditions with the policy transmission mechanism leads to the linear hamiltonian system of the discrete time linear quadratic regulator anderson hansen mcgrattan and sargent 1996 2 nx nk nz boundary conditions determining the policy maker s lagrangian system with 2 nx nk nz variables yt t zt with t the policy maker s lagrange multipliers related to each of the controllable variables yt table 1 table 1 2 nx nk nz boundary conditions number boundary conditions nz lim t tzt z 0 zt bounded nk nx lim t tyt y 0 lim t l yt 0 lim t t t t bounded nk nz k 0 and z 0 predetermined given nx x 0 x 0 l x 0 0 x t 0 predetermined essential boundary conditions are the initial conditions of predetermined variables k 0 and z 0 which are given natural boundary conditions are such that the policy maker s anchors unique optimal initial values of private sectors forward looking variables the policy maker s lagrange multipliers of private sector s forward lagrange multipliers variables are predetermined at the value zero x t 0 0 in order to determine the unique optimal initial value x 0 x 0 of private sector s forward variables bryson and ho 1975 p 55 explains natural boundary conditions as follows if xt is not prescribed at t t 0 it does not follow that x t 0 0 in fact there will be an optimum value for x t 0 and it will be such that l 0 for arbitrary small variations of x t 0 around this value for this to be the case we choose l x t 0 x t 0 0 1 which simply says that small changes of the optimal initial value of the forward variables x t 0 on the loss function is zero we have simply traded one boundary condition x t 0 given for another 1 boundary conditions such as 1 are sometimes called natural boundary conditions or transversality conditions associated with the extremum problem anderson hansen mcgrattan and sargent 1996 assume a bounded discounted quadratic loss function 3 e t 0 t ytt yt z t t zt u t t ut 4 this implies a stability criterion for eigenvalues of the dynamic system such that 2 i t 2 i 1 so that stable eigenvalues are such that i 1 1 a preliminary step is to multiply matrices by as follows ayy by in order to apply formulas of riccati and sylvester equations for the non discounted augmented linear quadratic regulator anderson hansen mcgrattan and sargent 1996 2 2 preliminary step check if the system is stabilizable assumption 1 the matrix pair ayy by is controllable all forward looking variables are controllable the matrix pair ayy by is controllable if the kalman 1960 controllability matrix has full rank rank by ayyby 3 2 a 2 yyby n k nx 2 ank nx 1 yy by nk nx 5 assumption 2 the system is stabilizable when the transition matrix azz for the non controllable variables has stable eigenvalues such that i 1 2 3 step 1 stabilizing solution of a linear quadratic regulator step 1 and 2 seems to disregard the forward looking aspect of the problem step 3 will take account of that if we temporarily ignore the fact that the x 0 component of the state y 0 is not actually a state vector then superficially the stackelberg problem has the form of an optimal linear regulator ljungqvist and sargent 2012 p 769 when the forcing variables are set to zero zt 0 a stabilizing solution of the linear quadratic regulator satisfies t pyyt 6 where py solves the matrix riccati equation anderson hansen mcgrattan and sargent 1996 py qy a yypyayy a yypyby r b ypyby 1 b ypyayy 7 the optimal rule of the linear quadratic regulator is ut fyyt 8 where fy is computed knowing py anderson hansen mcgrattan and sargent 1996 fy r b ypyby 1 b ypyayy 9 as demonstrated by simon 1956 certainty equivalence principle and by kalman 1960 solution the optimal rule parameters fy and py of the linear quadratic regulator are independent of additive random shocks and of initial conditions this confirms that it is correct to temporarily ignore the fact that x 0 is not a state vector 4 2 4 step 2 stabilizing solution of an augmented linear quadratic regulator this is the additional step missing in ljungqvist and sargent 2012 algorithm a stabi lizing solution of the augmented linear quadratic regulator satisfies anderson hansen mcgrattan and sargent 1996 t pyyt pzzt 10 where pz solves the matrix sylvester equation pz qyz ayy byfy pyayz ayy byfy pzazz 11 the optimal rule of the augmented linear quadratic regulator is ut fyyt fzzt 12 where fz is computed knowing pz fz r b ypyby 1 b y pyayz pzazz 13 as demonstrated by simon 1956 certainty equivalence principle and by anderson hansen mcgrattan and sargent 1996 solution the optimal rule parameters fz and pz of the augmented linear quadratic regulator are independent of additive random shocks and of initial conditions this confirms that it is correct to temporarily ignore the fact that x 0 is not a state vector until step 3 2 5 step 3 solve for x 0 the optimal initial anchor of forward looking variables the policy maker s lagrange multipliers on private sector forward looking variables are such that 0 x 0 at the initial date the optimal stabilizing condition is 0 k 0 x py k py kx py kx py x k 0 x 0 pz k pz x z 0 0 k 0 14 this implies py kxk 0 py xx 0 pz xz 0 0 15 which provides the optimal initial anchor x 0 p 1 y xpy kxk 0 p 1 y xpz xz 0 16 the exogenous forcing variables adds the term p 1 y xpz xz 0 with respect to ljungqvist and sargent 2012 algorithm 5 2 6 step 4 compute impulse response functions and optimal loss function the transmission mechanism is given computing fy and fz provides a reduced form of the optimal policy rule computing py and pz provides the missing initial conditions etyt 1 zt 1 ayy ayz 0 zy azz yt zt by 0 z ut ut fyyt fzzt x 0 p 1 y xpy kxk 0 p 1 y xpz xz 0 k 0 and z 0 given this information is sufficient to compute impulse response functions the optimal path of the expected values of variables yt zt and ut and to sum up over time their value in the the discounted loss function by contrast to other algorithms based on miller and salmon 1985 solution it is not necessary to compute all the values over time of all policy makers lagrange multipliers t these algorithms then add a step which is a change of vector basis for eliminating lagrange multipliers knowing the optimal path of variables yt zt one can compute the lagrange multipliers at the end of this algorithm t pyyt pzzt 17 2 7 step 5 optional an implementable representation of ram sey optimal policy policymakers cannot implement a ramsey optimal policy rule where policy instruments responds to non observable variables such as the shocks ut or the lagrange multipliers t they can implement an observationally equivalent representation of the ramsey optimal policy rule where policy instruments responds to lagged observable variables including the lags of the policy instruments this is also a useful representation for testing ramsey optimal policy using vector auto regressive system of equation h etyt 1 zt 1 ayy byfy ayz byfz 0 zy azz yt zt 0 1 t ut fyyt fzzt x 0 p 1 y xpy kxk 0 p 1 y xpz xz 0 k 0 and z 0 given etyt 1 ut 1 m 1 a bf m yt ut m 1 0 1 t zt f 1 z ut f 1 z fyyt x 0 p 1 y xpy kxk 0 p 1 y xpz xz 0 k 0 and z 0 given where 6 a bf ayy byfy ayz byfz 0 zy azz yt ut m 1 yt zt with m 1 1 0 fy fz in the estimation of dynamic stochastic general equilibrium model the controllable predetermined variables are usually set to zero at all periods they are as many auto regressive forcing variables than controllable forward looking variables if the number of policy instrument is equal to the number of controllable forward looking policy targets fz is a square matrix which can be invertible one eliminates forcing variables zt and replace them by policy instruments ut in the recursive equation doing a change of vector basis there is then of a representation of forward looking variables and policy instruments rule optimal policy dynamics in a vector auto regressive model this representation of ramsey optimal policy rule is such that policy instruments ut responds to lags of policy instruments ut 1 and of lags of the observable policy targets yt 1 this representation can be implemented by policy makers it can be estimated by econometricians chatelain and ralf 2017 a 2 8 examples chatelain and ralf 2017 a use this algorithm for the new keynesian phillips curve as a monetary policy transmission mechanism they check that it is equivalent to gali 2015 solution who used the method of undetermined coefficients they use the implementable representation of step 5 to estimate structural parameters chatelain and ralf 2017 b use this algorithm for the new keynesian phillips curve and the consumption euler equation as a monetary policy transmission mechanism they check the determinacy property of step 2 reduced form of the ramsey optimal policy rule chatelain and ralf 2016 use this algorithm for taylor 1999 monetary policy trans mission mechanism they check whether taylor principle applies to ramsey optimal policy 3 conclusion this algorithm complements ljungqvist and sargent 2012 algorithm taking into account forcing variables it is easy to code check and implement references 1 amman h 1996 numerical methods for linear quadratic models in amman h m kendrick d a and rust j editors handbook of computational economics else vier amsterdam 1 587 618 2 anderson e w hansen l p mcgrattan e r and sargent t j 1996 mechanics of forming and estimating dynamic linear economies in amman h m kendrick d a and rust j editors handbook of computational economics elsevier ams terdam 1 171 252 7 3 bryson a e and ho y c 1975 applied optimal control john wiley and sons new york 4 chatelain j b and ralf k 2016 countercyclical versus procyclical taylor prin ciples econstor working papers 5 chatelain j b and ralf k 2017 a can we identify the fed s preferences econstor working papers 6 chatelain j b and ralf k 2017 b hopf bifurcation from new keynesian taylor rule to ramsey optimal policy econstor working papers 7 kalman r e 1960 contributions to the theory of optimal control boletin de la sociedad matematica mexicana 5 pp 102 109 8 ljungqvist l and sargent t j 2012 recursive macroeconomic theory 3 rd edition the mit press cambridge massaschussets 9 miller m and salmon m 1985 dynamic games and the time inconsistency of optimal policy in open economies economic journal 95 supplement conference papers 124 137 10 simon h a 1956 dynamic programming under uncertainty with a quadratic criterion function econometrica 24 1 74 81 11 taylor j b 1999 the robustness and efficiency of monetary policy rules as guide lines for interest rate setting by the european central bank journal of monetary economics 43 3 655 679 8 1 introduction 2 a simple algorithm 2 1 the stackelberg problem 2 2 preliminary step check if the system is stabilizable 2 3 step 1 stabilizing solution of a linear quadratic regulator 2 4 step 2 stabilizing solution of an augmented linear quadratic regulator 2 5 step 3 solve for x 0 the optimal initial anchor of forward looking variables 2 6 step 4 compute impulse response functions and optimal loss function 2 7 step 5 optional an implementable representation of ramsey optimal policy 2 8 examples 3 conclusion