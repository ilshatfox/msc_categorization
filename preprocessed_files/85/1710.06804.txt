1 machine learning techniques for stellar light curve classification trisha a hinners 1 kevin tat 1 2 and rachel thorp 1 3 1 northrop grumman corporation one space park redondo beach ca 90278 2 california institute of technology pasadena ca 3 university of california berkeley berkeley ca abstract we apply machine learning techniques in an attempt to predict and classify stellar properties from noisy and sparse time series data we preprocessed over 94 gb of kepler light curves from mast to classify according to ten distinct physical properties using both representation learning and feature engineering approaches studies using machine learning in the field have been primarily done on simulated data making our study one of the first to use real light curve data for machine learning approaches we tuned our data using previous work with simulated data as a template and achieved mixed results between the two approaches representation learning using a long short term memory lstm recurrent neural network rnn produced no successful predictions but our work with feature engineering was successful for both classification and regression in particular we were able to achieve values for stellar density stellar radius and effective temperature with low error 2 4 and good accuracy 75 for classifying the number of transits for a given star the results show promise for improvement for both approaches upon using larger datasets with a larger minority class this work has the potential to provide a foundation for future tools and techniques to aid in the analysis of astrophysical data 1 introduction future space based telescopes and ground based observatories have a potential to add a large amount of unprocessed data into the astronomy community in the coming decade for example the hubble space telescope hst produced approximately 3 gb per day whereas the james webb space telescope jwst is expected to produce approximately 57 5 gb per day beichman 2014 taking this to further extremes the square kilometer array ska which will be online in 2020 is predicted to produce on the order of 109 gb per day this is the same amount of data the entire planet generates in a year spencer 2013 recent advances in computer science particularly data science have the potential to not only allow the astronomy community to make predictions about their data quickly and accurately but also to potentially aid in discovering which features make objects distinguishable these features may or may not be known by the human all correspondence to trisha a hinners northrop grumman corporation redondo beach ca 90278 usa trisha hinners ngc com 2 analyst and the method could have the potential to discover a relationship within the data previously unknown by the human astronomer there have been a number of efforts to extract meaning from stellar light curves over the past few years most extract specific features from a curve to tackle one particular physical property or come up with novel data processing techniques to improve analysis through a reduction of noise and or variability some notable examples include work by richards et al 2011 using periodicity features to measure stellar variability bastien et al 2015 to extract flicker to measure stellar surface gravity and wang et al 2016 used data driven models with pixel level de trending to produce low noise light curves while retaining important transit signals with the recent interest in machine learning we decided to approach the problem of understanding what physical properties of a star are most related to the light curve using two complementary machine learning approaches feature engineering and representation learning feature engineering takes raw data and summarizes that data with features that are deemed important by the analyst these features are then fed into a machine learning method representation learning differs from feature engineering in that the machine learning method is allowed to learn what attributes best distinguish the data removing the bias from the analyst there are very few examples using machine learning techniques in astronomy but that number is growing one of the first examples dates back to 2007 with bailey et al doing object classification for supernovae using the supernovae factory data with synthetic supernovae as training data in 2010 ball et al published a review paper on the uses of machine learning methods in astronomy more recent examples include work by armstrong et al 2017 on transit shapes and thompson et al 2015 on transit metrics both using real kepler data thompson et al described a new metric that uses machine learning to determine if a periodic signal found in a photometric time series appears to be transit shaped using this technique they were able to remove 90 of the non transiting signals and retain over 99 of the known planet candidates this study was done with feature engineering and extraction methods examples from the supernovae community include work on both real and simulated data cabrera vives et al 2017 used a convolutional neural network cnn for classifying images of transient candidates into either artifacts or real sources their training data set included both real transients and simulated transients they were able to distinguish between real and fake transients with high accuracy both karpenka et al 2013 and charnock moss 2017 used deep learning approaches on simulated supernovae light curves from the supernova photometric classification challenge snpcc karpenka et al used a perceptron artificial neural network for binary supernovae classification the perceptron is a supervised learning method based on a linear predictor function charnock moss used an lstm rnn to classify the synthetic supernova with a high rate of success their dataset consisted of just over 21 000 synthetic supernovae light curves this work inspired us to use an lstm rnn approach as our first attempt at applying machine learning to stellar light curve classification for the purpose of characterizing host stars the work described in this paper is divided into two separate efforts an approach in representation learning and an approach in feature engineering for our representation learning efforts we utilize a bi directional long short term memory lstm recurrent neural network rnn to both predict and classify properties from kepler light curves for the feature engineering approach we utilize a python library called fats feature engineering for time series nun et al 2015 which facilitates and standardizes feature extraction for time series data and was specifically built for 3 astronomical light curve analysis to the best of our knowledge this is the first work to do a comparative study of representation learning and feature engineering for prediction and classification using real astronomical data of light curves 2 data in an attempt to make this study widely applicable we classify a large number of kepler object light curves according to a wide range of stellar properties the respective sources and formats of both the time series measurements and property labels are discussed below 2 1 light curves all light curves used in this study were from the mikulski archive for space telescopes mast 1 the physical parameters 2 and their descriptions 3 were obtained from the table of stellar properties using the kepler stellar 17 csv gz file kepler flux measurements were made over multiple quarters for each source where the instrument rotates by 90 degrees from one quarter to the next to re orient its solar panels the quarters are approximately 90 days long with a data sampling every 29 4 minutes for long cadence observations and every 58 8 seconds for short cadence observations out of the 200 000 total stars only 512 are short cadence in order to maintain consistent data sample structures the short cadence light curves are removed from the dataset this is consistent with common practice we iteratively ran through the archived kepler quarter files and downloaded more than 234 000 files 94 gb the files are formatted as flexible image transport system fits files most commonly used digital file format in astronomy which contain headers that describe the observing environment and data quality and a table of the flux measurements over time there are two values reported for the flux measurements simple aperture photometry sap flux and pre search data conditioning pdc sap flux the pdc sap versions of the light curves remove instrumental variations and noise in the data while preserving both stellar and transiting exoplanet behavior therefore this is the flux measurement used to construct the light curves recall that the header of the light curve file contains information about the quality of data in an attempt to keep only observations with reliable signals we filter out all quarters that contain either contamination from neighboring stars greater than 5 of the total measured flux or a flux yield less than 90 of that object s total flux before training the remaining data a number of preprocessing steps are required these are given in order below 1 keep every tenth data point to make the files sparser cutting down on computation time the initial kepler data is extremely dense we found by visual inspection that sampling every 10 th data point still yielded representative curves while allowing for a larger number of targets using all time steps for each target was too slow to be tractable thinning it out 1 https mast stsci edu 2 https archive stsci edu kepler catalogs html 3 http archive stsci edu search fields php mission kepler stellar 17 https mast stsci edu https archive stsci edu kepler catalogs html http archive stsci edu search fields php mission kepler stellar 17 4 allowed us to include enough diversified targets to be an effective attempt at machine learning 2 normalize the curve raw flux values contain relatively little information on their own and are extremely inconsistent across a single object s multiple quarters a divide each by the median of the curve b subtract one from all points to shift down and center the curve about zero 3 iterative 2 5 clipping standard deviation to remove extreme outliers from the data likely to be remaining instrumental artifacts 4 pseudo random data augmentation to fill gaps in the data preserving the time step information in particular we identify any consecutive gap that exists in the data denoted in the files with nans not a number and fill each missing time slice with a random value between the two real values on either side of that respective gap to do this we first group together sequential nan appearances which is one or more nan entries bounded by real flux values on either side next for each of these empty values we substitute a random value between the left and right flux values on either side of the corresponding gap since the nan values are not measurements that we can assume to know i e missing data we wanted to avoid imposing any interpolated trend behavior that may or may not be present ideally the model will learn to ignore these noisy random portions as if the data was not present in figure 1 we display an example light curve quarter before and after preprocessing has been performed respectively figure 1 a demonstration of before a and after b light curve preprocessing on a single quarter finally we concatenate all processed quarters of a single object into one large curve to properly format the data for both the rnn and feature engineering approaches all curves must be the same length therefore we find the longest resulting light curve and prepend all others with 999 s until they are the same length the 999 value is distinct and is masked out later in the training and testing process this process reduced the initial 234 000 quarter files down to just over 48 500 unique object light curves each with a length of 7 000 time slices 5 2 2 labels the stellar properties used as labels in the classification and regression tasks were extracted from the kepler stellar 17 table on mast 4 this table includes properties for more than 200 000 kepler targets and of the 95 columns describing each target 5 we use the 10 properties given in table 1 to generate labels for 10 distinct prediction tasks parameter name description units minimum maximum prediction task teff effective temperature k 2500 27730 regression logg surface gravity log 10 cm s 2 0 016 5 52 regression feh metallicity dex 2 5 1 regression mass mass m 0 09 3 74 regression radius radius r 0 104 300 749 regression dens density g cm 3 0 124 regression kepmag kepler band magnitude mag 0 419 17 394 regression nconfp number of confirmed planets 0 7 classification nkoi number of associated kois 6 0 7 classification ntce number of associated tces 7 0 8 classification table 1 ten stellar properties used to generate labels for corresponding object light curves in prediction tasks 3 method as stated in the introduction we approach the problem of extracting and identifying physical properties of the star through two methods representation learning and feature engineering in the sections below we describe how each method was implemented results and discussion for each approach will follow in subsequent sections 3 1 machine learning introduction machine learning attempts to automate the data analysis process much of this is done by exploiting the tools of probability theory there are many different flavors of machine learning but it is usually divided into two main types in predictive or supervised learning the goal is to learn a mapping from inputs to outputs given a labeled set of input output pairs the training set the second main type is descriptive or unsupervised learning where we are only given inputs and the goal is to find interesting patterns in the data within this space one can perform either classification pattern recognition when the problem is categorical or regression to find a specific value murphy 2012 there are a large variety of algorithm approaches to machine learning 4 found at https archive stsci edu pub kepler catalogs 5 parameter information further discussed at http archive stsci edu kepler stellar 17 help columns html 6 kepler objects of interest 7 threshold crossing events e g exoplanet transits 6 these include as a few examples bayesian clustering ensemble instance based artificial neural networks regularization and feature engineering artificial neural networks anns are a much lauded tool of machine learning popular for their flexibility and power anns can be thought of mathematically as a form of function approximation and are used for tasks such as regression and classification ann s have a large number of tunable parameters all of which fall into two categories the weights and biases are internal parameters selected via an optimization routine e g stochastic gradient descent over a chosen metric e g mean squared error bottou 2010 the hyperparameters include width which is the number of nodes per layer and depth which is the number of layers stacked to form the network increasing the depth leads to deep learning where the definition of deep learning tends to change with advances in computation in general increasing depth and width enables better performance where depth is thought to have a greater payoff note that as depth and width increase so does computation time every ann consists of nodes and edges with an example ann shown in figure 2 the nodes of the input layer correspond to the input data the number of input nodes corresponds to the dimensionality of that data for example if we are interested in 8 x 8 pixel grayscale images the number of input nodes will be 64 the nodes of the output layer depend on the task for which the ann was designed if the network was designed to predict a single number then there were be a single output node if the intent is to classify an input image among k categories one would choose k output nodes each corresponding to the probability the input data belongs to a particular category the nodes of the hidden layer correspond to intermediate data transformations which are governed by both the learned weights and biases and the hyperparameters the arrows in figure 2 denote the flow of data between nodes the example is a densely connected feed forward network where data is allowed to flow between all nodes densely connected but only in the one direction feed forward the details of each individual node are shown in figure 2 on the diagram on the right each node takes some number of inputs combines them feeds them through an activation function and the result is then passed on to some other number of nodes the combination of inputs is usually scaled by individual weights then added along with a bias term the weights and biases are chosen via optimization but the activation function is chosen a priori the choice of activation function is a topic of active research but a current popular choice is the rectifier glorot et al 2011 7 figure 2 the figure on the left is a schematic for a simple artificial neural network with a depth of two and unspecified width and the figure on the right is a schematic for a simple generic node here three inputs xi are scaled by weights wi summed and biased b before being fed through an activation function f y there are several flavors of ann s but two of the most popular are recurrent neural networks rnns and convolutional neural networks cnns an rnn is an ann with internal memory what this means is that information is allowed to pass between nodes in the same layer if both forward and backward propagation are allowed then the rnn becomes bi directional a popular form of rnns is the long short term memory lstm rnn which provides facilities for memory management including the ability to forget or reset an internal state sak et al 2014 a cnn is an ann which assumes some invariance structure of the input data and therefore enforces invariance in the structure of the ann zhang et al 1990 the network is invariant in the sense that it applies the same small set of weights and biases to different portions of the input data more specifically the network performs convolution of learned kernels against the input data this design choice reduces the number of internal parameters decreasing the expense of training convolving against a kernel can be thought of as searching for patterns mishkin et al 2016 details an investigation of different cnn design choices and their relative performance a more thorough discussion about machine learning in general can be found in murphy 2012 and neural networks in particular in the review article by schmidhuber 2015 3 2 representation learning in an effort to understand which properties we can obtain from stellar light curves we turn to representation learning techniques representation learning allows the model to extract the features that it finds to be important in characterizing objects according to one physical property at a time while this may initially limit model interpretability it provides an opportunity for hidden features of the light curve to surface and help in classifying an object by various stellar properties while feature engineering can be extensive representation learning has the opportunity to remove human based preconceived notions about what may or may not affect a star s classification 8 in line with more common natural language processing nlp tasks we treat each set of 48 500 light curves as a corpus with each light curve simulating a sentence and each normalized flux measurement simulating a word by implementing a lstm rnn we hope that the model will learn both semantic relations between flux values in a sequence as well as the more general pattern meanings throughout the corpus of objects allowing the model to make accurate stellar predictions a similar approach of treating a light curve as a sentence was done by charnock moss 2017 in their analysis of supernovae light curves 3 2 1 network architecture we referred to related literature when determining the model architecture primarily charnock moss 2017 which optimized a lstm rnn in classifying supernovae light curves aside from similar data structures charnock moss had a comparable data set size although simulated and analogous prediction tasks leading us to utilize a similar model structure and complexity our lstm rnn was built in python using the keras neural network library 8 the ideal architecture was found to be an rnn with two lstm hidden layers of 16 nodes each and an initial masking layer to filter out prepended 999 s although we initially ran tests on just a single hidden layer to reduce computation time an example of a generic rnn with two lstm hidden layers can be seen in figure 3 figure 3 an example of the data and label inputs and architecture of a recurrent neural network with lstm nodes predict and classify stellar properties in building the lstm rnn we wanted to perform two types of predictive tasks binary classification does an object belong to one class or another and regression what is the numerical value of this star s physical property for both lstm layers we used a softmax 8 the keras deep learning library is an open source library developed by francois chollet at mit in 2015 more information can be found at https keras io 9 activation function for classification tasks and a softsign activation function for regression tasks the dense layer was always assigned a linear activation function in network compilation a categorical cross entropy loss was used for classification tasks and a mean squared error loss for regression tasks we applied the rmsprop 9 optimizer with default learning rate when fitting a batch size of 20 was used and in both classification and regression tasks and we surveyed the reported loss values between epochs to determine when performance had plateaued namely when loss values seemed to converge weights were balanced using scikit learn s class weight utility function specifying balanced weights this process effectively returns the frequency of each class or more specifically each class weight number of samples number of classes number of samples belonging to that class once a list of class weights were obtained we fed the list into the neural network when fitting all other parameters not specified here were keras layer defaults more specifics on these modifications for the two tasks are discussed below 3 2 2 modifications we decided to perform classification tasks on the parameters with discrete values within a limited set i e number of confirmed planets number of associated kepler objects of interest kois and number of associated threshold crossing events tces however while the sets of possible values for each of these properties are already quite limited each of these three parameters is heavily dominated by negative signals i e a value of zero thus we decided to simplify the tasks further by making each binary classification task either equal to or greater than zero however despite the classification simplification the data still consisted of a skewed population for each of the three relevant properties to combat heavy bias we instantiated the model with balanced weights such that the model would weight the importance of positive labels more highly than negative labels to avoid converging as a simple majority class predictor the key to creating a classification model versus a model that performs regression tasks is primarily in the structure of the output layer we implemented one node for each class of the classification task two for binary classification in the output layer additionally the loss function a metric over which each model is optimized varies slightly between classification and regression tasks since we want to correctly categorize the target we apply a categorical cross entropy loss function provided below log the loss function is applied to each prediction target i and each of the j possible classes e g j 2 in our binary predictions where t is the target or actual probability that an object belongs to that class and p is the corresponding predicted probability this function is minimized by the neural network to optimize prediction tasks rather than creating multiple nodes in the output layer as was done for the classification tasks regression tasks require just a single node which means that the output will be the estimated property value rather than a set of weights corresponding to the model s confidence in each respective class 3 2 3 evaluation metrics 9 https keras io optimizers 10 in determining the success of a predictive model various evaluation metrics are used to measure results these are not used in the training process but are helpful when considering how well the model performed on a certain task the metrics come from entries in a confusion matrix kohavi and provost 1998 which contains information about the actual and predicted classifications done by a classification system performance of the system in our case our machine learning methods is evaluated using the data contained in the confusion matrix for a binary classifier we utilize a two class matrix also known as a truth table as seen in table 2 predicted value actual value 0 1 0 tn fn 1 fp tp table 2 truth table where tn is the number of true negatives fn is the number false negatives fp is the number of false positives and tp is the number of true positives these values are used in calculating the metrics used to evaluate model performance traditional or raw accuracy is simply defined as the ratio between the number of correct predictions and the total number of predictions for two classes raw accuracy is calculated as where tp is the number of true positives tn is the number of true negatives p is the total number of positives and n is the total number of negatives therefore a random binary classifier would have an accuracy of 1 2 and a random classifier with three classes would have an accuracy of 1 3 each of our classification tasks contained extremely imbalanced data where the number of positive samples i e a confirmed transit was less than 10 of the total data set for each parameter therefore raw accuracy returned misleadingly high values even for a simple majority class predictor and was not an appropriate metric to evaluate prediction performance therefore we turned to balanced accuracy utilizing a confusion matrix of predictions for binary classification problems the confusion matrix splits predictions into true positives tp false positives fp false negatives fns and true negatives tns balanced accuracy is then defined as 2 additionally we can calculate the recall of a model which tells us how many positive cases were correctly identified and the precision which tells us how many of those predicted positive cases were correctly identified recall is defined as 11 and precision is defined as from recall and precision we can calculate the f 1 score which can be used to measure the accuracy of the model it uses both recall and precision which are obtained from the truth table the f 1 score provides a harmonic average of the precision and recall where the best value for f 1 is 1 and the worst is 0 f 1 is described as 1 2 3 2 4 representation learning lstm rnn results we found that both the classification and regression results resulted in approximately guessing accuracy for classification the balanced accuracy was approximately 52 for all three tasks and for regression the rnn was only finding the average of all of the values instead of predicting the individual value previous successful work had centered on simulated data charnock moss or other types of representation learning self organizing map som in the case of armstrong et al 2017 and it is possible that the variation in the light curve data the relatively small sample set of 48 500 light curves or the ratio of positive samples to negative was too low for the rnn to predict values upon these results we were driven to explore another machine learning method with more human knowledge in the loop namely feature engineering 3 3 feature engineering to attempt to improve our ability to perform prediction tasks we turned to feature extraction to construct feature representations of the light curves this strategy is commonly referred to as feature engineering feature engineering is the process of determining calculating and extracting features from raw data these features are typically properties of the raw data that are human interpretable and believed to provide insight on the prediction task at hand while this process can be arduous feature engineering often takes quite a lot of time and may be computationally intensive it also provides useful intuition into our understanding of certain properties and patterns of the raw data furthermore the fact that feature engineering typically utilizes human crafted properties allows us to perform a more in depth data analysis on why certain features predict certain physical properties while representation learning is able to extract features from raw data for unexpected insight it does not offer the depth of insight that feature engineering can provide 12 in order to extract features from light curves we turned to fats feature analysis of time series nun et al 2015 since there is extensive documentation for fats on its github repository 10 and within nun et al 2015 here we will only summarize how we extracted features from our preprocessed light curves fats takes time series data and depending on the target extracts mathematical properties and statistical information nun et al 2015 while fats can be applied to a variety of time series data we focus on using it to extract features from light curves specifically we extract 46 features from 6038 light curves and train them on the following models na ve bayesian k nearest neighbors support vector machine decision tree random forest l 1 norm regression l 2 norm regression and support vector regression this analysis was performed on the same data prepared in the lstm rnn experiment hyperparameters were determined by a simple script that trained from 1 to n classifiers and chose the value that minimized out of sample error the main data set was split into a testing and training set such that the training set was 80 of the data and the testing set was 20 of the data each model used for classification utilized a function to calculate out of sample error and each model used for regression utilized a function that provided rmse as an output 3 3 1 feature selection and extraction to accurately simulate the type of information we will be receiving from future synoptic surveys we utilize only magnitude and time measurements from the light curve as inputs to fats given magnitude and time there are a total of 53 features that can be calculated out of this 53 we exclude seven features fluxpercentileratiomid 20 fluxpercentileratiomid 35 fluxpercentileratiomid 50 fluxpercentileratiomid 65 and fluxpercentileratiomid 80 were excluded because they produce values of infinity during feature generation this issue is a product of the preprocessing done on the light curves which centered each time series around 0 fluxpercentileratio were calculated using the formula 50 2 5 95 where 5 95 is the difference between 95 and 5 of the flux this difference occasionally truncated to zero by python if it was too small this led to values of infinity that were removed from the list of features as they do not provide reliable information we also discarded percent amplitude and percent difference flux percentile percent amplitude is calculated as max and percent difference flux percentile from 5 95 both of these values rely on the median flux value which on occasion is equal to zero as the data was normalized to be centered around zero again during feature generation some of the light curves held values of infinity for these two properties and so we discarded them with the same 10 https github com isadoranun fats 13 reasoning as for the fluxpercentileratio values therefore we were left with 46 features which are listed in table 3 feature input data besides magnitude parameters default reference amplitude richards et al 2011 andersondarling test kim et al 2008 autocor length number of lags 100 kim et al 2011 con consecutive stars 3 kim et al 2011 etae time kim et al 2014 freq 1 harmonicsamp 0 time richards et al 2011 freq 1 harmonicsampi time richards et al 2011 freq 1 harmonicsrelphase 0 time richards et al 2011 freq 1 harmonicsrelphasei time richards et al 2011 freq 2 harmonicsamp 0 time richards et al 2011 freq 2 harmonicsampi time richards et al 2011 freq 2 harmonicsrelphase 0 time richards et al 2011 freq 2 harmonicsrelphasei time richards et al 2011 freq 3 harmonicsamp 0 time richards et al 2011 freq 3 harmonicsampi time richards et al 2011 freq 3 harmonicsrelphase 0 time richards et al 2011 freq 3 harmonicsrelphasei time richards et al 2011 linear trend time richards et al 2011 max slope time richards et al 2011 mean kim et al 2014 mean variance kim et al 2011 mean absolute deviation richards et al 2011 median brp richards et al 2011 pairslopetrend richards et al 2011 period lomb scargle time oversampling factor 6 kim et al 2011 period fit time kim et al 2011 cs time kim et al 2014 time kim et al 2014 q 3 1 kim et al 2014 rcs kim et al 2011 skew richards et al 2011 slotted autocor length time slot size t days 4 protopapas et al 2015 small kurtosis richards et al 2011 standard deviation richards et al 2011 table 3 features generated from fats used in machine learning methods in the freqn harmonics terms i 1 2 3 3 3 2 feature engineering regression results we ran three different regression models to predict values for stellar surface gravity log g stellar mass in units of m density stellar radius in units of r and the stellar effective temperature 14 the first two models are linear regression models the benefits of linear regression is its simplicity in both implementation and interpretability its drawback comes when the relationship between the inputs and outputs cannot be approximated by a linear relationship in which case the model will give poor predictions the two linear methods we used are lasso least absolute shrinkage and selection operator tibshirani 1996 and ridge regression rasmussen 2006 which we have denoted as l 1 regression and l 2 regression respectively l 1 regression is robust meaning it does not overly fit to outliers it is unstable such that small adjustments in the data have the potential to move the regression fit and it has multiple solutions l 2 regression is not robust so it could have a tendency to over fit it is stable so the regression line is not affected by small data adjustments and it has a unique solution the third method is a non linear method called support vector regression svr it was originally developed for classification problems and later extended to regression it is useful when the relationship between the inputs and outputs are not best fit by a linear relationship for a full description of the methods please refer to rasmussen et al 2006 and murphy 2012 the results obtained for regression are described in terms of root mean squared error rmse and are shown in table 4 recall that rmse is calculated within each of the regression models root mean squared error model stellar surface gravity log g stellar mass m density g cm 3 stellar radius r effective temperature k l 1 0 9088 0 6604 2 699 14 26 879 6 l 2 0 8254 0 6341 2 669 13 25 875 4 svr 0 8735 0 6050 2 829 19 87 967 2 table 4 feature engineering results for regression where the range in values for each stellar property is in table 5 range stellar surface gravity log g stellar mass m density g cm 3 stellar radius r effective temperature k 0 016 5 52 0 09 3 74 0 124 0 104 300 749 2500 27730 table 5 range of values for each stellar property to get a better comparison for how each model does at predicting these values we then normalized the rms error which can be seen in table 6 normalized root mean squared error model stellar surface gravity log g stellar mass m density g cm 3 stellar radius r effective temperature k l 1 0 1651 0 1809 0 0217 0 0474 0 0348 l 2 0 1499 0 1737 0 0215 0 0441 0 0347 svr 0 1587 0 1657 0 0228 0 0661 0 0383 table 6 normalized rms for each of the stellar properties with each different model feature engineering for regression proved to give good predictions for stellar surface gravity and stellar mass and very good predictions for stellar density stellar radius and effective stellar 15 temperature with both of the linear models performing slightly better than svr svr pulls ahead only for predicting the stellar mass and is pretty even with the linear models for predicting stellar surface gravity but overall the differences between the models are minor this technique could be used with confidence to classify the large database of unclassified stars without immediate need for follow up observations 3 3 3 feature engineering classification results classification was performed on three separate types of events number of threshold crossing events number confirmed planets and number of kepler objects of interest 3 3 3 1 feature importance using fats for each of these classification events we calculated the importance of each of the features from table 3 our first look was the number of kepler objects of interest in a given light curve as we see in figure 4 mean skew and freq 1 harmonicsrel phase 1 are all features that contribute greatly to understanding if an object of interest is contained within the light curve for a model using a random forest classifier figure 4 feature importance in random forest nkoi classification figure 5 shows the relative feature importance for the number of threshold crossing events here different features namely the period lomb scargle and etae are the two most dominant features but the freqn harmonicsrel phase terms are not important at all to the classification 16 figure 5 feature importance in random forest number of confirmed planets classification finally figure 6 shows the relative feature importance for the number of confirmed planets here we see that the freq 1 harmonics rel phase 1 is the dominant feature followed by skew with the features not contributing to the classification being the different freq harmonics rel phase 0 terms doing this analysis shows us that even for seemingly fairly related events the feature importance can vary greatly when it comes to classification figure 6 feature importance in random forest number of threshold crossing events classification 17 using these results we can reduce the data to only the features that hold importance for the classification tasks at hand and improve the overall classification accuracy 3 3 3 2 classification results upon running each of the five classifier models we are able to see how well each type predicts the correct value based on the two metrics out of sample error eout which measures the difference between the expected and empirical error and balanced accuracy to calculate eout we first used the training data on the scikit learn model after it was trained we used it to predict the classes of the testing data since the classes of the testing data are known we can compare them to the class that the model predicts we predicted all of the classes for each data point in the testing data and for every data point misclassified we incremented a counter after each point s class was predicted we divided the total number of points in the testing data to get the ratio of points that were misclassified the calculation for balanced accuracy can be seen in section 3 2 3 our experiment was to check if the machine learning method could pull from a complete set of noisy sparse kepler data the correct values for each of the classifications described below for the number of kepler objects of interest we had the model classify whether a given star had at least one koi associated with it the performance of each of the models for koi is in table 7 number of kepler objects of interest classifier eout balanced accuracy na ve bayes 92 38 51 15 svm 5 71 57 72 knn 4 72 58 96 d tree 8 19 62 82 random forest 1000 trees 4 64 57 58 table 7 comparison of classifier models for classifying the number of kepler objects of interest for a given set of light curves here we see that a na ve bayesian model has a very high eout and guessing level balanced accuracy each of the others have low out of sample error and the model appears to be moving beyond simply guessing these values of balanced accuracy are promising turning to the number of threshold crossing events in table 8 we start to see more favorable values for balanced accuracy here the models were ran against the full light curve set to determine if a given star had a transit event number of threshold crossing events classifier eout balanced accuracy na ve bayes 87 25 50 04 svm 14 98 66 86 knn 10 84 62 77 d tree 13 99 71 53 random forest 1000 trees 8 029 69 94 table 8 comparison of classifier models for classifying the number of threshold crossing events for a given set of light curves here again we see that a na ve bayesian model is not a good classifier for determining the number of threshold crossing events it has a large out of sample error and its balanced accuracy 18 is that of guessing each of the other model types are better to varying degrees decision trees produced the best balanced accuracy but had a slightly higher out of sample error than that of a random forest of 1000 trees which produced the least out of sample error and a very respectable value for balanced accuracy when compared to other examples using noisy sparse data with multi layer neural networks in the extended physics community the model is classifying fairly well as an example in a related field where the signal of interest higgs boson is an extreme minority in the an otherwise large data set the use of deep neural networks dnns for classifying the higgs boson at the lhc alves 2017 achieved accuracies ranging from 60 to 84 finally we look at the number of confirmed planets per stellar light curve in table 9 here we wanted to see if we could move beyond a potential transit and determine if the method could identify planets with some degree of confidence this would be very attractive as it would allow a set of data to be evaluated against training data containing confirmed planets and confidently tell us that a star that has yet to be analyzed indeed has a planet number of confirmed planets classifier eout balanced accuracy na ve bayes 94 54 52 23 svm 0 745 55 knn 0 745 55 d tree 1 49 54 62 random forest 1000 trees 745 55 table 9 comparison of classifier models for classifying the number of confirmed planets for a given set of light curves this classification proved to be difficult for all five classifiers here svm knn and random forests were all guessing a classification of zero i e no confirmed planets it only makes sense that the model might revert to this since the sample size is very small for light curves containing confirmed planets and even smaller for light curves with multiple planets 3 3 4 further analysis after achieving the first set of results we decided to take a look at what might be causing such low model performance we determined that our classification problems are heavily imbalanced where the minority class such as a light curve with a confirmed planet is significantly less than the majority class light curves without confirmed planets to help remedy this we turned to a method to attempt to oversample the minority class specifically we used synthetic minority over sampling technique or smote chawla et al 2002 in many cases with real data the interesting examples within the data can be severely underrepresented making classification difficult the machine learning community has approached this probably through both resampling the original dataset either by oversampling the minority class or under sampling the majority class kubat matwin 1997 japkowicz 2000 lewis cattlet 1994 ling li 1998 or by adding costs to the training examples pazzani et al 1994 domingos 1999 smote provides an approach that combines both oversampling the minority or interesting class and under sampling the majority class chawla et al 2002 used several different classifiers c 4 5 decision trees quinlan 1992 na ve bayes and ripper cohen 1995 and showed that this combined method achieves better performance 19 this algorithm does the following 1 takes the minority class sample xi and its k minority class nearest neighbors y 1 yk 2 introduces n synthetic examples along the line segments joining xi with its k neighbors a take the difference between yj and xi b multiply difference by number between zero and one c add the difference to xi we chose to apply this to our most promising classification set the number of threshold crossing events table 10 shows our post smote classification ratios where class 0 represents light curves without a crossing event and class 1 where a crossing event is detected post smote classification ratios smote model class 0 class 1 no smote 0 8781 0 1219 regular 0 5 0 5 baseline 1 0 5 0 5 baseline 2 0 5 0 5 svm 0 5001 0 4999 table 10 model results before and after applying smote to balance the majority minority class as one can see the data is dominated by class 0 events but by applying the various versions of a smote model we achieve closer to a 50 50 ratio of class 0 and class 1 events to provide additional metrics for model performance with the addition of smote we calculated recall and precision recall is defined as which is basically the ratio of positives that are correct out of all actual positives and precision is defined as which is the ratio of positives that are correct out of all guessed positives table 11 shows the previously reported eout and balanced accuracies as well as recall and precision for each model classifier number of threshold crossing events ncte classifier eout balanced accuracy recall precision f 1 score na ve bayes 87 25 50 04 0 993 0 122 0 217 svm 14 98 66 86 0 429 0 394 0 411 knn 10 84 62 77 0 279 0 621 0 385 d tree 13 99 71 53 0 517 0 409 0 457 random forest 1000 trees 8 029 69 94 0 395 0 828 0 535 table 11 comparison of the classifier models including recall and precision as metrics after applying smote to our data we saw that the smote svm achieved the greatest improvement in results which can be seen in table 12 20 ntce with smote svm classifier eout balanced accuracy recall precision f 1 score na ve bayes 85 4 50 5 0 980 0 123 0 219 svm 13 2 65 8 0 381 0 452 0 413 knn 21 4 62 0 0 517 0 289 0 371 d tree 17 1 69 8 0 524 0 362 0 428 random forest 1000 trees 8 86 74 7 0 530 0 672 0 593 table 12 comparison of the classifier models after applying smote to the minority class notice the improvement in balanced accuracy for the random forest and the trade off for achieving better recall at the sacrifice of some precision the na ve bayesian model still produced guessing results with a high eout however the use of smote greatly improved the random forest in particular achieving almost 75 balanced accuracy additionally in all cases but the d tree the f 1 score went up slightly as a comparison armstrong et al 2017 achieved 87 accuracy with a self organizing map som neural network for finding the true planet detections and discarding the false positives among the kois while the methods used between armstrong 2017 and our work are very different the results give us an idea about the type of accuracy obtainable with real kepler data with more data containing positive detections and additional data conditioning a smote feature engineering method could be useful in getting insight into exoplanet presence in a given stellar system this could provide astronomers a useful tool for quickly identifying stellar systems with an extremely high likelihood of exoplanet presence allowing for more focused analyses 4 discussion while the results from the lstm rnn was initially disappointing this led us to investigate feature engineering for both regression and classification problems feature engineering provided excellent results for regression and very promising results for classification once we achieved some confidence in the approach we decided to employ the smote technique on our data set to remove the severe imbalance after employing smote the classification results greatly improved the classification balance accuracy is in line with other results with real data using different methods but still does not achieve the 90 95 being achieved with simulated data charnock moss 2017 noisiness and sparseness of the data appear to play a large role in the ability to classify real light curve data with machine learning techniques but improvements in performance can be made utilizing minority class oversampling techniques such as smote initially we thought that the poor results from the lstm rnn were entirely due to the noisiness and sparseness of the data and that light curves may not be suited to analysis with an rnn however with the success of smote we now think that there may be techniques to boost the minority class and potentially improve the performance of representation learning methods with real astrophysical data it should be noted that smote cannot be used on time series data as it is dependent upon existing in feature space and is not applied to raw time series data future work will be to investigate such methods and test if the lstm rnn can be more successful with data augmentation this reinvestigation could be complementary to the work by naul et al 2018 using rnn feature extraction 21 the success of the feature engineering approach particularly with stellar property prediction gives us confidence that these techniques will make useful tools for the astronomy community when beginning to analyze the large volume of data that will be available with tess and jwst and provide better guidance in using precious revisit time from ground based observatories 5 summary with the eminent boom of astronomical data on the horizon new methods and techniques need to be developed and refined to reduce analysis time increase accuracy and provide new insights into the data itself we attempt to add techniques to the community through investigating representation learning and feature engineering approaches to better understand what may be possible upon investigation we discovered that our lstm rnn approach to representation learning was limited in its applicability this was either due to the limited positive sample size within our data or the sparseness and or noisiness of real data since successful applications of rnns have been shown primarily on simulated data where noise is also simulated and therefore more predictable while representation learning did not prove to be ideal feature engineering provided excellent results with regards to both regression and classification for regression the model could predict values for density stellar radius and effective temperature where the ridge regression model performed the best with a normalized rms error of 0 0215 0 0441 and 0 0347 for each value respectively classification results showed that a random forest of 1000 trees produced the lowest out of sample error at 8 86 with a balanced accuracy of 74 7 upon inspection of the literature in the community this may be the first comparative study of machine learning methods using real astronomical data we hope this work will be informative and provide a base for future endeavors both from our team and the extended community 6 acknowledgements we would like to thank the kepler team for making all of the data publicly available on mast we would also like to thank sara seager mit and david hogg nyu for discussions encouragement and advice this work was supported by northrop grumman corporation references alves a ghosh t sinha k 2017 phys rev d 96 035022 armstrong d j pollacco d santerne a 2017 mnras 465 3 bailey s aragon c romano r thomas r c weaver b a wong d 2007 the astrophysical journal 665 2 ball n m brunner r j 2010 int j mod phys d 19 1049 bastien f stassun k basri g pepper j 2015 the astrophysical journal 818 43 beichman benneke knutson et al 2014 pasp 126 1134 bottou l proceedings of compstat 2010 2010 pages 177 186 22 cabrera vives g reyes i forster f estevez p maureira j c 2017 the astrophysical journal 836 1 charnock t moss a 2017 apj letters 837 l 28 chawla n bowyer k hall l kegelmeyer w 2002 journal of artificial intelligence 16 321 257 cohen w w 1995 b proc 12 th international conference on machine learning pp 115 123 domingos p 1999 proceedings of the fifth acm sigkdd international conference on knowledge discovery and data mining pp 155 164 glorot x bordes a and bengio y 2011 proceedings of the fourteenth international conference on artificial intelligence and statistics pages 315 323 2011 japkowicz n 2000 proceedings of the 2000 international conference on artificial intelligence special track on inductive learning las vegas nevada karpenka n v feroz f hobson m p 2013 mnras 429 2 p 1278 1285 kim d w protopapas p alcock c byun y i bianco f 2008 13 1 kim d w protopapas p bailer jones c a l et al 2014 18 kim d w protopapas c byun y i et al 2011 the astrophysical journal 735 68 kohavi r and provost f 1998 in editorial for the special issue on applications of machine learning and the knowledge discovery process columbia university new york volume 30 kubat m matwin s 1997 proceedings of the fourteenth international conference on machine learning pp 179 186 lewis d catlett j 1994 proceedings of the eleventh international conference of machine learning pp 148 156 ling c li c 1998 proceedings of the fourth international conference on knowledge discovery and data mining kdd 98 mishkin d sergievskiy n and matas j 2016 arxiv preprint arxiv 1606 02228 murphy k p 2012 machine learning a probabilistic perspective the mit press naul b bloom j s perez f and van der walt s 2018 nature astronomy 2 151 155 nun i protopapas p sim b ming z rahul d castro n pichara k 2015 arxiv 1510 05988 pazzani m merz c murphy p ali k hume t brunk c 1994 proceedings of the eleventh international conference on machine learning quinlan j 1992 programs for machine learning 23 rasmussen c e williams c k i gaussian processes for machine learning the mit press 2006 isbn 026218253 x richards j w starr d l butler n r et al 2011 the astrophysical journal 733 10 sak h senior a and beaufays f 2014 fifteenth annual conference of the international speech communication association schmidhuber jurgen 2015 neural networks 61 85 117 sharma s stello d buder s et al 2017 arxiv 1709 00794 spencer r iet seminar on data analytics 2013 deriving intelligence and value from big data thompson s mulally f coughlin j et al 2015 the astrophysical journal 812 1 tibshirani r 1996 journal of the royal statistical society series b 58 1 267 288 wang d hogg d w foreman mackey d scholkopf b 2016 arxiv 1508 01853 v 2 zhang w itoh k tanida j and ichioka i 1990 applied optics 29 32 4790 4797 approved for public release ng 18 0875 4 24 18