fits and starts enterprise use of automland the role of humans in the loop fits and starts enterprise use of automl and the role of humans in the loop anamaria crisan tableau research acrisan tableau com brittany fiore gartland tableau software bfioregartland tableau com figure 1 levels of automation in data sciencework from our interviews we illustrate the desired level of automation accord ing to level of technical expertise in data science we ground our findings in the levels of automation proposed by parasuraman et al 41 and lee et al 34 abstract automl systems can speed up routine data science work and make machine learning available to those without expertise in statistics and computer science these systems have gained traction in en terprise settings where pools of skilled data workers are limited in this study we conduct interviews with 29 individuals from orga nizations of different sizes to characterize how they currently use or intend to use automl systems in their data science work our investigation also captures how data visualization is used in con junction with automl systems our findings identify three usage scenarios for automl that resulted in a framework summarizing the level of automation desired by data workers with different levels of expertise we surfaced the tension between speed and human oversight and found that data visualization can do a poor job bal ancing the two our findings have implications for the design and implementation of human in the loop visual analytics approaches ccs concepts human centered computing empirical studies in hci permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page copyrights for components of this work owned by others than acm must be honored abstracting with credit is permitted to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee request permissions from permissions acm org chi 21 may 08 13 2021 yokohama japan 2021 association for computing machinery acm isbn 978 1 4503 xxxx x 18 06 15 00 https doi org 10 1145 1122445 1122456 keywords data science automation machine learning data scientists acm reference format anamaria crisan and brittany fiore gartland 2021 fits and starts en terprise use of automl and the role of humans in the loop in chi 21 acm conference on human factors in computing systems may 08 13 2021 yokohama japan acm new york ny usa 15 pages https doi org 10 1145 1122445 1122456 1 introduction organizations are flush with data but bereft of individuals with the technical expertise required to transform these data into actionable insights 45 to bridge this gap organizations are increasingly turning toward automation in data science work beginning with the adoption of techniques that automate the creation of machine learning models 13 46 however the adoption of this technology into enterprise settings has not been seamless currently automl offerings have limitations in what they can flexibly support end to end systems encompassing the full spectrum of data science work from data preparation to communication are not yet fully real ized 34 54 consequently automl systems still require human in tervention to be practically applicable 42 46 this mode of human machine collaboration presents a number of challenges 2 35 chief among them being the importance of balancing the speed afforded by automl with the agency of individuals to interpret correct and refine automatically generated models and results 20 data visualization can play an important role in facilitating this human machine collaborative process 20 46 but there are few studies ar x iv 2 10 1 04 29 6 v 1 cs h c 1 2 ja n 20 21 https doi org 10 1145 1122445 1122456 https doi org 10 1145 1122445 1122456 https doi org 10 1145 1122445 1122456 chi 21 may 08 13 2021 yokohama japan crisan and fiore gartland et al that examine if and how data visualization is used in real world set tings together with automl to fill this gap we conduct interviews with 29 individuals from organizations of different sizes and that extend across different domains to capture how they currently or plan to use automl to carry out data science work we examine specifically if and how participants use data visualization as a way to integrate the human in the automation loop our investigation reveals that the practical use of automl tech nology in real world settings requires considerable human effort this effort is complicated by the need to trade off data work be tween individuals with different expertise for example data sci entists and business analysts this trade off is exacerbated by a data knowledge gap that participants believe automl technology is widening while participants saw the value of data visualization as one way to facilitate human in the loop interactions with au toml tools many still reported using visualization in a limited way participants found that creating quality visualizations for automl was often too difficult and time consuming and had the effect of slowing down automation often with limited benefit moreover participants reported a lack of useful visualization tools to support them in some of their more pressing needs such as collaborating on data work among their diverse teams and with automl technology altogether our study makes the following timely contributions to the existing literature on automl and the design of human in the loop tools for data science an interview study that presents real world uses of automl technologies in enterprise settings with a focus on the role of the human in the loop facilitated by data visualization a summary of three use cases for automl according to different organizational needs a framework that illustrates the level of automation that is desirable for individuals with different levels of technical expertise as automl systems continue to gain traction in enterprise set tings our contributions will be a resource to the research commu nities developing human in the loop approaches that support an appropriate balance of automation and human agency 2 relatedwork we review prior work that investigates the use of automl in data science the ways that humans act within these processes and current data visualization approaches that mediate these processes as we reviewed this work we were challenged by the varied use of the term automl the preliminary goals of automation in machine learning began with the objective of removing the hu man specifically from hyper parameter tuning and model selection steps 50 however it quickly became clear that other steps such as data preparation or feature engineering were also critical to the success of hyper parameter tuning the scope of the term automl and more recently autoai or driverless ai began to encompass broader steps in the data science workflow 46 54 we observed that the terms automl autoai and the phrase automation in data science are often used interchangeably in the literature here we use the term automl to broadly encompass automation across multiple data science steps from preparation to monitoring to de ployment 2 1 automl in data science data science leverages techniques from machine learning to derive new and potentially actionable insights from real world data 3 6 12 automl systems have been developed to automate the com putational work involved in building a data analysis pipeline that enable individuals to derive these insights from data several com mercial systems already exists and are used within different types of organizations including aws sagemaker autopilot 24 google s cloud automl 26 microsoft s automatedml 29 ibm s au toai 28 h 20 driverless ai 27 and data robot 25 there are also implementations of automl that build upon widely used data science packages such as the scikit learn 43 python library auto sklearn 15 16 and tpot 38 39 the focus of these automl systems are toward largely supervised tasks concerning feature en gineering hyper parameter tuning and model selection 14 50 54 recent innovations have proposed possible end to end solutions that also support data preparation 34 50 54 and it is likely that automl technologies will continue to expand toward broader end to end support the means and extent to which automl systems integrate with a computational data science pipeline is variable some automl systems exist as a single component within a larger pipeline such as automated feature selection step that the analyst or data scien tist creates at other times automl systems can also create these pipelines with minimal user input in their comprehensive analysis of existing automl tools z ller et al 54 describe three common configurations for including automl in data science work the two configurations are fixed structure pipelines where the automl system assumes a very specific configuration of computational pipeline the authors differentiate between fixed pipelines that are optimized for specific automl methods for example neural networks or random forests compared to those that are not while these fixed systems are common they have limitations when con fronted with different data types and tasks for example image data or text data demand more flexibility within the structure of the computational pipeline the second category is a variable struc ture pipeline which refers to a fairly recent approach that aims to learn the appropriate steps within a data science pipeline 54 tpot 38 39 is an example of one of the first variable pipelines unlike fixed models that execute a pre determined set of processes variable structure approaches learn a network of process in response to different datasets and user objectives while the stated goal of many of these automl systems is to effectively remove humans from many aspects of data science work 50 a view that data scientists themselves express 46 to day these systems still rely on considerable human labor to be of use 19 these limitations stem from both the complexity of data science work and the brittleness of fixed structure pipelines that are in common use 54 our study catalogs this human labor across data science work and examines how visualization is used by individuals engaged in data work 2 2 automation and the human in the loop human in the loop approaches provide a way to explicitly incor porate human interaction within automated processes identifying fits and starts enterprise use of automl and the role of humans in the loop chi 21 may 08 13 2021 yokohama japan figure 2 example illustrations of fixed and variable structure pipelines adapted with modification from z ller et al 54 when and how to add the human in the loop within automl pro cesses is important in order to appropriately balance the speed that automation affords with the importance of human guidance para suraman et al 41 proposed a model to help designers identify the appropriate type and level of automation for information seeking processes they define four broad functions for how automation is used 1 information acquisition 2 information analysis 3 deci sion and action selection and 4 action implementation they argue that the level of automation from none to fully automated should be evaluated against human performance consequences automa tion reliability and costs of actions when the impact of automation is both significant and potentially harmful human intervention is essential the question of when how and how much to automate remains critical to the discussion of automl technologies today a number of recent studies in the hci literature have examined this trade off between automation and human intervention as it relates to automl technology lee et al 34 gil et al 17 and liao et al 35 describe a set of interaction modalities for users to engage with automl sys tems lee et al 34 categorizes parasuraman s et al 41 levels of low to high automation into three different modes of interaction user driven cruise control and autopilot in cruise control a user directs an automl algorithm to a set of possible configura tions to explore as opposed to specifying a single and immediate next configuration as an example configuration can mean the user setting a parameter for hyper parameter tuning during model creation gil et al 17 describe a framework for human guided machine learning hgml which is predicated on the ability to effectively map user actions to a so called automl planner capable of translating and executing the action similar to gil e al liao et al 35 proposes a declarative way for the user to specify their objectives while allowing the system to automatically generate the underlying processes by their descriptions the systems proposed by lee et al gil et al and liao et al are akin to variable structure pipelines that were described in the previous section in that they learn the processes in the pipeline studies have also examined human ml ai collaboration as it pertains to model authoring and interpretation specifically while these studies are not exclusive to automl they highlight key challenges for interacting with and interpreting machine learning models in enterprise settings as an example hong et al 22 interviewed 20 individuals across different domains the majority of whom identified as data scientists and found that collaboration among different organizational roles was of chief importance for operationalizing machine learning models into organizational practices honeycutt et al 21 liao et al 35 and amershi et al 2 describe the ways that information can be shared between humans and automl systems throughout a variety interactions honeycutt et al 21 identifies relevance feedback and incremental learning as two general ways that humans can provide feedback to automl systems humans can provide relevant feedback which informs the automl systems about whether its actions were effective or not for example humans may provide labeled data or correct errors when they arise humans may also provide new information in the form of incremental feedback to automl systems which can be used to correct for issues like concept drift in models that have been deployed into production settings liao et al and amershi et al focus on the flow of information in the opposite direction which concerns the types of information humans require to interpret the results of from automl systems liao 35 conducted interviews with 20 ux design practitioners using a question bank to surface limitations in guidance targeting the development of explainable automl technologies their work demonstrates that the importance of the ml ai results and their presentation is highly dependent on the question posed by the individual finally amershi et al 2 proposes a comprehensive set of 18 design guidelines that outline the appropriate modes of interaction when experts a initially interact with an automl system b as the system is churning c when errors surface and d throughout user interactions studies that examine how people use automl technologies and how they respond to human in the loop features are also emerging wang et al 46 interviewed 20 data scientists across industries to interrogate their practices and perceptions of automl they found the benefits of automl for augmenting but not replacing human intuition were valued and appreciated by practitioners passi et al 42 conducted an extensive six month ethnographic study that involved over 50 data scientists their findings surface the differ ent organizational needs and challenges of data workers as they collaborated with each other in the context of automation in data science work zhang et al 53 drozal et al 13 and honeycutt et al 21 conducted controlled experiments to evaluate decision making and trust in automl technologies but their studies did not recruit current practitioners both zhang et al and honeycutt et al conducted their research via mechanical turk and drozal et al recruited undergraduate and graduate students in quantita tive disciplines zhang et al and honeycutt et al both found that reporting accuracy data alone was not sufficient for improving confidence and trust in the results produced by automl systems honeycutt et al observed that the act of interacting with a machine learning model reduced confidence of individuals in the model s performance even when the human guidance increased accuracy these findings by zhang et al and honeycutt et al underscore the challenges of designing useful feedback mechanisms between humans and automl systems while many human in the loop approaches to support automl processes and by extension data science work exist there are few chi 21 may 08 13 2021 yokohama japan crisan and fiore gartland et al studies aimed at understanding how they are integrated by practi tioners in enterprise settings we found two studies that concretely explore automl in enterprise and we build upon these findings in our present study in order to further assesses attitudes of individu als in enterprise settings toward human in the loop approaches 2 3 data visualization and automl our work specifically focuses on visualization systems that sup port human in the loop interactions for automl two prior and comprehensive state of the art surveys capture the role of visual ization in explaining 7 and building trust 8 in machine learning recent work by yuan 51 demonstrates visual analytic approaches throughout the data science process including prior to model build ing data prep and feature engineering during model building and after model building verification deployment these surveys show the diversity of approaches that are taken to support decision mak ing throughout the data science pipeline here we highlight five systems that collectively capture this diversity google vizier 18 and atmseer 47 a surface the complex latent space of models b search this space through interaction and visualization and c triage machine learning models these systems present users with results from multiple models across their hyper parameters through mul tiple coordinated views of the data as with googlevizier pipeline profiler 40 and autoaiviz 48 make use of parallel coordinate plots to help users navigate the model search space and to highlight possible hyper parameter settings autoaiviz shows the utility of conditional parallel coordinates plots to visualize subsequent steps in an automl pipeline based upon the user s current selections one limitation of visualization for automl in data science pipelines is the assumption of a fixed structure see section 2 1 making it difficult to visually compare variable automl pipelines to address this limitation pipelineprofiler was developed as a wrapper for the auto sklearn 15 package supporting the visualization and comparisons of different end to end automl implementations taken together we believe that these systems represent a cruise control mode of including a human in the loop balancing between the slower user driven and faster but less transparent autopi lot modes for executing and interacting with automl moreover these systems co created with experts in design and data science represent real implementations of the existing design guidance toward the use of visualization to help interrogate automl sys tems however it remains to be understood how such systems that are intended to build trust or transparency in automl actually get used or perhaps more concerning whether they get used at all our study sought to surface the visualization strategies within automl in enterprise settings 2 4 situating our research the current state of the art in automl is informed by multidisci plinary research endeavours spanning machine learning human computer interaction and visualization given this research effort there exist a number of automl offerings with varying types of pipeline configurations from fixed to variable and that support different modes of interaction so that intelligent services and users may collaborate efficiently to achieve the user s goals 23 how ever there remain few studies on how this technology is applied table 1 summary of the participants in enterprise settings whether users can effectively leverage the benefits of this technology and how adding the human in the loop via visualization is viewed by enterprise users moreover existing studies 22 42 46 looking at enterprise settings focused on specific themes namely collaboration and trust and did not closely examine how automl broadly intersects with data science work building on these prior findings our study conducts a broader examination of automl and data science work that surfaces how automl is situated within organizational processes 3 methodology we conducted semi structured interviews to develop an understand ing of how automl is used to automate data science work we were also interested in surfacing the role of the human in the loop as it is mediated by data visualization tools such as those used to explore data or support model tuning and selection 3 1 interviews and data collection we recruited participants through a snowball sampling approach 9 with the first point of contact being individuals that had participated in prior studies were known to the authors or other collaborators we recruited and conducted interviews with 29 individuals that self identified as data scientists or analysts engaged in data science fits and starts enterprise use of automl and the role of humans in the loop chi 21 may 08 13 2021 yokohama japan type work or a manager overseeing a team comprising either en tirely data scientists or a mixture of data scientists with others the semi structured interview format prompted participants to discuss data science work in their organization if and how they currently use automl systems or plan to deploy automl systems and the ways they use data visualization using the tableau platform or other tools interviews were scheduled for approximately 60 minutes audio recorded and transcribed our participant screening questionnaires and interview guides are provided as supplemental materials due to the nature of semi structured interviews the range of topics that participants chose to touch upon were quite broad moreover due to the novelty and diversity of uses for automl technology the perceptions and pain points described by our participants were not always overlapping all interviews were conducted over video con ferencing software a summary of participants their organization size and domain are summarized in table 1 3 1 1 sensitization to emerging concepts sensitizing con cepts are an important component of qualitative research as they ground the analysis in important emergent features and operate as a key interpretative device in data analysis 4 at the outset of our study we had some preliminary concepts that we were sensitized to from prior research we conducted that examined the nature of data science work and workers 10 we used this prior research as part of selective coding processes in addition to this prior framework we also had our own notions of concepts that could be pertinent to automl visualization and human in the loop interactions specifi cally and these informed our initial interview questions as we completed interviews we debriefed and conducted initial thematic coding of transcripts we became sensitized to particular themes in our analysis that further refined our existing concepts of data science work and generated new ideas that we had not previously considered specifically these emerging themes included the importance of different types and levels of participant expertise and participants use and attitudes around click low or no code solutions as opposed to code based solutions analysis of par ticipant pain points surfaced issues of tool switching trust and collaboration finally we also found that predictive modeling was the primary way that these organizations applied automl tech nology as we became sensitized to these concepts we revised our interview guide to ask more pointed questions about these themes we provide both the preliminary and modified interview guides in our supplemental materials 3 1 2 participant characteristics and automl use partici pants self identified as either analysts or managers analysts were individuals that were engaged in the day to day tasks of data anal ysis including data scientists business analysts or other technical analysts engaged in data science work managers oversaw teams that often contained a mixture of data scientists business analysts or other types of organizational decision makers in total 17 partic ipants in our study were analysts and 12 were managers overall participants had high data science expertise although one could be classified more as a citizen data scientist which did not have formal training in data science but was exploring this field with the aide of automl participants also represented organizations of different sizes performing a variety of functions four participants were at or ganizations with fewer than 100 individuals 10 with between 100 to 1 000 individuals 4 with between 1 000 and 10 000 2 with between 10 000 and 50 000 and 9 with more than 50 000 individuals partic ipants worked in a broad range of organizations across different industries that were focused on data analytics finance government healthcare management and consulting security telecommunica tions and travel we further stratified participants according to their current us age of automl technology active users were those who reported that they or members of their team used a specific automl tech nology to conduct their work we did not stipulate some required frequency of use daily vs not or the number of individuals cur rently using this technology experimenting users were those that reported creating proof of concepts or described at least some pre liminary projects specifically for the purposes of exploring automl technologies unlike active users those that were experimenting with the technology articulated that their use of automl was in the early stages and exploratory in nature finally those individuals that we categorized as knowledgeable had high context for data science work including automl but were not using or planning to use this technology in their work among our 29 participants 8 were active users 10 were experimenting and 11 were knowledgeable 3 2 selective coding process a prior study 10 used an open coding process to define a frame work of data science work that comprises four higher order pro cesses and fourteen lower order processes we use the set of codes from this prior study to carry out a selective coding of our interview transcripts selective coding is a stage in grounded theory research that serves to organize the analysis around a core set of variables 5 in this case the processes of data science work rather than derive and organize a new set of codes as is done in open and axial coding the reason we use selective as opposed to more commonly used open and axial coding approaches 37 is due to automl technol ogy being relatively new and as a result participants having varied experiences with it while our interviews captured a rich diversity of experiences with automl this diversity also led to spareness in our data that made it difficult to achieve theoretical saturation in an open coding process using a selective coding process allowed us to scaffold our analysis around a cohesive narrative of how automl is used across data science work the selective coding process still makes use of constant comparison that allowed us to eventually achieve theoretical saturation in our findings the set of four higher order processes and fourteen lower order processes in this framework for data science work were preparation defining needs data gathering data creation profiling and data wrangling analysis experimentation exploration modeling verifica tion and interpretation deployment monitoring and refinement communication dissemination and documentation the authors of 10 also indicated two lower order processes collaboration and pedagogy that were identified as emergent but did not have sufficient context to place within the higher order categories chi 21 may 08 13 2021 yokohama japan crisan and fiore gartland et al figure 3 example of annotating interviews with processes from an existing framework of data science work and work ers 10 in figure 3 we exemplify how we performed a selective coding for these processes across our interviews some statements made explicit references to data science processes for example hard part data discovery data curation are explicit references to the preparation higher order process as the terminology used can be linked directly to a higher order or lower order processes in the existing framework by comparison some references to processes were more implicit and were inferred by the authors with other context from the interviews for example still need to educate and visualization is important for that still need someone who is thinking through the problem was determined to be an implicit reference to communication processes although there were not explicit terms specific to communication as with putting any model into practice the prior framework not only deepened our analysis but also generated natural tensions between our observations and our framing of data science we lever aged these tensions as points of inquiry that allowed us to critique or expand upon these frameworks based upon the participants reported experiences we reflect on our approach and propose mod ifications to it that we describe in section 5 4 as these modifications were motivated by our analysis and again in discussion section 6 4 results we first present our general findings regarding prevailing attitudes toward automl and the role of automation of data science work then we examine the intersection of automl in data science work at a level of higher order processes 4 1 attitudes toward automation in this section we describe prevailing attitudes toward adopting automation in data science as described by our participants we identified four primary themes that encapsulate these attitudes the role of automl to drive productivity the importance of tool integration the concerns about automating bad decisions and finally the desire to limit the role of the human in the loop 4 1 1 improving productivity automl was embraced with cautious optimism by participants at organizations of different sizes but we found that it tended to be more widely used or ex plored at larger organizations it is not clear what is driving these differences but we believe that it may relate to different amounts and rates of data collection at larger organizations that motivate a greater need for automation among larger organizations that had implemented data science automation tools the primary reason for investing in automl was that it just makes data scientists more productive p 01 by automating aspects of their work and allowing them to triage to focus on more pressing problems as a specific example p 07 indicated that there is lots of waste determining which models to work on i wonder if we should focus on managing the pipeline so that the things get through have more impact we need a predictive model to figure out which predictive models are the ones to work on the automation of routine work like model tuning and selec tion was seen as a desirable way to shift the effort of human labor toward model verification and if needed correction tasks while some participants felt strongly that technical expertise was required to safely use automl technology for productivity gains a topic we return to in 4 1 3 others p 03 p 12 saw the benefit of automl to democratize data work individuals without a background in statistics and computer science that occupy roles of business an alysts or moonlighters 10 33 would benefit from the lower barrier to entry that automl affords this democratization effort may improve productivity in those roles but it also opens a door to capabilities across self service analytics that were previously inaccessible overall automl systems reduce the amount of code that is needed to use data within data science workflows individuals with high technical expertise such as data scientists can leverage au toml systems to improve speed and efficiency of routine tasks for non experts automl systems can also democratize the accessibility of data science workflows and machine learning solutions 4 1 2 the importance of integrating tools participants re ported using a variety of commercial tools to facilitate automl work and the need to create custom solutions for preparation de ployment and communication data science processes participants used or were actively investigating platforms like alteryx n 5 for automating their workflows and integrating with data robot n 3 or h 2 o ai n 3 to facilitate automatic modeling steps dataiku was also used in lieu of alteryx and was seen as a better tool for facil itating collaboration across processes participants also reported using sagemaker n 2 powerbi n 2 azure and data bricks 1 participants report leveraging libraries like tensorflow n 4 scikit learn n 2 and mxnet n 1 for their automl work python r and their attendant notebook environments were described as being used by roles that had higher technical expertise however p 02 observed that businesses can t deal with the notebooks be cause data scientist s are now needing to build things that can run in a production environment in order to operationalize models moreover as organizations seek to spread out the data work from data scientists to others in the organization p 15 observed that they were starting to see heavier reliance on data science products that don t require heavy coding for individuals without a data science or computer science background the need to write code appear to be a barrier but our participants comments indicate that automl can lower or potentially remove this barrier moreover there is an increasing appetite for a platform that helps people move between tools that they have selected p 04 and where 75 of the organization could work tool switching is common in data science because there are different tools for different analysis and yet we found most users would prefer to stay in one environment p 06 fits and starts enterprise use of automl and the role of humans in the loop chi 21 may 08 13 2021 yokohama japan importantly data science processes are not linear but occur in a big recursive p 09 loop constantly changing environments within multiple cycles of iteration and refinement is time consuming and impractical participants did report visualizing their data via sys tems like tableau or via charting libraries in r or python but many described their limited use as organizations scale they re going to spend less and less time doing visualizations the job is to deliver results of a model in some form data scientists aren t going to deploy with ggplot but they may use it for static reporting or just for their information p 17 this participant didn t see visualization tools as scaling well alongside automl and other data science work leading to aban donment especially within results communication two other par ticipants had to awkwardly move back and forth across modeling and visualization tools and as a result the role of visualization was limited throughout the process 4 1 3 concerns of automating bad decisions participants also clearly understood that blind trust in automl could lead to po tentially catastrophic failures p 20 worries that lots of people will try to predict things without really understanding people will make horrific mistakes and not realize they ve made them p 12 col orfully indicated that having this automl tooling may just allow people to make stupid mistakes easier p 05 observed that it s bad to slap together models and try to make decisions from it without understanding how things work that s like giving a loaded gun to a child participants were also concerned about regulatory con straints for example the european gdpr legislation that requires organizations to be able to explain decisions made by automated data science technologies even without legislative pressures there were internal organizational concerns around these technologies especially when large financial decisions were involved a toler ance for errors and failure was an important factor in evaluating the use of automl technology however in many cases perfection was not required for instance p 12 observed that there were lots of business use cases where 80 accurate could be okay p 29 s observation echoes p 12 s that it is desirable for automation to help your surface failure points in your data preparation and analysis processes i think they executives want you to use those auto mated insights to look at a graph and say oh wow this is life changing let s go make this change in our business we didn t use it like that we used it to make sure that the results we were getting back made common sense a surprising finding was the general concern around the use of automl by citizen data scientists or domain experts that were not formally trained in data science statistics or computer science p 12 stated that while they understand organizations want to democ ratize data science work it still worries them because in practice you ll still have to be pretty technical to analyze data p 22 raised the issue of the overhead needed to ensure those who aren t as well versed in the data science space are able to not make silly mistakes that they shouldn t be making perhaps the strongest stance we heard was from a participant who stated that they would restrict it automl just to the data scientists and use it to get efficiency after demonstrating they know they are doing p 05 this attitude was a recurrent theme in our study overall from participants responses we see that the promise of automating data science is tempered by very real concerns of how things could go wrong however this does not mean that organizations are pulling back from their investment in these tech nologies as p 02 noted ambition is still industry 4 0 with lots of automation 4 1 4 limiting thehuman in the loop concerns toward safety and trust of automl inmanyways highlight the value of humans in the loop approaches to balance automation with human oversight however participants also expressed concerns about the inclusion of humans within the automl loop for example while p 02 ex pressed that there was still lots of room for humans in the loop innovations in their industry they also stated that the manual part where you have to visualize something is getting cut out as much as possible p 01 stated that even as there are lots of automated tools in place making decisions at the same time there was a lot of anxiety in the firm about what people do with ml stemming from concerns of automating decisions at scale we interpret these seemingly contradictory positions to mean that human in the loop approaches are valuable when applied at the right time and in the right way 4 1 5 summary we briefly summarize the key takeaways for participant attitudes toward automl while participants expressed concerns about the potential to automating bad decision making there was also a growing interest in using automl technology to produce a good enough result that could scope out the viability and possible issues with the data or machine learning product automl allows for the creation of sophisticated tools with minimal code and offers opportunities to fail fast which enables data scientists and even so called citizen data scientists to surface issues earlier however what is most clear is that applying automl technology at suitable points in data sciencework is very important otherwise it is dismissed as intrusive to further explore when and where automl technologies could support data science we analyzed interviews through the lens of an existing model for data science work 4 2 automl in data science work in this section we summarize our findings on the use of automl in the data science process we consider places where considerable human labor is required either to support the creation of a machine learning model or to interpret communicate and act on its find ings following the framework described in section 3 2 we begin by examining automl in data preparation followed by analysis deployment and communication 4 2 1 data preparationcontinues to be arate limiting step for automation participants understood that without robust data preparation the automl portion of their data science processes would be ineffective p 02 succinctly stated that automl has never been the solution it s a shiny toy it s always going to be about the quality of the data do you understand what you are modeling chi 21 may 08 13 2021 yokohama japan crisan and fiore gartland et al in our interviews participants identified several challenges in data preparation work that still required a lot of human labor from gathering data profiling it and wrangling it into shape for analy sis it is important to emphasize that participants rarely began by cleaning a single tabular dataset but often needed to bring several data sources together p 12 reported that 40 50 of my team s time was spent on alteryx to bring data together while p 23 reflected that the most difficult part of my day is getting the data that i need to work with once the data were gathered participants faced difficulties with data profiling a challenge that was also surfaced in prior work by kandel 31 and alspaugh 1 p 19 expressed that automation in data profiling would be a huge win i spend a ton of time having to explain the shape of data and what shapes work best how to explore the data and how to refactor as needed even when participants have data gathered and profiled they still need to assess its utility for further downstream analysis rapid iteration via automl plays a role in speeding up thismanual process p 23 described that they get the data to a point where maybe it s 60 clean and they start to run algorithms in order to expand on the data itself the workflow described here resonates with rapid prototyping and failing fast to discover issues or limitations in the data this observation also echoes data reconnaissance and task wrangling processes previous described in 11 inwhich individuals acquire and quickly view data in order to assess its suitability for analysis and decide whether to pursue additional data sources despite the usefulness of automl driven prototyping challenges associated with data preparation remain this reflects an emerging theme from our analysis that there is a growing need to more tightly couple investments in data prep and model building for instance the experience of these challenges led p 03 and their team to make more significant investments toward tools for democratization of data prep and to a lesser extent model building it is not surprising that data preparation is both time consuming and important to the successful application of automl and data science more generally prior studies 33 46 with data scientists and other domain experts have routinely pointed to this bottleneck for years and visualization tools such as trifacta and its academic predecessors wrangler 32 and profiler 30 and tableau prep have been developed to address this challenge it is disconcerting that preparation continues to be such a significant bottleneck de spite existing tools our observations suggest that one reason for this may be that existing tools for data preparation do not easily fit within a data workers analytics environment by extension of these observations automl technology needs to be well integrated with existing tooling environments while also surfacing the manual labor and lack of adequate tooling for data preparation 4 2 2 use ofautoml inanalysis varies bydata sciencerole perhaps as a testament to the advancement of automl technology participants reported that model building is fast and easy p 12 p 25 further elaborated that if i can actually get through all the data stuff then getting the predictive model is not really that hard there s a huge bunch of code to get the data ready for the model then a tiny bit of code for the model and then the rest of the work is delivery to the customer the desired amount of oversight and control over automl in the analysis appeared to vary by level of technical expertise p 26 felt that individuals with high expertise in statistics and or computer science were less likely to use automation because they want everything to be customizable whereas thosewith less technical expertise whom they refer to as citizen data scientits were focused on integrating intelligence to their app and tended to prefer higher levels of automation this latter group is growing as p 03 observed the vast majority of data science type work is done by non data scientist s from participants responses we also noted that this group with a low or evolving technical expertise often needed heavy guidance low or no code automl implementations and visualization p 29 also observed how individuals with higher technical expertise could act as a rate limiting step to analysts engaged in data work but that automation could serve as a catalyst analysts maybe can do their own little their own little predictions off to the side and they can do them fast phds could always do it better but are they there do they have time the answer is almost always no you can either do good or you can do nothing better is there but you re not getting better they re phds busy working on the big problems moreover summarize that individual withwithout high technical expertise benefited from proper guidance no code solutions and data visualization to help situate themselves within the analysis process given many steps in data science workflow contain lots of details that are hidden p 03 it was surprising that visualization was not more widely men tioned to steer the model authoring processes even though there exists a number of visualizations systems to help individuals do so 7 8 53 one possibility is that individuals with high technical expertise are constructing novel and bespoke models that exist ing data visualization tools cannot easily support instead these technical experts might benefit from highly customized visualiza tions for certain classes of models such as those generated by tensorboard 49 in contrast individuals with lower technical ex pertise lack the background knowledge to orient themselves and effectively interact with visualizations exposing the mathematical underpinnings of machine learning models they rely on the au toml systems to make model decisions and it may not be easy for them to correct and refine these models while participants did raise concerns that automl derived mod els and results were a black box it also appears that technical acumen in statistics and computer science was perceived as nec essary and possibly sufficient to open up the black box echoing concerns we summarized in section 4 1 3 participants saw automl as potentially contributing an existing knowledge gap that is becoming wider p 19 because the availability of automl meant that individuals with lower technical expertise could harness the power of machine learning without having to seriously engage with its technical and nuanced underpinnings our interpretation of these concerns was that trust in the individual conducting the data analysis was as important as trust in the automl process itself moreover collaboratively sharing knowledge or including fits and starts enterprise use of automl and the role of humans in the loop chi 21 may 08 13 2021 yokohama japan human oversight may mitigate some of these concerns and could be achieved through visualization of data science processes the differences in data science roles and the extension of data science work to individuals without formal training in statistics and com puter science has several implications for the design of automl and visualization tools while automl tools reduce or even eliminate the need to write code it becomes important to consider what kinds of guard rails might need to be put in place we believe that data visualization tools are an important component of such guardrails but that we require a finer grained understanding of data workers to design such tools effectively 4 2 3 good enough rapid prototyping to bootstrap anal ysis participants used automl technologies to rapidly prototype viable solutions in both data preparation and analysis the need for rapid prototyping stems from the challenges of generalizing automl to a variety of problems which requires manual effort p 21 acknowledged that automl is really hard and i think we have so many operations with such nuance that we actually most of the time really just want to be doing simple stuff correctly rather than adding additional layers of complication p 24 was much more ex plicit in stating that every customer is different but automl is supposed to be a generalized framework so that is a problem the challenges of automl to generalize to a variety of problems are known especially when it concerns fixed structure computa tional pipelines which is the most common implementation of automl 54 despite this lack of generalizability participants found that they could leverage automl to rapidly prototype data science solutions p 23 offered description of such a use case i talk to clients daily if i could get ml done just real quick as a prototype into what we could build in depth that would be super helpful can you get me 50 of the way to answering some question quickly that would benefit me p 21 reported using automatically generated results to start a conversation with others ahead of making serious personnel or infrastructure investments they shared that when starting out with a client we ll run the default model andwe ll say hey here are some of the topics some of the interesting trends that are coming out and then use the clients reaction to further refine upon default model or craft a different solution altogether as we previously reported p 12 and p 29 alsomake the case for failing fast to discover issues in the data or analysis without expensive upfront investment in fully developing an automated data science pipeline this rapid and iterative use of automl to drive different data conversations evokes a complex picture of a data worker operatingwithinmultiple loops of data science and organizational processes this prototyping scenario offers an evocative example of how the limitations of automl technology can be beneficial leveraged through human in the loop interactions we argue that with adequate guardrails in place automl systems may also be able to further support the process of surfacing potentially more complex issues of bias 4 2 4 inadequate support for governed and managed de ployment processes the majority of machine learning models often do not advance to production environments where they are applied to real data those that do are often required to go through a set of governed processes before they are deployed and are con stantly monitored once they are out in the wild these governed processes vary as p 01 described a governed workflow is important looking at what all teams are doing are there divergences around governance etc e g models with a financial impact have a very stringent governance process the volume and variety of both data and models makes it chal lenging to monitor and govern automl models deployed in pro duction p 03 reported that their practice was to err on the side of letting people use tools they preferred and to monitor what tools are being used they emphasized that vigilance was important to ensure mistakes do not clog up the server with bad content which might happen when pushing a model generated by automl into production without adequately vetting it these problems exist for all software code in general but may be further exacerbated by the novelty and complexity of automl moreover the amount of data produced by automation can make it overwhelming to effectively govern models that need to be continually validated and have a process that employs someone to look for drift look to increase accuracy and effectiveness of these models over time p 07 larger organizations working under enforceable regulatory constraints struggle to find the right balance between integrating a potentially valuable new technology like automl while conforming to these constraints there are areas where critical models are developed that will likely have very strict controls often imposed by a regulator if you have no clue what that model result means you are on pretty thin ice p 03 as with preparation the processes of governing deployedmodels still requires considerable human effort moreover we believe that adding some sort of automation to these processes is desirable in order to reap the efficiency benefits of automl dashboards are often used to monitor changes in data 44 but participants did not report using dashboards for automl work even though they may already use dashboards for other types of work we hypothesize that this relates to the tooling environment and that monitoring and the governance of automl systems require more specialized dashboards that are not well supported by existing tools there may be fruitful work here for visualization and hci research to improve governance processes through better monitoring and at least help them triage governance violations improved awareness and consideration for governance throughout the visualization design process can also inform the implementation of guardrails for automl throughout data science work 4 2 5 correction and repair of deployed models human oversight of automation is critical to detecting when something new or unexpected has happened identifying the source of what has happened and implementing appropriate corrective actions as needed while there may be some ability to automatically detect anomalies and thus make governed workflows easier to monitor participants expressed doubt that such an approach would work in practice p 12 stated that if the forecast is clearly wrong a human can detect this whereas it is harder for the automl tool to do so still other participants articulated the limited abilities of analysts chi 21 may 08 13 2021 yokohama japan crisan and fiore gartland et al to intervene appropriately suggesting that some analysts wouldn t necessarily knowwhat to do next whereas a data scientist might know what to do next for improving forecasts for analyzing how good it might be p 26 succinctly summarized that as you re only as good as what you debug these observations align with a recurrent theme in our findings that trust between the underlying technology and the data science teams is critical for the wider adoption of automl moreover these observations expose the brittleness of automl technology and its reliance on iterative loops of correction and refinement with humans in the next section we also emphasize that automl loops are not closed systems rather these are loops that interact with many other loops of business processes and pre existing modes of human collaboration thus debugging not only requires technical expertise that spans the preparation to deployment processes but includes sufficient domain expertise to recognize and account for other loops that interact with and beyond data science 4 2 6 communication andcollaboration build trust in au toml communication and collaboration are essential data science processes including but not limited tomodel automation 33 46 52 automl systems require communication between humans and the technical system p 22 expresses one such mode of communication in which the automl system helps guide users in analysis by com municating this is what it is that you re about to do and this is the impact it will have and should also prompt users with respect to certain actions with are you sure you want to do this p 17 also noted that more could be done to walk the user through that a data analysis for example given a kind of data to predict here are the kinds of models and visualizations to use automl introduces a new mode of collaboration between humans as well this new frontier can also be challenging to navigate as p 29 observed so there s human interaction along the whole life cy cle and interpreting that human interaction is what we re trying to get machine learning to do however participants indicated that these diverse individuals must still work together to deliver actionable and safe results from automating technology a common theme emerged around the de sire to broaden data engagement across the organization bringing more people into the data sensemaking loops in p 21 s words we need our workforce to be more data savvy across the board an engineer needs to be able to play with data as much as the mba does and giving them better tools will help with ramp up a big part of having teams work more effectively together is to provide more situational awareness of data science workflows and who has done which task for instance p 06 described what would be needed to support teams working together across workflows this support includes surfacing notification s that people are working on the same step and underlying metadata about how people were using the platform p 06 integral to this collaboration was the ability to hand off different aspects of the data or analysis processes to different team members likely with a different data science role they can create a workflow share it with other people people can build off of that workflow grab a table from that workflow and then build their own that collaboration aspect of it was important to us p 29 in order to improve collaboration some participants defined a vi able solution around making workflows visual interrogable and extensible participants also highlighted the importance communicating to individuals that were one step removed from the data analysis pro cesses most often communication to executives or other business leaders in this process visualization plays a clear role as a communica tion tool a theme emerging from the analysis was that participants often framed this part of the process as more difficult than the modeling itself this was due in part to the extra work required for example p 19 describes the additional labor it takes especially when the visualization tools are not well integrated into existing processes there is a gap once your analysis is done on present ing the results nobody wants to spend more hours in another tool to build charts for explanation for instance p 05 described the challenges of authoring compelling visualizations and how nice visualizations feel like a hack that the average user can t build themselves the other challenge often cited was around the efficacy of visual izations as a medium of communication to drive business decisions or processes participants described the challenge of translating their work to business users that were not versed in modeling vernacular in one participant s words we don t want people to actually understand model jargon we want to help them under stand what the model is saying in business terms this participant relies on interactive visualizations to support the dialogues that they anticipate will happen when showing a snapshot of results to bridge the gap still despite efforts to translate for business users this participant s team experienced a range of challenges in opera tionalizing their models p 26 describes how the challenges that we saw as the data science team is we give this model or results to them but then actually the action of implementation of this in the market sometimes doesn t always pull through so it s like we did all this work you said it was good but now you have to take it to the last mile actually get to marketing creative and content and get it out to market they point to communication difficulties between data scientists and others at the organizations as exacerbating this last mile problem which results from either lack of funding or sense of disbelief in prediction models and ml techniques p 26 validation measures may also be required for regulated industries that can slow this process down taken together the collaborative nature of data science work imposes constraints on the design of vi sualization tools which must be usable across the organization and interoperable by individuals embedded within a variety of analytic business and governance processes 4 2 7 summary our examination of automl technology along the data science pipeline both where it exists and where it does not helps us to understand the current capabilities of this technology and how the technology and its surrounding ecosystem can be fur ther developed to support data scientists and others we see gaps for automl technology outside of data analysis processes and that translate to unmet tooling needs in data preparation governance fits and starts enterprise use of automl and the role of humans in the loop chi 21 may 08 13 2021 yokohama japan and deployment processes these are also processes where consid erable human labor is still required to make automl technology in data analysis viable automation that extends to these other pro cesses ideally with appropriate guardrails could improve both the quality and speed of data science work moreover the relationship between automation and data science expertise emerged as a criti cal consideration for what future tools should support including the types of guardrails that should be built in we were surprised to surface some of the tensions that existed between data science experts and data workers with different training emerging from this tension was one heavy handed guardrail strategy to restrict access to automl technology that many sought to implement we believe this view has surfaced from a lack of adequate tools to support the safe creation deployment and governance of these models and that there are many fertile opportunities for visualiza tion research in this space however our analysis of participants comments reveals that existing visualization tools are falling short of their needs moreover that data visualizations tools can have a steep learning curve and their is little motivation to use following intensive analysis we underscore that it is critical to understand the diversity of teams that carry out data science work and the ways they intersect with many organizational processes in other words visualization tools need to work for many humans engaged in many loops 5 interpretation of findings we now reflect on our findings and summarize the central themes that emerged from our analysis 5 1 three usage scenarios for automl emerge the general attitudes toward automl suggest three usage scenarios for this technology that are conditioned on the technical expertise statistics and computer science of the individual analyzing the data and the magnitude of consequences associated with errors the first usage scenario is automating routine tasks thereby re ducing the coding efforts of data science teams and improving the speed of the analysis processes a second usage scenario is the rapid exploration of potential data science solutions through low effort prototyping such prototyping approaches can be used by individu als with varying degrees of technical expertise its possible that for individuals with high technical expertise such as data scientists generalists research scientists ml ai engineers and data shapers prototyping allows them to quickly create a base framework that they further develop into novel solutions for arising technical chal lenges for other individuals prototyping enables them to have a conversation around the data with customers and other members of their organization prototyping also enables individuals and data science teams to fail fast and discover issues with their data and analysis before investing in considerable engineering effort a third and final usage scenario is the use of automl toward democratizing the ability to create a machine learning model empowering indi viduals that would not be able to build a model otherwise in this third scenario we argue that individuals require heavy guidance and guardrails from an automl systems and may have very limited ability to identify errors or correct them the delineation of these usage scenarios is intended to guide visualization researchers as they explore opportunities to develop techniques or systems for automl 5 2 varying the level of automation across data science processes considerable human labor is still expended to prepare data govern and deploy a model and to communicate the results to impacted individuals and other decision makers an end to end automl so lution capable of addressing the full scope of such data science work does not currently exist and as a result data workers which includes individuals that are and are not data scientists are finding ad hoc ways of bootstrapping automl technology into their work in figure 1 we outline a common set of eight steps synthesized from participants responses describing automl use in enterprise settings we further align these steps within higher order data sci ence processes for data preparation and analysis these tasks were prototyping exploring the results and settling on a solution to implement should this solution reach a certain level of maturity it is deployed into production following a verification of the solution including compliance of regulations where it is consistently mon itored while in production finally these deployed models can be used to take action through an inspection of the results that surface new insights for decision making we illustrate the levels of automa tion 41 that we believe are desirable for future automl systems to support considering the range of participant challenges and concerns this study surfaced importantly the level of automation is not consistent across all data science processes human oversight is still required throughout data science work and is dictated by both regulatory requirements and organizational practices most automation likely needs to adopt a cruise control mode of interac tion 34 where humans can oversee and steer automl systems without needing to guide the systems at each step even this would be an improvement over current automl systems that appear to oscillate between autopilot and user driven modes we further illustrate the level of automation required by individuals with high expertise in computer science and or statistics data scientists ml ai or data engineers and low or an evolving technical exper tise in these areas business analysts moonlighters individuals with high expertise can benefit from full automation for example when speeding up routine work usage scenario one or to rapidly prototype and explore new solutions usage scenario two even in these two usage scenarios individuals with high technical expertise still rely on considerable manual effort but this in fact might be an appropriate use of their expertise and focus on bigger problems especially if other trivially automated tasks are reliably handled by an automl system individuals with lower or and evolving techni cal expertise require much more support and guidance and would rely much more on full automation to rapidly prototype solutions usage scenario two or even to begin to engage in data science work more generally usage scenario three however while these individuals rely on automl systems to guide them their domain expertise still needs to be incorporated in downstream steps while figure 1 is a useful illustrative summary of our findings it needs to be further validated in future studies that assess its generalizability we suggest how to do so in our discussion section chi 21 may 08 13 2021 yokohama japan crisan and fiore gartland et al 5 3 eliciting tasks for visualization design taken together these usage scenarios an levels of automation im pose a set of constraints for the design of visualization tools that op erate together with automl technologies visualization researchers need to carefully consider where and how automation is currently deployed the diversity and expertise of the data science teams and the full breadthof data science processes we have illustrated a set of steps and proposed the levels of automation in figure 1 that data workers with different levels of expertise desire importantly by illustrating an end to end pipeline we encourage visualization researchers to consider how changes across a workflow influence the kinds of data to be visualized and the fundamental tasks that these workflow steps support for example prototyping may have different tasks associated to it depending on whether the analysts want to develop a new model fail fast or prototype some solution for a customer the monitor process in deployment could rea sonably rely on high automation until the system requires human action much like auto pilot in aircraft alternatively exploration may require less automation if the user is expected to steer the algorithm without a concrete understanding of usage scenarios data science steps and level of automation researchers risk elicit ing inappropriate tasks and creating visualization tools that will be dismissed because they are not well integrated into end to end data science workflows visualization researchers can reference our findings and the summary in figure 1 as a guide to support their own task elicitation for the design and evaluation of visualization tools 5 4 modifications to our analytic framework lastly we briefly reflect on our findings and propose modifica tions to the framework of data science work and workers reported in 10 we remind the reader that this framework is described in section 3 2 and delineates a set of higher and associated lower order data science processes that we used as part of selective cod ing analysis first we propose that collaboration be added as a lower order processes of communication while collaboration was part of the original framework there was not enough evidence to determine how it should be incorporated this analysis sug gests it belongs as a component of communication alongside documentation and dissemination lower order processes moreover collaboration emphasizes the ways that individuals engage in multi directional exchanges of knowledge and data products data code models documents whereas dissemination refers to a more uni directional exchange of knowledge from an individual to others second we propose that governance be included as a lower order process of deployment while governance processes can technically encompass all of data science work our findings point to its specific importance in managing the process of launching monitoring and refining machine learning models deployed into production set tings finally we propose a new higher order process guidance which follows communication we assign three lower order guid ance processes based upon our analysis human machine guidance human human guidance or pedagogy and organizational guid ance human machine guidance describes the interplay between automl tools surfacing new data insights to humans and humans making corrections and refinements of automl models and results human human guidance describes the collective work in building a data savvy organization and other efforts to bridge the data science knowledge gap alternatively this could be referred to as peda gogical process finally organization guidance refers to regulations and other organizational processes that impose constraints on the use of data models and the level of automation 6 discussion visualization and hci researchers have used enterprise studies to discover unmet needs of practitioners that have inspired new re search trajectories that have ultimately led to new techniques and tools as we consider the future of automl in enterprise we believe a cruise control level of interaction 34 figure 1 is more likely to be adopted however we see significant barriers to implementing such a level of automation that stem from the diversity among data workers with different types expertise a complex tooling environ ment that needs to be integrated and brittle workflows that still rely on considerable human effort although visualization can play a role in supporting cruise control type automation it was not being widely used to that effect and in some cases getting actively removed from automated data science workflows we believe this lack of uptake is that visualization tools are potentially misspecified for the tasks they need to support and that this stems from poor understand of how automation is used in data science work and where there are opportunities for human in the loop interaction our study fills this gap by surfacing usage scenarios and illustration of automation throughout data science work which informs the goals and tasks feeding into visualization design and evaluation 6 1 implications for automating data science work throughout our analysis we found both automl and human in the loop to be misnomers for the processes that participants were describing first we noted in section 2 that automl is used to refer to an ever expanding set of data science processes from preparation to deployment and as such is being used interchangeably with automating data science among other phrases we argue this is limiting as not all automation of data science needs to be in service of machine learning systems moreover the notion of end to end automl obscures the human labor required for these systems to work now and in the future leaving inadequate support for human machine collaboration echoing wang s 46 language we encourage researchers to augmenting data science with automl rather than automating it it is more than a matter of semantics the idea of augmenting data work explicitly makes space for human engagement and brings humans needs to the forefront of consideration second when we make explicit space for human engagement we are encouraged to consider the diversity among data workers as we summarize in our three usage scenarios this type of en gagement will vary depend on the goals of data workers and their level of technical expertise along with prior studies 42 52 we found collaboration among data workers to be of critical impor tance to the success of data work commensurate with findings from hong 22 we also show that trust amongst individuals en gaged in data work was as important or more so than trust fits and starts enterprise use of automl and the role of humans in the loop chi 21 may 08 13 2021 yokohama japan in automl surprisingly automl technology appeared to erode trust among collaborators of different technical expertise by en abling so called citizen data scientists to potentially automate bad decision making in theory a human in the loop paradigm for augmenting data science work can also be useful to understand the types of engagement between humans and machines that could ameliorate some of these trust concerns however here too we find that human in the loop is a limiting term an automl correction and refinement loop not only exists within a wider scope of data science processes but also within organizational processes while the nomenclature of human in the loop is not exclusive to a single individual interacting with automl we argue that the notion of humans in the loops more accurately captures how this technol ogy is used within enterprise settings we note that a limitation of our findings was that study participants were primarily although with some exceptions experts in data science while several were managers who oversaw mixed teams we none the less believe it is useful to follow up our findings by soliciting the views of those individuals that are not data scientists but work closely with them as visualization and hci researchers continue to explore ap plications of technology like automl in data science work we encourage them to consider the diversity of humans involved in data science work their different needs and varying degrees to which they benefit from automl technology as well as the myriad organizational loops that are entangled within automl and data science 6 2 implications for data visualization systems overall we see that there are opportunities for visualization tools in data science work especially in areas where there already ex ist considerable human labor we especially see that participants struggle to get an overview of data work and that this complicates their ability to effectively handoff data models and results within their organizations a visual overview of data science workflows emerged as an organic solution and is a promising area of future research but beyond this specific example we hope that the usage scenarios we present will help researchers identify new unmet visu alization needs toward the use of automl that we did not surface here however the most troubling findings from our study concern the ecological validity of data visualization systems we hypothe size that one reason visualization tools were not more widely used by participants was because they did not integrate well into existing data science tooling environments this may be because existing visualization tools are developed as stand alone systems where it is difficult to import data and export results or because existing systems do not scale well to the volumes and varieties of data that organizations collect or even because these visualization systems are themselves too brittle to flexibly adapt to variable data science or automl workflows moreover visualization tools may not cater well to individuals across the gradient of technical expertise and thus may be too rudimentary for those with high technical exper tise and too complex for those with lower expertise we encourage researchers to use our findings as a guide for surfacing these threats of ecological validity early another fruitful area for visualization researchers is the creation of guardrails that surface and alert individuals of potential issues with their data models or results the development of guardrails can help to examine concerns toward automating bad decisions our research indicates that their design is contingent upon individual expertise the context in which individuals are using automl and the level of automation that is expected some areas like data preparation will require more human labor alongside tools that automate their processes others like monitoring a deployment model would rely on human labor primarily to respond to events like the detection of model drift guardrails in both scenarios can help analysts contextualize and triage problems as they arise but the design of these guardrails will differ between these two scenarios well designed guardrails may also increase trust and collaboration not only between data workers and automated processes but also among data science teams while prior research has suggested design considerations 2 and potential analytic pitfalls across visual analytics processes 36 research is needed to bring these together to explore dynamic and adaptive visualization guardrails that are appropriate for an individual s current analytic context 6 3 limitations and future work the lack of existing studies on automl use in enterprise settings was the motivating factor for carrying out this research our find ings support prior research and shed new light on the challenges and uses of automl in enterprise settings however we also found that participants had quite different experiences in their use and expectations of automl as a result our findings were simulta neously rich in capturing the diversity of experiences and sparse in that some of our findings relied on a handful of observations to produce a cohesive analysis of these experiences we used an existing framework for data science work and workers as a scaffold this sparseness of data and reliance on a scaffold is the primary limitation of our findings further work is needed to validate the generalizability of our findings but this may be difficult due to the novelty of automl technology itself one fruitful area of future work is to take the key insights from our research as constructs around which to develop a survey instrument that probes into automl uses more specifically than our current interview study we did not take this approach here because we felt we needed additional information on automl use in the enterprise settings and beyond a future survey instrument could also be used within a large mixed methods approach such as sequential explanatory design which uses the survey results in lieu of the framework we use here as a more data driven approach to inform a subsequent qualitative analysis 7 conclusion automating data science work through automl technology will continue to be commonplace in enterprise settings especially at large organizations that work with large volumes of data we iden tified three usage scenarios for automl that we argue are routine in current enterprise environments these are automation routine work rapid prototyping for a potential solution and democratizing access to machine learning technology and data science work more generally moreover we surface the complex handoff of data work chi 21 may 08 13 2021 yokohama japan crisan and fiore gartland et al between automl systems and data workers as well as between data workers having different levels of technical expertise indeed automl systems still rely on considerable human effort to be effec tive and even as this technology improves human oversight will still be required to be sure it is safe and effective while data visual ization can play an important role together with automl we find that it is used infrequently and is actively being minimized in data science work we see our findings as having important implications for recasting the role of visualization in conjunction with automl and data science more generally acknowledgments the authors wish to acknowledge and thank to study participants for sharing their insights with us we also wish to acknowledge members of the tableau research user research and tableau crm for their feedback on our study and findings references 1 sarah alspaugh nava zokaei andrew liu cindy jin and marti a hearst 2019 futzing and moseying interviews with professional data analysts on exploration practices ieee transactions on visualization and computer graphics 25 1 2019 22 31 https doi org 10 1109 tvcg 2018 2865040 2 saleema amershi dan weld mihaela vorvoreanu adam fourney besmira nushi penny collisson jina suh shamsi iqbal paul n bennett kori inkpen jaime teevan ruth kikin gil and eric horvitz 2019 guidelines for human ai interaction in proc chi 19 1 13 https doi org 10 1145 3290605 3300233 3 david m blei and padhraic smyth 2017 science and data science proceedings of the national academy of sciences 114 33 2017 8689 8692 https doi org 10 1073 pnas 1702076114 4 glenn a bowen 2006 grounded theory and sensitizing concepts interna tional journal of qualitative methods 5 3 2006 12 23 https doi org 10 1177 160940690600500304 5 anthony bryant and kathy charmaz 2007 the sage handbook of grounded theory sage publications los angeles calif 6 longbing cao 2017 data science a comprehensive overview comput surveys 50 3 2017 1 42 https doi org 10 1145 3076253 7 angelos chatzimparmpas rafael m martins ilir jusufi and andreas kerren 2020 a survey of surveys on the use of visualization for interpreting machine learning models information visualization 19 3 2020 207 233 https doi org 10 1177 1473871620904671 8 angelos chatzimparmpas rafael m martins ilir jusufi kucher kostiantyn rossi fabrice and andreas kerren 2020 the state of the art in enhancing trust in machine learning models with the use of visualizations computer graphics forum 39 3 2020 713 756 https doi org 10 1111 cgf 14034 9 johnw creswell and cheryl n poth 2018 qualitative inquiry research design choosing among five approaches fourth edition ed sage publications los angeles calif 10 anamaria crisan brittany fiore gartland and melanie tory 2020 passing the data baton a retrospective analysis on data science work and workers ieee transactions on visualization and computer graphics 2020 https doi org 10 1109 tvcg 2020 3030340 11 anamaria crisan and tamara munzner 2019 uncovering data landscapes through data reconnaissance and task wrangling 2019 ieee visualization conference vis 46 50 https doi org 10 1109 visual 2019 8933542 12 david donoho 2017 50 years of data science journal of computational and graphical statistics 26 4 2017 745 766 https doi org 10 1080 10618600 2017 1384734 13 jaimie drozdal justin weisz dakuo wang gaurav dass bingsheng yao changruo zhao michael muller lin ju and hui su 2020 trust in automl ex ploring information needs for establishing trust in automatedmachine learning systems in proc iui 20 297 307 https doi org 10 1145 3377325 3377501 14 manuel fern ndez delgado eva cernadas sen n barro and dinani amorim 2014 do we need hundreds of classifiers to solve real world classification problems journal of machine learning research 15 90 2014 3133 3181 http jmlr org papers v 15 delgado 14 a html 15 matthias feurer katharina eggensperger stefan falkner marius lindauer and frank hutter 2020 auto sklearn 2 0 the next generation https arxiv org abs 2007 04074 16 matthias feurer aaron klein katharina eggensperger jost tobias springenberg manuel blum and frank hutter 2015 efficient and robust automated machine learning in proc neurips 15 2755 2763 https doi org 10 5555 2969442 2969547 17 yolanda gil james honaker shikhar gupta yibo ma vito d orazio daniel garijo shruti gadewar qifan yang and neda jahanshad 2019 towards human guided machine learning in proc iui 19 614 624 https doi org 10 1145 3301275 3302324 18 daniel golovin benjamin solnik subhodeepmoitra greg kochanski john karro and d sculley 2017 google vizier a service for black box optimization in proc kdd 17 1487 1495 https doi org 10 1145 3097983 3098043 19 mary l gray and siddharth suri 2019 ghost work how to stop silicon valley from building a new global underclass houghton mifflin harcourt 20 jeffrey heer 2019 agency plus automation designing artificial intelligence into interactive systems proceedings of the national academy of sciences 116 6 2019 1844 1850 https doi org 10 1073 pnas 1807184115 21 donald honeycutt mahsan nourani and eric ragan 2020 soliciting human in the loop user feedback for interactive machine learning reduces user trust and impressions of model accuracy proc aaai hcomp 2020 8 1 63 72 https ojs aaai org index php hcomp article view 7464 22 sungsoo ray hong jessica hullman and enrico bertini 2020 human fac tors in model interpretability industry practices challenges and needs proc cscw 2020 article 068 2020 26 pages https doi org 10 1145 3392878 23 eric horvitz 1999 principles of mixed initiative user interfaces in proc chi 99 159 166 https www microsoft com en us research publication principles mixed initiative user interfaces 2 24 amazon inc 2020 amazon sagemaker autopilot https aws amazon com sagemaker autopilot accessed 2020 09 01 25 datarobot inc 2020 datarobot empowering the human heroes of the intelli gence revolution https www datarobot com accessed 2020 09 01 26 google inc 2020 cloud automl https cloud google com automl accessed 2020 09 01 27 h 20 ai inc 2020 h 20 driverless ai https www h 2 o ai products h 2 o driverless ai accessed 2020 09 01 28 ibm inc 2020 autoai with ibm watson studio https www ibm com cloud watson studio autoai accessed 2020 09 01 29 microsoft inc 2020 azure machine learning studio https azure microsoft com en us services machine learning automatedml accessed 2020 09 01 30 sean kandel andreas paepcke joseph hellerstein and jeffrey heer 2011 wran gler interactive visual specification of data transformation scripts in proc chi 11 3363 3372 https doi org 10 1145 1978942 1979444 31 sean kandel andreas paepcke joseph m hellerstein and jeffery heer 2012 enterprise data analysis and visualization an interview study ieee transac tions on visualization and computer graphics 18 12 2012 2917 2926 https doi org 10 1109 tvcg 2012 219 32 sean kandel ravi parikh andreas paepcke joseph m hellerstein and jeffrey heer 2012 profiler integrated statistical analysis and visualization for data quality assessment in proc avi 12 547 554 https doi org 10 1145 2254556 2254659 33 minyung kim thomas zimmermann robert deline and andrew begel 2018 data scientists in software teams state of the art and challenges ieee transac tions on software engineering 44 11 2018 1024 1038 https doi org 10 1109 tse 2017 2754374 34 d lee stephen macke doris xin angela lee silu huang and aditya g parameswaran 2019 a human in the loop perspective on automl mile stones and the road ahead ieee data eng bull 42 2 2019 59 70 http sites computer org debull a 19 june p 59 pdf 35 q vera liao daniel gruen and sarah miller 2020 questioning the ai informing design practices for explainable ai user experiences proc chi 20 2020 1 15 https doi org 10 1145 3313831 3376590 36 andrew mcnutt gordon kindlmann and michael correll 2020 surfacing visu alization mirages proc chi 20 1 16 https doi org 10 1145 3313831 3376420 37 judith s olson and wendy a kellogg 2014 springer new york https doi org 10 1007 978 1 4939 0378 8 38 randal s olson nathan bartley ryan j urbanowicz and jason h moore 2016 evaluation of a tree based pipeline optimization tool for automating data science in proc gecco 16 485 492 https doi org 10 1145 2908812 2908918 39 randal s olson nathan bartley ryan j urbanowicz and jason h moore 2016 evaluation of a tree based pipeline optimization tool for automating data science in proc gecco 16 485 492 https doi org 10 1145 2908812 2908918 40 jorge piazentin ono sonia castelo roque lopez enrico bertini juliana freire and claudio silva 2020 pipelineprofiler a visual analytics tool for the explo ration of automl pipelines ieee transactions on visualization and computer graphics 2020 https doi org 10 1109 tvcg 2020 3030361 41 raja parasuraman thomas b sheridan and christopher d wickens 2000 a model for types and levels of human interaction with automation ieee trans actions on systems man and cybernetics part a systems and humans 30 3 2000 286 297 https doi org 10 1109 3468 844354 42 samir passi and steven j jackson 2018 trust in data science collabora tion translation and accountability in corporate data science projects proc cscw 2018 cscw article 136 2018 28 pages https doi org 10 1145 3274405 https doi org 10 1109 tvcg 2018 2865040 https doi org 10 1145 3290605 3300233 https doi org 10 1073 pnas 1702076114 https doi org 10 1073 pnas 1702076114 https doi org 10 1177 160940690600500304 https doi org 10 1177 160940690600500304 https doi org 10 1145 3076253 https doi org 10 1177 1473871620904671 https doi org 10 1177 1473871620904671 https doi org 10 1111 cgf 14034 https doi org 10 1109 tvcg 2020 3030340 https doi org 10 1109 tvcg 2020 3030340 https doi org 10 1109 visual 2019 8933542 https doi org 10 1080 10618600 2017 1384734 https doi org 10 1080 10618600 2017 1384734 https doi org 10 1145 3377325 3377501 http jmlr org papers v 15 delgado 14 a html http jmlr org papers v 15 delgado 14 a html https arxiv org abs 2007 04074 https arxiv org abs 2007 04074 https doi org 10 5555 2969442 2969547 https doi org 10 1145 3301275 3302324 https doi org 10 1145 3301275 3302324 https doi org 10 1145 3097983 3098043 https doi org 10 1073 pnas 1807184115 https ojs aaai org index php hcomp article view 7464 https ojs aaai org index php hcomp article view 7464 https doi org 10 1145 3392878 https www microsoft com en us research publication principles mixed initiative user interfaces 2 https www microsoft com en us research publication principles mixed initiative user interfaces 2 https aws amazon com sagemaker autopilot https aws amazon com sagemaker autopilot https www datarobot com https cloud google com automl https www h 2 o ai products h 2 o driverless ai https www h 2 o ai products h 2 o driverless ai https www ibm com cloud watson studio autoai https www ibm com cloud watson studio autoai https azure microsoft com en us services machine learning automatedml https azure microsoft com en us services machine learning automatedml https doi org 10 1145 1978942 1979444 https doi org 10 1109 tvcg 2012 219 https doi org 10 1109 tvcg 2012 219 https doi org 10 1145 2254556 2254659 https doi org 10 1145 2254556 2254659 https doi org 10 1109 tse 2017 2754374 https doi org 10 1109 tse 2017 2754374 http sites computer org debull a 19 june p 59 pdf http sites computer org debull a 19 june p 59 pdf https doi org 10 1145 3313831 3376590 https doi org 10 1145 3313831 3376420 https doi org 10 1007 978 1 4939 0378 8 https doi org 10 1007 978 1 4939 0378 8 https doi org 10 1145 2908812 2908918 https doi org 10 1145 2908812 2908918 https doi org 10 1109 tvcg 2020 3030361 https doi org 10 1109 3468 844354 https doi org 10 1145 3274405 fits and starts enterprise use of automl and the role of humans in the loop chi 21 may 08 13 2021 yokohama japan 43 fabian pedregosa ga l varoquaux alexandre gramfort vincent michel bertrand thirion olivier grisel mathieu blondel peter prettenhofer ron weiss vincent dubourg jake vanderplas alexandre passos david cournapeau matthieu brucher matthieu perrot and douard duchesnay 2011 scikit learn machine learning in python journal of machine learning research 12 85 2011 2825 2830 http jmlr org papers v 12 pedregosa 11 a html 44 alper sarikaya micharl correll lyn bartram melanie tory and danyel fisher 2019 what do we talk about when we talk about dashboards ieee transactions on visualization and computer graphics 25 1 2019 682 692 https doi org 10 1109 tvcg 2018 2864903 45 bledi taska steven m miller debbie hughes will markow and soumya bra ganza 2017 the quant crunch how the demand for data science skills is disrupting the job market https www ibm com downloads cas 3 rl 3 vxga 46 dakuo wang justin d weisz michael muller parikshit ram werner geyer casey dugan yla tausczik horst samulowitz and alexander gray 2019 human ai collaboration in data science exploring data scientists perceptions of auto mated ai proc cscw 19 24 https doi org 10 1145 3359313 47 qianwen wang yao ming zhihua jin qiaomu shen dongyu liu micah j smith kalyan veeramachaneni and huamin qu 2019 atmseer increasing transparency and controllability in automatedmachine learning in proc chi 19 1 12 https doi org 10 1145 3290605 3300911 48 daniel karl i weidele justin d weisz erick oduor michael muller josh andres alexander gray and dakuo wang 2020 autoaiviz opening the blackbox of automated artificial intelligence with conditional parallel coordinates in proc iui 20 308 312 https doi org 10 1145 3377325 3377538 49 kanit wongsuphasawat daniel smilkov james wexler jimbo wilson dandelion man doug fritz dilip krishnan fernanda b vi gas and martin wattenberg 2018 visualizing dataflow graphs of deep learning models in tensorflow ieee transactions on visualization and computer graphics 24 1 2018 1 12 https doi org 10 1109 tvcg 2017 2744878 50 quanming yao mengshuo wang hugo jair escalante isabelle guyon yi qi hu yu feng li wei wei tu qiang yang and yang yu 2018 taking human out of learning applications a survey on automated machine learning http arxiv org abs 1810 13306 51 jun yuan changjian chen weikai yang mengchen liu jiazhi xia and shixia liu 2020 a survey of visual analytics techniques for machine learning compunational visual media 2020 https doi org 10 1007 s 41095 020 0191 7 52 amy x zhang michael muller and dakuo wang 2020 how do data science workers collaborate roles workflows and tools proc cscw 2020 article 022 may 2020 23 pages https doi org 10 1145 3392826 53 yunfeng zhang q vera liao and rachel k e bellamy 2020 effect of confidence and explanation on accuracy and trust calibration in ai assisted decision making in proc facct 20 295 305 https doi org 10 1145 3351095 3372852 54 marc andr z ller and marco f huber 2019 benchmark and survey of auto mated machine learning frameworks https arxiv org abs 1904 12054 http jmlr org papers v 12 pedregosa 11 a html https doi org 10 1109 tvcg 2018 2864903 https www ibm com downloads cas 3 rl 3 vxga https doi org 10 1145 3359313 https doi org 10 1145 3290605 3300911 https doi org 10 1145 3377325 3377538 https doi org 10 1109 tvcg 2017 2744878 http arxiv org abs 1810 13306 http arxiv org abs 1810 13306 https doi org 10 1007 s 41095 020 0191 7 https doi org 10 1145 3392826 https doi org 10 1145 3351095 3372852 https arxiv org abs 1904 12054 abstract 1 introduction 2 related work 2 1 automl in data science 2 2 automation and the human in the loop 2 3 data visualization and automl 2 4 situating our research 3 methodology 3 1 interviews and data collection 3 2 selective coding process 4 results 4 1 attitudes toward automation 4 2 automl in data science work 5 interpretation of findings 5 1 three usage scenarios for automl emerge 5 2 varying the level of automation across data science processes 5 3 eliciting tasks for visualization design 5 4 modifications to our analytic framework 6 discussion 6 1 implications for automating data science work 6 2 implications for data visualization systems 6 3 limitations and future work 7 conclusion acknowledgments references