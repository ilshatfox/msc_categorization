cbr controlled burst recording oscar cornejo snt centre for security reliability and trust university of luxembourg luxembourg email oscar cornejo uni lu daniela briola daniela micucci and leonardo mariani department of informatics systems and communication university of milano bicocca milan 20126 italy email daniela briola daniela micucci leonardo mariani unimib it abstract collecting traces from software running in the field is both useful and challenging traces may indeed help revealing unexpected usage scenarios detecting and reproducing failures and building behavioral models that reflect how the software is actually used on the other hand recording traces is an intrusive activity that may annoy users negatively affecting the usability of the applications if not properly designed in this paper we address field monitoring by introducing controlled burst recording a monitoring solution that can collect comprehensive runtime data without compromising the quality of the user experience the technique encodes the knowledge extracted from the monitored application as a finite state model that both represents the sequences of operations that can be exe cuted by the users and the corresponding internal computations that might be activated by each operation our initial assessment with information extracted from ar gouml shows that controlled burst recording can reconstruct behavioral information more effectively than competing sampling techniques with a low impact on the system response time index terms field monitoring tracing logging i introduction field data is an essential source of information for a number of tasks such as discovering emerging usage scenarios 1 profiling users 2 obtaining data about the reliability of the software 3 mining models 4 5 and validating soft ware 6 7 the importance of observing the software while running in the field has been also well recognized by industry for instance the video streaming company netflix has started testing and collecting data directly from the field using fault injection and monitoring techniques 8 collecting data from the field can be challenging in partic ular monitoring and data collection can easily interfere with the user activity 9 while some solutions such as simple crash reporting features require collecting relatively few data for a short amount of time e g a snapshot of the system at the time of the crash 10 11 12 many interesting and sophisticated approaches require monitoring applications more extensively for example many approaches collect sequences of method calls to reproduce failures 13 detect malicious behaviors 14 debug applications 15 profile software 2 optimize applications 16 and mine models 5 17 18 unfortunately extensively recording sequences of function calls might introduce an annoying overhead and cause un acceptable slowdowns as for example experienced by jin et part of this work was carried out while the author was affiliated with university of milano bicocca al 13 slow software is a major threat to the success of a project indeed it is reported as one of the main reasons why users stop using applications 19 20 21 since preventing any interference with the user activity is a mandatory requirement in many cases monitoring techniques have to limit the amount of collected data this can be achieved in several ways by limiting the portion of the system that is monitored 7 22 23 by distributing the monitor ing activity among multiple instances of a same application running on different machines 24 25 by collecting events probabilistically 26 27 28 29 and by collecting bursts of events rather than full executions 30 31 limiting the amount of collected data reduces the effectiveness of the approaches that must work with a limited number of samples since non negligible overhead levels can be hardly rec ognized by users as long as the overhead lasts for few interactions 32 33 34 monitors could be feasibly used to collect fairly complete traces for a limited amount of time in particular a monitor might be turned on and off several times during a program execution in order to collect bursts that is chunks of executions with no internal gaps 30 since the monitor is used intermittently its impact on the user experience is limited unfortunately individual bursts capture only part of the history of an execution providing scattered evidence of the behavior of the monitored software to obtain additional in formation while controlling the overhead this paper proposes controlled burst recording cbr a novel monitoring tech nique for recording bursts whose activation and deactivation is controlled by the operations performed by the users on the target application in particular when a new user operation is started the monitor that records the burst is activated and once the user request has been fully processed the burst is finalized and the monitor is turned off since the recording of the burst is controlled cbr can also recombine the recorded bursts a posteriori to obtain a comprehensive picture of the behavior of the monitored software in particular cbr annotates bursts with state in formation that captures the state of the monitored application at the beginning and at the end of each burst i e before and after a user operation is performed this information allows cbr to generate a hierarchical finite state model that represents the behavior of the monitored application when used in the field in this work we refer to bursts composed of sequences of method calls due to their wide applicability ar x iv 2 00 2 01 87 2 v 2 cs s e 8 f eb 2 02 0 step 1 class detection set of relevant classes step 2 function extraction abstraction functions step 3 function filtering monitor reduced abstraction functions step 4 bursts collection program state 1 methoda p 1 methodb p 1 methodc program state 2 step 5 model synthesis ps 1 ps 2 ps 3 ps 4 ps 5 a 4 a 3 a 2 a 5 a 6 application component 1 component 2 component 3 a 1 developer indicate monitoring target bursts fig 1 overview of controlled burst recording approach but the same concepts can be applied to bursts that include other information we evaluated cbr on argouml and found that cbr pro vides a valuable tradeoff between overhead and data accuracy compared to regular sampling techniques that probabilistically record bursts without controlling when the execution of the burst begins and ends this paper is organized as follows section ii describes cbr section iii presents the empirical validation we con ducted to assess our technique sections iv reports the empir ical results finally sections v and vi discuss related work and provide concluding remarks respectively ii cbr framework controlled burst recording cbr is a technique that can reconstruct an approximate representation of the behavior shown in the field by a program and represents it as a hierar chical finite state model the resulting model is approximated because its states and transitions are obtained by heuristically combining the information in the recorded bursts especially exploiting the state information that appears at the beginning and end of each burst figure 1 shows the steps that compose cbr the first step of the technique requires that the developer specifies the components that must be monitored in the field although the full application can be monitored the developers might be interested in the behavior of some components only based on this input cbr analyzes the code of the application and identifies the scope of the instrumentation that must be added to the program which includes all the classes that may directly or indirectly affect the behavior of the monitored components step 1 we refer to the identified classes as the relevant classes to associate contextual information useful to generate the final finite state model with the recorded data cbr records bursts that both start and end with state information the state information should be accurate enough to distinguish the different logical states of the components and inexpensive enough to be obtained at runtime without introducing a signifi cant overhead to identify a small but relevant amount of state information to be recorded with bursts cbr automatically derives the abstraction functions that can be used at runtime to produce abstract representations of the concrete program states step 2 the intuition is that the values of the state variables are relevant only to the extent they can affect the actual execution of the program and this largely depends on the conditions that are computed on the state variables for this reason cbr analyzes the set of relevant classes looking for boolean functions that can capture the behavior of the program for example if a relevant class implements an operation op whose code checks if the state variable x is positive cbr will output the x 0 abstraction function which is assumed to capture a relevant state property this is intuitively true by construction since it is a condition that is known to influence a computation in one of the relevant classes that is the execution takes different paths in op depending on the value of x note that only the satisfaction of the condition is relevant while the specific value of x is not relevant for the computation this is why cbr embeds the evaluation of the conditions and not the values of the program variables in the abstract program states cbr obtains the abstract representation i e an abstract state of a concrete state by applying all the available abstraction functions i e conditions thus producing a set of function evaluations once cbr has derived the abstraction functions from all the relevant classes it analyzes and compares the resulting functions to eliminate the ones that are redundant e g an abstraction function defined as the negation of another ab straction function adds no information about a concrete state of the program reducing the set of abstraction functions is useful to improve the performance of the approach which has to compute fewer functions at runtime and to save smaller ab stract states the set of the remaining functions are embedded into the software monitor that is used at runtime to collect bursts decorated with state information step 3 in the field cbr collects bursts coherently with computa tions step 4 that is every time the application starts a new user operation a burst is collected with a given probability a user operation starts with a user input e g a click or a keyboard input and ends with a feedback to the user e g a result shown on the gui when the burst is recorded the resulting trace includes a representation of the abstract program state the sequence of the executed methods and again a representation of the abstract program state reached at the end of the computation caused by the user operation the collected bursts are finally analyzed offline the ab stract program states at the beginning and at the end of each burst abstractly represent the state of the system at the time the trace was recorded to summarize the observed executions cbr creates a finite state model step 5 where each abstract state that occurs in the bursts is a different state of the model and each user operation that causes a transitions between two abstract states is represented with a transition of the model the sequences of method calls that can be executed as a consequence of a user operation are represented as annotations of the transitions the resulting model thus captures the activity observed in the field at multiple abstraction levels for this reason it is a hierarchical model the states and transitions show how the operations performed by users affect the status of the system while the annotations show the actual methods involved in the computations in the next section we introduce a running example that we use in the paper to present the steps of the approach a running example let us consider a java program that includes the cart class see listing 1 which represents a simplified shop ping cart of an online store the cart class implements four different methods and includes the product class the additem method adds a product object to the shopping cart the emptycart method empties the shopping cart the calculatetotal method estimates the total price of all the products in the cart and the applydiscount method applies a discount to the total price 1 public class cart 2 3 static int price 1000 4 static double discount 0 8 5 static double tax percentage 0 22 6 static int cart size 30 7 8 product products 9 int nproducts 0 10 double total 0 11 12 public void additem product product 13 if nproducts 0 14 products new product cart size 15 16 products nproducts product 17 nproducts 18 19 20 public void emptycart 21 if nproducts 0 22 products new product cart size 23 24 25 public void applydiscount 26 for int i 0 i nproducts i 27 if products i value price 28 return 29 total total discount 30 31 32 public double calculatetotal 33 for product p products 34 double ptaxes 0 35 if p taxfree 36 ptaxes 0 37 else 38 ptaxes p value tax percentage 39 total total p value ptaxes 40 41 return total 42 43 44 public class product 45 int value 46 boolean taxfree 47 48 listing 1 shopping cart class let us assume that the developer wants to collect data about how a certain program uses the cart class in the following sections we discuss how cbr can address this scenario of course here we consider the monitoring of a single class in a small program for simplicity in reality multiple classes and packages can be selected as targets b step 1 class detection the class detection step identifies the set of classes that may directly or indirectly determine the sequence of execution of the methods in the target components specified by the developer these classes are automatically identified by first computing the dependency graph of the classes in the program then cbr transitively follows the dependency edges in the graph starting from the target classes every class reached during this process is included in the set of the relevant classes analyzed in the second step of the process in the running example the process is quite simple and both the cart and the product classes are selected c step 2 function extraction cbr analyzes the relevant classes identified with step 1 to extract the abstraction functions which capture conditions that represent how the values of the state variables may influence the execution of the monitored program the abstraction func tions provide a natural and efficient abstraction mechanism that can be applied at runtime to generate an abstract representation of a program state to generate the abstraction functions we use symbolic execution 35 36 the main intuition is that each method in each relevant class can be executed symbolically to derive the path conditions corresponding to all the paths that can be executed up to a given bound each path condition represents a set of conditions over the state variables and the inputs of the program that may drive the execution toward a specific computation i e towards a specific path from the entry of the method to an exit point for example the condition cart products length 0 identifies a specific path of the program in the calculatetotal method the path that does not enter in the for loop at line 33 and can be evaluated at runtime to distinguish the state that may lead to one path rather than another when the calculatetotal method is executed when deriving path conditions from methods the conditions may include clauses containing the input parameters of the processed methods since these path conditions are used to derive abstraction functions that might be computed at any time of the execution of a program and not necessarily when methods with specific parameters are invoked these clauses are removed from the path conditions when turning them into abstraction functions for instance the abstraction functions resulting from the symbolic execution of the methods in the cart class are shown in table i when an abstraction function is evaluated at runtime it is evaluated against the state of the program cbr uses a monitor to intercept the creation and the destruction of the monitored table i abstract functions extracted from cart class example identifier code ref abstract functions additem function 1 line 13 cart nproducts 0 cart products length 0 additem function 2 line 14 cart nproducts 0 cart cart size 0 cart nproducts cart cart size additem function 3 line 14 cart nproducts 0 cart cart size 0 cart nproducts cart cart size additem function 4 line 13 cart nproducts 0 cart products length 0 applydiscount function 1 line 26 cart nproducts 0 cart products length 0 applydiscount function 2 line 26 cart nproducts 0 cart products length 0 applydiscount function 3 line 27 cart nproducts 0 cart products length 0 cart products 0 value cart price applydiscount function 4 line 27 cart nproducts 0 cart products length 0 cart products 0 value cart price calculatetotal function 1 line 35 cart products length 0 cart products 0 taxfree true calculatetotal function 2 line 37 cart products length 0 cart products 0 taxfree false calculatetotal function 3 line 33 cart products length 0 calculatetotal function 4 line 33 cart products length 0 emptycart function 1 line 21 cart nproducts 0 emptycart function 2 line 21 cart nproducts 0 cart cart size 0 objects of the program so that functions can be evaluated efficiently on the existing objects a function evaluates to true if it exists a set of objects in the program state that can satisfy it for instance the first abstraction function in table i evaluates to true if there exists a cart with at least one element in addition to true and false values an abstraction func tion can also produce the value unknown this happens when some of the elements that appear in the abstrac tion function cannot be evaluated for instance the clause cart products 0 taxfree true evaluates to unknown if there is no element at the position 0 of the array if a clause evaluates to unknown the full abstract function returns unknown the result of the evaluation of a set of abstraction functions is an array of ternary values referred as the abstract program state more formally given a program p with a concrete state s its abstract program state abs s vi vi fi s fi af where af is an ordered set of the available abstraction functions note that the specific ordering is not important but it is important to keep it consistent across all the evaluations so that the abstract states are comparable that is the value vi in an abstract state must be produced by the same function fi every time the abstract state is computed d step 3 function filtering symbolic execution normally produces a large number of path conditions since it considers every possible execution path for every method under analysis up to a given bound turning all the resulting path conditions into abstraction functions to be used in the field would not be practical and would cause unacceptable overhead levels for this reason cbr filters out the least useful path conditions returned by symbolic execution to guarantee a good compromise between the accuracy of the state information that is traced and the cost of producing such a state information from the original set of path conditions cbr just needs the ones that give unique information about the behavior of the application that is information that is not subsumed by the information provided by the evaluation of the other functions to find the optimal set of conditions to be used as abstraction functions cbr assesses the available conditions against a set of test executions and discards the ones that do not contribute in distinguishing the program states in particular cbr executes the monitored program covering diverse scenarios e g using a set of system test cases and evaluates all the available abstraction functions every time a method of the program is invoked this produces a large number of evaluations for all the available abstraction functions the collected data can be represented in a matrix where the abstraction functions appear on the columns and the evaluations on the rows each row corresponds to an evaluation of all the abstraction functions performed at the time a method was invoked the specific method is not relevant on the other hand each column includes all the values that have been returned by an abstraction function across all the function evaluations that have been performed each cell may evaluate to true t false f or unknown u figure 2 shows a sample matrix with 7 abstraction functions evaluated 5 times sample af 1 af 2 af 3 af 4 af 5 af 6 af 7 1 u u t u u u f 2 u f t t f f f 3 u f t t f f f 4 u f t t f f t 5 u f t u t f t fig 2 sample matrix with 5 evaluations of 7 abstraction functions the filtering process goes through four steps that reduce the size of the matrix until reaching a small number of abstraction functions that are really indispensable to generate the abstract program states the four steps are removal of du plicated samples removal of non discriminating abstraction functions removal of equivalent abstraction functions and finally removal of redundant abstraction functions figure 3 shows the four steps applied to the matrix in figure 2 we describe the four steps below removal of duplicated samples this step reduces the size of the matrix by removing duplicated rows which are useless for the purpose of determining the ability of the functions to distinguish different concrete states in addition to increase sample af 1 af 2 af 3 af 4 af 5 af 6 af 7 1 u u t u u u f 2 u f t t f f f 3 u f t t f f f 4 u f t t f f t 5 u f t u t f t sample af 1 af 2 af 3 af 4 af 5 af 6 af 7 1 u u t u u u f 2 u f t t f f f 4 u f t t f f t 5 u f t u t f t sample af 2 af 4 af 5 af 6 af 7 1 u u u u f 2 f t f f f 4 f t f f t 5 f u t f t sample af 2 af 4 af 5 af 7 1 u u u f 2 f t f f 4 f t f t 5 f u t t equivalent abstraction function non discriminating abstraction functionduplicated sample redundant abstraction function final matrix sample af 5 af 7 1 u f 2 f f 4 f t 5 t t equivalent row column fig 3 example filtering process the efficiency of the next steps since the matrix becomes smaller this step is necessary to facilitate the identification of the redundant functions see last rule formally given the matrix mij with i 1 k j 1 n two rows mi 1 and mi 2 are duplicated if mi 1 j mi 2 j for all j 1 n in our example the second and third rows are duplicated and thus only one of them is preserved for the rest of the analysis removal of non discriminating abstraction functions this step eliminates those abstraction functions that never change their values throughout all the evaluations being de facto con stant and thus not contributing to distinguishing the program states at runtime these functions can be for instance the result of the analysis of infeasible program paths more formally an abstraction function in column j is non discriminating if m 1 j m 2 j mkj in our example the abstraction functions af 1 and af 3 are non discriminating and are thus removed from the matrix removal of equivalent abstraction functions this step eliminates abstraction functions that consistently return the same abstract values indeed keeping only one of this function is enough more formally two functions in columns j 1 and j 2 are equivalent if their columns are the same that is mij 1 mij 2 for all i 1 k in the example af 2 and af 6 are equivalent thus af 6 is dropped from the matrix removal of redundant abstraction functions this step removes the abstraction functions that are not needed to actually distinguish the possible program states the process works by removing one abstraction function at time i e one column at time and checking if the remaining functions are still sufficient to distinguish all the abstract program states collected so far if a column is not needed no rows become equal due to a column dropped from the matrix that is the available states can still be distinguished with the remaining functions note that after the application of the first rule only distinct rows remained in the matrix each row is thus a distinct abstract program state discovered by the tests if the removal of a column generates two equal rows it implies that the remaining functions are not sufficient to distinguish the actual states of the program the application of this process to our example causes the removal of functions af 2 and af 4 the functions that remain at the end of this process i e the remaining columns are the ones used to produce the abstract states at runtime in our example the two remaining functions are af 5 and af 7 e step 4 bursts collection cbr records bursts synchronously with user operations to make sure to collect state information when the monitored application is in a sound and steady state in particular when the user interacts with the application asking for an operation cbr decides with a given probability if a burst must be collected if the burst is collected the abstract state corre sponding to the current concrete state is collected the actual burst is recorded e g the sequences of methods executed as a consequence of the request and when the monitored application has completed the computation and has produced a result the abstract state is collected again more formally a burst b is a tuple b label abs sa trace abs sb where label is the user operation that originated the burst abs sa and abs sb are two abstract states collected before and after the execution of the burst and the trace trace is the sequence of events method calls in our case collected in the field while a program is used a number of bursts b 1 bn are collected and used in the final step to reconstruct a representation of the behavior of the program f step 5 model synthesis the set of bursts represent chunks of executions collected in different instants each burst carries some knowledge about the behavior of the system that is how a user operation made the monitored system to change from a given abstract state to another abstract state and the relative internal computation that has been observed e g the sequence of method calls it is however important to gain a comprehensive picture of how an application or a set of components behave in the field putting the collected bursts in context this is something sampling techniques that collect bursts without context cannot do 30 while controlled burst recording can do thanks to the presence of the state annotations cbr generates a finite state model to capture the knowl edge extracted in the field in particular it produces a finite state model fsm where state transitions are annotated with information about the computations that may happen in the target components when that specific transition is executed the way the fsm is reconstructed is driven by the abstract states that is each distinct abstract state in the recorded bursts is a different state of the fsm and the user operations are transitions in the fsm the content of the burst produces the annotations more formally an annotated fsm is a tuple g s t a where s is a finite non empty set of states t label s s is a finite set of transitions between states in s with a label in label and a t trace is a function that associates each transition in the model with a set of traces trace denotes the powerset of all the possible traces note that the fsm captures various state transitions that have been observed in the field without encoding a notion of initial and final states given a set of bursts b b 1 bn with bi labeli abs sa i tracei abs sb i the corresponding fsm s t a is defined as follows s i abs sa i abs sb i is the union of all the states in the bursts t l sa sb b b b l sa trace sb is a representation of all the state transitions caused by the user operations present in the bursts a t a with t l sa sb t implies a l sa tracej sb tracej is a function that annotates each transition with the corresponding set of traces the model is simply created by sequentially mapping each burst into the corresponding states transitions and annota tions a 1 clickonadditem u u u f f f a 2 clickonpay burst 1 cart additem product 1 burst 2 cart applydiscount cart calculatetotal burst 3 cart applydiscount cart calculatetotal fig 4 excerpt of fsm derived from a set of bursts figure 4 shows an excerpt of the resulting model each state of the model is a different abstract state of the program for simplicity we only report two values in the represented states the transitions show changes in the current state of the monitored components each transition is annotated with traces as represented with dotted arrows in figure 4 note that all the steps of the approach are driven by the initial selection made by the user thus both the derived ab straction functions and the resulting model specifically capture the behavior of the monitored components in a nutshell cbr provides useful information at two different levels 1 it shows how the usage of the application affects the state of the monitored components and 2 it shows the computations that might be produced in the monitored components every time a transition is traversed in the next section we evaluate cbr in comparison to other approaches for sampling executions from the field iii empirical evaluation this section presents the empirical evaluation that we con ducted for controlled burst recording to assess the approach in comparison to sampling techniques note that here even if cbr itself record bursts with a given probability we use the term sampling techniques to refer to the techniques that collect bursts in an uncontrolled way i e not synchronously with the processing of user operations in particular we aim to answer the following research questions rq 1 what is the overhead introduced by controlled burst recording this research question studies the overhead introduced by cbr in comparison to other sampling techniques rq 2 what is the precision of the model generated by controlled burst recording this research question investigates the precision of the information captured in the model produced by cbr with respect to the behaviors shown by the system since sampling techniques do not recombine the recorded traces their precision is always 1 and do not need to be studied empirically rq 3 what is the completeness of the model generated by controlled burst recording this research question studies the capability of cbr to capture the actual be haviors shown by the system in comparison to sampling techniques a prototype our tool is implemented in java and targets java programs it integrates third party tools for static analysis symbolic execution and monitoring in particular cbr uses wala 37 to statically analyze the code of the monitored program and identify the relevant classes in addition it uses jbse 36 to symbolically analyze the relevant classes and produce the path conditions that are transformed into abstraction functions the generation of the conditions from each analyzed method is bounded by limiting the number of branches and the number of states that can be traversed sequentially to 10 and 1000 respectively the analysis time of each method is also limited to 60 seconds finally cbr uses aspectj 38 to collect data about the executed methods b experimental subject to empirically answer the three research questions we selected argouml 39 which is a non trivial 389 952 locs open source java application for editing uml diagrams that can be used in a variety of ways e g to produce largely different diagrams and whose behavior can be studied in terms of the executions produced in the field to consider the situation in which we are interested in a specific part of the application we selected the entire activity package as the target of the monitoring activity this package manages all the functionalities related to the design and management of activity diagrams in argouml as monitoring objective we consider collecting calls to methods implemented in the classes of the target package including the values of the parameters in order to recreate proper executions of argouml we have implemented 25 test cases reproducing typical usage scenarios for the activity package each test case consists of drawing a different activity diagram using different elements and features to avoid non determinism and for the reproducibility of the test cases we recorded and executed them with the sikulix testing tool 40 all the measurements have been obtained by repeating the execution of the tests three times the test cases our tool and the experimental material are available in the following repository https github com cbr paper cbr experimental c function filtering in this section we discuss the result of the filtering process applied to our experimental subject step 3 when running cbr in the considered setting the symbolic executor produced 5 732 abstraction functions cbr then identified and filtered out all the non discriminating equivalent and redundant abstraction functions overall cbr reduced the number of abstraction functions to be used to generate the abstract pro gram states from 5 575 to 157 abstraction functions filtering out 97 2 of the functions table ii shows the number of functions that have been filtered out in each step by cbr confirming the usefulness of all the steps table ii function filtering abstraction functions initial number of abstraction functions 5 732 non discriminating abstraction functions 1 631 equivalent abstraction functions 2 646 redundant abstraction functions 1 298 final set of abstraction functions 157 d experiment design in our assessment we compare cbr to sampling techniques which have been used widely for monitoring applications in the field 27 41 42 43 these solutions limit the overhead by collecting data with a given probability note that differently from cbr these bursts have neither a semantics associated with the processing of the user requests nor the state annotations but consist of traces containing a fixed number of method calls we considered sequences of length 30 similarly to the configuration setup used for bursty tracing 30 which is the closest technique to cbr in our evaluation we compare cbr to sampling monitoring configured with two sampling probabilities 5 and 10 higher sampling frequencies might be hardly considered since they may interfere with the user activity we thus compared three solutions cbr sampling monitoring with 5 sampling probability and sampling monitoring with 10 sampling probability to answer rq 1 we measure the overhead introduced in the subject program by the three monitoring techniques when running the available test cases to measure overhead we collect the system response time of each user operation that is executed to capture how monitoring may impact the execution of operations of different nature we organize the data based on the well known and widely accepted classification from the human computer interaction area proposed by seow 44 in this classification operations are organized according to four categories which have been derived from direct user engagement each category represents a different type of operation and has a foreseen maximum system response time the four categories are instantaneous these are the simplest operations that can be performed on an application such as entering inputs or navigating throughout menus their system response time is expected to be 200 ms at most immediate these are the operations that generate ac knowledgments or very simple outputs their system response time is expected to be 1 s at most continuous these are operations that produce a result within a short period of time to not interrupt the dialog with the user their system response time is expected to be 5 s at most captive these are operations requiring some relevant processing for which users will wait for results their system response time is expected to be 10 s at most these operations are not present in argouml we study the impact of the monitoring activity per category because the relative overhead can be quite different for each type of operation to answer rq 2 we measure to what extent the behaviors represented in the model generated by cbr correspond to actual original traces of the monitored program we col lected the complete traces of execution with all the generated function calls once at the beginning of the experiment we study this aspect locally to each node in comparison to the actual set of observed behaviors because nodes are the joint points between bursts which may introduce imprecision that is we evaluate precision locally i e node precision and then globally i e overall nodes precision in particular we first assess if the local decisions taken in each node have a corresponding evidence in the original traces and then we compute a global metric as mean of the local precision of each node fig 5 fsa node with state information and incoming and outgoing transitions to assess node precision for each node in the model we check if every possible sequence of events of length 2 which https github com cbr paper cbr experimental https github com cbr paper cbr experimental involves that node is an actual program behavior for example for the node in figure 5 we first generate all the possible combinations of sequence of actions that is a 1 b 1 a 1 b 2 a 3 b 3 then we verify if the traces produced by these sequences are present in the set of original recorded traces in particular the node precision for a particular node nodei is computed with the formula precision nodei csi tsi where csi is the number of sequences of length 2 that traverse nodei and that have a counterpart in the original traces and tsi is the total number of sequences of length 2 that traverse node i the overall nodes precision is obtained by computing the mean node precision of all the nodes in the model for simplicity in the rest of the document we refer to overall nodes precision simply as precision note that we do not compute precision for sampling tech niques because they do not provide any form of generalization of the collected traces and thus the precision of the extracted information is always 1 to answer rq 3 we measure trace level recall that is we measure how complete the extracted information is with respect to the complete traces of executions produced by the monitored application note that all the monitoring techniques collect only a subset of these traces when the sampling is activated both cbr and sampling techniques collect bursts while missing the rest of the computation however the information that is not recorded from an execution can still be recorded in future executions thus finally obtaining a more complete picture of the behavior observed in the field to measure the ability of the monitoring technique to extract complete traces from the bursts collected from the field we measure the trace recall for a given trace as recall tracej ej eoj where ej is the number of calls captured by the monitoring technique and eoj is the overall number of method calls in the original trace we use the available test cases to obtain the program traces note that while sampling techniques extract sequences of fixed length cbr can reconstruct longer executions combining multiple samples thanks to the state information attached to bursts in the rest of the document we refer to trace level recall simply as recall let us remark that both cbr and sampling techniques are used to reconstruct information about behaviors observed in the field and not the general behavior of an application for this reason both the precision and the recall metrics are defined with respect to the full traces produced by running the test cases of the monitored application and not about all the feasible behaviors of the monitored program iv results in this section we present the results of the experiment we conducted to validate cbr all the experiments were executed on a computer running macos version 10 13 6 with a 3 1 ghz intel core i 7 processor and 16 gb of ram a rq 1 performance to answer the research question rq 1 what is the overhead introduced by controlled burst recording we assessed the impact of the monitors collecting data about their overhead to this end we repeated the execution of our 25 test cases 3 times obtaining 3 459 measurements of the response time of each operation when the various types of monitors are active based on the categorization of the operations presented in the previous sections we assigned the category to each operation considering the system response time of the application without any monitoring we collected data from 915 operations in the instantaneous category 25 operations in the immediate category and 213 operations in the continuous category given the nature of the functionalities tested we did not identify operations in the captive category table iii performance results with respect to srt categories monitoring technique monitoring overhead instantaneous immediate continuous cbr 123 78 40 70 0 71 sampling p 10 17 03 4 65 1 37 sampling p 5 7 12 2 88 0 28 the mean overhead introduced by each approach can be found in table iii note that the overhead produced by cbr corresponds to the overhead experienced while recording every call executed while processing an operation on the contrary sampling techniques record only a subset of the methods executed while processing operations for the operations that require less than a second to execute i e instantaneous and immediate cbr introduces consider able more overhead than the other sampling techniques the higher overhead introduced for operations that can be completed in less than a second is explained by the need of recording the information about the abstract states before and after each burst indeed the absolute overhead is still small for instance the slowest instantaneous operations may go from 200 ms its maximum time from the category to 450 ms with the overhead which is still a difference that can be hardly recognized by users as also confirmed in other studies where overhead levels up to 180 are reported as hard to detect for instantaneous operations as long as introduced for a few operations in a row 32 33 on the contrary cbr performs well with continuous op erations where high overhead values may result in noticeable slowdowns for the users indeed the cost of collecting state data is well compensated by the duration of the operations in summary cbr is more expensive than sampling tech niques due to the state abstraction and recording activities per formed when a burst is recorded the relative extra overhead is significant for operations that complete quickly but still hardly recognizable in terms of the absolute slowdown while the overhead introduced in longer operations to record state information is compensated by the length of the operation b rq 2 precision fig 6 precision results with respect to different runs of the application for answering the research question rq 2 what is the precision of the model generated by controlled burst recording we measured the precision of the information reported in the model generated by cbr with respect to the set of original traces we only show results for cbr since it is the only technique that recombines bursts to obtain a more comprehensive model possibly introducing imprecision on the contrary sampling techniques do not recombine the recorded information thus the portion of traces collected are always precise that is every sequence of method calls recorded corresponds to an actual sequence produced while running the software since cbr collects a burst with a given probability we studied how precision changes with respect to the probability to record the bursts and the number of executions of the monitored software the results are reported in figure 6 the ability to recombine bursts produces a loss of precision of about 20 interestingly cbr reaches its maximum preci sion level quite quickly with the exception of data collected from a single execution which clearly provides imprecise and unstable information 15 20 runs with a sampling rate of 20 are already sufficient to reach the maximum precision if we reduce the sampling rate we proportionally need more executions to obtain the same amount of information for instance the same results obtained for 15 runs observed with a probability to collected a burst equals to 20 could be approximatively obtained with a probability equals to 2 after having observed 150 runs assuming to keep cbr active in the field for long time bursts could be feasibly collected with a probability lower than 1 in summary recombining bursts in a model as cbr does may introduce imprecision based on our preliminary re sults cbr manages to represent combinations of bursts that correspond to actually observed behaviors in 80 of the cases while 20 of these combinations represent behavior not observed in the traces fig 7 recall results with respect to different runs of the application c rq 3 recall in this section we present the results for the research question rq 3 what is the recall of the traces produced by controlled burst recording we consider the ability of the various monitoring techniques to capture the behavior observed in the field sampling tech niques do not have the ability to recombine observations thus they can capture only short prefixes of the executions that happen in the field thus if sampling has a precision equals to 1 by construction it has also a nearly 0 recall by construction in our evaluation the recall of the sampling techniques ranged from 4 15 to 7 77 the main objective of cbr is to obtain a better recall re combining the collected bursts without annoying the end user in figure 7 we plot how the recall of the model produced by cbr changes for different sampling probabilities i e different probabilities of recording a burst when a user operation is performed and different number of collected executions interestingly 10 runs of the applications are already suffi cient to obtain 90 recall with a 30 sampling probability again collecting additional executions allows to reduce the sampling probability still retaining a similar recall that is a 3 sampling probability may approximatively lead to similar recall after the observation of 100 runs in summary sampling strategies largely miss the ability to reconstruct the observed executions on the contrary cbr can obtain high recall values by recombining the collected bursts d threats to validity and discussion we studied the effectiveness of cbr in comparison to sampling strategies with a case study based on argouml we cannot make claims about the generalizability of the results however the presented study provides an initial evidence of the complementarity between cbr and sampling sampling techniques are useful when collecting extensive evidence of the field behavior is not important but collecting small but precise evidence is the priority on the contrary cbr can be used when full precision of the extracted information is not a mandatory requirement and obtaining a comprehensive representation of the observed behavior is more important for instance to support heuristic program analysis and profiling techniques in these cases cbr represents a good tradeoff between the introduced overhead almost not recognizable when using a low sampling rate the high recall of the collected traces and the good precision of the reconstructed traces v related work our work focuses on the cost effectiveness of monitoring aimed at collecting field data in a non intrusive way possibly missing a limited amount of information to this end we relate cbr to probabilistic and state based monitoring approaches probabilistic monitoring accounts for lowering the impact of monitoring by collecting runtime information within a certain probability liblit et al 29 exploited this strategy to isolate bugs by profiling a large distributed user community and using logistic regression to find the program predicates that could be faulty similarly jin et al 27 presented a monitoring framework called cooperative crug concurrency bug isolation to diagnose production run failures caused by concurrency bugs this technique uses sampling to monitor different types of predicates while keeping the monitoring overhead low in the same way hirzel et al 30 developed bursty monitors which collect subsequences of events with ad hoc strategies to construct a temporal program profile in general probabilistic monitoring is designed to collect partial information about executions with little ambition to re construct a wider picture of the behavior that can be observed in the field while cbr focuses on the construction of extended evidence by combining multiple bursts state based monitoring approaches focus on using a small subset of variables to represent a significant program state these techniques are often used either for replaying field executions or for trace analysis e g debugging for instance orso et al 23 proposed a technique for selectively capturing and replaying program executions this technique allows to select a subsystem of interest capture at runtime all the interactions of the applications with its subsystem and then replay the recorded interactions in a controlled environment for each interaction of the application the technique captures a minimal subset of the application s state and environment required to replay the execution similar to cbr this framework exploits the idea of tracing just the entities defined inside the subsystem of interest however this framework is not designed to derive extensive knowledge about the behavior of the system but focuses on reproduction diep et al 45 presented a technique for analyzing traces produced by field applications in particular to identify and delete irrelevant events from traces that do not offer interesting information for offline analyses before deploying the appli cation practitioners select a subset of program variables to be used to represent the program state then while the application is running in the field the state of these variables is regularly saved before and after each monitored event in a second step i e offline time the technique divides the full trace in several pieces using the variables state as splitting points after this operation the technique deletes all the events that do not change the program state and those events that whose occurrence can be re ordered without affecting the program state leaving in the trace only the most relevant information for understanding the program behavior contrary to cbr this technique does not take into account the monitoring overhead introduced by the action of regularly saving state information besides the fact that the way the state representation is obtained is specified manually while cbr performs this operation in an automated way the heuristic used in cbr to merge abstract states and produce a finite state representation of the observed behavior is similar to the one used in some automata inference tech niques 46 47 5 however none of these approaches are designed to work with bursts as defined in this paper finally some techniques can be generally useful to optimize resource consumptions and further reduce overhead such as delayed saving that can reduce the cost of persisting the information about the collected events 48 these kinds of approaches can be integrated in cbr to further improve its performance vi conclusions cbr extracts relevant information about the behavior of a software running in the field by collecting bursts of executions synchronously with the computations that is each burst corresponds to the processing of a user operation moreover each burst is annotated with state information collected at the beginning and the end of the burst this allows cbr to recombine the information present in the bursts and build a hierarchical model that well captures the behavior observed in the field for a target application we conducted a case study based on argo uml as prelim inary evaluation when assessing performance we discovered that the overhead introduced by cbr in the worst case with respect to other sampling approaches can be higher for short operations but similar for the other operations the higher overhead for short actions is relatively harmless since it can be hardly recognized by users 32 33 when assessing the quality of the extracted information we discovered that cbr can reconstruct behavioral information more effectively than sampling techniques which are highly precise but can hardly produce a fairly comprehensive picture of the observed behaviors thus cbr succeeds in recording useful field data with hardly recognizable impact on the system response time of the monitored application as part of future work we would like to extend the empirical evaluation with other applications and case studies as well as exploiting the information that can be effectively collected in the field to support program analysis tasks acknowledgment this work has been partially supported by the eu h 2020 learn project which has been funded under the erc consolidator grant 2014 program grant agreement n 646867 and the gauss national research project which has been funded by the miur under the prin 2015 program contract 2015 kwremx references 1 j srivastava r cooley m deshpande and p n tan web usage mining discovery and applications of usage patterns from web data acm sigkdd explorations newsletter vol 1 pp 12 23 2000 2 s elbaum and m diep profiling deployed software assessing strategies and testing opportunities ieee transactions on software engineering tse vol 31 no 4 pp 312 327 2005 3 l gazzola l mariani f pastore and m pezze an exploratory study of field failures in proceedings of the international symposium on software reliability engineering issre 2017 4 p ohmann and b liblit lightweight control flow instrumentation and postmortem analysis in support of debugging automated software engineering vol 24 no 4 pp 865 904 2017 5 l mariani a marchetto c d nguyen p tonella and a i baars revolution automatic evolution of mined specifications in proceed ings of the international symposium on software reliability engineering issre 2012 6 p ohmann d b brown n neelakandan j linderoth and b liblit optimizing customized program coverage in proceedings of the international conference on automated software engineering ase 2016 7 c pavlopoulou and m young residual test coverage monitoring in proceedings of the international conference on software engineering icse 1999 8 a basiri a blohowiak l hochstein and c rosenthal a platform for automating chaos experiments in proceedings of the international symposium on software reliability engineering issre 2016 9 a orso monitoring analysis and testing of deployed software in proceedings of the fse sdp workshop on future of software engi neering research foser 2010 10 eclipse community eclipse http www eclipse org visited in 2019 11 microsoft windows 10 http www microsoft com visited in 2019 12 n delgado a q gates and s roach a taxonomy and catalog of runtime software fault monitoring tools ieee transactions on software engineering tse vol 30 no 12 pp 859 872 2004 13 w jin and a orso bugredux reproducing field failures for in house debugging in proceedings of the international conference on software engineering icse 2012 14 a gorji and m abadi detecting obfuscated javascript malware using sequences of internal function calls in proceedings of the acm southeast regional conference se 2014 15 s murtaza a hamou lhadj n h madhavji and m gittens to wards an emerging theory for the diagnosis of faulty functions in function call traces in proceedings of the semat workshop on general theory of software engineering gtse 2015 16 z zhao b wu m zhou y ding j sun x shen and y wu call sequence prediction through probabilistic calling automata in proceedings of the acm international conference on object oriented programming systems languages applications oopsla 2014 17 l mariani f pastore and m pezze dynamic analysis for diagnosing integration faults ieee transactions on software engineering tse vol 37 no 4 pp 486 508 2011 18 f pastore d micucci and l mariani timed k tail automatic inference of timed automata in proceedings of the ieee international conference on software testing verification and validation icst 2017 19 i ceaparu j lazar k bessiere j robinson and b shneiderman determining causes and severity of end user frustration international journal of human computer interaction vol 17 no 3 pp 333 356 2004 20 r b miller response time in man computer conversational transac tions in proceedings of the fall joint computer conference part i afips 1968 21 j a hoxmeier and c d cesare system response time and user satisfaction an experimental study of browser based applications in proceedings of the association of information systems americas conference 2000 22 t apiwattanapong and m j harrold selective path profiling in acm sigsoft software engineering notes vol 28 no 1 2002 pp 35 42 23 a orso and b kennedy selective capture and replay of program executions vol 30 no 4 pp 1 7 2005 24 j bowring a orso and m j harrold monitoring deployed software using software tomography in proceedings of the acm sigplan sigsoft workshop on program analysis for software tools and en gineering paste 2002 25 a orso d liang m j harrold and r lipton gamma system continuous evolution of software after deployment in proceedings of the international symposium on software testing and analysis issta vol 27 2002 26 e bartocci r grosu a karmarkar s a smolka s d stoller and j n seyster adaptive runtime verification in proceedings of the international conference on runtime verification rv 2012 27 g jin a thakur b liblit and s lu instrumentation and sampling strategies for cooperative concurrency bug isolation in proceedings of the acm international conference on object oriented programming systems languages and applications oopsla 2010 28 t m chilimbi b liblit k mehra a v nori and k vaswani holmes effective statistical debugging via efficient path profiling in proceedings of the international conference on software engineering icse 2009 29 b liblit a aiken a x zheng and m i jordan bug isolation via remote program sampling acm sigplan notices vol 38 no 5 pp 141 154 2003 30 m hirzel and t chilimbi bursty tracing a framework for low overhead temporal profiling in proceedings of the acm workshop on feedback directed and dynamic optimization fddo 4 2001 31 o cornejo d briola d micucci and l mariani fragmented monitoring in proceedings of the international workshop on pre and post deployment verification techniques ifm 2017 32 in the field monitoring of interactive applications in proceed ings of the international conference on software engineering new ideas and emerging results track icse nier 2017 33 in the field monitoring of functional calls is it feasible journal of systems and software jss vol 163 no 5 2020 34 p r killeen and n a weiss optimal timing and the weber function psychological review vol 94 no 4 pp 455 468 1987 35 r baldoni e coppa d cono d elia c demetrescu and i finocchi a survey of symbolic execution techniques acm computing surveys csur vol 51 no 3 pp 50 1 50 39 2018 36 p braione g denaro and m pezze enhancing symbolic execution with built in term rewriting and constrained lazy initialization in pro ceedings of the joint meeting on foundations of software engineering fse 2013 37 j dolby s j fink and m sridharan tj watson libraries for analysis wala http wala sourceforge net visited on 2019 38 eclipse community aspectj https www eclipse org aspectj visited on 2019 39 tigris argouml http argouml tigris org visited in 2019 40 r hocke sikulix capture and replay tool http sikulix com visited on 2019 41 b liblit m naik a x zheng a aiken and m i jordan scalable statistical bug isolation acm sigplan notices vol 40 no 6 pp 15 26 2005 42 y joshi g m tchamgoue and s fischmeister runtime verification of ltl on lossy traces in proceedings of the symposium on applied computing sac 2017 43 r babaee a gurfinkel and s fischmeister prevent a predictive run time verification framework using statistical learning in proceed ings of the international conference on software engineering and formal methods sefm 2018 44 s c seow designing and engineering time the psychology of time perception in software addison wesley professional 2008 45 m diep s elbaum and m dwyer trace normalization in proceed ings of the symposium on software reliability engineering issre 2008 46 v dallmeier c lindig a wasylkowski and a zeller mining object behavior with adabu in proceedings of the international workshop on dynamic systems analysis woda 2006 47 a marchetto p tonella and f ricca state based testing of ajax web applications in proceedings of the ieee international conference on software testing verification and validation icst 2008 48 o cornejo d ginelli d briola d micucci and l mariani field monitoring with delayed saving ieee access vol 7 pp 85 913 85 924 2019 http www eclipse org http www microsoft com http wala sourceforge net https www eclipse org aspectj http argouml tigris org http sikulix com