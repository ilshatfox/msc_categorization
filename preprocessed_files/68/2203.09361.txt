expressivity of planning with horn description logic ontologies technical report stefan borgwardt 1 jo rg hoffmann 2 alisa kovtunova 1 markus kro tzsch 1 bernhard nebel 3 marcel steinmetz 2 1 faculty of computer science technische universita t dresden germany 2 saarland university saarland informatics campus germany 3 faculty of engineering university of freiburg germany firstname lastname tu dresden de lastname cs uni saarland de lastname informatik uni freiburg de abstract state constraints in ai planning globally restrict the legal environment states standard planning languages make closed domain and closed world assumptions here we address open world state constraints formalized by planning over a descrip tion logic dl ontology previously this combination of dl and planning has been investigated for the light weight dl dl lite here we propose a novel compilation scheme into standard pddl with derived predicates which applies to more expressive dls and is based on the rewritability of dl queries into datalog with stratified negation we also provide a new rewritability result for the dl horn alchoiq which al lows us to apply our compilation scheme to quite expressive ontologies in contrast we show that in the slight extension horn sroiq no such compilation is possible unless the weak exponential hierarchy collapses finally we show that our approach can outperform previous work on existing bench marks for planning with dl ontologies and is feasible on new benchmarks taking advantage of more expressive ontologies 1 introduction ai planning is concerned with sequential decision making problems where an agent needs to choose actions to achieve a goal or to maximize reward ghallab nau and traverso 2004 such problems are compactly described in a declar ative language specifically in the most basic classical version of planning a planning task describes an initial state of the agent s environment a set of actions that can affect that environment and a goal formula that is to be satisfied in order to reach the goal actions can be applied whenever their preconditions are satisfied in the current state here we are interested in state constraints constraints that should hold globally i e at every state in difference to preconditions which merely need to hold locally moreover standard plan ning formalisms based on variants of the pddl language mcdermott et al 1998 haslum et al 2019 follow closed domain and closed world assumptions in which absent facts are assumed to be false and no new objects can be created in particular these assumptions underly state constraints as can be specified in pddl 3 gerevini et al 2009 here we instead target open domain open world reasoning copyright 2022 association for the advancement of artificial intelligence www aaai org all rights reserved one way to do this is via explicit input knowledge and ac tion bases ekabs calvanese et al 2016 where states sets of ground atoms are interpreted using open world seman tics all states are subject to a background ontology which describes high level concepts and global state constraints together a state and an ontology describe a multitude of possible worlds which leaves room for unknown information about existing and unknown objects for example an ontol ogy could express that everyone operating a machine works for an engineering department and everyone who works for a department is an employee without explicitly identify ing the department of each person or even stating that they are employees action preconditions contain queries that are evaluated under open world semantics e g the query for all employees would return all machine operators among other people finally action effects add or remove atoms in the state e g reassign machines or departments this allows for a clean separation of what is directly observed i e the state which contains e g operational data and sensor data from what is indirectly inferred using the ontology calvanese et al 2016 investigated ekabs with ontolo gies and queries formulated in the description logic dl lite which is a popular formalism for conceptual modeling cal vanese et al 2007 b queries in this logic enjoy first order rewritability which means that the queries and the ontology can be compiled into first order fo formulas that are then evaluated under closed world semantics based on this prop erty the authors described a compilation of dl lite ekabs into classical pddl planning tasks later this compilation was further optimized to enable practical planning with dl lite background ontologies borgwardt et al 2021 the goal of this paper is to extend the expressivity of state constraints in ekabs from the light weight dl lite to more powerful description logics dls baader et al 2017 we mainly consider horn dls which are fragments of horn fol kro tzsch rudolph and hitzler 2013 jung et al 2019 we investigate for which horn dls compilations into pddl exist for this purpose we adapt the notion of compilation schemes nebel 2000 thie baux hoffmann and nebel 2005 which relate the expressivity of two formalisms on the one hand polynomial compilation schemes show that the expres sivity of dl ekabs is not higher than that of pddl on the other hand although such ekabs could be considered syn tactic sugar they represent powerful tools that allow domain ar x iv 2 20 3 09 36 1 v 1 cs a i 1 7 m ar 2 02 2 engineers to add open world constraints to planning tasks our first contribution is a generic compilation scheme for any dl and queries that enjoy datalog rewritability which essentially allows us to compile them into a set of pddl derived predicates using this we can immediately employ many existing rewritability results from the dl lit erature for ai planning ortiz rudolph and s imkus 2010 eiter et al 2012 bienvenu and ortiz 2015 we continue by describing a novel polynomial datalog rewriting for queries in the very expressive dl horn alchoiq ortiz rudolph and s imkus 2011 which allows us to extend the previous compilability result even further in contrast to this we then show that such a compilation cannot exist under a reasonable complexity theoretic assumption for the slightly more expressive dl horn sroiq ortiz rudolph and s imkus 2011 for this we follow the idea of a previous non compilability result for pddl with derived predicates into pddl without derived predicates thie baux hoffmann and nebel 2005 this more or less draws a line between the standardized ontology languages owl 1 1 which results in planning tasks of equal expressivity as pddl and owl 2 2 where queries are strictly more expressive than pddl while polynomial rewritings are nice in theory they are often not practical due to a polynomial increase in the ar ity of predicates we therefore conclude the paper with an experimental evaluation that combines an existing practical implementation of an exponential datalog rewriting for horn shiq eiter et al 2012 with our generic compilation scheme compares this against previous approaches for dl lite ekabs on existing benchmarks calvanese et al 2016 borgwardt et al 2021 and also introduces new benchmarks exploiting the newly increased expressivity 2 preliminaries we first introduce description logics datalog planning with derived predicates and ontologies and compilations between these formalisms as usual we use the symbol with two different meanings open world entailment of formulas from sets of formulas where all possible interpretations of arbi trary even infinite size are considered and closed world satisfaction of a formula in a fixed finite interpretation it should always be clear from the context which one is used description logics description logics are a family of kr formalisms baader et al 2017 that describe open world knowledge using axioms in restricted first order logic over unary and binary predicates members of this family differ in their expressivity and complexity a tbox ontology is a finite set of dl axioms which can be seen as first order sentences the precise syntax of these axioms depends on the specific dl that is used but this is not important for most of the paper a state abox is a finite set of ground atoms p c where p is a predicate and c is a sequence of objects constants since we use standard planning formalisms we also allow predicates of arity higher than 2 in states but 1 http www w 3 org tr owl features 2 http www w 3 org tr owl 2 overview those cannot occur in tboxes so essentially have a closed world semantics for a state s o s is the set of all objects occurring in s two special unary predicates are and which always evaluate to true and false respectively queries a conjunctive query cq is a formula of the form q x y x y where is a conjunction of unary and binary atoms a union of cqs ucq is a disjunction of cqs an instance query iq is a cq of the form p x where p is unary the central reasoning problem is to decide whether s t q where s is a state t a tbox and an assignment of objects from o s to the free variables in the u cq q in an abuse of notation we may denote with the cq x x ecqs were introduced to combine open world and closed world reasoning calvanese et al 2007 a we further extend ecqs by closed world atoms that can also be of higher arity ecqs are defined by the grammar q p x q q q q y q where p is a predicate x are terms q is a ucq and y is a variable the semantics of ecqs is defined as follows s t p x iff s p x s t q iff s t q s t q 1 iff s t 6 q 1 s t q 1 q 2 iff s t q 1 and s t q 2 s t y q 1 iff o o s s t y 7 o q 1 there is a difference between the ecqs b x which is answered directly in the closed world model described by s and b x which is evaluated w r t the tbox as well for example if s c a and t c v b then b x is not satisfied by any instantiations but b x is datalog a datalog rule is a formula p x x y whose body x y is a conjunction of literals and whose head p x is an atom a set of datalog rulesr is stratified if the set of its predicates can be partitioned into p 1 pn such that for all pi pi and pi x x y r if pj pj occurs in x y then j i and if pj pj occurs negated in x y then j i in the following all sets of datalog rules are stratified datalog is the restriction of datalog to positive rule bodies all variables in datalog rules are implicitly universally quantified given a state s and a set of datalog rulesr we denote byr s the minimal herbrand model of s r definition 1 a tbox t and a ucq q x are datalog rewritable if there is a set of datalog rules rt q with a predicate pq such that for all states s and substitutions of x in o s we have s t q x iffrt q s pq x a datalog rewriting may use additional predicates and constants but only needs to be correct for the original sym bols we talk about datalog rewritability if the setrt q does not contain negation a variety of such rewritability results for dls exist for example a very complex but polynomial size datalog rewriting for iqs over horn alchoiq ortiz rudolph and s imkus 2010 a polynomial size datalog rewriting for iqs in el kro tzsch 2011 or an exponential size datalog rewriting for ucqs over horn shiq tboxes implemented in the clipper system 3 eiter 3 https github com ghxiao clipper http www w 3 org tr owl features http www w 3 org tr owl 2 overview https github com ghxiao clipper et al 2012 which is polynomial for the sublogic elh bienvenu and ortiz 2015 datalog rewritability naturally extends to ecqs q take the disjoint union rt q of all rt q for ucqs q occurring inq and construct an fo formulaqt by replacing each ucq atom q x in q with pq x then s t q x is equiv alent tort q s qt x calvanese et al 2007 a pddl with derived predicates we recall pddl 2 1 ex tended with derived predicates fox and long 2003 hoff mann and edelkamp 2005 in this context states are viewed under the closed world assumption and all sets are finite definition 2 a pddl domain description is a tuple p pder a r where p pder are disjoint sets of predicates a is a set of actions and r is a set of rules an action is of the form x pre eff with parameters x precondition pre and a finite set eff of effects the precondition is an fo for mula over p pder with free variables from x and an effect is of the form y cond add del where y are variables cond is an fo formula over p pder with free variables from x y add is a finite set of atoms over p without pder with free variables from x y and del is a finite set of such negated atoms rules are of the form p x x with p pder and a first order formula over p pder the setr must be stratified i e fulfill the same condition as sets of datalog rules when considering the rule bodies x in nnf a pddl task is a tuple o i g where is a pddl domain description o is a finite set of objects including the ones in i is the initial state and g is the goal a closed fo formula over p pder and constants from o derived predicates are not allowed to be modified by ac tions i e they are only determined by the current state and the rules the semantics of rules is defined similarly to datalog i e for a state s r s is the minimal herbrand model ob tained by exhaustively applying the rules in r stratum by stratum to the facts in s in order to populate the derived pred icates pder in fact all such rule setsr can be reformulated into datalog rule sets abiteboul hull and vianu 1995 thie baux hoffmann and nebel 2005 although the defini tion of derived predicates requires the head and body to have the same free variables this is compatible with the semantics of datalog since additional body variables can be viewed as implicitly existentially quantified for an action a x pre eff and x o the ground action a has no parameters a ground action a pre eff is applicable in a state s if r s pre and its applica tion yields a new state sjak that contains a ground atom iff 1 there are y cond add del eff and such that r s cond and add or 2 s and for all y cond add del eff and it holds thatr s 6 cond or del a plan is a sequence of ground actions such that is applicable in i andr ij k g ekabs we recall explicit input action and knowledge bases calvanese et al 2016 but slightly adapt the nota tion to be consistent with pddl notation definition 3 an ekab domain description is a tuple p a t where p is a finite set of predicates a is a finite set of dl actions and t is a tbox over the unary and bi nary predicates in p a dl action is of the form x pre eff where pre is an ecq over p with free variables from x and eff consists of dl effect of the form y cond add del where cond is an ecq over p with free variables from x y and add and del are as in pddl an ekab task is a tuple o o 0 i g where is an ekab domain description o is a possibly infinite set of ob jects o 0 is a finite subset of o including the objects from i is the initial state overo 0 which is consistent with t and g is the goal a closed ecq over p and constants from o 0 a ground action a is applicable in s if s pre and sjak t is consistent the application sjak contains a fact iff 1 there are y cond add del eff and y o s o 0 such that s t cond and add or 2 s and for all y cond add del eff and as above it holds that s t 6 cond or del a plan must be applicable in i and satisfy ij k t g substitutions for effects range overo s o 0 since the tbox may contain objects fromo 0 in the following we assume w l o g that o 0 o s additional assumptions actions can refer to new objects parameters x that are not in the precondition and thereby increase the number of objects in a state to obtain manage able state transition systems in the literature the assumption of state boundedness is often considered for ekab like for malisms it requires that there exists a bound b such that any state reachable from i contains at most b objects cal vanese et al 2013 de giacomo et al 2014 for a fixed b b boundedness of an ekab is decidable de giacomo et al 2014 even if a given ekab is not state bounded one could instead ask for the existence of a b bounded plan ahmetaj et al 2017 an abstraction result implies that any b bounded ekab can be reformulated into one where o o 0 n b where n is the maximum number of parameters of any ac tion calvanese et al 2013 2016 any plan of the original ekab can still be encoded using this finite set of objects conversely any abstract plan can be reformulated into a plan of the original ekab by replacing the n b abstract objects by fresh objects from the original set o where necessary i e if those objects did not occur in the previous state we will also make this assumption here and assume for simplicity that o o 0 is finite and denote both sets by o even for a b bounded ekab the tbox t can entail the existence of objects that are not mentioned in a state s these objects are not affected by the bound b because they are never explicitly materialized in s hence the reasoning problems still employ standard dl semantics rather than fixed domain reasoning gaggl rudolph and schweizer 2016 we also assume that goals of ekab and pddl tasks con sist of a single closed world atom g c if that is not the case we can introduce a new action with the goal formula g x as precondition that adds g x to the state the pa rameters x correspond to the constants c in the original goal formula g c this assumption simplifies some of the formal definitions but does not affect our main insights without this assumption for example the following definition of do main compilation f would also need to depend on the goal formula since we later need to compile all ucqs also those in the goal into derived predicates compilations to study the relative expressivity of these formalisms we adapt the notion of compilation schemes nebel 2000 thie baux hoffmann and nebel 2005 definition 4 a compilation scheme f from ekabs to pddl is a tuple of functions f fo fi fg that induces a func tion f from ekab tasks o i g to pddl tasks f f o fo fi o i fg o g such that a there exists a plan for iff there exists a plan for f and b fi and fg are polynomial time computable if f and fo are bounded polynomially expo nentially in then f is polynomial exponential if for every plan p solving an instance there exists a plan p solving f such that p c p n k for positive integer constants c n k we say that f preserves plan size polynomially if n 1 it preserves plan size linearly and if additionally c 1 then it preserves plan size exactly to be considered of the same expressivity there should be a polynomial compilation scheme between two formalisms that at least preserves plan size polynomially but ideally ex actly compilation schemes for specific dls are restricted to tboxes t formulated in the specified dl for example there exists an exponential compilation scheme for dl lite ekabs that rewrites ecqs in situ into fo conditions cal vanese et al 2016 this compilation has been optimized by borgwardt et al 2021 by using derived predicates to simplify the conditions in contrast the compilations we in vestigate in the following directly use datalog rewritings to compile ucqs into derived predicates 3 compiling tboxes into derived predicates we start by describing a generic compilation that exploits datalog rewritability of specific dls to compile open world ecqs into closed world formulas using derived predicates one restriction of pddl derived predicates is that they cannot occur in action effects however datalog rewritings may derive new facts about the predicates occurring in the state and tbox which can also occur in action effects to circumvent this issue we observe that query rewriting is only necessary for evaluating conditions but does not affect the states themselves therefore we separate the condition eval uation and action effects by using two disjoint signatures of predicates we use the datalog rewriting on a copy s of the state s in which each original predicate p has been replaced by a copy p this copying process can be simulated by mak ing p a derived predicate with the rule p x p x in the following we denote by t the result of replacing each predicate p in t by p and likewise for ecqs q another issue is that the rewriting may introduce additional constants which are not allowed for instantiating actions because that would change their behavior we simulate this via two new predicates s and n and a new action as n with precondition s and unconditional effect s and n o for all objects o that are not in the original domain description all other action conditions are also extended by s and n x x x n x for their parameters x to ensure that they can only be instantiated by the original objects definition 5 let p a t o i g be a b bounded ekab for which all ucqs as well as are datalog rewritable w r t t let rt be the disjoint union of rt and all rt q for ecqs q in the ekab then the pddl task p s n p a r o i g is obtained as follows p consists of the predicates occurring inrt a contains as n and all actions obtained from a by replacing preconditions pre by s n x p pre t and effect conditions cond by cond t r rt p x p x p p o o o rt and g s p g the goal does not need to be rewritten w r t t since we assumed that it is a single closed world atom theorem 1 def 5 is a compilation scheme from datalog rewritable ekabs to pddl that preserves plan size exactly proof the new goal g can be computed in polynomial time since we only add s p moreover as n and the set of rulesrt depend only on the objects and conditions occurring in the original ekab domain description we show that all plans of either planning task are also plans for the other modulo the initializing action as n consistency of s t is equivalent to rt s 6 p where s is obtained from s by replacing each p with p hence the rules p x p x and the conjuncts p in all conditions ensure that all states reached while executing a plan for the pddl task are consistent with t this includes the initial state since i is consistent with t by assumption similarly for any ecq q we have r s q t x iff s t q x which is equivalent to s t q x due to as n the substitutions for instantiating action and effect conditions range over the same objects in both tasks hence both formalisms allow equivalent action applications in each state and can reach a goal state by the same plans for example this immediately implies that ekabs with horn shiq tboxes have exponential compilations into pddl with derived predicates without negation and for elh and dl lite we even obtain polynomial compila tions eiter et al 2012 bienvenu and ortiz 2015 the latter also holds for horn shoiq if all conditions are restricted to eiqs ortiz rudolph and s imkus 2010 in general our construction applies to any ontology language where ucqs or iqs are datalog rewritable and to any specific tboxes and queries that happen to be datalog rewritable 4 a polynomial rewriting for horn alchoiq to extend the compilability results we develop a polynomial size rewriting for ucqs over horn alchoiq into datalog it is based on a query answering approach devel oped by carral dragoste and kro tzsch 2018 and encodes the relevant definitions from their paper into datalogs rules which extend datalog by set terms that denote sets of ob jects we then adapt a known polynomial translation to obtain a set of datalog rules ortiz rudolph and s imkus 2010 the full details can be found in the appendix but we de scribe the main ideas here the rewriting starts by translating the horn alchoiq axioms of the given tbox t into dat alog rules carral dragoste and kro tzsch 2018 however since the resulting rule set is exponential we here refor mulate it into polynomially many datalogs rules loosely following ideas from ortiz rudolph and s imkus 2010 the original approach uses exponentially many constants tx where x is a set of unary predicates to describe anonymous objects that satisfyx in datalogs these individuals can di rectly be described by sets x that can be used as arguments to predicates for example our rewriting introduces a new predicate role r x y to express that the objects represented byx and y are connected by the binary predicate r which is now viewed as an additional element of o using such addi tional predicates the translation of the original datalog rules by carral dragoste and kro tzsch 2018 is straightforward the remainder of the rewriting encodes the filtration phase from that paper into several strata of datalogs rules we use bespoke predicates to encode the constructions of expanded states and graphs in definitions 7 and 8 in carral dragoste and kro tzsch 2018 e g to compute a partial expansion of the input state to obtain more query matches and an acyclicity check over a dependency graph between query variables to fil ter out spurious matches after a translation from datalogs into datalog ortiz rudolph and s imkus 2010 correct ness of the rewriting follows mostly from theorem 3 in the paper by carral dragoste and kro tzsch 2018 theorem 2 ucqs over horn alchoiq tboxes are datalog rewritable with rewritings of polynomial size by theorem 1 we thus obtain a polynomial compila tion scheme for horn alchoiq ekabs into pddl that preserves plan size exactly admittedly this construction is rather complex but theoretically very interesting in particu lar in light of the next section 5 non compilability for expressive ekabs as a counterpoint to the previous section we now prove that polynomial compilations cannot exist for horn sroiq not even if we allow the plan size to increase polynomi ally horn sroiq differs from horn alchoiq only in allowing one additional type of axiom called complex role inclusions the following result is inspired by a similar non compilability result for pddl with derived predicates thie baux hoffmann and nebel 2005 we start with some observations about the complexity of the involved problems the polynomial step planning problem is to decide whether a given planning task has a plan of length polynomial for some given polynomial and the 1 step planning problem is the special case where the polynomial is 1 theorem 3 the polynomial step planning problem for pddl is exptime complete proof hardness follows from the complexity of the 1 step planning problem for pddl with derived predicates thie baux hoffmann and nebel 2005 theorem 1 mem bership can be seen as follows in exponential time we can enumerate all plans of polynomial length for a fixed poly nomial for each such plan we can check whether each ground action was applicable which facts were generated or deleted and whether the goal is satisfied in the end the most complex part of this check is the evaluation of the derived predicates after each action which can be done in exponential time dantsin et al 2001 theorem 4 the 1 step planning problem for horn sroiq ekabs is 2 exptime complete proof hardness follows from the complexity of reasoning in horn sroiq ortiz rudolph and s imkus 2010 member ship holds since we can enumerate all candidate 1 step plans in pspace the cqs in preconditions and the goal can be evaluated in 2 exptime ortiz rudolph and s imkus 2011 and the remaining parts of the ecqs can be evaluated in pspace abiteboul hull and vianu 1995 while these complexity results already indicate that rea soning in horn sroiq is more powerful than polynomial planning in pddl with derived predicates they tell us noth ing about the relative expressivity of these two formalisms there could still exist a polynomial size compilation scheme from the former to the latter that preserves plan size polynomi ally because the compilation can use arbitrary computational resources as long as the result is of polynomial size to prove that such a compilation indeed cannot exist we follow thie baux hoffmann and nebel 2005 by using the notion of advice taking turing machines karp and lipton 1982 such machines are equipped with an advice oracle a which is a function from positive integers to bit strings on input w the machine receives the advice a w and then starts its computation as usual the advice depends only on the length of the input but not on its contents an advice oracle is polynomial if the length of a w is bounded poly nomially in w exptime poly non uniform exptime is the class of problems that can be decided by turing machines with polynomial advice and exponential time bound the following result shows that a polynomial compilation scheme from horn sroiq ekabs to pddl would imply that the weak exponential hierarchy collapses completely the latter is considered to be unlikely in particular it would mean that one can eliminate any bounded quantifier prefix in second order logic and presburger arithmetic gottlob leone and veith 1995 haase 2014 theorem 5 unless exptimenp exptime there is no polynomial compilation scheme from horn sroiq ekabs to pddl preserving plan size polynomially proof sketch let m be a universal turing machine with double exponential time bound that can simulate all other such tms in the appendix we show how to construct a fam ily of horn sroiq ekab domain descriptions n such that m accepts a word w of length n iff n o iw g has a plan of length 1 here o contains only the two objects o and e iw is a state that can be computed from w in polyno mial time and g is a nullary predicate this construction is based on the 2 exptime hardness proof for horn sroiq ortiz rudolph and s imkus 2010 assume now that there is a compilation scheme f f fo fi fg from horn sroiq ekabs to pddl pre serving plan size polynomially this scheme could be used as an advice oracle as follows let m be a tm with double exponential time bound then m accepts w iff m accepts w m w in some fixed encoding let n be the size of w the compilation of n to a pddl domain descrip tion n f n as well as fo n can be used as polyno mial advice for a turing machine that on input w computes o o e iw and n o fo n fi o iw fg o g which can be done in polynomial time it then decides polynomial step plan existence for this pddl task which can be done in exptime by theorem 3 and is equivalent to deciding whether m accepts w by definition 5 over all this implies that exptimenp 2 exptime is included in exptime poly and therefore exptimenp exptime buhrman and homer 1992 which contradicts the assump tion of the theorem corollary 1 unless exptimenp exptime in general there can be no polynomial datalog rewritings for iqs over horn sroiq tboxes proof by theorem 1 such a rewriting would yield a poly nomial compilation from horn sroiq ekabs to pddl preserving plan size exactly which contradicts the assump tion by theorem 5 we obtain a similar result also for the non horn dls sh and alci because for them similar 2 exptime hardness proofs can be adapted lutz 2008 eiter et al 2009 a theorem 6 unless exptimenp exptime there is no polynomial compilation scheme from sh or alci ekabs to pddl preserving plan size polynomially 6 experiments while polynomial compilations are nice in theory they have one major drawback the size of the rules and in particular the arity of the new predicates grows polynomially with the input carral and kro tzsch 2020 in contrast the existing exponential compilation from horn shiq to datalog uses rules of constant size and in many cases does not exhibit an exponential blowup eiter et al 2012 moreover from a pragmatic perspective it is the only datalog rewriting for cqs over horn dls that has been implemented so far in the clipper system we thus implemented our compilation from section 3 using clipper to answer the following questions 1 is the compilation feasible i e can the generated classi cal planning tasks be handled by state of the art planners 2 how does our compilation perform against existing ekab compilations for the experiments we use the fast downward fd planning system helmert 2006 version 20 06 the newest version as of august 2021 the main implementation plat form for classical planning today we ran fd with a dual queue greedy best first search using the hff heuristic a com monly used baseline in the planning literature all experi ments were run on a computer with an intel core i 5 4590 cpu 3 30 ghz and run time and memory cutoffs of 600 s 0 50 100 150 200 0 20 40 60 grid dimension t im e s 0 200 400 600 f il e si ze k b domain description planning time compilation time figure 1 comparison of the robot dashed and robotconj solid domains w r t domain description size compilation and planning times and 8 gbs respectively the benchmarks and the compiler are available online 4 implementation we encode horn shiq ekab tasks as ontology files accompanied by pddl files whose syntax has been extended to allow conjunctive queries the ontology file uses turtle syntax which can be processed by any off the shelf ontology tool our compiler reads the cq pddl and ontology files and generates a classical planning task in stan dard pddl format the datalog rewriting is generated with clipper eiter et al 2012 the compilation additionally normalizes complex conditions via a tseitin like transforma tion tseitin 1983 which has been shown to be effective before borgwardt et al 2021 benchmarks our benchmark collection consists of 125 instances adapted from existing dl lite ekab benchmarks calvanese et al 2016 borgwardt et al 2021 and 110 newly created instances a detailed description can be found in the appendix we manually translated the existing ekab do mains cats elevator robot taskassign tpsa vta and vta roles into the format described above modifications almost exclusively pertained to extracting the ontology from the ekab description into a separate turtle file and moving so called condition action rules calvanese et al 2016 into action preconditions the translated instances are equivalent to the originals since horn shiq is more expressive than dl lite we also created 3 new domains drones queens and robotconj in which we make use of conjunctions qualified existential restrictions occurring with negative polarity and symmetric and transitive relations all of which are not supported by dl lite baader et al 2017 drones describes a complex 2 d drone navigation problem in which drones need to be moved to avoid critical situations the latter are described in the ontology using axioms with qualified existential restrictions 4 https gitlab perspicuous computing science a kovtunova pd dl horndl https gitlab perspicuous computing science a kovtunova pddl horndl https gitlab perspicuous computing science a kovtunova pddl horndl solved compiled planning time compilation time domain cal 16 bor 21 horn cal 16 bor 21 horn cal 16 bor 21 horn cal 16 bor 21 horn cats 20 14 20 20 20 20 20 63 46 0 13 0 03 0 16 0 22 0 65 elevator 20 20 20 20 20 20 20 0 36 0 30 0 03 0 60 0 73 0 66 robot 20 4 12 20 12 12 20 15 05 10 10 0 11 138 52 138 55 0 75 taskassign 20 3 20 20 20 20 20 0 81 0 12 0 06 2 87 39 21 0 66 tpsa 15 14 5 15 15 5 15 2 01 2 42 0 30 0 84 25 37 0 59 vta 15 15 13 15 15 15 15 23 06 371 56 16 91 0 33 1 21 0 65 vta roles 15 15 5 15 15 5 15 2 25 11 61 1 36 0 59 95 53 0 66 125 85 95 125 117 97 125 19 99 77 33 3 59 18 01 31 84 0 66 drones 24 20 24 101 42 0 69 queens 30 15 30 21 66 0 69 robotconj 56 56 56 8 14 2 77 110 91 110 30 87 1 75 table 1 per domain aggregated statistics solved number of instances solved by the planner compiled number of instances for which the compilers could generate the pddl input files for the planner planning time average planner run time over the commonly solved instances compilation time average time of generating the pddl files and symmetric relations queens generalizes the eight queens puzzle to board sizes n 5 10 and numbers of queens m n 4 n queens are initially placed randomly on the board and need to be moved to a configuration where no queen threatens another the ontology contains a symmetric transitive relation to describe legal moves robotconj is a redesign of robot that moves some of the complexity from actions into the ontology the original robot benchmark encodes static knowledge about 2 d grid cell adjacency in the action descriptions which can be encoded much more naturally in the ontology using conjunctions note that the original robot benchmark consists of 20 instances grid sizes 3 3 up to 22 22 whereas for the new robotconj we included 56 instances up to 200 200 since they could be easily handled by our compiler scalability study we use robot and robotconj to ana lyze how our compilation performs as a function of domain description size including the ontology figure 1 depicts the results for 56 instances of each domain obtained by scal ing the grid from 3 3 to 200 200 in both domains the file size is directly proportional to size of the grid even the largest tested instance could be compiled and solved in less than 90 seconds attesting the feasibility of our approach the increased complexity of robotconj s ontology does not affect the performance on the contrary both compilation and planning for robotconj are actually consistently faster than for robot due to the simplified actions comparison to dl lite compilations we compare to cal 16 the original dl lite ekab compiler calvanese et al 2016 and to bor 21 its recently introduced optimization using derived predicates to compile away complex formulas borgwardt et al 2021 we refer to our compilation by horn table 1 gives a summary of the results cal 16 and bor 21 were only run on the original dl lite ekab benchmarks considering the dl lite benchmark part horn has similar or better performance than cal 16 and bor 21 in robot the cal 16 compilation and hence also bor 21 could only pro cess the 12 smallest instances up to grid size 14 14 exceed ing the 600 seconds time limit thereafter while cal 16 and bor 21 both show a blow up in compilation time in some do mains our new horn compiler could process all instances in less than 1 second on average the compilation time of horn is almost consistently larger than 0 6 seconds which can be attributed to the fixed overhead of calling clipper while the compilation time of horn is very competitive with the previous dl lite compilers the planner s performance statis tics really substantiate this advantage regarding planning time and the number of solved instances horn significantly outperforms both alternatives on the dl lite benchmarks the more complex ontologies in the horn shiq bench mark part did not pose a challenge to horn all instances could still be translated within 3 seconds on average the con structed instances of drones and queens are however much more challenging from a planning perspective contrary to the dl lite benchmarks before average planning runtime is higher and some instances could not be solved in time the difficulty of the instances was chosen intentionally with the purpose of creating challenging problems for future work 7 conclusion we have shown that adding horn dl background ontologies often does not increase the expressivity of pddl planning tasks this is due to datalog rewritability which allows us to reduce open world to closed world reasoning how ever adding more axiom types horn sroiq or using non horn dls sh or alci increases the expressivity beyond pddl unless the weak exponential hierarchy col lapses an evaluation of our generic compilation approach using the clipper system demonstrates the feasibility of us ing datalog rewritings even compared to more specialized compilation schemes for the smaller logic dl lite more over we have contributed additional benchmarks to showcase the increased expressivity of our proposed approach in future work we will investigate the existence of a poly nomial compilation scheme for horn shoiq whose ex pressivity lies between that of horn alchoiq and horn sroiq we also want to investigate planning formalisms with different effect semantics e g the one described by de giacomo et al 2021 acknowledgements this work is supported by dfg grant 389792660 as part of trr 248 cpec https perspicuous computing science references abiteboul s hull r and vianu v 1995 foundations of databases addison wesley ahmetaj s calvanese d ortiz m and s imkus m 2017 managing change in graph structured data using descrip tion logics acm transactions on computational logic 18 4 27 1 27 35 baader f horrocks i lutz c and sattler u 2017 an introduction to description logic cambridge university press bienvenu m and ortiz m 2015 ontology mediated query answering with data tractable description logics in faber w and paschke a eds reasoning web 11 th int summer school volume 9203 of lecture notes in computer science 218 307 springer borgwardt s hoffmann j kovtunova a and steinmetz m 2021 making dl lite planning practical in bienvenu m and lakemeyer g eds proc of the 18 th int conf on principles of knowledge representation and reasoning kr 21 641 645 ijcai buhrman h and homer s 1992 superpolynomial cir cuits almost sparse oracles and the exponential hierarchy in shyamasundar r ed proc of the 12 th conf on foun dations of software technology and theoretical computer science fsttcs 92 volume 652 of lecture notes in com puter science 116 127 springer verlag calvanese d de giacomo g lembo d lenzerini m and rosati r 2007 a eql lite effective first order query processing in description logics in veloso m m ed 20 th int joint conf on artificial intelligence ijcai 274 279 calvanese d de giacomo g lembo d lenzerini m and rosati r 2007 b tractable reasoning and efficient query answering in description logics the dl lite family journal of automated reasoning 39 3 385 429 calvanese d de giacomo g montali m and patrizi f 2013 verification and synthesis in description logic based dynamic systems in faber w and lembo d eds 7 th int conf web reasoning and rule systems rr 50 64 springer calvanese d montali m patrizi f and stawowy m 2016 plan synthesis for knowledge and action bases in kambhampati s ed 25 th int joint conf on artificial in telligence ijcai 1022 1029 aaai press carral d dragoste i and kro tzsch m 2018 the com bined approach to query answering in horn alchoiq in thielscher m toni f and wolter f eds proc of the 16 th int conf on principles of knowledge representation and reasoning kr 18 339 348 aaai press carral d and kro tzsch m 2020 rewriting the descrip tion logic alchiq to disjunctive existential rules in bessiere c ed proc of the 29 th int joint conf on artificial intelligence and the 17 th pacific rim int conf on artificial intelligence ijcai pricai 20 1777 1783 ijcai dantsin e eiter t gottlob g and voronkov a 2001 complexity and expressive power of logic programming acm computing surveys 33 3 374 425 de giacomo g lespe rance y patrizi f and vassos s 2014 progression and verification of situation calculus agents with bounded beliefs in amd paul scerri a l baz zan a and huhns m eds 13 th int conf on autonomous agents and multiagent systems aamas 141 148 acm de giacomo g oriol x rosati r and savo d f 2021 instance level update in dl lite ontologies through first order rewriting journal of artificial intelligence research 70 1335 1371 eiter t lutz c ortiz m and s imkus m 2009 a query answering in description logics with transitive roles in boutilier c ed proc of the 21 st int joint conf on artificial intelligence ijcai 09 759 764 aaai press eiter t lutz c ortiz m and s imkus m 2009 b query answering in description logics with transitive roles inf sys research report 1843 09 02 institut fu r information ssysteme tu wien eiter t ortiz m s imkus m tran t k and xiao g 2012 query rewriting for horn shiq plus rules in hoffmann j and selman b eds proc of the 26 th aaai conf on artificial intelligence aaai 12 726 733 aaai press fox m and long d 2003 pddl 2 1 an extension to pddl for expressing temporal planning domains journal of artificial intelligence research 20 61 124 gaggl s a rudolph s and schweizer l 2016 fixed domain reasoning for description logics in kaminka g a fox m bouquet p hu llermeier e dignum v dignum f and van harmelen f eds proc of the 22 nd eur conf on artificial intelligence ecai 16 volume 285 of frontiers in artificial intelligence and applications 819 827 ios press gerevini a haslum p long d saetti a and dimopou los y 2009 deterministic planning in the fifth international planning competition pddl 3 and experimental evaluation of the planners artificial intelligence 173 5 6 619 668 ghallab m nau d and traverso p 2004 automated planning theory and practice morgan kaufmann gottlob g leone n and veith h 1995 second order logic and the weak exponential hierarchies in wieder mann j and ha jek p eds proc of the 20 th int symp on mathematical foundations of computer science mfcs 95 volume 969 of lecture notes in computer science 66 81 springer verlag haase c 2014 subclasses of presburger arithmetic and the weak exp hierarchy in henzinger t and miller d eds proc of the joint meeting of the 23 rd eacsl annual conf on computer science logic csl and the 29 th annual https perspicuous computing science acm ieee symp on logic in computer science lics 14 1 14 10 acm haslum p lipovetzky n magazzeni d and muise c 2019 an introduction to the planning domain definition language synthesis lectures on artificial intelligence and machine learning 13 2 1 187 helmert m 2006 the fast downward planning system journal of artificial intelligence research 26 191 246 hoffmann j and edelkamp s 2005 the deterministic part of ipc 4 an overview journal of artificial intelligence research 24 519 579 hoffmann j weber i scicluna j kacmarek t and ankolekar a 2008 combining scalability and expres sivity in the automatic composition of semantic web ser vices in 8 th international conference on web engineering icwe 08 jung j c papacchini f wolter f and zakharyaschev m 2019 model comparison games for horn description logics in bouyer p ed proc of the 34 th annual ieee symp on logic in computer science lics 19 1 14 ieee karp r m and lipton r j 1982 turing machines that take advice l enseignement mathe matique 28 191 209 kro tzsch m 2011 efficient rule based inferencing for owl el in walsh t ed proc of the 22 nd int joint conf on artificial intelligence ijcai 11 2668 2773 aaai press kro tzsch m rudolph s and hitzler p 2013 complex ities of horn description logics acm transactions on computational logic 14 1 2 1 2 36 lutz c 2007 inverse roles make conjunctive queries hard in calvanese d franconi e haarslev v lembo d motik b turhan a y and tessaris s eds proc of the 20 th int workshop on description logics dl 07 volume 250 of ceur workshop proceedings 100 111 lutz c 2008 the complexity of conjunctive query an swering in expressive description logics in proc of the 4 th int joint conf on automated reasoning ijcar 08 vol ume 5195 of lecture notes in artificial intelligence 179 193 springer verlag mcdermott d ghallab m howe a knoblock c ram a veloso m weld d and wilkins d 1998 the pddl planning domain definition language the aips 98 plan ning competition comitee nebel b 2000 on the compilability and expressive power of propositional planning formalisms journal of artificial intelligence research 12 271 315 ortiz m rudolph s and s imkus m 2010 worst case op timal reasoning for the horn dl fragments of owl 1 and 2 in lin f sattler u and truszczynski m eds proc of the 12 th int conf on principles of knowledge representation and reasoning kr 10 269 279 aaai press ortiz m rudolph s and s imkus m 2011 query an swering in the horn fragments of the description logics shoiq and sroiq in walsh t ed proc of the 22 nd int joint conf on artificial intelligence ijcai 11 1039 1044 aaai press thie baux s hoffmann j and nebel b 2005 in defense of pddl axioms artificial intelligence 168 38 69 tseitin g s 1983 on the complexity of derivation in propositional calculus in siekmann j h and wrightson g eds automation of reasoning 2 classical papers on computational logic 1967 1970 466 483 springer berlin heidelberg isbn 978 3 642 81955 1 a proof of theorem 2 we first describe the logic horn alchoiq in more detail we use classical dl terms here i e unary predicates are called concept names binary predicates are role names objects constants are individual names and states are aboxes we assume that all axioms in horn alchoiq tboxes are in normal form carral dragoste and kro tzsch 2018 i e they have one of the following shapes where c c 1 cn d are concept names r s are role names and a is an individual name i c 1 u u cn v d ii c v r d iii r c v d iv c v 1 r d v c v a vi r v s vii a v c we added the last axiom type here since our goal is a tbox rewriting that is independent of the abox i e we need to distinguish the tbox axiom a v c from the equivalent abox fact c a a first order interpretation i satisfies these axioms if it satisfies the sentences i x c 1 x cn x d x ii x c x y r x y d y iii x y r x y c y d x iv x y z c x r x y d y r x z d z y z v x c x x a vi x y r x y s x y or vii c a respectively additionally there is a bijective and irreflexive function on the set of role names such that r r and x y r x y r y x is required to hold in all models of a tbox for all role names r r is called the inverse of r following ortiz rudolph and s imkus 2010 we will use datalogs rules to encode reasoning in horn alchoiq datalogs extends datalog rules by introducing fixed set sorts 2 c where c is a set of constants set terms of sort 2 c are built inductively from the constructors c 1 cn and t 1 t 2 where c 1 cn c and t 1 t 2 are set terms of this sort every predicate has an associated sort function that assigns to each position a unique sort i e either the normal element sort or one of the fixed set sorts this means that the positions of this predicates always accept only terms of the associated sort the semantics of the resulting stratified datalogs rules is intuitive ortiz rudolph and s imkus 2010 to make it easier to compare with the existing constructions ortiz rudolph and s imkus 2010 carral dragoste and kro tzsch 2018 in the following we write datalogs rules with instead of we also use rules with conjunctions of atoms in the head instead of only one atom encoding instance queries in the following let t be a horn alchoiq tbox in normal form and c r i denote the sets of concept names role names individual names in t in addition to the individuals in i the construction by carral dragoste and kro tzsch 2018 uses artificial individuals of the form tx where x is a set of concept names and new predicates r that represent a set of role names that have to be satisfied at the same time we represent such r and x using sets of the sorts 2 r and 2 c i respectively the latter includes named individuals since we want to treat named and anonymous individuals using the same predicates however named individuals a will only appear as singleton sets a formally we are not allowed to treat individuals from the abox in this way because then the set sorts which need to be fixed would depend on the abox we nevertheless do this in the following and at the end of this section describe how to translate these datalogs rules into datalog rules that are abox independent instead of an atom c x carral dragoste and kro tzsch 2018 we now use atoms of the form concept c x where c c is treated as a new constant and x is a set as described above i e either a set of concept names or a singleton set containing an individual name likewise role atoms r x y and r x y are transformed into role r x y and roles r x y respectively additionally we distinguish sets x c from sets a with a i by the predicate anon which is populated by the following rules for all c c anon c 1 anon x anon x c 2 we also compute the set of inverse roles of a set r for all r r ortiz rudolph and s imkus 2010 inv r r 3 inv r r inv r r r r 4 additionally the original rewriting uses atoms of the form n x and x y which we simply adapt to n x and x y where x y are as described above we also add a predicate ind which identifies all individual names from the abox in order to identify query answers in the end this predicate represents a subset of the predicate n which will also contain anonymous individuals x that are inferred to represent a unique element in every interpretation the original datalog rewriting starts with several auxiliary rules which we translate below into their modified datalogs form for all c c and r r carral dragoste and kro tzsch 2018 figure 2 concept c x concept x 5 role r x y concept x concept y 6 roles r x y n y inv r r roles r y x 7 roles r x y r r role r x y 8 c x concept c x ind x 9 r x y role r x y ind x ind y 10 ind x n x 11 x y y x 12 x y y z x z 13 concept c x x y concept c y 14 n x x y n y 15 roles r x y x z roles r z y 16 roles r x y y z roles r x z 17 rules 9 and 10 were further modified from their originals to convert the abox predicates into our datalogs syntax in an abox independent way in a slight abuse of notation on the left hand side of rule 9 c is treated as a concept name and on the right hand side c is treated as a constant similarly for rule 10 the axioms of the tbox t are translated into the following datalogs rules carral dragoste and kro tzsch 2018 figures 3 and 4 for every axiom of the form i concept c 1 x concept cn x concept d x 18 for axioms of the form ii concept c x role r x d 19 for axiom type iii role r x y concept c y concept d x 20 concept c x roles r x y r r inv r r anon y roles r x y d 21 axiom type iv requires more complex rules concept d y role r y x concept c x role r x z concept d z n z y z 22 concept c x r r roles r x y concept d y anon y r s roles s x z concept d z anon z roles r s x y z 23 concept c x r r inv r r concept d y roles r y x r s inv s s anon z e z roles s x z concept d z concept e y roles r s y x 24 concept d y role r y x concept c x n x n y 25 in addition we need the following rule that completes the translation of axioms of types ii iv by adding the newly created anonymous individuals to the required concepts role r x y c y concept c y 26 for axiom type v concept c x a x n a 27 for axiom type vi we use the predicate sup that connects each role name to the set of all its super roles rule 29 is instantiated for every s v t t or s v t t sup r r 28 sup r s s s sup r s t 29 role r x y sup r s roles s x y 30 role r x y sup r s inv s s roles s x y 31 finally axiom type vii can be handled like a concept assertion concept c a n a 32 so far the rules did not use negation and can be seen as the first stratum of the final rule set this part is already a rewriting of any instance query over the tbox signature i e concept c a is contained in the least herbrand model of these rules and an abox iff c a is entailed by the original tbox over the abox carral dragoste and kro tzsch 2018 lemma 4 to be able to answer arbitrary ucqs we also need to encode the so called filtration phase carral dragoste and kro tzsch 2018 building a canonical model the next stratum encodes definition 7 from carral dragoste and kro tzsch 2018 by using negated atoms over the predicate n the goal of this part is to derive a dependency relation role r x y that encodes the order in which individuals are created during the construction of a model of the ontology extended individuals of the form tir x are used in this relation where r r x c and i 0 1 2 carral dragoste and kro tzsch 2018 therefore the sets x y in role r x y are now considered to be subsets of r c i 0 1 2 where again individuals can only occur in singleton sets a and at most one index 0 1 2 can be present in any given set in addition to role the following rules also compute extensions role and concept of role and concept respectively to the new individuals together these three predicates describe a kind of canonical model called co over which ucqs will be answered as a prerequisite we need to introduce an intermediate stratum to define a total order on sets of the form r x for this purpose we consider an enumeration r 1 rn cn 1 cn m of all role and concept names and use the following rules to define the lexicographic order based on the auxiliary relations i and i i 1 n m all using infix notation 1 33 1 r 1 34 r 1 1 r 1 35 x 1 y x 2 y 36 x 1 y x 2 y 37 x 1 y x 2 y r 2 38 x 1 y x r 2 2 y r 2 39 x n m y x y 40 x n m y x y 41 the following rules which use the negations of and n from the previous strata correspond to definition 7 from carral dragoste and kro tzsch 2018 where j i 1 mod 3 n x role r x y n y role r x y role r y x 42 n x roles r x y anon y n y r r role r x r y 0 43 role r x r y i roles s y z anon z n z s s r y s z role s r y i s z j 44 role r x r y i roles s y z anon z n z s s r y 6 s z role s r y i s z i 45 role s x r y i role r y z n z role r r y i z 46 role r z r y i 47 role s x y concept c y concept c y 48 role s x r y i concept c y concept c r y i 49 role r x y role r x y role r y x 50 the least herbrand model of these rules restricted to role concept and role corresponds to the set co carral dragoste and kro tzsch 2018 conditions of the type tir y is in co are translated into body atoms like role r x r y i since these new individuals are only introduced into co inside of role facts encoding the filtration finally we encode definition 8 from carral dragoste and kro tzsch 2018 which constructs a family of graphs that use the variables of a given cq as vertices and their edges encode possible matches of the cq into co some of these matches have to be filtered out since they lead to spurious answers we assume that the input cq q is of the form v 1 v v 1 vk i e v 1 vk are the free variables ucqs can be treated by encoding each component cq individually and then merging the results in a single predicate by v 1 vk we denote the result of replacing each concept atomc vi in by concept c vi and similarly r vi vj by role r vi vj where each vi is viewed as a set variable over r c i and denotes a possible mapping of vi into co we use the indices 1 k to refer to the vertices in the graphs that are constructed and atoms of the form edge i j v 1 vk to denote an edge from i to j which depends on a specific instantiation of all variables by individuals in co the following are the rules corresponding to the first part of definition 8 from carral dragoste and kro tzsch 2018 for all role atoms r vi vj in v 1 vk role r vi vj role r vj vi edge i j v 1 vk 51 v 1 vk role r vj vi role r vi vj edge j i v 1 vk 52 now for all i j 1 k we apply the following rules to collapse this graph according to definition 8 from carral dragoste and kro tzsch 2018 edge i j v 1 vk edge m j v 1 vk equal i m v 1 vk 53 edge i j v 1 vk edge m n v 1 vk equal j n v 1 vk equal i m v 1 vk 54 we now need to check whether the resulting graph is a rooted directed forest i e contains no cycles and no diamonds that reconnect different branches edge i j v 1 vk reach i j v 1 vk 55 reach i j v 1 vk equal j m v 1 vk reach i m v 1 vk 56 reach i j v 1 vk equal i m v 1 vk reach m j v 1 vk 57 reach i j v 1 vk edge j m v 1 vk reach i m v 1 vk 58 reach i i v 1 vk bad v 1 vk 59 edge i j v 1 vk edge i m v 1 vk equal j m v 1 vk reach j n v 1 vk reach m n v 1 vk bad v 1 vk 60 finally we can use the predicate bad to filter out spurious matches and return the actual answers to q in the predicate pq v 1 vk bad v 1 vk p q v 1 vk 61 p q v 1 vk ind v 1 ind vk a 1 v 1 ak vk pq a 1 ak 62 from datalogs to datalog to simulate set terms in plain datalog we adapt an existing construction which did not deal with negation or abox independent rule sets ortiz rudolph and s imkus 2010 first each set union t 1 t 2 over the domain s is replaced with a fresh variable x and the ternary atom us t 1 t 2 x is added to the body of the rule in which this term occurs new rules are added to simulate the set union with this predicate see below then sets x s are represented as bit vectors of length s and set variables as vectors of variables and all atoms are replaced accordingly this gets rid of all set expressions while increasing the arity of the predicates polynomially the main problem we face here is that we used singleton sets a to refer to individual names a from the abox which means that the set sort 2 c i was treated as if it contained all these individual names although our translation cannot depend on the abox see definition 1 to avoid this issue we modify the bit vector encoding above to directly represent constants by themselves for this recall that individual names a can only occur in singleton sets a because sets x are only extended if they belong to anon see e g rules 21 23 or 43 thus we can represent each instantiated set x which is either of the form a or a subset of c as a vector a 0 0 or 0 b 1 bm respectively where m c and bi 1 iff the i th concept name of c is in x according to some fixed enumeration of c the new constants 0 and 1 are used to represent bit values correspondingly set variables x are split into vectors x 0 x 1 xm where x 0 holds the individual name if any and x 1 xm represent a subset of c the encoding works similarly for sets of the sorts 2 r 2 r c and 2 r c i 0 1 2 that are employed in the rewriting above for example the datalog versions of rules 9 and 19 are c x concept c x 0 0 ind x 0 0 and 63 concept c x 0 xm role r x 0 xm 0 b 1 bm 64 respectively where bi 1 iff d is the i th concept name in c apart from the new predicates like uc i this encoding clearly preserves the stratification of the original rule set the following additional rules are used to define uc i and similarly for the other set sorts max 0 0 0 65 max 1 0 1 66 max 0 1 1 67 max 1 1 1 68 max x 1 y 1 z 1 max xm ym zm uc i 0 x 1 xm 0 y 1 ym 0 z 1 zm 69 this suffices to define the set union since we never need to compute unions involving singleton sets a with a i these additional rules can be included in the first stratum since max and us do not occur in any other rule heads this finishes the presentation of the datalog rewriting for any ucq over a horn alchoiq tbox its correctness follows mainly from an existing result carral dragoste and kro tzsch 2018 theorem 3 since we only translated the relevant definitions into datalogs rules it can also be verified that the resulting set of datalog rules is of polynomial size b proof of theorem 5 we show how to construct the ekab task n o iw g such that m accepts a word w of length n iff there is a plan of length 1 the construction is based on the 2 exptime hardness proof for horn sroiq ortiz rudolph and s imkus 2010 and uses only a single action with precondition x b x and unconditional effect g we do not repeat all details of the original construction here but only adapt the relevant parts the proof encodes the turing machine m and an input word w into a tbox t using the two objects o and e such that m accepts w iff at least one unary predicate hqf representing a final state of the tm is empty in every model of t the original proof then goes on to add axioms hqf v to force t to become unsatisfiable in such a case since we require the initial state to be consistent with the tbox we instead use the axioms hqf v b which allows us to query for x b x instead of checking unsatisfiability we further adapt the original reduction by extracting from t the description of the input word w into a state iw for w w 0 wn 1 t contains the following axioms to encode the input tape notation is slightly adjusted to avoid clashes o v i 1 uhq 0 70 ij v awj u h ij 1 0 j n 71 ij v hr 1 j n 72 in v a 73 in v h in 74 the object o indicates the starting point of the tape and the unary predicates ij identify the first n cells which are connected via the binary predicate h the predicates awj indicate the presence of the input symbols in these cells the predicates hq 0 and hr indicate the presence and absence of the head respectively finally all cells to the right of the input word are labeled with a blank symbol by using the auxiliary predicate in we leave the axioms 72 74 in the tbox but replace 70 71 by the following axioms 75 76 and assertions for iw 77 78 sj a v hj ij uaa 0 j n a 75 in 1 v hn in 76 hq 0 o 77 sj wj o 0 j n 78 here hj stands for j nested restrictions of the form h and sj a indicates the presence of the symbol a of the tm alphabet at cell j in this way the final tbox tn only depends on the length n of the input word w but not on w itself the final domain description is n pn an tn where pn contains all symbols from tn as well as g and an consists of the single action described above c proof of theorem 6 the proof follows the same arguments as for theorem 5 the only difference being how the domain description n and state iw are obtained for cq entailment in alci we adapt a reduction from a universal aexpspace turing machine lutz 2007 the single action we use in the reduction will have a precondition qw where qw is the cq from that reduction which despite its name does not depend on the input word w w 0 wn 1 but only on the length n again the only adaption we have to do is to extract the part of the tbox encoding the input word into a state iw consider the relevant axioms again with slightly adapted notation where 0 j n lutz 2007 r u i o 79 i v sn 2 gh u pos j wj 80 i v sn 2 gh u pos 0 q 0 81 i v sn 2 gh u pos n b 82 here r u i describes the starting point of the initial configuration and its sn 2 successors marked with gh identify the exponentially many tape cells the counter pos identifies particular cells wj describes the tape content q 0 the initial state and b the blank symbol we use a similar trick as before to split 80 into abox facts and tbox axioms that do not depend on the input word w but only on its length for all 0 j n a sj a v sn 2 gh u pos j a 83 sj wj o 84 the state iw now consists of all facts 84 as well as 79 and all other axioms are part of tn the remaining arguments are the same as in the proof of theorem 5 the reduction for cq entailment over sh tboxes eiter et al 2009 b is very similar to the previous case except that the predicates r and gh are not used sn 2 is replaced by rn 1 wj is replaced by r eh wj and similarly for q 0 and b many other details not relevant here are different as well hence we can use very similar adaptations d benchmark description our collection of benchmarks consists of a total of 235 instances adapted from the publicly available dl lite ekab benchmark collection borgwardt et al 2021 as well as newly developed high expressivity domains the benchmarks and the compiler are available in the supplementary material each problem instance has two representations the horn shiq ekab task encoding with an ontology written in turtle 5 and its compilation into pddl adapted dl lite ekab benchmarks we translated the original benchmarks into equivalent representations in our horn shiq ekab task encoding detailed descriptions of these domains are available online in short in robot calvanese et al 2016 a robot is positioned on a grid without knowing its position and the goal is to reach a target cell the ontology describes relations between rows and columns the goal of taskassign inspired by calvanese et al 2016 is to hire two electronic engineers for a company while the ontology describes relations between different job positions the elevator and cats benchmarks are inspired by standard planning benchmarks in the cats domain there is a set of packages that contain either cats or bombs and the task is to disarm all bombs an elevator in the elevator benchmark can move up and down between floors to serve passengers according to their origins and destinations both the vta and tpsa benchmarks are adaptations from older work on semantic web service composition hoffmann et al 2008 vta roles is a more complex variant of vta high expressivity domains drones models a complex 2 d drone navigation problem in which drones need to be moved while avoiding certain situations the latter is given by ontology reasoning involving horn concept inclusions with qualified existential restrictions occurring negatively and symmetric roles grid cells are occupied with different objects like humans or trees or weather conditions like lowvisibility or rain there is a set of drones randomly placed on the board depending on the distances to other objects a drone can enter a critical state defined by the ontology the goal is to move the drones such that no two drones in a critical state are next to each other in the benchmark instances vary in the board size and the number of drones we have chosen the instances such that some of them remain hard for the planner to solve the compilation itself is always very fast queens generalizes the eight queens puzzle from chess to variable numbers of board sizes n 5 10 and queens m n 4 n in the initial state queens are placed randomly and the ontology contains a symmetric transitive role to describe which queen movements are legal similarly to drones the planner must find a sequence of legal moves such that no two queens threaten each other 5 https www w 3 org tr turtle https www w 3 org tr turtle robotconj is a redesign of robot moving complexity from action descriptions into the ontology the original robot benchmark encoded static knowledge about 2 d grid cell adjacency in the action descriptions which via the use of horn clauses can be encoded much more naturally directly in the ontology more precisely in a slightly simplified notation the action movedown contains the two redundant conditional effects when and aboveof 1 x belowof 2 x 85 row 0 x which one can read as if the robot is above or in row 1 and below row 2 then move the robot to row 0 and when row 1 x 86 row 0 x i e if the robot position is in row 1 then move the robot to row 0 however encoding the static knowledge that aboveof 1 and belowof 2 imply row 1 is beyond dl lite moreover the actions moveup moveleft and moveright have similar redundant effects for robotconj we have simplified these descriptions by using axioms like aboveof 1 ubelowof 2 v row 1 which allows us to get rid of 85 1 introduction 2 preliminaries 3 compiling tboxes into derived predicates 4 a polynomial rewriting for horn alchoiq 5 non compilability for expressive ekabs 6 experiments 7 conclusion a proof of theorem 2 encoding instance queries building a canonical model encoding the filtration from datalogs to datalog b proof of theorem 5 c proof of theorem 6 d benchmark description