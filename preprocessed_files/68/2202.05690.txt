hat 5 hate language identification using text to text transfer transformer sana sabah sabry tosin adewumi nosheen abid gyo rgy kova cs foteini liwicki and marcus liwicki department of computer science electrical and space engineering lulea university of technology lulea sweden email sana sabah sabry al azzawi ltu se tosin adewumi ltu se nosheen abid ltu set gyorgy kovacs ltu se foteini liwicki ltu se marcus liwicki ltu se abstract we investigate the performance of a state of the art sota architecture t 5 available on the superglue and compare with it 3 other previous sota architectures across 5 different tasks from 2 relatively diverse datasets the datasets are diverse in terms of the number and types of tasks they have to improve performance we augment the training data by using an autoregressive model we achieve near sota results on a couple of the tasks macro f 1 scores of 81 66 for task a of the olid 2019 dataset and 82 54 for task a of the hate speech and offensive content hasoc 2021 dataset where sota are 82 9 and 83 05 respectively we perform error analysis and explain why one of the models bi lstm makes the predictions it does by using a publicly available algorithm integrated gradient ig this is because explainable artificial intelligence xai is essential for earning the trust of users the main contributions of this work are the implementation method of t 5 which is discussed the data augmentation using a new conversational ai model checkpoint which brought performance improvements and the revelation on the shortcomings of hasoc 2021 dataset it reveals the difficulties of poor data annotation by using a small set of examples where the t 5 model made the correct predictions even when the ground truth of the test set were incorrect in our opinion we also provide our model checkpoints on the huggingface hub 1 to foster transparency index terms hate speech detection data augmentation transformers t 5 xai i introduction hate speech is usually viewed as any communication that disparages any person or group of people 1 2 it is an unethical behaviour and has legal repercussions in many countries 2 3 the increasing importance of detecting hate speech automatically has come to the fore with the increasing influence of social media in addition to mainstream media for example xenophobia and other social vices have been encouraged as a result of online social media comments 4 examples of hate speech which may incite others in the offensive language identification dataset olid 5 training data are given below user if jamie oliver fucks with my 3 meal deals at tesco i ll kill the cunt 1 https huggingface co sana ngu hat 5 augmentation https huggingface co sana ngu hat 5 https huggingface co sana ngu hat 5 roberta user she is wortless why is she not checked out by secret service she is irresponsible in trying to generate hste to have somone kill thre president user regarding the story i think i m going to kill the president why is it reporters never follow up on how a convicted felon could obtain in this case 6 guns what s the police doing about or would that bring light to the gun control issue bias for societies to be peaceful and promote equality it is crucial to automatically detect hate speech and address it this is also important to prevent perpetuating such undesirable behaviour or characteristics in new technologies such as conversational systems and other ai technologies 6 7 automatic hate speech detection is imperative because of the herculean task of doing it manually and the delay that manual detection involves 2 besides a manual approach is more likely to be subjective while a trained automated approach is more objective 8 9 our work spans 5 english tasks from 2 publicly avail able datasets the datasets are olid 5 and hasoc 2021 10 the tasks are tasks a b of the hasoc 2021 and tasks a b c of the olid dataset details of the datasets are provided in the data section iii these datasets were selected because of their importance and the subtasks covered with regards to hate speech this work compares the performance of different sota architectures over these datasets the architectures include the bi directional long short term memory network bi lstm the convolutional neural network cnn robustly optimized bert approach roberta and text to text transfer transformer t 5 we use pretrained models for both the roberta and t 5 from the huggingface library 11 in addition we perform data augmentation on the training set of hasoc and evaluate the performance we investigate two types of data augmentation in this work and achieve near sota result on task a of the hasoc dataset by using one of these approaches to promote transparency we provide our model checkpoints for public access on the huggingface 2 bbc com news world europe 35105003 ar x iv 2 20 2 05 69 0 v 1 cs c l 1 1 f eb 2 02 2 platform 3 and part of our codes 4 other key contributions of this paper are summarized as follows 1 insight into the autoregressive data augmentation technique 2 argument for more credible data annotation and 3 investigation of the bi lstm with regards to explainability using ig and error analysis for the t 5 model the rest of the paper is divided as follows section ii provides an overview of prior work in automatic hate speech detection within the field of deep learning the datasets used in this work are described in section iii later section iv explains the methods used in this study lastly the results obtained along with their critical analysis and discussion are reported in section v ii related work the prevalence of hate speech has probably increased with advancements in technology making it easier and faster to spread on social media platforms this has motivated re searchers to put significant efforts into creating datasets and designing intelligent algorithms for hate speech detection linguists in addition have analyzed contents and defined different categories of hate speech data 12 reference 13 introduced the hate speech offensive hso dataset a logistic regression model with l 2 regularization gave the best per formance f 1 score of 0 9 during experimentation with the dataset in their approach they trained the model on the entire dataset but used a one versus rest framework for prediction reference 4 experimented with only the hso dataset using different transformer based architectures their prepro cessing approach involved removing low frequency words from the dataset though this may result in newly introduced terms of hate speech escaping detection their best model distilbert achieved 0 75 f 1 score the transformer by 14 has gained fast adoption in the nlp community since its introduction it is based solely on the attention mechanism and is therefore able to handle long term dependencies 14 15 this advantage of models based on the attention mechanism makes dependency modeling possible regardless of distance in the sequence of input or output therefore the transformer based models have gained much attention in hate speech detection 4 16 17 among the many transformer based models are bert 18 roberta 19 and t 5 20 new datasets have been introduced since hso while some have also been extended this shows the growing awareness of the importance of hate speech detection besides extend ing the olid dataset by 5 21 performed cross domain experiments on hateval 22 after training on two different datasets their reason for extending the olid dataset was to annotate the distinction between messages deemed as explicit containing slur or profanity and implicit having no slur 3 https huggingface co sana ngu hat 5 augmentation https huggingface co sana ngu hat 5 https huggingface co sana ngu hat 5 roberta 4 the t 5 code will be released after a planned competition iii data the following datasets are considered in this work 1 hasoc 2021 this is the third edition of hasoc 10 reference 10 provided another set of tweets dataset with the same tasks as hasoc 2020 the dataset includes the following subtasks 1 task a which is to identify hate speech and offensive text and 2 task b which is a further classification for the previous task to categorize the hateful and offensive content into either hate content hate offensive offn or profane prfn the english dataset consists of 3 843 training samples and 1 281 samples in the test set they gathered the data during the covid 19 wave therefore the text has covid related topics we split 10 of the training set as the dev validation set in this work for evaluation after each epoch 2 olid the dataset of offenseval 2019 task 6 of semeval 2019 is based on olid it contains 14 200 annotated english tweets and encompasses the following three subtasks a offensive language detection b categoriza tion of offensive language as to whether it s targeted at someone or a group or not and c offensive language target identification such that distinction is made among individual group and other entities like an organisation or event 5 olid is derived from twitter crowdwork ers performed its data annotation and the original data split was into training and test sets only similarly with hasoc 2021 we split 10 of the training set as the dev validation set for evaluation after each epoch in this study iv methodology the following subsections describe the different parts of the methodology all experiments were conducted on a shared dgx 1 machine with 8 32 gb nvidia v 100 gpus the server runs on ubuntu 18 and has 80 cpu cores each experiment was conducted 3 times and the average results including standard deviation obtained each experiment was run for 6 epochs but the model checkpoint with the lowest validation loss is saved and used for evaluation of the test set dev set results are also based on the model with the lowest validation loss we use a linear schedule with warm up for the learning rate adjustment for both roberta and t 5 we experimented with only very limited hyperparameters for all the models due to time and resource constraints a models 1 bi lstm lstm is one form of recurrent neural net work rnn 23 rnn is used with sequential data and can capture long term dependencies in text bi directional long short term memory network bi lstm is another improved variant of rnn that comprises of two lstms where the input text flows forward and backwards thereby providing more contextual information and as a result improves the network performance 24 first we used an embedding layer to convert input text to its corresponding word embeddings word and subword embeddings have been shown to improve performance of downstream tasks 25 27 we used glove pre trained word embedding 26 of vector size 100 to capture the semantics of words with the surrounding context then we applied a dropout layer to prevent overfitting we used 2 bi directional layers the dimension of the hidden state is 20 finally a fully connected layer follows the last bi lstm layer to classify the text this model has 1 317 721 parameters 2 cnn cnn was initially used for image processing ref erence 28 shows the effectiveness of the cnn in capturing the local patterns in text on different nlp tasks both the bi lstm and cnn were used as feature based models where for each tweet we computed embeddings using pre trained glove then we used the sequence of embeddings as an input to the model for the cnn the model is composed of 3 convolution layers with 100 filters each the filter size for the first layer is 2 100 100 is the size for the word embeddings the filter size for the second layer is 3 100 and for the third layer it is 4 100 we used a rectified linear unit relu activation function and max pooling after each convolution layer finally we perform dropout on the outputs and fully connected layer for final classification the total trainable parameters for the cnn are 1 386 201 3 roberta roberta is the product of a replication study of bert it makes changes to bert in the following ways 1 training for longer over more data 2 removing the next sentence prediction objective 3 using longer sequences for training and 4 changing the masking pattern dynamically when applied to the training data 19 the base version of the model has 12 layers and 110 m parameters for our study we use roberta base a batch size of 32 initial learning rate of 1 e 5 and maximum sequence length of 256 we restricted the number of tasks to only binary tasks for this model 4 t 5 the t 5 20 follows the originally proposed trans former architecture by 14 it maps input sequence of tokens to embeddings before passing it to the encoder comprising an alternating series of multi head attention layer and feed forward linear layer a different layer normalization is applied where there s no additive bias applied and the activations are only rescaled the decoder includes a standard attention mechanism in addition to each self attention layer causal or autoregressive self attention is used in the decoder for it to attend to past outputs relative position embeddings are used instead of the original sinusoidal position signal since self attention is order independent the t 5 base model has about twice the number of parameters as that of bert base its training method uses teacher forcing i e standard maximum likelihood and a cross entropy loss it was pretrained on 34 b tokens cutting the computational budget considerably when compared to bert or roberta which were trained on 137 b and 2 2 t tokens respectively its base model has 220 m parameters and 12 layers each in the encoder and decoder blocks 20 using this instead of the t 5 small model required more memory and would not fit on a single v 100 gpu for the batch size of 64 hence we lowered the batch size to 16 the task prefix we use is classification for all the tasks as the model takes a hyperparameter called a task prefix b preprocessing preprocessing was carried out on all the data to remove duplicates and unwanted strings or characters for example for olid task c there are nans empty entries in some columns of the labels the nans cause problems for the models increasing the total number of categories and dropping model performance we therefore dropped all such rows during the preprocessing step furthermore tweets are noisy and unstructured which can affect the performance of the models to prepare the text for each model the following preprocessing steps were applied to the datasets urls are excluded uppercase characters are changed to lowercase emails are removed spaces more than 2 characters long are replaced as one space special characters such as hashtags emojis and men tion symbols are removed numbers are removed ip addresses are removed c data augmentation we experimented with two data augmentation techniques 1 a simple token level deletion of the start and end tokens for each sample and 2 autoregressive text generation using the model checkpoint by 7 it was fine tuned on the multiwoz dataset by 29 the autoregressive model is originally a pre trained dialogpt medium model 6 the second technique effectively doubled the training set size in the first technique samples ending or starting with offensive words are kept as they are in the new augmented training data and are therefore dropped when merged with the original to avoid duplicates examples from hasoc 2021 of the original sample and the augmented sample using the second technique are given below bloody hell is that all they can do https t co jqoiow 8 nps bloody hell is that all they can do it is have a great day he voted against migration by voting brexit the wanker https t co 5 t 419 w 0 iq 9 he voted against migration by voting brexit the wanker i m confused are you saying you don t have a single moderate priced hotel in the centre of town with free parking shoot now asshole shoot now asshole booking was successful reference number is n 0 lqra 43 for the first technique we use the list of offensive words available from the online resource at carnegie mellon univer sity 5 to ensure offensive or hate speech tokens are not dropped the document originally contains almost 1 400 english terms that could be found offensive however we removed some words 160 which are nationalities geographical locations or adjectives of emotions we consider that these may not qualify as offensive words examples of such words are african american arab canadian european angry and many non harmful words there are 1 223 words left in the document we used for our experiment the first technique was found to be less effective in improving model performance so we did not report its results in the next section d metrics the f 1 score is the harmonic mean of the precision and recall the relative contribution to the f 1 from precision and recall are equal micro f 1 calculates globally by counting the total true positives false negatives and false positives macro f 1 does not take label imbalance into account unlike weighted f 1 which accounts for label imbalance by finding the labels mean weighted by support each label s true instances 30 6 we report both weighted and macro f 1 scores because of past studies reported metrics v results and discussion table i shows the results obtained across the models and datasets and those from 31 and 10 we report both weighted and macro f 1 scores for the dev and test sets where applicable also the standard deviation sd is reported considering the test set results it is perhaps not surprising that the transformer based models outperform both the bi lstm and cnn models in almost all instances the bi lstm obtains better results than the cnn in the tasks a of both hasoc and olid but the cnn outperforms it with a smaller margin in the tasks b c of olid it also outperforms the bi lstm in task b of hasoc t 5 outperforms roberta on all tasks it has near sota performance in task a of olid given the result in 31 the t 5 augmented data version shows improved scores in both tasks of hasoc when compared with the plain t 5 this makes the result near sota when compared with 10 adequate exploration of hyperparameter tuning may have produced better scores with the models but we did not have sufficient time to do this we observe the performance of the lstm trails behind that of the t 5 indeed the t 5 may have performed even better but for a certain shortcoming text classification in t 5 outputs a prediction of a single word of the target label however in our experiments we found out that the model is more stable with predictions when fine tuned with target 5 cs cmu edu biglou resources 6 scikit learn org stable modules generated sklearn metrics f 1 score html table i model comparison of mean scores for olid hasoc tasks sd standard deviation bold values are best scores for a given task implies no informaton available task weighted f 1 macro f 1 dev sd test sd dev sd test sd lstm olid a 79 59 0 89 83 89 0 57 78 48 1 52 79 49 0 olid b 82 50 1 70 83 46 0 46 76 0 47 32 0 olid c 49 75 3 95 43 82 9 63 35 65 2 81 36 82 0 hasoc 2021 a 78 05 0 85 78 43 0 84 77 99 1 79 77 19 0 hasoc 2021 b 50 65 1 34 52 19 1 95 43 19 2 09 42 25 0 cnn olid a 79 10 0 26 82 47 0 56 77 61 0 39 78 46 0 olid b 82 43 0 49 83 46 0 46 76 0 47 88 0 olid c 47 54 1 36 38 09 3 91 35 65 0 36 85 0 hasoc 2021 a 77 22 0 52 77 63 0 70 74 28 0 58 75 67 0 hasoc 2021 b 55 60 0 61 59 84 0 41 50 41 0 41 54 99 0 roberta olid a 82 70 0 55 84 62 0 80 51 0 76 80 34 0 olid b 82 70 0 13 83 46 0 46 76 0 04 47 02 0 hasoc 2021 a 79 9 0 57 76 2 0 77 77 0 75 74 0 t 5 base olid a 92 90 1 37 85 57 0 92 93 1 42 81 66 0 olid b 99 75 0 43 86 81 0 99 77 0 44 53 78 0 olid c 58 35 1 22 54 99 0 33 09 0 76 43 12 0 hasoc 2021 a 94 60 1 98 82 3 0 94 73 5 26 80 81 0 hasoc 2021 b 65 40 0 82 62 74 0 62 43 6 32 59 21 0 t 5 base augmented data hasoc 2021 a 95 5 3 27 83 0 92 97 2 20 82 54 0 hasoc 2021 b 64 74 3 84 66 85 0 65 56 1 48 62 71 0 31 best scores olid a 82 90 olid b 75 50 olid c 66 10 best scores hasoc 2021 a 83 05 hasoc 2021 b 66 57 labels of numbers explicitly type cast as string otherwise some predictions during fine tuning can be an empty string or expressions from the training set especially in the early epochs of the training this problem is noted as a possibility by 20 though they did not experience this behaviour in their trained models using target labels of numbers explicitly type cast as string greatly reduces this occurrence a error analysis we investigate the errors made by the t 5 model on the hasoc 2021 test set figure 1 reveals the distribution of the predictions in a confusion matrix 33 13 160 of the not class not offensive was misclassified while only 7 52 of the hof hate or offensive class was misclassified this may not be unconnected to the fact that the training set had more hof samples so the model is better at identifying such this is because the training set has 2 251 hof samples and 1 207 not samples improving the model s ability on identifying not samples and the overall performance may involve using a balanced training set or stratifying the categories during training a strong case for better annotation of data is evident when one considers some interesting cases in the hasoc 2021 test set the examples below were annotated with the ground truth of being not offensive not however the model was intelligent enough to predict them as hate or offensive hof this issue has implications for the assessments done during the competitions organized furthermore it is certain the t 5 and other models would have reported better scores if not for the issue raised here fig 1 confusion matrix of t 5 on hasoc 2021 test set table ii examples from hasoc 2021 test set with suspicious labels id text task 1 task 2 60 c 5 d 6 bf 5659 ea 5 e 55 df 0242 miya four creeps into every thought i have what the fuck not none 60 c 5 d 6 bf 5659 ea 5 e 55 defe 58 at least we re being freed from the sham bles of the evangelical but damn y all couldn t just go w the flow y all just had to find jebus through crystals and astrol ogy smdh not none 60 c 5 d 6 bf 5659 ea 5 e 55 defb 73 these terrorists are more dangerous than chinesevirus https t coiazltym 8 st not none 60 c 5 d 6 bf 5659 ea 5 e 55 defe 24 kumarmbayar actor siddharth he is mentally upset why he s not talking about bengalburning and why stupid talks about tejasvi surya not none b explanability xai explainable ai xai is essential for trust and the purpose of this section is to understand why the bi lstm model miss classified specific tweets and what makes the model struggle in making the correct prediction there are many ways to explain nlp models and several researchers have proposed different methods to explain the output of the ml black box 32 33 in this study we use integrated gradient ig ig is a simple but powerful axiomatic attribution originally proposed by 34 it is an attribution method that attributes a model s prediction to the input features attributing the text classification to individual words in this case we have computed the attribution compared to a baseline sequence of tokens by creating a path from the baseline to the input text at each step on that path we aggregate the gradient and finally we calculate the path integral for the aggregated gradients the attribution showed which word of the text input to the model affects the model prediction and how strongly in both figures 2 and 3 the important words are highlighted the words in green contribute to non hate speech those highlighted in red contribute to hate speech figure 3 shows examples of wrongly classified tweets the second tweet has offensive words but it is annotated wrongly as not not offensive the bi lstm however predicts this correctly in the third example the model makes the prediction not mainly because of the hashtag indiacovidcrisis which is strongly associated with non hate in both figures this is very likely because in the training set most of the tweets containing this hashtag are classified as non hateful content in the fourth tweet the most important words to the model for considering the tweet as hateful are shag and blood however the model may have misunderstood the context of the tweet for the last example the model appears completely oblivious to the word bombing and paid attention to other words which ended in its wrong prediction vi conclusion automatically detecting hate speech is a very important task and we show in this study that progress has been made especially with the transformer based architectures we also show that the quality of annotated data is crucial for the success of automatically detecting hate speech and other offensive communication we compared the performance of different sota architectures over multiple tasks in 2 datasets the t 5 pretrained model outperformed the lstm cnn and fig 2 visualize attributions for bi lstm on hasoc 2021 test set correct classification fig 3 visualize attributions for bi lstm on hasoc 2021 test set miss classification roberta architectures models data augmentation provided additional performance gains establishing near sota result on tasks a of the hasoc 2021 datasets while the plain t 5 achieved near sota performance on task a of olid 2019 future direction may include using a voting ensemble method although this is potentially powerful it may suffer due to poor votes from weak models another direction is improving the predictive power of models in cross domain or zero shot inference finally it is also important to study the performance of models on raw data even though preprocessing is an important step in obtaining better performance 35 this is because some offensive messages may contain only disparaging emojis or special characters or other expressions of hate speech and not text references 1 j t nockleby hate speech encyclopedia of the american constitu tion vol 3 no 2 pp 1277 1279 2000 2 a brown what is hate speech part 1 the myth of hate law and philosophy vol 36 no 4 pp 419 468 2017 3 t quintel and c ullrich self regulation of fundamental rights the eu code of conduct on hate speech related initiatives and beyond in fundamental rights protection online edward elgar publishing 2020 4 r mutanga n naicker and o o olugbara hate speech detection in twitter using transformer methods international journal of advanced computer science and applications vol 11 no 01 2020 5 m zampieri s malmasi p nakov s rosenthal n farra and r kumar predicting the type and target of offensive posts in social media in proceedings of naacl 2019 6 y zhang s sun m galley y c chen c brockett x gao j gao j liu and b dolan dialogpt large scale generative pre training for conversational response generation in proceedings of the 58 th annual meeting of the association for computational linguistics system demonstrations 2020 pp 270 278 7 t adewumi n abid m pahlavan r bra nnvall s s sabry f li wicki and m liwicki sm aa prat dialogpt for natural language generation of swedish dialogue by transfer learning arxiv preprint arxiv 2110 06273 2021 8 s javed t p adewumi f s liwicki and m liwicki understanding the role of objectivity in machine learning and research evaluation philosophies vol 6 no 1 p 22 2021 9 t p adewumi f liwicki and m liwicki conversational systems in machine learning from the point of view of the philosophy of science using alime chat and related studies philosophies vol 4 no 3 p 41 2019 10 t mandl s modha g k shahi h madhu s satapara p majumder j schaefer t ranasinghe m zampieri d nandini et al overview of the hasoc subtrack at fire 2021 hate speech and offensive content identification in english and indo aryan languages arxiv preprint arxiv 2112 09301 2021 11 t wolf l debut v sanh j chaumond c delangue a moi p cistac t rault r louf m funtowicz j davison s shleifer p von platen c ma y jernite j plu c xu t le scao s gugger m drame q lhoest and a rush transformers state of the art natural language processing in proceedings of the 2020 conference on empirical methods in natural language processing system demonstrations online association for computational linguistics oct 2020 pp 38 45 online available https aclanthology org 2020 emnlp demos 6 12 s jaki t de smedt m gwo z dz r panchal a rossa and g de pauw online hatred of women in the incels me forum linguis tic analysis and automatic detection journal of language aggression and conflict vol 7 no 2 pp 240 268 2019 13 t davidson d warmsley m macy and i weber automated hate speech detection and the problem of offensive language in proceedings of the international aaai conference on web and social media vol 11 no 1 2017 14 a vaswani n shazeer n parmar j uszkoreit l jones a n gomez kaiser and i polosukhin attention is all you need in advances in neural information processing systems 2017 pp 5998 6008 15 d bahdanau k cho and y bengio neural machine translation by jointly learning to align and translate in international conference on learning representations iclr 2015 2015 online available https arxiv org pdf 1409 0473 pdf 16 b mathew p saha 1 s m yimam c biemann p goyal 1 and a mukherjee 1 hatexplain a benchmark dataset for explainable hate speech detection in proceedings of the 35 th association for the ad vancement of artificial intelligence conference on artificial intelligence 2021 17 g kova cs p alonso and r saini challenges of hate speech detection in social media sn computer science vol 2 no 2 pp 1 15 2021 18 j devlin m w chang k lee and k toutanova bert pre training of deep bidirectional transformers for language understanding in proceedings of the 2019 conference of the north american chapter of the association for computational linguistics human language technologies volume 1 long and short papers minneapolis minnesota association for computational linguistics jun 2019 pp 4171 4186 online available https aclanthology org n 19 1423 19 y liu m ott n goyal j du m joshi d chen o levy m lewis l zettlemoyer and v stoyanov roberta a robustly optimized bert pretraining approach arxiv preprint arxiv 1907 11692 2019 20 c raffel n shazeer a roberts k lee s narang m matena y zhou w li and p j liu exploring the limits of transfer learning with a unified text to text transformer journal of machine learning research vol 21 no 140 pp 1 67 2020 online available http jmlr org papers v 21 20 074 html 21 t caselli v basile j mitrovic i kartoziya and m granitzer i feel offended don t be abusive implicit explicit messages in offensive and abusive language in proceedings of the 12 th language resources and evaluation conference 2020 pp 6193 6202 22 v basile c bosco e fersini n debora v patti f m r pardo p rosso m sanguinetti et al semeval 2019 task 5 multilingual detection of hate speech against immigrants and women in twitter in 13 th international workshop on semantic evaluation association for computational linguistics 2019 pp 54 63 https aclanthology org 2020 emnlp demos 6 https aclanthology org 2020 emnlp demos 6 https arxiv org pdf 1409 0473 pdf https aclanthology org n 19 1423 http jmlr org papers v 21 20 074 html 23 s hochreiter and j schmidhuber long short term memory neural computation vol 9 no 8 pp 1735 1780 1997 24 a graves and j schmidhuber framewise phoneme classification with bidirectional lstm and other neural network architectures neural networks vol 18 no 5 6 pp 602 610 2005 25 t mikolov i sutskever k chen g s corrado and j dean distributed representations of words and phrases and their composi tionality in advances in neural information processing systems 2013 pp 3111 3119 26 j pennington r socher and c d manning glove global vectors for word representation in proceedings of the 2014 conference on empirical methods in natural language processing emnlp 2014 pp 1532 1543 27 t p adewumi f liwicki and m liwicki word 2 vec optimal hyper parameters and their impact on nlp downstream tasks arxiv preprint arxiv 2003 11645 2020 28 y kim convolutional neural networks for sentence classification in proceedings of the 2014 conference on empirical methods in natural language processing emnlp doha qatar association for computational linguistics oct 2014 pp 1746 1751 online available https aclanthology org d 14 1181 29 m eric r goel s paul a sethi s agarwal s gao a kumar a goyal p ku and d hakkani tur multiwoz 2 1 a consolidated multi domain dialogue dataset with state corrections and state tracking baselines in proceedings of the 12 th language resources and evaluation conference marseille france european language resources association may 2020 pp 422 428 online available https www aclweb org anthology 2020 lrec 1 53 30 f pedregosa g varoquaux a gramfort v michel b thirion o grisel m blondel p prettenhofer r weiss v dubourg j vander plas a passos d cournapeau m brucher m perrot and e duch esnay scikit learn machine learning in python journal of machine learning research vol 12 pp 2825 2830 2011 31 m zampieri s malmasi p nakov s rosenthal n farra and r kumar semeval 2019 task 6 identifying and categorizing offensive language in social media offenseval arxiv preprint arxiv 1903 08983 2019 32 m t ribeiro s singh and c guestrin why should i trust you explaining the predictions of any classifier in proceedings of the 22 nd acm sigkdd international conference on knowledge discovery and data mining 2016 pp 1135 1144 33 s m lundberg and s i lee a unified approach to interpreting model predictions in proceedings of the 31 st international conference on neural information processing systems 2017 pp 4768 4777 34 m sundararajan a taly and q yan axiomatic attribution for deep networks in international conference on machine learning pmlr 2017 pp 3319 3328 35 h s obaid s a dheyab and s s sabry the impact of data pre processing techniques and dimensionality reduction on the accu racy of machine learning in 2019 9 th annual information technol ogy electromechanical engineering and microelectronics conference iemecon ieee 2019 pp 279 283 https aclanthology org d 14 1181 https www aclweb org anthology 2020 lrec 1 53 i introduction ii related work iii data iv methodology iv a models iv a 1 bilstm iv a 2 cnn iv a 3 roberta iv a 4 t 5 iv b preprocessing iv c data augmentation iv d metrics v results and discussion v a error analysis v b explanability xai vi conclusion references