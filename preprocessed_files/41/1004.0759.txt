ar x iv 1 00 4 07 59 v 2 m at h n a 1 j un 2 01 4 the mystery of the shape parameter iii lin tian luh department of financial and computational mathematics providence university shalu area taichung city taiwan email ltluh pu edu tw november 2 2018 abstract this is a continuation of our earlier study of the shape parameter c contained in the famous multiquadrics 1 2 c 2 x 2 2 0 and the inverse multiquadrics c 2 x 2 0 in the previous two papers we presented criteria for the optimal choice of c based on the exponential type error bound in this paper a new set of criteria is developed based on the improved exponential type error bound this results in much sharper error estimates when c is chosen appropriately with the same size of fill distance what is important is that the optimal value of c can be successfully predicted without any search when fill distance is of reasonable size making it practically useful the drawback is that the distribution of the data points is not purely scattered however it seems to be harmless key words radial basis function multiquadric shape parameter interpolation 1 introduction we begin with some basic ingredients of our theoretical ground let tn denote the n simplex in r n whose definition can be found in 3 a 1 simplex is a line segment a 2 simplex is a triangle and a 3 simplex is a tetrahedron with four vertices let vi 1 i n 1 be the vertices of tn then any point x tn can be written as a convex combination of the vertices x n 1 i 1 civi n 1 i 1 ci 1 ci 0 the numbers c 1 cn 1 are called the barycentric coordinates of x for any n simplex tn the evenly spaced points of degree l are those points whose barycentric coordinates are of the form k 1 l k 2 l kn 1 l ki nonnegative integers with n 1 i 1 ki l if we let pnl denote the space of polynomials of degree not exceeding l in n variables it is easily seen that the number of evenly spaced points of degree l is exactly n dimpnl n l n also such points form a determining set for pnl by 2 1 http arxiv org abs 1004 0759 v 2 in this paper the interpolation will happen in an n simplex and the set x of centers interpolation points will be evenly spaced points in the n simplex the radial function we use is h x 2 c 2 x 2 2 r 2 n 0 c 0 1 where x is the euclidean norm of x rn is the classical gamma function and c are constants note that this definition is slightly different from the one mentioned in the abstract we adopt 1 because it will greatly simplify its fourier transform and our future work the function h x in 1 is conditionally positive definite c p d of order m max 0 2 where 2 means the smallest integer greater than or equal to 2 further details can be found in 13 17 given data points xj yj j 1 n where x x 1 xn is a subset of rn and yj are real or complex numbers our interpolant will be of the form s x p x n j 1 cjh x xj 2 where p x is a polynomial in pnm 1 to be determined and cj are coefficients to be chosen as is well known in the theory of radial basis functions if x is a determining set for pnm 1 there exists a unique polynomial p x and unique constants c 1 cn satisfying the linear system p xi n j 1 cjh xi xj yi i 1 n 3 n j 1 cjq xj 0 where q ranges over all basis elements of pnm 1 all these can be found in 13 17 1 1 fundamental theory each function h of the form 1 induces a function space ch m called native space whose definition and characterization can be found in 13 14 4 5 8 17 here m max 0 2 also there is a seminorm f h for each f ch m in our theory every interpolated function belongs to the native space before entering the main theorem let us introduce two constants definition 1 1 let n and be as in 1 the numbers and 0 are defined as follows a suppose n 3 let s n 3 2 then i if 0 3 s 3 and 0 2 s 1 s 3 2 ii if 0 1 s 2 2 3 and 0 2 m 2 s 2 m 1 s 2 m 3 2 m 2 where m 2 b suppose n 3 n 1 then 1 and 0 1 2 c suppose n 1 let s n 3 2 then 1 and 0 1 2 m 2 2 m 1 2 m s 3 where m 2 our criteria for the optimal choice of c is based on the following theorem which we take directly from 7 but with a slight modification to make it easier to understand theorem 1 2 let h be as in 1 for any positive number b 0 let c max 2 3 b 0 8 c and 0 1 3 c for any n simplex q of diameter r satisfying 1 3 c r 2 3 c note that 2 3 c b 0 if f ch m f x s x 2 n 7 4 n 1 4 n nc 2 0 3 c 1 f h 4 holds for all x q and 0 0 where s x is defined as in 2 with x 1 xn the evenly spaced points of degree l in q satisfying 1 3 c l 2 3 c the constant n denotes the volume of the unit ball in rn and 0 1 is given by 2 3 1 3 c which only in some cases mildly depends on the dimension n remark this seemingly complicated theorem is in fact not difficult to understand note that the right hand side of 4 approaches zero as tends to zero hence is in spirit like the well known fill distance although not exactly the same also the upper bound in 4 is greatly influenced by the shape parameter c the only thing which is not transparent is the relation between c and f h consequently in order to make it useful in the choice of c we still have to do some work we begin with the following definition definition 1 3 for any 0 the class of band limited functions f in l 2 rn is defined by b f l 2 rn f 0 if where f denotes the fourier transform of f now we cite theorem 1 6 of 9 as a lemma lemma 1 4 let h be as in 1 with 0 any function f in b belongs to ch m and f h m s m n 2 n 1 4 n 1 4 1 n 4 e c 2 c 1 n 4 f l 2 rn where c are as in 1 and s m n is a constant determined by m and n corollary 1 5 let h be as in 1 with 0 if 0 and f b the inequality 4 can be transformed into f x s x 2 2 3 4 n 2 3 n 4 n n 0 3 c m s m n 1 n 4 c 1 n 4 e c 2 1 f l 2 rn 5 in order to handle the case 0 we need the following lemma which is just theorem 1 7 of 9 lemma 1 6 let h be as in 1 with 0 such that n 1 or n 1 any function f in b belongs to ch m and satisfies f h 2 n 1 4 n 1 4 1 n 4 e c 2 c 1 n 4 f l 2 rn 3 corollary 1 7 let h be as in 1 with 0 such that n 1 or n 1 if 0 and f b the inequality 4 can be transformed into f x s x 2 2 3 4 n 3 n 2 4 n n 0 3 c 1 n 4 c 1 n 4 e c 2 1 f l 2 rn 6 note that corollary 1 7 does not cover the frequently seen case 1 n 1 for this we need the following lemma which is just lemma 2 1 of 9 lemma 1 8 let h be as in 1 with 1 n 1 for any 0 if f b then f ch m and f h 2 n 2 1 4 1 k 0 1 1 c f 2 d 1 a 0 1 c f 2 c ec d 1 2 if 1 c where a 0 1 2 3 and f h 2 n 2 1 4 1 k 0 1 1 c f 2 d 1 2 if 1 c corollary 1 9 let h be as in 1 with 1 n 1 if 0 and f b the inequality 4 can be transformed into f x s x 2 2 3 n 4 3 n 1 4 n n 0 3 cc 2 1 a b 1 2 7 where a 1 k 0 1 1 c f 2 d for all c b 2 3 1 c f 2 c ec d if 1 c and b 0 if 1 c 2 criteria of choosing c the results of section 1 provide us with useful theoretical ground for choosing c note that in the right hand side of 5 6 and 7 there is always a main function determined by c let us call it the mn function denoted by mn c as in 10 its graph is called the mn curve then finding the optimal value of c is equivalent to finding the minimum of mn c the range of c should be clarified first in order to satisfy the condition 0 as required by theorem 1 2 for any given b 0 we require that b 0 2 and c 24 then we have three cases as follows case 1 0 nd n 1 let f b and h be defined as in 1 with 0 and n 1 for any given b 0 0 and b 0 2 under the conditions of theorem 1 2 the optimal choice of c in the interval 24 is the number minimizing mn c 8 c 1 n 4 e c 2 2 3 c 24 if 24 c 12 b 0 2 3 b 0 c 1 n 4 e c 2 2 3 b 0 2 if c 12 b 0 reason this follows directly from 5 examples 4 4 6 8 10 c 2 0 2 1 2 2 2 3 2 4 mnhcl mn curve with 0 04 figure 1 here n 2 1 b 0 10 and 1 25 30 35 40 c 0 875 0 880 0 885 0 890 mnhcl mn curve with 0 035 figure 2 here n 2 1 b 0 10 and 1 112 114 116 118 120 122 124 c 0 0003 0 0004 0 0005 0 0006 mnhcl mn curve with 0 03 figure 3 here n 2 1 b 0 10 and 1 5 118 120 122 124 c 1 10 18 1 5 10 18 2 10 18 2 5 10 18 3 10 18 mnhcl mn curve with 0 02 figure 4 here n 2 1 b 0 10 and 1 118 120 122 124 c 5 10 62 1 10 61 1 5 10 61 2 10 61 mnhcl mn curve with 0 01 figure 5 here n 2 1 b 0 10 and 1 for 0 we separate it into two cases case 2 0 and n 1 or n 1 let f b and h be defined as in 1 with 0 and n 1 or n 1 for any given b 0 0 and b 02 under the conditions of theorem 1 2 the optimal choice of c in the interval 24 is the number minimizing mn c 8 c 1 n 4 e c 2 2 3 c 24 if 24 c 12 b 0 2 3 b 0 c 1 n 4 e c 2 2 3 b 0 2 if c 12 b 0 reason this is an immediate result of corollary 1 7 examples 6 35 40 45 50 c 0 112 0 113 0 114 0 115 0 116 0 117 mnhcl mn curve with 0 027 figure 6 here n 3 1 b 0 20 and 1 95 100 105 110 c 0 03670 0 03675 0 03680 0 03685 0 03690 mnhcl mn curve with 0 026 figure 7 here n 3 1 b 0 20 and 1 316 317 318 319 320 321 322 c 0 00035 0 00040 0 00045 mnhcl mn curve with 0 025 figure 8 here n 3 1 b 0 20 and 1 7 315 320 325 330 c 5 10 21 1 10 20 1 5 10 20 2 10 20 2 5 10 20 3 10 20 mnhcl mn curve with 0 02 figure 9 here n 3 1 b 0 20 and 1 315 320 325 330 c 5 10 108 1 10 107 1 5 10 107 2 10 107 mnhcl mn curve with 0 01 figure 10 here n 3 1 b 0 20 and 1 now we begin the case 1 and n 1 case 3 1 and n 1 let f b and h be defined as in 1 with 1 and n 1 for any given b 0 0 and b 0 2 under the conditions of theorem 1 2 the optimal choice of c in the interval 24 is the number minimizing mn c 8 c 1 2 2 3 c 24 m c if 24 c 12 b 0 2 3 b 0 c 2 2 3 b 0 2 m c if c 12 b 0 where m c is defined by m c 1 k 0 1 if c 1 1 k 0 1 2 3 c ec 1 2 if c 1 k 0 being the modified bessel function 8 reason note that in 7 a b 1 2 can be further treated as follows for 0 c 1 we have 1 c and a 1 k 0 1 1 c f 2 d 1 k 0 1 f 2 d 1 k 0 1 f 2 l 2 rn because f b therefore a b 1 2 a 1 k 0 1 f l 2 rn if 0 c 1 now if 1 c a b 1 2 1 k 0 1 1 c f 2 d 2 3 1 c f 2 c ec d 1 2 1 k 0 1 f 2 d 2 3 f 2 c ec d 1 2 1 k 0 1 f 2 l 2 rn 2 3 c ec f 2 l 2 rn 1 2 1 k 0 1 2 3 c ec 1 2 f l 2 rn our conclusion thus follows examples 8 10 12 14 c 2 10 2 15 2 20 2 25 2 30 mnhcl mn curve with 0 04 figure 11 here n 1 1 b 0 5 and 1 9 42 44 46 48 50 c 0 661 0 662 0 663 0 664 0 665 mnhcl mn curve with 0 035 figure 12 here n 1 1 b 0 5 and 1 58 60 62 64 c 0 02 0 03 0 04 0 05 0 06 mnhcl mn curve with 0 03 figure 13 here n 1 1 b 0 5 and 1 58 60 62 64 c 1 10 9 1 5 10 9 2 10 9 2 5 10 9 3 10 9 mnhcl mn curve with 0 02 figure 14 here n 1 1 b 0 5 and 1 10 58 60 62 64 c 5 10 31 1 10 30 1 5 10 30 2 10 30 mnhcl mn curve with 0 01 figure 15 here n 1 1 b 0 5 and 1 note that the optimal c increases rapidly as becomes small 3 experiment in this section we test case 1 of the preceding section and let n 2 1 b 0 10 1 in order to make it more useful and understandable we replace the function h x defined in section 1 by the more commonly used function h x c 2 x 2 12 x r 2 the interpolation occurs in a regular triangle with side length r as required by theorem 1 2 1 3 c r 2 3 c we choose to let r 2 3 c so that the centers interpolation points will not be too close to each other by the very definition of c c depends on c therefore as c changes the diameter r of the triangle also changes let the original vertices be v 1 1 0 v 2 1 0 and v 3 0 3 then the triangle we adopt has vertices w 1 r 2 v 1 w 2 r 2 v 2 and w 3 r 2 v 3 as a result the side length will be c 12 if c 120 and 10 if c 120 the centers are evenly spaced ponits of degree l in the triangle theorem 1 2 requires that 1 3 c l 2 3 c the smaller l is the less data points will be used as can be seen in the beginning of section 1 hence we choose l 1 3 c once the centers are arranged we let the test points be the evenly spaced points in the same triangle with degree l l 1 we adopt the root mean square error to evaluate the distance between the approximated and approximating functions at the test points let f and s denote the approximated and approximating functions respectively if the test points are z 1 zn then rms n i 1 f zi s zi 2 n is its root mean square error we denote the number of data points and the number of test points by nd and nt respectively thus if the centers are evenly spaced points of degree l then nd l 2 l 1 2 and nt l 3 l 2 2 respectively there is a crucial logical problem in using our approach note that in our core theorem theo rem 1 2 the function h and hence the shape parameter c appears first theoretically one should fix c and then choose the other parameters including which is in spirit like the well known fill 11 distance however since the optimal c cannot be known in advance we choose the other parameters first then choose the optimal c according to the mn curve once c is chosen we begin to design the simplex triangle in the r 2 case and the interpolation points centers in the simplex according to theorem 1 2 this is just a trick for avoiding logical troubles in this experiment the approximated function is f x y sin x 2 x 2 sin y 2 y 2 where we let sin z z 1 if z 0 the map f can be easily checked to belong to b defined in definition 1 3 we emphasize that our approach for choosing c optimally is reliable only when the parameter is small enough this phenomenon can also be seen in the experiment of 12 note that in figures 1 5 the value c minimizing the mn curve moves rapidly to 120 and remains there when is small it strongly suggests that one should choose c 120 as the optimal value when is small enough we test 0 225 0 2 0 175 0 15 0 125 0 1 0 085 and 0 075 in the following tables we use cond nd and nt to denote the condition number of the interpolation matrix the number of data points used and the number of test points respectively the condition number is the traditional one i e the infinity norm condition number in virtue of the arbitrarily precise computer software mathematica the problem of ill conditioning is resolved by adopting enough effective digits to the right of the decimal point for each calculation when the condition number is very large at the cost of spending considerable computer time table 1 0 225 c 80 100 110 115 117 118 rms 2 0 10 13 8 8 10 16 6 1 10 17 3 9 10 17 6 0 10 17 7 4 10 17 cond 7 4 1053 1 0 1068 1 3 1075 4 1 1078 4 1 1078 4 1 1078 nd 136 210 253 276 276 276 nt 153 231 276 300 300 300 c 119 120 130 140 160 rms 3 5 10 18 4 3 10 18 4 8 10 18 5 3 10 18 6 0 10 18 cond 1 4 1082 1 4 1082 5 5 1083 1 7 1085 7 8 1087 nd 300 300 300 300 300 nt 325 325 325 325 325 12 table 2 0 2 c 80 100 110 115 116 117 rms 1 5 10 15 7 8 10 18 5 8 10 19 3 6 10 19 1 8 10 20 2 2 10 20 cond 8 5 1060 1 3 1075 1 4 1082 5 0 1085 1 6 1089 1 6 1089 nd 171 253 300 325 351 351 nt 190 276 325 351 378 378 c 118 119 120 130 140 160 rms 2 8 10 20 3 4 10 20 4 2 10 20 5 0 10 20 5 6 10 20 6 7 10 20 cond 1 6 1089 1 6 1089 1 6 1089 8 8 1090 3 6 1092 2 8 1095 nd 351 351 351 351 351 351 nt 378 378 378 378 378 378 table 3 0 175 c 80 100 110 116 117 118 rms 6 1 10 19 6 8 10 21 2 9 10 23 2 5 10 23 3 3 10 23 1 5 10 24 cond 3 5 1071 5 0 1085 1 9 1096 6 2 1099 6 2 1099 2 1 10103 nd 231 325 406 435 435 465 nt 253 351 435 465 465 496 c 119 120 130 140 160 rms 1 9 10 24 2 5 10 24 3 3 10 24 4 1 10 24 5 5 10 24 cond 2 1 10103 2 1 10103 2 2 10105 1 6 10107 3 7 10110 nd 465 465 465 465 465 nt 496 496 496 496 496 13 table 4 0 15 c 80 100 110 118 119 120 rms 1 3 10 22 1 3 10 25 6 7 10 28 3 8 10 29 6 6 10 30 9 6 10 30 cond 1 4 1082 6 2 1099 2 4 10110 2 7 10117 8 8 10120 8 8 10120 nd 300 435 528 595 630 630 nt 325 465 561 630 666 666 c 121 122 130 140 160 rms 1 0 10 29 1 1 10 29 1 8 10 29 2 9 10 29 5 3 10 29 cond 1 5 10121 2 7 10121 2 0 10123 3 1 10125 2 7 10129 nd 630 630 630 630 630 nt 666 666 666 666 666 table 5 0 125 c 80 100 110 114 116 117 rms 4 2 10 28 7 1 10 34 8 3 10 36 2 8 10 36 2 5 10 37 4 3 10 37 cond 1 9 1096 8 8 10120 3 2 10131 1 1 10135 3 7 10138 3 7 10138 nd 406 630 741 780 820 820 nt 435 666 780 820 861 861 c 118 119 120 130 140 160 rms 2 4 10 38 4 8 10 38 9 1 10 38 5 1 10 37 1 4 10 36 4 4 10 36 cond 1 2 10142 1 2 10142 1 2 10142 7 1 10144 2 7 10147 1 2 10152 nd 861 861 861 861 861 861 nt 903 903 903 903 903 903 14 table 6 0 1 c 80 100 110 116 117 118 rms 3 9 10 28 7 2 10 45 2 8 10 48 3 0 10 51 5 2 10 51 1 4 10 52 cond 8 8 10120 1 3 10149 1 5 10163 5 5 10173 5 5 10173 1 8 10177 nd 630 946 1128 1275 1275 1326 nt 666 990 1176 1326 1326 1378 c 119 120 130 140 160 rms 4 4 10 52 9 9 10 52 7 7 10 52 7 7 10 51 2 6 10 49 cond 1 8 10177 1 8 10177 5 4 10180 8 9 10183 5 6 10189 nd 1326 1326 1326 1326 1326 nt 1378 1378 1378 1378 1378 note that when the parameter decreases the condition numbers get large for 0 1 and c 120 we adopted 200 effective digits to the right of the decimal point for each calculation and successfully overcame the problem of ill conditioning the other cases were handled in a similar way as we emphasized our approach of choosing c optimally is reliable only when is small enough we of course want to decrease further until the optimal c coincides with the theoretical value completely however limited by the speed of the computer we have to reduce the scale of our experiment for 0 1 in the following two tables we only test five values of c for each table 7 0 085 c 110 118 119 120 130 rms 1 6 10 59 1 7 10 63 2 6 10 65 1 4 10 64 1 6 10 64 cond 2 2 10191 2 4 10205 8 0 10208 8 0 10208 1 0 10213 nd 1540 1770 1830 1830 1830 nt 1596 1830 1891 1891 1891 15 table 8 0 075 c 110 115 118 119 120 rms 2 5 10 70 5 6 10 72 5 4 10 74 3 0 10 75 4 2 10 75 cond 2 8 10219 3 0 10226 3 2 10233 1 0 10237 1 0 10237 nd 2016 2145 2278 2346 2346 nt 2080 2211 2346 2415 2415 it can be seen that in these tables the optimal c tends to be moving to the theoretical value 120 as decreases among them the case 0 075 is most important because is smaller to our regret there is still a very small gap between the experimentally optimal value and the theoretically predicted one we have reason to believe that if is further decreased they will coincide completely as can be seen in the experiment of 12 in this paper we cannot do so because it takes too much computer time even for 0 075 it requires two and half hours to complete only one command in order to test one c at least five hours must be spent if is further decreased maybe 30 hours will be needed to test only one value of c as a whole these results are quite satisfactory and our approach of choosing the shape parameter can be trusted 4 summary both 9 and this paper deal with the interpolation of band limited functions in 9 the range of c is 12 ne 2 n n n m 1 where is the well known fill distance and n s are integers which grow very fast as the dimension n increases in order to make the left endpoint of the closed open interval small enough often must be very small the consequence is that a huge number of data points will be involved making the criteria of choosing c only theoretically valuable especially for n 2 now we have greatly improved this restriction and replaced the left endpoint by 24 which is much smaller in fact we can further enlarge the range of c and allow c 0 however the interpolation domain the simplex required by our main theorem will become very small and is not worth doing experiments show that our criteria apply even for c less than 24 we just cannot prove it consequently the restriction c 24 does not seem to be a big problem what is important is that our criteria of choosing c are based on the error bound presented in theorem 1 2 after all error bound and error are not exactly the same what we can control is error bound not error maybe the choice of c is also influenced by the closeness of the shapes of the approximated and the approximating functions if the two surfaces match each other well the root mean square error will be small even when the error bound is not small in any case empirical results show that our criteria are very reliable even if there is a gap between the experimental and theoretical values the gap is very small as for the function space although it is required that the approximated function should belong to the b space our approach in fact applies to any function in the sobolev space as shown in 16 18 any function in the sobolev space can be interpolated by a b function with a good error bound 16 then any b function can be interpolated by mq multiquadrics or imq inverse multiquadrics also with a good error bound thus the function in the sobolev space can be interpolated by mq and imq with the same set of data points the b function plays only an intermediate role and need not be found explicitly one needs only to know its existence the error estimate can be handled by triangle inequality in other words when dealing with functions in the sobolev space we already know how to choose the shape parameter contained in mq and imq this is particularly meaningful in solving partial differential equations with mq and imq because a lot of important pde s have solutions in the sobolev space references 1 abramowitz and segun a handbook of mathematical functions dover publications inc new york 1970 2 l p bos bounding the lebesgue function for lagrange interpolation in a simplex j approx theory 38 1983 43 59 3 w fleming functions of several variables second edition springer verlag 1977 4 l t luh the equivalence theory of native spaces approx theory appl 2001 17 1 76 96 5 l t luh the embedding theory of native spaces approx theory appl 2001 17 4 90 104 6 l t luh on the high level error bound for multiquadric and inverse multiquadric interpola tions arxiv math 0601158 2006 7 l t luh an improved error bound for multiquadric interpolation inter j numeric methods appl vol 1 no 2 pp 101 120 2009 8 l t luh on wu and schaback s error bound inter j numeric methods appl vol 1 no 2 pp 155 174 2009 9 l t luh the mystery of the shape parameter arxiv 1001 5087 2010 10 l t luh the mystery of the shape parameter ii arxiv 1002 2082 2010 11 l t luh the mystery of the shape parameter iv arxiv 1004 0761 2010 12 l t luh the shape parameter in the shifted surface spline iii eng anal boundary elem 2012 36 1604 1617 13 w r madych and s a nelson multivariate interpolation and conditionally positive definite function approx theory appl 4 no 4 1988 77 89 14 w r madych and s a nelson multivariate interpolation and conditionally positive definite function ii math comp 54 1990 211 230 15 w r madych miscellaneous error bounds for multiquadric and related interpolators com puters math applic vol 24 no 12 pp 121 138 1992 16 narcowich f j ward j d wendland h sobolev error estimates and a berstein inequality for scattered data interpolation via radial basis functions constr approx 2006 24 175 186 17 http arxiv org abs math 0601158 http arxiv org abs 1001 5087 http arxiv org abs 1002 2082 http arxiv org abs 1004 0761 17 h wendland scattered data approximation cambridge university press 2005 18 wendland h multiscale analysis in sobolev spaces on bounded domains numer math 116 pp 493 517 2010 18 1 introduction 1 1 fundamental theory 2 criteria of choosing c 3 experiment 4 summary