psd figures wn 0 psd eps ar x iv 1 90 8 11 36 4 v 1 st at o t 6 a ug 2 01 9 introduction to geodetic time series analysis m s bos j p montillet s d p williams r m s fernandes abstract the previous chapter gave various examples of geophysical time series and the various trajectory models that can be fitted to them in this chapter we will focus on how the parameters of the trajectory model can be estimated it is meant to give researchers new to this topic an easy intro duction to the theory with references to key books and articles where more details can be found in addition we hope that it refreshes some of the details for the more experienced readers we pay special attention to the modelling of the noise which has received much attention in the literature in the last years and highlight some of the numerical aspects the subsequent chapters will go deeper into the theory explore different aspects and describe the state of art of this area of research 1 gaussian noise and the likelihood function geodetic time series consist out of a set observations at various epochs these observations stored in a vector y are not perfect but contain noise which can be described as a set of multivariate random variables let us define this m s bos instituto dom luiz universidade da beira interior portugal e mail machiel segal ubi pt j p montillet space and earth geodetic analysis laboratory universidade da beira interior portugal institute of earth surface dynamics university of lausanne lausanne switzerland e mail jpmontillet segal ubi pt s d p williams national oceanographic centre liverpool united kingdom e mail sdwil noc ac uk r m s fernandes instituto dom luiz universidade da beira interior portugal e mail rui segal ubi pt 1 http arxiv org abs 1908 11364 v 1 machiel segal ubi pt jpmontillet segal ubi pt sdwil noc ac uk rui segal ubi pt 2 filtering gps time series and common mode error analysis as the vector w w 1 w 2 w 3 wn where each wi is a random variable if f w is the associated probability density function then the first moment 1 the mean of the noise is defined as casella and berger 2001 1 e w wf w dw 1 where e is the expectation operator it assigns to each possible value of random variable w a weight f w over an infinitely small interval of dw sums each of them to obtain the mean expected value e w the second moment 2 is defined in a similar manner 2 e w 2 w 2 f w dw w 2 df w 2 the last term f is the cumulative distribution the second moment is better known as the variance since we have n random variables we can compute variances for e wiwj where both i and j range from 1 to n the result is called the covariance matrix in this book the probability density function f w is assumed to be a gaussian f w 1 1 2 2 exp w 1 2 2 2 3 where is the standard deviation the square root of the variance of ran dom variable w this function is very well known and is shown in figure 1 for zero 1 the standard error is defined as the 1 interval and contains on average 68 of the observed values of w the reason why it is so often encountered in observations is that the central limit theorem states that the sum of various continuous probability distributions always tends to the gaussian one an additional property of the gaussian probability density function is that all its moments higher than two 3 4 are zero therefore the mean and the covariance matrix provide a complete description of the stochastic prop erties actually we will always assume that the mean of the noise is zero and therefore only need the covariance matrix the term in front of the exponen tial is needed to ensure that the integral of f x from to produces 1 that is the total probability of observing a value between these limits is 1 as it should be we have not one but several observations with noise in our time series the probability density function of the multi variate noise is f w c 1 2 n det c exp 1 2 w t c 1 w 4 introduction to geodetic time series analysis 3 0 0 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 4 3 2 1 0 1 2 3 4 f w w 68 95 99 7 fig 1 the gaussian probability density function together with the 1 2 and 3 intervals we assumed that the covariance matrix c is known the expression f w c should be read as the probability density function f for variable w for given and fixed covariance matrix c next we assume that our obser vations can be described by our model g x t where x are the parameters of the model and t the time the observations are the sum of our model plus the noise y g x t w or w y g x t 5 the noise w is described by our gaussian probability density function with zero mean and covariance matrix c the probability that we obtained the actual values of our observations is f y x c 1 2 n det c exp 1 2 y g x t t c 1 y g x t 6 however we don t know the true values of x or the covariance matrix c we only know the observations consequently we need to rephrase our prob lem as follows what values of x and c would produce the largest probability that we observe y thus we are maximising f x c y which we call the likelihood function l furthermore we normally work with the logarithm of it which is called the log likelihood ln l 1 2 n ln 2 ln det c y g x t t c 1 y g x t 7 4 filtering gps time series and common mode error analysis we need to find value of x to maximise this function and the method is therefore called maximum likelihood estimation mle the change from f y x c to f x c y is subtle assume that the covariance matrix c also depends on parameters that we store in vector x in this way we can simplify the expression f y x c to f y x bayes theorem expressed in terms of probability distributions gives us f x y f y x f x f y 8 where f y and f x are our prior probability density function for the ob servations y and parameters x respectively these represent our knowledge about what observations and parameter values we expect before the mea surements were made if we don t prefer any particular values these prior probability density functions can be constants and they will have no influ ence on the maximising of the likelihood function f x y l another subtlety is that we changed from random noise and fixed pa rameter values of the trajectory model f y x to fixed noise and random parameters of the trajectory model f x y if the trajectory model is for ex ample a linear tectonic motion then this is a deterministic fixed velocity not a random one however one should interpret f x y as our degree of trust our confidence that the estimated parameters x are correct see also koch 1990 2007 and jaynes 2003 the last one is particularly recommended to learn more about bayesian statistics 2 linear models so far we simply defined our trajectory model as g x t an important class of models that are fitted to the observations are linear models these are defined as g x t x 1 g 1 t x 2 g 2 t xmgm t 9 where x 1 to xm are assumed to be constants we can rewrite this in matrix form as follows g x t g 1 t 1 g 2 t 1 gm t 1 g 1 t 2 g 2 t 2 gm t 2 g 1 tn g 2 tn gm tn x 1 xm ax 10 matrix a is called the design matrix from chapter 1 we know that tec tonic motion or sea level rise can be modelled by a linear trend i e the standar linear trajectory model thus g 1 t is a constant and g 2 t a lin ear trend this can be extended to a higher degree polynomial to model introduction to geodetic time series analysis 5 acceleration for example next in many cases an annual and semi annual signal is included as well a periodic signal can be described by its amplitude bk and its phase lag k with respect to some reference epoch g t bk cos kt k bk cos cos kt bk sin k sin kt ck cos kt sk sin kt 11 since the unknown phase lag k makes the function non linear one must almost always estimate the amplitudes ck and sk see chapter 1 these pa rameters are linear with functions cos and sin and derive from these values the amplitude bk and phase lag k other models that can be included in g t are offsets and post seismic relaxation functions see chapter 1 an example of a combination of all these models into a single trajectory model is shown in figure 2 80 70 60 50 40 30 20 10 0 10 20 30 2000 2002 2004 2006 2008 2010 2012 2014 2016 2018 d is p la ce m e n t m m years seasonal exponential or logarithmic decay velocity 2 instantaneous displacement velocity 1 signal offsets fig 2 sketch of a trajectory model containing common phenomena for linear models the log likelihood can be rewritten as ln l 1 2 n ln 2 ln det c y ax t c 1 y ax 12 this function must be maximised assuming that the covariance matrix is known then it is a constant and does not influence finding the maximum next the term y ax represent the observations minus the fitted model and are normally called the residuals r it is desirable to choosing the pa rameters x in such a way to make these residuals small the last term can 6 filtering gps time series and common mode error analysis be written as rt c 1 r and it is a quadratic function weighted by the inverse of matrix c now let us compute the derivative of ln l d ln l dx at c 1 y at c 1 ax 13 the minimum of ln l occurs when this derivative is zero thus a t c 1 ax at c 1 y x a t c 1 a 1 a t c 1 y 14 this is the celebrated weighted least squares equation to estimate the pa rameters x most derivations of this equation focus on the minimisation of the quadratic cost function however here we highlight the fact that for observations that contain gaussian multivariate noise the weighted least squares estimator is a maximum likelihood estimator mle from eq 14 it can also be deduced that vector x like the observation vector y follows a multi variate gaussian probability density function the variance of the estimated parameters estimated is var x var a t c 1 a 1 a t c 1 y a t c 1 a 1 a t c 1 var y c 1 a a t c 1 a 1 a t c 1 a 1 a t c 1 c c 1 a a t c 1 a 1 a t c 1 a 1 15 next define the following matrix i x i x e 2 x 2 ln l 2 x 2 ln f f dx 16 it is called the fisher information matrix as in eqs 1 and 2 we use the expectation operator e remember that we simply called f our likelihood l but these are the same we already used the fact that the log likelihood as function of x is horizontal at the maximum value let us call this x the second derivative is related to the curvature of the log likelihood function the sharper the peak near its maximum the more accurate we can estimate the parameters x and therefore the smaller their variance will be next it can be shown that the following inequality holds 1 x x 2 f dx ln f x 2 f dx 17 introduction to geodetic time series analysis 7 the first integral represents the variance of x see eq 2 the second one after some rewriting is equal to the fisher information matrix this gives us for any unbiased estimator the following crame r rao lower bound kay 1993 var x 1 i x 18 eq 18 predicts the minimum variance of the estimated parameters x for given probability density function f and its relation with the parameters x that we want to estimate if we us eq 13 to compute the second derivative of the log likelihood then we obtain i x at c 1 a 19 comparing this with eq 15 one can see that for the case of the weighted least square estimator the crame r rao lower bound is achieved therefore it is an optimal estimator because we also need to estimate the parameters of the covariance matrix c we shall use mle which approximates this lower bound for increasing number of observations therefore one can be sure that out of all existing estimation methods none of them will produce a more accurate result than mle only equal or worse for more details see kay 1993 3 models for the covariance matrix least squares and maximum likelihood estimation are well known techniques in various branches of science in recent years much attention has been paid by geodesists to the structure of the covariance matrix if there was no re lation between each noise value then these would be independent random variables and the covariance matrix c would be zero except for values on its diagonal however in almost all geodetical time series these are depen dent random variables in statistics this is called temporal correlation and we should consider a full covariance matrix c 211 2 12 2 1 n 221 2 22 2 2 n 2 n 1 2 nn 1 2 nn 20 where 212 is the covariance between random variables w 1 and w 2 if we assume that the properties of the noise are constant over time then we have the same covariance between w 2 and w 3 w 3 and w 4 and all other correlations with 1 time step separation as a result 212 2 23 2 n 1 n are all equal a simple estimator for it is 8 filtering gps time series and common mode error analysis 212 2 23 2 n 1 n 1 n 1 n 1 i 1 wiwi 1 21 this is an approximation of the formula to compute the second moment see eq 2 and it called the empirical or sample covariance matrix there fore one could try the following iterate scheme fit the linear model to the observations some a priori covariance matrix compute the residuals and use this to estimate a more realistic covariance matrix using eq 20 and fit again the linear model to the observations until all estimated parameters have converged the previous chapter demonstrated that one of the purpose of the trajec tory models is to estimate the linear or secular trend for time series longer than 2 years the uncertainty of this trend depends mainly on the noise at the lowest observed periods bos et al 2008 he et al 2019 however the empirical covariance matrix estimation of eq 20 does not result in an ac curate estimate of the noise at long periods because only a few observations are used in the computation in fact only the first and last observation are used to compute the variance of the noise at the longest observed period i e 21 n this problem has been solved by defining a model of the noise and es timating the parameters of this noise model the estimation of the noise model parameters can be achieved using the log likelihood with a numerical maximisation scheme but other methods exist such as least squares variance component estimation see chapter 6 the development of a good noise model started with the paper of hurst 1957 who discovered that the cumulative water flow of the nile river de pended on the previous years the influence of the previous years decayed according a power law this inspired mandelbrot and van ness 1968 to de fine the fractional brownian motion model which includes both the power law and fractional gaussian noises see also beran 1994 and graves et al 2017 while this research was well known in hydrology and in econometry it was not until the publication by agnew 1992 who demonstrated that most geophysical time series exhibit power law noise behaviour that this type of noise modelling started to be applied to geodetic time series in hind sight press 1978 had already demonstrated similar results but this work has not received much attention in geodesy that the noise in gnss time series also falls in this category was demonstrated by johnson and agnew 1995 power law noise has the property that the power spectral density of the noise follows a power law curve on a log log plot it converts into a straight line the equation for power law noise is p f p 0 f fs 22 where f is the frequency p 0 is a constant fs the sampling frequency and the exponent is called the spectral index introduction to geodetic time series analysis 9 granger 1980 granger and joyeux 1980 and hosking 1981 demon strated that power law noise can be achieved using fractional differencing of gaussian noise 1 b 2 v w 23 where b is the backward shift operator bvi vi 1 and v a vector with independent and identically distributed iid gaussian noise hosking and granger used the parameter d for the fraction 2 which is more concise when one focusses on the fractional differencing aspect it has been adopted by people studying general statistics sowell 1992 beran 1995 however in geodesy the spectral index is used in the equations hosking s definition of the fractional differencing is 1 b 2 i 0 2 i b i 1 2 b 1 2 2 1 2 b 2 i 0 hi 24 the coefficients hi can be viewed as a filter that is applied to the indepen dent white noise these coefficients can be conveniently computed using the following recurrence relation kasdin 1995 h 0 1 hi i 2 1 hi 1 i for i 0 25 one can see that for increasing i the fraction i 2 1 i is slightly less than 1 thus the coefficients hi only decrease very slowly to zero this implies that the current noise value wi depends on many previous values of v in other words the noise has a long memory actually the model of fractional gaus sian noise defined by hosking 1981 is the basic definition of the general class of processes called auto regressive integrated moving average taqqu et al 1995 if we ignore the integrated part then we obtain the auto regres sive moving average arma model box et al 2015 brockwell and davis 2002 which are short memory noise models the original definition of the arima processes only considers the value of the power 2 in eq 24 as an integer value granger and joyeux 1980 further extended the definition to a class of fractionally integrated models called farima or arfima where is a floating value generally in the range of 1 i 1 montillet and yu 2015 discussed the application of the arma and farima models in mod elling gnss daily position time series and concluded that the farima is only suitable in the presence of a large amplitude coloured noise capable of generating a distribution with large tails i e random walk aggregations 10 filtering gps time series and common mode error analysis equation 25 also shows that when the spectral index 0 then all coefficients hi are zero except for h 0 this implies that there is no temporal correlation between the noise values in addition eq 22 shows that this corresponds to a horizontal line in the power spectral density domain using the analogy of the visible light spectrum this situation of equal power at all frequencies produces white light and it is therefore called white noise for 6 0 some values have received a specific colour for example 1 is known as pink noise another name is flicker noise which seems to have originated in the study of noise of electronic devices red noise is defined as power law noise with 2 and produces hi 1 for all values of i thus this noise is a simple sum of all its previous values plus a new random step and is better known as random walk mandelbrot 1999 however note that the spectral index does not need to be an integer value williams 2003 one normally assumes that vi 0 for i 0 with this assumption the unit covariance between wk and wl with l k is c wk wl k i 0 hihi l k 26 since 0 produces an identity matrix the associated white noise covari ance matrix is represented by unit matrix i the general power law covariance matrix is represented by the matrix j the sum of white and power law noise can be written as williams 2003 c 2 plj 2 wi 27 where pl and w are the noise amplitudes it is a widely used combination of noise models to describe the noise in gnss time series williams et al 2004 besides the parameters of the linear model i e the trajectory model maximum likelihood estimation can be used to also estimate the parameters pl and w this approach has been implemented various software packages such as cats williams 2008 est noise langbein 2010 and hector bos et al 2013 in recent years one also has detected random walk noise in the time series and this type has been included as well in the covariance matrix langbein 2012 dmitrieva et al 2015 we assumed that vi 0 for i 0 which corresponds to no noise before the first observation this is an important assumption that has been introduced for a practical reason for a spectral index smaller than 1 the noise be comes non stationary that is the variance of the noise increases over time if it is assumed that the noise was always present then the variance would be infinite most gnss time series contain flicker noise which is just non stationary using the assumption of zero noise before the first observation the covariance matrix still increases over time but remains finite introduction to geodetic time series analysis 11 for some geodetic time series such as tide gauge observations the power law behaviour in the frequency domain shows a flattening below some thresh old frequency to model such behaviour langbein 2004 introduced the generalised gauss markov ggm noise model which is defined as 1 b 2 v w 28 the only new parameter is the associated recurrence relation to com pute the new coefficients hi is h 0 1 hi i 2 1 hi 1 i for i 0 29 if 1 then we obtain again our pure power law noise model for any value of slightly smaller than one this term helps to shorten the memory of noise which makes it stationary that is the temporal correlation decreases faster to zero for increasing lag between the noise values the power spectrum of this noise model shows a flattening below some threshold frequency which guarantees that the variance is finite and that the noise is stationary finally it is even possible to generalise this a bit more to a fractionally integrated generalised gauss markov model figgm 1 b 1 2 1 b 2 2 v w 1 b 1 2 u w 30 this is just a combination of the two previous models one can first apply the power law filter to v to obtain u and afterwards apply the ggm filter on it to obtain w other models will be discussed in this book such as arma box et al 2015 brockwell and davis 2002 but the power law ggm and figgm capture nicely the long memory property that is present in most geodetic time series a list of all these noise models and their abbreviation is given in table 1 table 1 common abbreviation of noise models noise model abbreviation auto regressive moving average arma auto regressive fractionally integrated moving average arfima or farima flicker noise fn fractionally integrated ggm figgm generalised gauss markov ggm power law pl random walk rw white noise wn 12 filtering gps time series and common mode error analysis 4 power spectral density figure 3 shows examples of white flicker and random walk noise for a dis placement time series one can see that the white noise varies around a stable mean while the random walk is clearly non stationary and deviates away from its initial position 40 30 20 10 0 10 20 2000 2001 2002 2003 2004 2005 2006 2007 2008 2009 m m years white noise flicker noise random walk noise fig 3 examples of white flicker and random walk noise in the previous section we mentioned that power law noise has a specific curve in the power spectral density plots methods to compute those plots are given by buttkus 2000 a simple but effective method is based on the fourier transform that states that each time series with finite variance can be written as a sum of periodic signals yn 1 n n 2 k n 2 1 yk ei 2 kn n for n 0 n 1 31 actually this is called the inverse discrete fourier transform yk are com plex numbers denoting the amplitude and phase of the periodic signal with period k nt where t is the observation span an attentive reader will remember that flicker and random walk noise are non stationary while the fourier transform requires time series with finite variance however we never have infinitely long time series which guarantees the variance remains within some limit the coefficients can be computed as follows introduction to geodetic time series analysis 13 yk n 1 n 0 yn e i 2 kn n for k n 2 1 n 2 32 the transformation to the frequency domain provides insight which pe riodic signals are present in the signal and in our case insight about the noise amplitude at the various frequencies this is a classic topic and more details can be found in the books by bracewell 1978 and buttkus 2000 the one sided power spectral density sk is defined as s 0 y 0 2 fs sn 2 yn 2 2 fs sk 2 yk 2 fs for k 1 n 2 1 33 the frequency fk associated to each sk is fk kfs n for k 0 n 2 34 the highest frequency is half the sampling frequency fs 2 which is called the nyquist frequency the power spectral density psd computed in this manner is called a periodogram there are many refinements such as applying window functions and cutting the time series in segments and averaging the resulting set of psd s however a detail that normally receives little attention is that the fourier transform produces positive and negative frequencies time only increases and there are no negative frequencies therefore one always uses the one sided power spectral density another useful relation is that of parseval buttkus 2000 1 n n 1 n 0 yn 2 1 n 2 n 2 k n 2 1 yk 2 35 thus the variance of the noise should be equal to the sum of all sk values and an extra fs n 2 scale the one sided power spectral density of the three time series of figure 3 are plotted in figure 4 it shows that power law noise indeed follows a straight line in the power spectral density plots if a log log scale is used in fact the properties of the power law noise can also be estimated by fitting a line to the power spectral density estimates mao et al 1999 caporali 2003 the psd of power law noise generated by fractionally differenced gaussian noise is kasdin 1995 14 filtering gps time series and common mode error analysis random walk noise 10 5 10 4 10 3 10 2 10 1 100 101 100 101 102 frequency cpy 10 4 10 3 10 2 10 1 100 101 100 101 102 frequency cpy 10 3 10 2 10 1 100 101 102 p o w e r m m 2 c p y frequency cpy 1 2 white noise flicker noise 0 fig 4 one sided power spectral density for white flicker and random walk noise the blue dots are the computed periodogram welch s method while the solid red line is the fitted power law model s f 2 2 fs 2 sin f fs 2 2 fs f fs p 0 f fs for f fs 36 for small value of f this approximates p 0 f fs the sine function is the result of having discrete data kasdin 1995 the psd for ggm noise is s f 2 2 fs 1 2 2 cos 2 f fs 2 37 for 1 it converts to the pure power law noise psd the fourier trans form and especially the fast fourier transform can also be used to filter a time series for example eqs 23 and 24 represent a filtering of white noise vector v to produce coloured noise vector w wi i 1 j 0 hi j vj 38 let us now extend the time series y and the vector h containing the filter coefficients with n zeros this zero padding allows us to extend the summation to 2 n using eq 32 their fourier transforms yk and hk can be computed in the frequency domain convolution becomes multiplication and we have press et al 2007 wk hk yk for k n n 39 using eq 31 and only using the first n elements the vector w with the coloured noise can be obtained introduction to geodetic time series analysis 15 5 numerical examples to explain the principle of maximum likelihood this section will show some examples of the numerical method using python 3 for some years matlab has been the number one choice to analyse and visualise time series however in recent years python has grown in popularity due to the fact that it is open source and has many powerful libraries the following examples are made in ipython https ipython org using the jupyter notebook webapplication how to install this program is described on the afore mentioned website the examples shown here can be downloaded from the publisher website the first step is to import the libraries import math import numpy as np from matplotlib import pyplot as plt from scipy optimize import minimize from numpy linalg import inv next step is to create some data which we will store in numpy arrays as in matlab the linspace operator creates a simple array on integers fur thermore as the name implies random normal creates an array of gaussian distributed random numbers we create a line y with slope 2 and offset 6 on which we superimpose the noise w that were created using a standard deviation pl 0 5 for vector v see eq 23 n 500 number of daily observations t np linspace 0 n 365 25 n time in years np random seed 0 assure we always get the same noise kappa 1 flicker noise h np zeros 2 n note the size 2 n h 0 1 eq 25 for i in range 1 n h i i kappa 2 1 i h i 1 v np zeros 2 n again zero padded n 2 n v 0 n np random normal loc 0 0 scale 0 5 size n w np real fft ifft fft fft v fft fft h eq 39 y 6 3 t w 0 n trajectory model noise plt plot t y b plot the time series of course the normal situation is that we are given a set observations and that we need to estimate the parameters of the trajectory model y t a bt 16 filtering gps time series and common mode error analysis 0 0 0 2 0 4 0 6 0 8 1 0 1 2 1 4 5 6 7 8 9 10 11 fig 5 our synthetic time series containing a simple line plus flicker noise however creating synthetic time series is a very good method to test if your estimation procedures are correct first we will estimate the trajectory assuming white noise in the data the design matrix a np empty n 2 for i in range 0 n a i 0 1 a i 1 t i old white noise method c np identity n x inv a t inv c a a t inv c y eq 14 y hat a x r y y hat residuals c x np var r inv a t inv c a eq 15 print white noise approximation print a 0 6 3 f 1 5 3 f mm format x 0 math sqrt c x 0 0 print b 0 6 3 f 1 5 3 f mm yr format x 1 math sqrt c x 1 1 the result should be introduction to geodetic time series analysis 17 white noise approximation a 6 728 0 064 mm b 1 829 0 080 mm yr what we have done here is using weighted least squares with a white noise model that has unit variance the real variance of the noise has been estimated from the residuals and the uncertainty of the estimated parameters x have been scaled with it at this point the reader will realise that this approach is not justified because the noise is temporally correlated it will be convenient to define the following two functions that will create the covariance matrix for power law noise and apply weighted least squares williams 2003 bos et al 2008 power law noise covariance matrix def create c sigma pl kappa u np identity n h prev 1 for i in range 1 n h i kappa 2 1 i h prev eq 25 for j in range 0 n i u j j i h h prev h u sigma pl scale noise return u t u eq 26 weighted least squares def leastsquares c a y u np linalg cholesky c t u inv inv u b u inv t a z u inv t y x inv b t b b t z eq 14 variance of the estimated parameters c x inv b t b eq 15 compute log of determinant of c ln det c 0 0 for i in range 0 n ln det c 2 math log u i i return x c x ln det c the function that creates the covariance matrix for power law noise has been discussed in section 3 and uses eqs 25 and 26 the weighted least squares function contains some numerical tricks first the cholesky decom 18 filtering gps time series and common mode error analysis position is applied to the covariance matrix bos et al 2008 c ut u 40 where u is an upper triangle matrix that is only the elements above the diagonal are non zero a covariance matrix is a positive definite matrix which ensures that the cholesky decomposition always exists the most important advantage it that one can compute the logarithm of the determinant of matrix c by just summing the logarithm of each element on the diagonal of matrix u the factor two is needed because matrix c is the product of ut u using these two functions we can compute the correct parameters x the correct flicker noise covariance matrix sigma pl 4 kappa 1 c create c sigma pl kappa x c x ln det c leastsquares c a y print correct flicker noise print a 0 6 3 f 1 5 3 f mm format x 0 math sqrt c x 0 0 print b 0 6 3 f 1 5 3 f mm yr format x 1 math sqrt c x 1 1 the result is correct flicker noise a 6 854 2 575 mm b 1 865 4 112 mm yr if one compares the two estimates one assuming white noise and the other assuming flicker noise then one can verify that the estimates themselves are similar the largest difference occurs for the estimated errors which are 5 times larger for the latter this also happens in real geodetic time series mao et al 1999 concluded that the velocity error in gnss time series could be underestimated by factors of 5 11 if a pure white noise model is as sumed langbein 2012 demonstrated that an additional factor of two might be needed if there is also random walk noise present for sea level time series bos et al 2014 obtained a more moderate fac tor of 1 5 2 but still white noise underestimates the true uncertainty of the estimated linear trend williams et al 2014 estimated a factor 6 for the grace gravity time series as discussed in section 3 most geodetic time series are temporally correlated and therefore one nowadays avoids the white noise model so far we have assumed that we knew the true value of the spectral index and the noise amplitude pl using mle we can estimate these parameters from the data log likelihood with opposite sign introduction to geodetic time series analysis 19 def log likelihood x noise sigma pl x noise 0 kappa x noise 1 c create c sigma pl kappa x c x ln det c leastsquares c a y r y a x residuals eq 12 logl 0 5 n math log 2 math pi ln det c r t inv c r return logl x noise 0 np array 1 1 sigma pl and kappa guesses res minimize log likelihood x noise 0 method nelder mead options xatol 0 01 print sigma pl 0 6 3 f kappa 1 6 3 f format res x 0 res x 1 note that we inverted the sign of the log likelihood function because most software libraries provide minisation subroutines not maximisation in ad dition it is in this function that we need the logarithm of the determinant of matrix c if one tries to compute it directly from matrix c then one quickly encounters too large numbers that create numerical overflow this function also shows that we use weighted least squares to estimate the pa rameters of the trajectory model while the numerical minisation algorithm i e nelder mead is only used the compute the noise parameters the rea son for using weighted least squares also a maximum likelihood estimator as we have shown in section 2 is solely for speed numerical minisation is a slow process which becomes worse for each additional parameter we need to estimate the results is sigma pl 0 495 kappa 1 004 these values are close to the true values of pl 0 5 and 1 the following code can be used to plot the log likelihood as function of and pl s np empty 21 21 for i in range 0 21 sigma pl 1 2 0 05 i for j in range 0 21 kappa 1 9 0 1 j x noise 0 sigma pl kappa s i j math log log likelihood x noise 0 plt imshow s extent 1 9 0 1 0 2 1 2 cmap nipy spectral 20 filtering gps time series and common mode error analysis aspect auto plt colorbar plt ylabel sigma pl plt xlabel kappa plt show 1 75 1 50 1 25 1 00 0 75 0 50 0 25 0 00 kappa 0 2 0 4 0 6 0 8 1 0 1 2 si gm a pl 6 0 6 5 7 0 7 5 8 0 fig 6 the log of the log l function as function of and pl the result is shown in figure 6 which indeed shows a minimum around pl 0 5 and 1 depending on the computer power it might take some time to produce the values for this figure in section 3 we noted that for gnss time series the power law plus white noise model is common thus one must add the covariance matrix for white noise 2 wi to the covariance matrix we discussed in the examples in addition it is more efficient to write the covariance matrix of the sum of power law and white noise as follows c 2 plj 2 wi 2 j 1 i 41 where can be computed using introduction to geodetic time series analysis 21 rt c 1 r n 42 since can be computed from the residuals we only use our slow numerical minisation algorithm need to find the value of williams 2008 note that we only analysed 500 observations while nowadays time series with 7000 observations are not uncommon if one tries to rerun our examples for this value of n then one will note this takes an extremely long time the main reason is that the inversion of matrix c requires o n 3 operations bos et al 2008 2013 have investigated how the covariance matrix c can be approximated by a toeplitz matrix this is a special type of matrix which has a constant value on each diagonal and one can compute its inverse using only o n 2 operations this method has been implemented in the hector software package that is available from http segal ubi pt hector the hector software was used to create time series with a length of 5000 daily observations around 13 7 years for 20 gnss stations which we will call the benchmark synthetic gnss bsg this was done for the the horizontal and vertical components producing 60 time series in total each contains a linear trend an annual and a semi annual signal the sum of flicker and white noise wi was added to these trajectory models wi i 1 j 0 hi jvj 1 ui 43 with both ui and vi are gaussian noise variables with unit variance the factor was defined in eq 41 to create our bsg time series we used 1 4 mm 0 6 and horizontal components and 4 8 mm 0 7 for the vertical component it is customary to scale the power law noise amplitudes by t 4 where t is the sampling period in years for the vertical flicker noise amplitude we obtain pl t 4 4 8 0 7 1 365 25 1 4 17 6 mm yr 0 25 44 the vertical white noise amplitude is 2 6 mm for the horizontal compo nent these values are pl 4 7 mm yr 0 25 and w 0 9 mm respectively the bgs time series can be found on the springer website for this book and can be used to verify the algorithms developed by the reader these series will also be compared with other methods in the following chapters 22 filtering gps time series and common mode error analysis 6 discussion in this chapter we have given a brief introduction to the principles of time se ries analysis we paid special attention to the maximum likelihood estimation mle method and the modelling of power law noise we showed that with our assumptions on the stochastic noise properties the estimated parameters have their variance bounded by the cramer rao lower bound therefore the mle is an optimal estimator in the sense of asymptotically unbiased and efficient minimum variance in this book we will present other estimators such as the kalman filter the markov chain monte carlo algorithm and the sigma method all have their advantages and disadvantages and to explain them was one of the reasons for writing this book the other reason was to highlight the importance of temporal correlated noise this phenomenon has been known for a long time but due to increased computer power it has now become possible to include it in the analysis of geodetic time series we illustrated how this can be done by various examples in python 3 that highlighted some numerical aspects that will help the reader to implement their own algorithms references agnew dc 1992 the time domain behaviour of power law noises geophys res letters 19 4 333 336 doi 10 1029 91 gl 02832 beran j 1994 statistics for long memory processes monographs on statis tics and applied probability chapman hall new york beran j 1995 maximum likelihood estimation of the differenc ing parameter for invertible short and long memory autore gressive integrated moving average models journal of the royal statistical society series b methodological 57 4 659 672 url http www jstor org stable 2345935 bos ms williams sdp arau jo ib bastos l 2008 fast error analysis of continuous gps observations j geodesy 82 157 166 doi 10 1007 s 00190 007 0165 x bos ms williams sdp arau jo ib bastos l 2013 fast error analysis of continuous gnss observations with missing data j geodesy 87 351 360 doi 10 1007 s 00190 012 0605 0 bos ms williams sdp arau jo ib bastos l 2014 the effect of temporal correlated noise on the sea level rate and acceleration uncertainty geophys j int 196 1423 1430 doi 10 1093 gji ggt 481 box gep jenkins gm reinsel gc ljung gm 2015 time series analysis forecasting and control 5 th edn wiley bracewell r 1978 the fourier transform and its applications 2 nd edn mcgraw hill kogakusha ltd tokyo http www jstor org stable 2345935 introduction to geodetic time series analysis 23 brockwell p davis ra 2002 introduction to time series and forecasting second edition edn springer verlag new york buttkus b 2000 spectral analysis and filter theory in applied geophysics springer verlag berlin heidelberg caporali a 2003 average strain rate in the italian crust inferred from a per manent gps network i statistical analysis of the time series of permanent gps stations geophys j int 155 241 253 doi 10 1046 j 1365 246 x 2003 02034 x casella g berger r 2001 statistical inference 2 nd edn duxbury resource center dmitrieva k segall p demets c 2015 network based estimation of time dependent noise in gps position time series j geodesy 89 591 606 doi 10 1007 s 00190 015 0801 9 granger c 1980 long memory relationships and the aggregation of dynamic models journal of econometrics 14 2 227 238 doi https doi org 10 1016 0304 4076 80 90092 5 granger cwj joyeux r 1980 an introduction to long memory time series models and fractional differencing journal of time series analysis 1 1 15 29 doi 10 1111 j 1467 9892 1980 tb 00297 x https onlinelibrary wiley com doi pdf 10 1111 j 1467 9892 1980 tb 00297 x graves t gramacy r watkins n franzke c 2017 a brief history of long memory hurst mandelbrot and the road to arfima 1951 1980 entropy 19 9 doi 10 3390 e 19090437 url http www mdpi com 1099 4300 19 9 437 he x bos ms montillet jp fernandes rms 2019 investigation of the noise properties at low frequencies in long gnss time series journal of geodesy doi 10 1007 s 00190 019 01244 y url https doi org 10 1007 s 00190 019 01244 y hosking jrm 1981 fractional differencing biometrika 68 165 176 hurst he 1957 a suggested statistical model of some time series which occur in nature nature 180 494 doi 10 1038 180494 a 0 jaynes et 2003 probability theory the logic of science cambridge uni versity press cambridge johnson ho agnew dc 1995 monument motion and measurements of crustal velocities geophys res letters 22 21 2905 2908 doi 10 1029 95 gl 02661 kasdin nj 1995 discrete simulation of colored noise and stochastic pro cesses and 1 f power law noise generation proc ieee 83 5 802 827 kay sm 1993 fundamentals of statistical signal processing estimation theory prentice hall inc upper saddle river nj usa koch kr 1990 bayesian inference with geodetic applications lecture notes in earth sciences springer verlag doi 10 1007 bfb 0048699 koch kr 2007 introduction to bayesian statistics 2 nd edn springer verlag berlin heidelberg https onlinelibrary wiley com doi pdf 10 1111 j 1467 9892 1980 tb 00297 x http www mdpi com 1099 4300 19 9 437 https doi org 10 1007 s 00190 019 01244 y 24 filtering gps time series and common mode error analysis langbein j 2004 noise in two color electronic distance meter measurements revisited j geophys res 109 b 04406 doi 10 1029 2003 jb 002819 langbein j 2010 computer algorithm for analyzing and processing bore hole strainmeter data comput geosci 36 5 611 619 doi 10 1016 j cageo 2009 08 011 langbein j 2012 estimating rate uncertainty with maximum likelihood differences between power law and flicker random walk models j geodesy 86 775 783 doi 10 1007 s 00190 012 0556 5 mandelbrot bb 1999 multifractals and 1 f noise springer doi 10 1007 978 1 4612 2150 0 mandelbrot bb van ness jw 1968 fractional brownian motions fractional noises and applications siam review 10 422 437 mao a harrison cga dixon th 1999 noise in gps coordinate time series j geophys res 104 b 2 2797 2816 doi 10 1029 1998 jb 900033 montillet jp yu k 2015 modeling geodetic processes with levy stable distribution and farima mathematical geosciences 47 6 627 646 press wh 1978 flicker noises in astronomy and elsewhere comments on astrophysics 7 103 119 press wh teukolsky sa vetterling wt flannery bp 2007 numerical recipes 3 rd edition the art of scientific computing 3 rd edn cambridge university press new york ny usa sowell f 1992 maximum likelihood estimation of stationary univariate frac tionally integrated time series models j econom 53 165 188 taqqu ms teverovsky v willinger w 1995 estimators for long range de pendence an empirical study fractals 3 785 798 williams sd moore p king ma whitehouse pl 2014 re visiting grace antarctic ice mass trends and accelerations con sidering autocorrelation earth and planetary science letters 385 12 21 doi https doi org 10 1016 j epsl 2013 10 016 url http www sciencedirect com science article pii s 0012821 x 13005797 williams sdp 2003 the effect of coloured noise on the uncertainties of rates from geodetic time series j geodesy 76 9 10 483 494 doi 10 1007 s 00190 002 0283 4 williams sdp 2008 cats gps coordinate time series analysis software gps solut 12 2 147 153 doi 10 1007 s 10291 007 0086 4 http www sciencedirect com science article pii s 0012821 x 13005797 introduction to geodetic time series analysis m s bos j p montillet s d p williams r m s fernandes 1 gaussian noise and the likelihood function 2 linear models 3 models for the covariance matrix 4 power spectral density 5 numerical examples 6 discussion references