i itsec author s paper template modsim world 2013 2013 paper no 15838 page 1 of 7 epistemology of modeling and simulation how can we gain knowledge from simulations andreas tolk saikou y diallo jose padilla ross gore emse old dominion university vmasc old dominion university norfolk virginia suffolk virginia atolk odu edu sdiallo odu edu jpadilla odu edu rgore odu edu abstract epistemology is the branch of philosophy that deals with gaining knowledge it is closely related to ontology the branch that deals with questions like what is real and what do we know as it provides these components when using modeling and simulation we usually imply that we are doing so to either apply knowledge in particular when we are using them for training and teaching or that we want to gain new knowledge for example when doing analysis or conducting virtual experiments this paper looks at the history of science to give a context to better cope with the question how we can gain knowledge from simulation it addresses aspects of computability and the gen eral underlying mathematics and applies the findings to validation and verification and development of federations as simulations are understood as computable executable hypotheses validation can be understood as hypothesis testing and theory building the mathematical framework allows furthermore addressing some challenges when de veloping federations and the potential introduction of contradictions when composing different theories as they are represented by the federated simulation systems about the authors andreas tolk is professor of engineering management and systems engineering with a joint appointment to mod eling simulation and visualization engineering at old dominion university he is also affiliated with the virginia modeling analysis and simulation center he holds a m s and ph d in computer science from the university of the federal armed forces in munich germany saikou y diallo is research assistant professor at the virginia modeling analysis and simulation center at old dominion university he received a b s in computer engineering and a m s and ph d in modeling and simula tion from old dominion university jose j padilla is research assistant professor at the virginia modeling analysis and simulation center at old dominion university he received a b s in industrial engineering from the universidad nacional de colombia an m b a in international business from lynn university and a ph d in engineering management from old domin ion university ross gore is a post doctoral research associate at virginia modeling analysis and simulation center at old do minion university he holds a b s in computer science from the university of richmond and a m s and phd in computer science from the university of virginia mailto atolk odu edu mailto sdiallo odu edu mailto jpadilla odu edu mailto rgore odu edu modsim world 2013 2013 paper no 15838 page 2 of 7 epistemology of modeling and simulation how can we gain knowledge from simulations andreas tolk saikou y diallo jose padilla ross gore emse old dominion university vmasc old dominion university norfolk virginia suffolk virginia atolk odu edu sdiallo odu edu jpadilla odu edu rgore odu edu introduction the quote that essentially all models are wrong but some are useful is attributed to george e p box this quote raises the question if we can gain knowledge from something that is essentially wrong what are we doing when we build models derive simulations and then execute the simulations what is the scientific justification for applying models is simulation really the new third column of science as suggested in the nsf report 2006 standing as an equal partner beside theory and experimentation within this paper we will look at several foundations for modeling and simulation m s to justify why we can learn from m s despite a lot of challenges con nected with the epistemology of m s which is dealing with the theory of the nature and grounds of knowledge gained with m s especially with reference to its limits and validity we will start with a very limited view on science and how we gain understanding using the scientific method as the category of m s as we are in particular inter ested in is computer based simulation we will than look into computability next finally we will look at the mathematical foundations of m s in particular when it comes to the development of federations i e more than one independently devel oped simulation systems are combined using interoper ability protocols to support a common objective all these observations lead to the need to revisit our ideas of verification and validation to ensure that we not only learn something from m s but that we gain knowledge in the epistemological sense a brief history of science it may seem to be unnecessary to many readers starting this paper with a brief history of science as every young student learns the scientific principles in ele mentary school already in order to understand a phe nomenon the scientist formulates a hypothesis that pre dicts the outcome of an experiment if the outcome is actually observed the hypothesis is supported and be comes an explanation and ultimately can contribute to a theory this understanding however is actually not very old and actually is not even one common understanding goldman 2006 provides some fundamental insights it goes beyond the scope of this paper to deal with the details but the following observations prepare the ground for the arguments used later the british jurist and educational reformer fran cis bacon is generally recognized as the father of the experimental method he proposed a strictly controlled inductive empirical method to gain knowledge only based on observation and data collection analyses of data can uncover correla tions that lead to hypotheses further testing con firmation and ultimately the recognition of na ture s law the french mathematician and philosopher ren descartes proposed at the same time an alternative approach he supported the deductive rational method he put the mathematical model in the center and used deductive reasoning to get new insights experiments are just a tool of limited value as all experiments had to be conducted us ing too many constraints and their results were often equivocal isaac newton s work on the mathematical principles of natural philosophy 1687 became the foundation for scientific work for two and a half centuries his laws could not be deducted from experiments but were consistent with expe rience however he defined the components of his laws in way they supported his mathematics to describe the laws they were neither inductively nor deductively derivable from experience or ex perimentation but they allowed a coherent and consistent interpretation a conceptualization of experience mailto atolk odu edu mailto sdiallo odu edu mailto jpadilla odu edu mailto rgore odu edu modsim world 2013 2013 paper no 15838 page 3 of 7 today we know that many of newton s concepts are wrong or better stated they are not generally appli cable as relativity theory and quantum physics did lead to new insights and provided alternative views these new concepts are the best we currently have but how can we assume that these new conceptualizations are correct and will stand the test of time and if for how long nonetheless the laws described by newton were very successfully applied to gain a better under standing of nature and although no longer believed to be universally applicable they are still fundamental in today s school education popper 1935 formulated the implications of these observations that theories cannot be proven to be generally correct but we can state that they have not been falsified so far by new observations or insights science is still defined by analyses of data discovering of correlations and explaining the correlations by cau salities that have to be confirmed by observation and experimentation new tools allow more accurate obser vations new conceptualizations provide better struc tures to capture the knowledge in coherent frameworks but nobody knows for sure that our current frame work is the ultimate truth or if it is just the best thing currently available the essence of this little discourse into the history of science shall be that science itself is a series of models that provide functional causalities leading to observa ble correlations although wrong from the current per spective they all help mankind to gain new under standing about nature or in other words to produce knowledge that could be applied to solve problems and provide solutions computability and m s in this paper modeling is understood as the process to develop a model while simulation is understood as exe cuting such a model it is therefore understood that modeling resides on the abstraction level whereas sim ulation resides on the implementation level modeling identifies the data and the correlation and provides the functionality representing the causality leading to the observed correlation this is done by simplifying and abstracting from the observation as such a model is a purposeful task driven simplification and abstraction of a perception of reality each simulation is therefore an implementation of a model which hopefully is explic itly captured in form of a conceptual model balci and ormsby 2007 the authors are in particular interested in computer based simulations so the aspect of computability be comes important computability deals with the question if something can be executed on a digital computer and in particular whether the functions can be implemented as a computer program a function is computable when a finite algorithm exists that describes what the function is doing and if the function works on a discrete and finite set of arguments many alternative but equivalent definitions exist that all use different models of computation but the idea of discrete and limited range and domain and the existence of an algorithm are common features simulations can become very complex and in recent history are equipped with impressive means of visuali zation we can create breath taking virtual worlds that seem as real as reality but all these cannot take away the fact that computer based simulations are made up out of computable functions which means all the con straints and limitations of computable functions are applicable to simulations as well one of these constraints is that certain classes of prob lems cannot have an algorithmic solution turing 1936 described the halting problem as an example and gave the proof that no algorithm can exist that solves the problem the problem is the following given a program and an input to the program determine if the program will eventually stop when it is given that in put the well known proof works with the assumption that such an algorithm exists and derives a contradic tion as the only assumption is that such an algorithm exists the contradiction is the proof that such an algo rithm cannot exist as it would lead to the contradiction let us assume we can write the algorithm that solves the halting problem we call it the pro gram h when the program halts h produces halt otherwise loop we use h to construct the program k k uses h and halts when h produces the output loop and when h produces halt it loops forever we can now apply h to k if h says that k halts then k itself would loop and if h says that k loops then k will halt this cannot be which means h cannot exist the observation that many problems exist that cannot be decided by an algorithm is directly applicable to m s as these problems cannot be solved by m s either known problems belonging to this class are questions like will the system terminate are two modeled actions order independent or do i have to or chestrate them is the specification complete is modsim world 2013 2013 paper no 15838 page 4 of 7 the specification minimal or are two specifications functionally equivalent in other words do the delivery the same functionality beside these challenges of existence of an effective algorithm decidability of a problem the challenge of finding an efficient algorithm complexity of a prob lem needs to be addressed as well even if we can solve a problem effectively the time needed to solve it may be prohibitive to use such a solution in a simula tion system only effective and efficient algorithms make sense for computer based simulations which limits the number of useful functions significantly in comparison with all functions that can be used to ex plain correlations it is worth to point out that at no point in this argument we limited it to a certain paradigm the observations are true for monte carlo simulations continuous sim ulations discrete event simulation agent based simula tion and all other imaginable forms of simulation peo ple may come up with in the future the epistemologi cal constraints of composability are universal for com puter based simulation mathematical foundations another aspect becomes obvious when looking at the mathematical foundations a simulation system is a production system that applies the procedures captured in the system to transform input parameters into output parameters the simulation itself can therefore be un derstood as a formal language that produces terms out put parameters based on observations input parame ters this justifies the application of model theory weiss and d mello 1997 model theory is a branch of mathematics that deals with the interpretation of formal languages using set theo retic structures in particular it deals with the equiva lency of interpretations in different formal languages the fundamental terms of model theory are the formal languages that are used to express the concepts to be evaluated in order to interpret a sentence of a language a structure is needed this structure interprets sentences to be true or false the set of sentences that are inter preted to be true builds the theory structures are there fore understood as the model of a language the theo ries of these models are the sets of true statements in these models the detailed definitions and applications in support of m s are given in tolk et al 2013 we know from the earlier section on computability that no general algorithm can exist that decides if two for mal system specifications are functionally equivalent however by using model theory to define m s allows the applications of findings and results already gener ally proven to gain new insights e g two simulation systems are equivalent if they produce the same sen tences at all observed moments the two results of model theory that are directly applicable in support of such challenges are robinson consistency theorem and o theorem robinson consistency theorem simply states that the union of two theories is satisfiable under a model if and only if their intersections are consistent in other words there is only one interpretation of truth valid in both models as it is possible that two theories are using different languages and the resulting sen tences are not comparable o theorem generalizes the idea of expanding a universe through the cartesian product and defines filters that allow the comparison in a common equivalent representation epistemologically this is a very significant insight as terms like interoperability and composability don t need to be redefined and interpreted but using formal ap proaches allows to unambiguously address when to models are equivalent if transformations between model representations and implementations are lossless etc what was subject of discussions and expert opinion now becomes subject of mathematical rigor and proof a new look at v v the following graphic was published in sargent 2007 to explain the relations of real world and simulation world with verification and validation v v figure 1 v v relationships sargent 2007 modsim world 2013 2013 paper no 15838 page 5 of 7 sargent already made clear that we do not use the real system for validation but the system theories that de scribe our current understanding of this system the system theories of isaac newton s classic physics al bert einstein s relativity werner heisenberg s quantum physics and brian greene s string theory are all very different although all try to describe how the observa ble world works when we validate we validate against such a theory not the real thing utilizing the insights from the earlier section on model theory we do not have to rely on subject matter experts and best practices but we can apply the robinson con sistency theorem and o theorem to proof validity as long as the system theory is provided in form of a for mal language in addition user requirements can now be dealt with in a similar manner as mathematically rigorously cap tured data in systems engineering e g validation ac tually normally addresses the evaluation if a system meets all user requirements which means requirements need to be captured accordingly the system modeling language sysml was derived from the universal modeling language uml for better support of systems engineering but added among some other changed two important diagrams namely the requirement dia grams that represent a visual modeling of requirements for the system which are pivotal for systems engineer ing and the parametric diagrams that show the rela tions between parameters for system components on all levels the diagrams allow for tracing of all other clas ses to the requirements from which they are derived by relating them to the requirement diagram as well as introducing metrics to measure the fulfillment of the requirements this idea was utilized for the development of the mod eling and simulation system development framework ms sdf described in tolk et al 2013 and shown in figure 2 system theories recognized by the user as well as re quirements assumptions and constraints are collected in mathematically unambiguous form to make up the reference model for the simulation tolk et al 2013 define a reference model as an explicit model of a real or imaginary referent its attributes capabilities and relations as well as governing assumptions and con straints under all relevant perceptions and interpreta tions the reference model captures what is known and assumed about a problem situation of interest as this model captures all inputs it is complete regarding de fining elements but likely not consistent as contra dicting system theories are possible and not aligned requirements from different stake holders are highly likely figure 2 the m s system development framework tolk et al 2013 to build a simulation system however we need a con sistent conceptual model robinson 2008 defines a conceptual model as a non software specific descrip tion of the computer simulation model that will be is or has been developed describing the objectives in puts outputs content assumptions and simplifications of the model all this information is captured in the reference model so that a conceptual model can be ex tracted by filtering the filter is defined by the con sistency requirement no contradictions can pass the filter and the relevance requirement only concepts identified in the modeling question can pass the filter in case of contradictions several conceptual models can be derived that illuminate the different aspects of the challenge as understood in the reference model this approach was envisioned as multi simulation in yilmaz et al 2007 a good example for the proposed way is the use of weather models to predict hurricane paths instead of building one federation of all models the models are used in parallel and their projections are displayed in a common context namely as hurricane tracks with wind strength on a map the common elements shared by all weather models are wind strength and coordinates the framework allows identifying common concepts that can be used to display results side by side without having to force contradicting theories into one single model why this approach the developing of federa tions is epistemologically dangerous will be discussed in our last section modsim world 2013 2013 paper no 15838 page 6 of 7 developing federations in particular in the military application domain the use of federations is very common the idea is intriguing instead of developing new m s solutions existing part solutions are federated to expose their partial function ally so that in the sum the overall need functionality is provided to the user by the federation if e g a closed air support operation is needed an air force model can simulate the air crafts while an army model can simu late the land based operations the problem with this approach is that we are implicitly assuming that all participating simulations support one world view in other words we are assuming that we start from the common ground of a common and ac cepted description of reality in form of an object model that can serve as the bermodell from which all simu lation representations can be derived by pruning and aggregating but that is not necessarily true as tolk et al 2011 explain it as we are connecting simulated things we need transparency of what we are simulating as the real world referent use in other interoperability domains has been replaced in the modeling phase by its representing conceptualization in the m s interopera bility domain this is a general problem winsberg 2010 uses nano sciences as an example where scientists are interested in how cracks evolved and move through material to address this problem three different levels of resolution are necessary in order to understand how cracks begin sets of atoms governed by quantum mechanics are modeled in small regions these regions are embedded into medium scale regions that are governed by molec ular dynamics finally most of the material is neither cracking nor close to a developing crack and can be modeled using continuum mechanics based on linear elastic theory the challenge is that these three theories cannot be mapped to each other as they are inconsistent no theory exists that allows creating a common theory however we can create a federation based on coupling heuristics which winsberg calls handshakes in the given example the common expression of energy was utilized to exchange information between the regions and allow for a common model that executes perfectly fine but what is the foundation this federation is based on three theories that are valid in themselves but the federation is only based on a heuristic supported by no theory whatsoever so can it be valid conclusions let s summarize the findings before coming back to our question posted in the introduction from the history of science we understand that a theory is the best con sistent explanation of observables by providing causal ity that explains correlations this causality can be captured by functions and relations we can capture these in a model that can be implemented as a simula tion however when the simulation is computer based the limitations of computability are given model theory helps to better understand when models are consistent with the implemented theory as well as with additional requirements which is in alignment with ideas of vali dation and verification although these processes need to be supported by more rigorous methods the current practice of building federations ignores or is unaware of these findings and needs to be revisited however does this mean that we cannot gain knowledge from something that is essentially wrong weirich 2012 makes a strong case that models are still very useful as long as we understand the underlying assumptions and constraints what is needed is a better education of m s engineers to understand the princi ples captured in this paper a simulationists must not only be a good computer engineer he also needs to understand the underlying conceptualizations and mathematics that are the philosophical foundations on which m s as a discipline is build our current m s curricula do not all support this well enough and the need is not yet fully recognized in industry with this paper we hope to reach some decision makers to ad dress these issues better in the future the second question posted in the introduction whether simulation stands equally beside theory and experi mentation needs also further discussion padilla et al 2013 in this paper the authors observe that simulation is either used for theory building theory testing or a mixed mode thereof when simulations are used to generate data from which new insights are derived this process is the creating of a new theory if data is com pared with empirical evidence the simulation is tested using the methods of theory testing if empirical data is used to test a simulation and afterwards the simulation is used to generate new data to be evaluated we have a mixed form in all cases the simulation either stands in place of the theory or in the place of the experimenta tion again there is a vast amount of methods applica ble that has been developed of centuries of theory and simulation development simulationists must know what they are doing and which methods are applicable m s as a discipline is still young and in development that is why it is even more important to address these questions and embed it into the context of other scien tific disciplines modsim world 2013 2013 paper no 15838 page 7 of 7 acknowledgements the authors like to thank their colleague from the epistemology of simulation epos group for the dis cussions and ideas during the recent workshops references balci o and w f ormsby conceptual modeling for designing large scale simulations journal of sim ulation 1 3 175 186 2007 goldman s l science wars what scientists know and how they know it lehigh university the teaching company chantilly va 2006 national science foundation nsf blue ribbon panel report on simulation based engineering science revolutionizing engineering science through simu lation nsf press washington dc 2006 object model group omg system modeling lan guage http www omg org spec sysml last ac cessed april 2013 padilla j j a tolk and s y diallo m s methodo logical challenges proceedings of the spring sim ulation multiconference 2013 popper k r logik der forschung the logic of sci entific discovery springer 1935 robinson s conceptual modelling for simulation part i definition and requirements journal of the operational research society 59 278 290 2008 sargent r g verification and validation of simula tion systems proceedings of the winter simulation conference pp 124 137 2007 tolk a s y diallo j j padilla and c d turnitsa how is m s interoperability different from other interoperability domains proceedings of the spring simulation interoperability workshop pp 12 20 2011 tolk a s y diallo j j padilla h herencia zapana reference modeling in support of m s founda tions and applications journal of simulation doi 10 1057 jos 2013 3 2013 turing a m on computable numbers with an ap plication to the entscheidungsproblem proceedings of the london mathematical society series 2 42 230 265 1936 weirich w models as partial explanations in on tology epistemology and teleology for modeling and simulation edited by a tolk springer pp 105 119 2012 weiss w and c d mello fundamentals of model theory university of toronto 1997 winsberg e science in the age of computer simula tion the university of chicago press 2010 yilmaz l t ren a lim and s bowen require ments and design principles for multisimulation with multiresolution multistage multimodels proceed ings of the winter simulation conference pp 823 832 2007