ar x iv 1 80 1 02 00 9 v 1 m at h o c 6 j an 2 01 8 neural networks 2013 doi 10 1016 j neunet 2013 01 014 1 probabilistic dhp adaptive critic for nonlinear stochastic control systems randa herzallah abstract following the recently developed algorithms for fully probabilistic control design for general dynamic stochastic systems 15 18 this paper presents the solution to the probabilistic dual heuristic programming dhp adaptive critic method 15 and randomized control algorithm for stochastic nonlinear dynamical systems the purpose of the randomized control input design is to make the joint probability density function of the closed loop system as close as possible to a predetermined ideal joint probability density function this paper completes the previous work 15 18 by formulating and solving the fully probabilistic control design problem on the more general case of nonlinear stochastic discrete time systems a simulated example is used to demonstrate the use of the algorithm and encouraging results have been obtained index terms nonlinear stochastic systems fully probabilistic design nonlinear randomized control input design adaptive critic i introduction the mean variance 2 and utility function in linear quadratic optimal control 1 31 have been firstly introduced to characterize the performance of the closed loop stochastic control systems in more recent work stochastic adaptive control 22 stochastic linear quadratic martingale 25 6 sliding mode control for stochastic systems 23 and predictive stochastic control 9 5 have been proposed in most of previous works the system under control has been assumed to be linear or of gaussian probability density function pdf however it has been shown 14 30 7 that in systems where the stochastic signals is non gaussian or the system dynamics have strong nonlinearity existing control methods do not generally yield optimization of the control system consequently in the past few years four groups of control algorithms for general stochastic systems with inherent models and parameters uncertainty have been developed 1 the control of the shape of the output pdf 27 29 2 the minimum entropy control 28 3 the bayesian techniques for modelling and control 13 26 and 4 the control of the closed loop pdf 18 17 the control objective in the first group is to find a control input which makes the shape of the measured output pdf follows a given desired distribution the second group is a generalization of the minimum variance control for linear gaussian systems the entropy in this group of control algorithms is used to characterize the performance of the closed loop systems and the controller is designed such that the shape of the pdf of the closed loop system is made as narrow as possible in the third group a general class of stochastic estimation and control problems is formulated from the bayesian decision theoretic viewpoint which is shown to be a general framework to solve stochastic estimation and control problems motivated by the probabilistic description of the closed loop control system the kullback leibler divergence distance has been proposed in the fourth group of control as a performance measure rather than the mean variance this method of control is known as fully probabilistic design fpd for stochastic systems with measurable states xt the objective of the fpd is to determine the pdf of a randomized optimal control law ut described by c ut xt 1 1 that minimizes the discrepancy between the actual joint pdf of the closed loop system f and an ideal joint pdf if measured by the kullback leibler divergence distance d f if f xt ut ln f xt ut if xt ut dxtdut 2 the fpd problem is further simplified by the assumption that all pdfs needed in the design paradigm are existent and known the main advantage of the fpd is that it provides an explicit form of the randomized optimal controller however since the evaluation of the randomized optimal controller involves multivariate integration steps which need to be computed by backward recursion the problem renders to be nontrivial and computationally very intensive to overcome the difficulties arising in the fpd a probabilistic dhp adaptive critic method is proposed in 15 the dhp adaptive critic method uses a critic network to circumvent the need for explicitly evaluating the optimal value function therefore dramatically reducing computational requirements further more unlike the fpd method all pdfs in the probabilistic dhp adaptive critic approach are assumed to be unknown therefore estimated using recent development in neural networks however up to now the previous methods of r herzallah is with al balqa applied university jordan http arxiv org abs 1801 02009 v 1 neural networks 2013 doi 10 1016 j neunet 2013 01 014 2 fpd 18 and probabilistic dhp critic 15 are demonstrated only on linear stochastic gaussian systems where the means of the associated density functions are restricted to be linear functions hence the solution to the control problem is constrained to the linear gaussian control theory this is restrictive in many real world applications that are characterized by strong nonlinearity and uncertainty in practical processes where the forward and inverse dynamics of the system have strong nonlinearities the means of the associated density functions are in general going to be nonlinear functions this motivates the work in the current paper which is concerned with the development of the solution to the fpd problem 18 for nonlinear stochastic systems where the means of the various density functions are allowed to be general nonlinear functions for this purpose we adopt the probabilistic dhp adaptive critic method proposed in 15 although systems under consid eration are nonlinear stochastic systems all pdfs are assumed to be gaussians this assumption can be shown to represent no real restriction provided that the conditional expectations of these pdfs are estimated using nonlinear models however it is worth mentioning that although the pdfs of the nonlinear stochastic systems are approximated by gaussian density functions it is in general difficult to integrate the nonlinear conditional expectations of these density functions to the probabilistic dhp adaptive critic method or even the fpd method as such radial basis function rbf neural network with gaussian basis functions 4 is proposed in this paper to approximate the conditional expectations of the nonlinear stochastic models an important property of such a neural network is that it forms a unifying link with density estimation as will be clear from subsequent developments the use of rbf networks with gaussian basis functions to approximate the unknown nonlinear models facilitates the evaluation of the gaussian integrations and integrates naturally to the framework of probabilistic dhp adaptive critic paradigm the main achievement of this paper is the solution of the nonlinear fully probabilistic optimal control problem for stochastic nonlinear systems although the previous methods 15 18 have discussed the general framework of nonlinear control systems the problem rendered to be very hard to implement even under the gaussian and linear models assumptions hence the control solution to these methods are derived and demonstrated on linear systems only by using the probabilistic dhp critic method proposed in 15 and rbf networks to estimate all required density functions we develop and demonstrate the solution to the fpd control problem on stochastic nonlinear systems the derived solution provides an efficient approach to the solution of the fully probabilistic control design for nonlinear stochastic systems to achieve the objective of this paper it will be organized as follows section ii formulates the problem and discusses the problem of estimating the pdf of the system dynamics section iii presents the probabilistic dhp adaptive critic solution to nonlinear stochastic systems the control algorithm of nonlinear control problems based on the probabilistic dhp adaptive critic method is discussed in section iv section v contains a simulation example to show the effectiveness of the proposed probabilistic controller the conclusion is provided in section vi ii problem formulation and preliminaries a model description and control objective the system considered in this paper is a nonlinear stochastic dynamical control system described by the following general stochastic equation xt h xt 1 g xt 1 ut t 3 where xt r n is the measured state vector ut r r is the control input vector h xt 1 r n 7 rn and g xt 1 r n 7 rr are unknown nonlinear functions of the state and t r n is an additive noise vector the control problem confronted here is to design a control strategy for the system in 3 to control the state of the system to a predefined desired state value however because of the noise input t the previous state and present and future controls do not completely specify the present state but instead determine only the probability distribution of these states s xt ut xt 1 it is assumed that the noise input t is unknown and hence the probability distribution of the states is unknown since only probability distribution of the states can be determined the above objective of this control problem should be re defined in terms of the probabilistic control theory therefore to achieve this control objective we consider designing a probabilistic controller c ut xt 1 that shapes the joint pdf of the closed loop system f xt ut and makes it as close as possible to a predefined desired pdf if xt ut this design method was originally presented in 18 where the probabilistic controller is obtained such that it minimizes the kullbackleibler divergence distance defined in 2 the minimum cost function resulting from minimization of 2 with respect to admissible control sequence ut t 1 h with h being the control horizon is then shown to be given by the following recurrence equation 15 ln xt 1 min c ut xt 1 s xt ut xt 1 c ut xt 1 ln s xt ut xt 1 c ut xt 1 is xt ut xt 1 ic ut xt 1 partial cost u xt ut ln xt optimal cost to go d xt ut 4 neural networks 2013 doi 10 1016 j neunet 2013 01 014 3 where ln xt 1 is the expected minimum cost to go function and f xt ut s xt ut xt 1 c ut xt 1 5 is the decomposition of the actual joint pdf by the chain rule 24 which represents the most complete probabilistic description of the closed loop system here the pdf s xt ut xt 1 describes the dynamics of the observed state vector xt similarly if xt ut is xt ut xt 1 ic ut xt 1 6 is the decomposition of the ideal joint pdf of the closed loop system and is xt ut xt 1 and ic ut xt 1 represent the pdfs of the desired dynamics of the observed state vector and ideal controller respectively the solution of the fpd is given in the following proposition proposition 1 the pdf of optimal controller minimizing the cost to go function 4 is given by c ut xt 1 ic ut xt 1 exp ut xt 1 xt 1 xt 1 ic ut xt 1 exp ut xt 1 dut ut xt 1 s xt ut xt 1 ln s xt ut xt 1 is xt ut xt 1 ln xt dxt 7 proof this proposition can be proven by adapting the proof of proposition 2 in 17 it should be noted that although a closed form can be found for the pdf of the optimal controller the multivariate integrations in 7 are only tractable for the linear gaussian case where the mean of the gaussian distribution is linear in the state and control values besides even for the linear gaussian case the solution to the optimal control history need to be computed from 7 by backward recursion this backward dynamic programming approach is computationally very expensive and grows exponentially with the dimensionality of the state vector to avoid these difficulties of the fpd a probabilistic dhp adaptive critic method is proposed in 15 to approximate the optimal cost to go function and the probabilistic controller unknown pdfs were also estimated using recent development from neural network models however numerical experiments and previous analytical studies have demonstrated the usefulness of this control approach to obtain the control efforts only on linear stochastic gaussian systems the solution to the probabilistic dhp adaptive critic methods for the nonlinear stochastic systems 3 on the other hand was not discussed the objective of this paper is to discuss the various steps to obtain this solution and demonstrate the theoretical development on a nonlinear stochastic simulation example of the form given in 3 we first start by discussing the estimation problem of unknown probabilistic models of the stochastic system defined in 3 and reviewing the probabilistic dhp adaptive critic methods that will be needed for further development in the article b pdf of the system dynamics to estimate the probabilistic model of the nonlinear stochastic system 3 we adopt the method proposed in 15 where neural network models are used to provide a prediction for the conditional expectation of the system state values and calculating the global average variance of its residual error for such a system there exists a neural network model 15 such that the inequality xt nf ut xt 1 8 holds where 0 is a known small number and nf ut xt 1 x t is a neural network approximation of the state xt assuming a rbf neural network model of the form nf ut xt 1 h xt 1 g xt 1 ut in which h xt 1 and g xt 1 are estimates of the nonlinear functions h xt 1 and g xt 1 respectively the stochastic system 3 can be re expressed as xt h xt 1 g xt 1 ut e xt 1 ut 9 here e xt 1 ut represents the approximation error satisfying e xt 1 ut this means that the resulting conditional distribution of the system dynamics s xt ut xt 1 is gaussian distribution function with conditional expectation of the distribution being given by the neural network approximation and a global average covariance given by 15 e xt x t xt x t t 10 with e denoting the expected value neural networks 2013 doi 10 1016 j neunet 2013 01 014 4 c review of the probabilistic dhp adaptive critic method the probabilistic dhp adaptive critic method uses two neural networks an adaptive critic network that approximates the derivative of the optimal cost to go function 4 with respect to the state xt 1 ln xt 1 xt 1 and an action network that produces optimal randomized control inputs u t in the probabilistic dhp critic method the optimal control law is computed by deriving 4 with respect to the control input 15 ln xt 1 ut ut u t s xt ut xt 1 c ut xt 1 u xt ut xt xt ut u xt 1 ut ut xt xt ut d xt ut 0 11 so the action network is optimized such that the error between optimal control input u t obtained from 11 and estimated control input ut from the neural network is minimized once this network is optimized information about the error between optimal control u t and estimated control ut will become available this allows estimation of the conditional distribution of the randomized controller c ut xt 1 which is assumed to be gaussian with mean computed from the output of the controller network and a global covariance matrix computed from the residual error between the output of the controller network and the optimal control signal e u t ut u t ut t given estimation of control law from the controller network and the derivative of the output of the critic network xt the critic network is then optimized by computing its desired value as follows 15 xt 1 s xt ut xt 1 c ut xt 1 u xt ut xt xt xt 1 u xt ut xt xt ut ut xt 1 u xt ut ut ut xt 1 xt xt xt 1 xt xt ut ut xt 1 d xt ut 12 the training process for the adaptive critic network is a two stage process the training of the action network which outputs the optimal control policy u xt and the training of the critic network which approximates the derivative of the cost function xt 1 as a first step in the training process the critic and the action networks need to be designed and the initial weights of these networks should be randomized since the derivative of the partial cost function can be calculated this in combination with the critic outputs and the system model derivatives allows the use of 12 to calculate the target value of the critic xt 1 the difference between xt 1 and the output of the critic xt 1 is used to correct the critic network until it converges the output from the converged critic is used in 11 solving for the target u t which is then used to correct the action network this alternating process of training the action and the critic networks is repeated until an acceptable performance is reached iii solution to the problem a basic elements in this section we derive the probabilistic dhp adaptive critic solution to the nonlinear stochastic system defined in 3 for presentations clarity and simplicity the solution to this problem will be developed for a regulation problem where the objective is to reach a zero state with a spread determined by a specified covariance matrix generalization to a state value that is different than zero is straight forward as discussed in section ii the conditional distribution of the nonlinear system 3 is estimated as a gaussian distribution described by xt h xt 1 g xt 1 ut e xt 1 ut s xt ut xt 1 nxt h xt 1 g xt 1 ut 13 for the considered regulation problem the system is initially in state xt 1 and the aim is to return the system state to the origin hence the distribution of the ideal state of the system is taken to be is xt ut xt 1 nxt 0 14 where here the desired mean value of the state is taken to be zero and where specifies the covariance of the innovation of the state values the stochastic model of the randomized controller to be designed is estimated as discussed in section ii c by the well known rbf neural network ukt m j 0 wkj j xt 1 k t ut w xt 1 t c ut xt 1 nut w xt 1 15 neural networks 2013 doi 10 1016 j neunet 2013 01 014 5 where w wkj is the matrix of the weight parameters m is the number of basis functions of the controller network t is the residual error of the control input vector is the covariance of the residual error of control and the rbf activation functions j xt 1 are gaussian basis functions 4 j xt 1 exp xt 1 j t 1 j xt 1 j 16 the distribution of the ideal controller is also assumed to be ic ut xt 1 nut 0 17 the desired value of the critic network given in 12 is also taken to be the target of an rbf neural network as follows 4 m xt 1 l l 0 ml l xt 1 xt 1 xt 1 18 where is the matrix of weight parameters of the critic network l is the number of basis functions and the basis functions l xt 1 are taken to be gaussian basis functions 4 l xt 1 exp xt 1 zl t 1 l xt 1 zl 19 having defined those elements the solution to the probabilistic dhp adaptive critic can now be obtained by calculating the desired value of the critic network and the optimal control inputs we start in the next section by calculating the desired value of the critic the optimal control input will be calculated in section iii c b desired value of the critic network for the conditional distribution of nonlinear system 13 conditional distribution of nonlinear controller 15 and nonlinear critic model 18 the desired target value of the critic network can be calculated by carrying out the calculations implied by 12 starting by the first term on the right hand side of 12 we get s xt ut xt 1 c ut xt 1 u xt ut xt xt xt 1 d xt ut exp ut u t t 1 ut u t exp xt x t t 1 xt x t 2 x t t 1 h xt 1 g xt 1 ut dxt dut exp ut u t t 1 ut u t 2 x t t 1 h xt 1 g xt 1 ut dut 2 h xt 1 g xt 1 u t t 1 h xt 1 g xt 1 u t 20 where we have introduced the definitions x t h xt 1 g xt 1 ut and u t w xt 1 and where h xt 1 h xt 1 xt 1 and g xt 1 g xt 1 xt 1 the definition of the partial cost u xt ut is given in 4 for the considered regularization problem it evaluates to u xt ut 2 x t t 1 xt x t t 1 x t 2 u t t 1 ut u t t 1 u t for the second term the partial derivatives of u xt ut xt and ut with respect to xt ut and xt 1 respectively need to be calculated s xt ut xt 1 c ut xt 1 u xt ut xt xt ut ut xt 1 d xt ut exp ut u t t 1 ut u t exp xt x t t 1 xt x t 2 x t t 1 g xt 1 w xt 1 dxt dut exp ut u t t 1 ut u t 2 x t t 1 g xt 1 w xt 1 dut 2 h xt 1 g xt 1 u t t 1 g xt 1 w xt 1 21 where xt 1 xt 1 xt 1 neural networks 2013 doi 10 1016 j neunet 2013 01 014 6 the third term requires calculation of the partial derivatives of u xt ut and ut with respect to ut and xt 1 respectively s xt ut xt 1 c ut xt 1 u xt ut ut ut xt 1 d xt ut exp ut u t t 1 ut u t exp xt x t t 1 xt x t 2 u t t 1 w xt 1 dxt dut exp ut u t t 1 ut u t 2 u t t 1 w xt 1 dut 2 u tt 1 w xt 1 22 the propagation of xt through the stochastic model of 13 back to xt yields the fourth term s xt ut xt 1 c ut xt 1 xt xt xt 1 d xt ut exp ut u t t 1 ut u t ut xt 1 dut 23 where we used ut xt 1 exp xt x t t 1 xt x t xt t h xt 1 g xt 1 ut dxt 24 and where we used 18 with xt as input to obtain xt xt using 19 but again with xt as an input in 24 yields ut xt 1 exp xt x t t 1 xt x t exp xt z 1 t 11 xt z 1 exp xt x t t 1 xt x t exp xt z 2 t 12 xt z 2 exp xt x t t 1 xt x t exp xt zl t 1 l xt zl t t h xt 1 g xt 1 ut dxt 25 exp x t z 1 t 1 1 x t z 1 exp x t z 2 t 2 1 x t z 2 exp x t zl t l 1 x t zl t t h xt 1 g xt 1 ut 26 where the sum of two quadratics as a result of the multiplication of the two exponentials of the first term in brackets in 25 is rewritten in the following form xt x t t 1 xt x t xt zl t 1 l xt zl xt el t 1 1 l xt el x t zl t l 1 x t zl and the integration with respect to xt is evaluated here el 1 1 l 1 1 x t 1 l zl the substitution of 26 in 23 yields the value of the fourth term s xt ut xt 1 c ut xt 1 xt xt xt 1 d xt ut exp ut u t t 1 ut u t exp x t z 1 t 1 1 x t z 1 exp x t z 2 t 2 1 x t z 2 exp x t zl t l 1 x t zl t t h xt 1 g xt 1 ut dut exp x t z 1 t 1 1 x t z 1 ut u t t 1 ut u t exp x t z 2 t 2 1 x t z 2 ut u t t 1 ut u t exp x t zl t l 1 x t zl ut u t t 1 ut u t t t h xt 1 g xt 1 ut dut 27 to simplify the integration in 27 the square of the argument of the exponential is completed x t zl t l 1 x t zl ut u t t 1 ut u t ut hl t l ut hl zl h xt 1 t l 1 zl h xt 1 u tt 1 u t h t l lhl 28 where l g t xt 1 l 1 g xt 1 1 and hl 1 l gt xt 1 l 1 zl h xt 1 1 u t denoting the exponential of the last constant three terms the terms that are independent of ut on the right hand side of 28 by neural networks 2013 doi 10 1016 j neunet 2013 01 014 7 l exp zl h xt 1 t l 1 zl h xt 1 u t t 1 u t h t l lhl and substituting 28 in 27 yields s xt ut xt 1 c ut xt 1 xt xt xt 1 d xt ut exp ut h 1 t 1 ut h 1 exp ut h 2 t 2 ut h 2 exp ut hl t l ut hl t t t h xt 1 g xt 1 ut dut th xt 1 t g xt 1 h 29 finally the fifth term can be calculated by propagating xt through the stochastic model of 13 back to ut and then through the action network which yields s xt ut xt 1 c ut xt 1 xt xt ut ut xt 1 d xt ut exp ut u t t 1 ut u t exp xt x t t 1 xt x t xt t g xt 1 w xt 1 dxt dut t g xt 1 w xt 1 30 adding 20 21 22 29 30 together yields the target vector of the critic network xt 1 2 h xt 1 g xt 1 u t t 1 h xt 1 g xt 1 u t 2 h xt 1 g xt 1 u t t 1 g xt 1 w xt 1 2 u t t 1 w xt 1 th xt 1 t g xt 1 h t g xt 1 w xt 1 31 equation 31 can then be used to correct the critic network and update its parameters remark all of the above integrals implied by 20 30 are gaussian integrals which can be evaluated using theorems and corollaries provided in 10 chapter 10 c probabilistic control the randomized control input can be computed by solving the optimality equation 11 the first term on the right hand side of 11 is the expected value of the partial derivatives of u xt ut and xt with respect to xt and ut respectively s xt ut xt 1 c ut xt 1 u xt ut xt xt ut d xt ut exp ut u t t 1 ut u t exp xt x t t 1 xt x t 2 x t t 1 g xt 1 dxt dut exp ut u t t 1 ut u t 2 h xt 1 g xt 1 ut t 1 g xt 1 dut 2 h xt 1 g xt 1 u t t 1 g xt 1 32 the second term requires the evaluation of the expected value of the partial derivatives of u xt ut with respect to ut s xt ut xt 1 c ut xt 1 u xt ut ut d xt ut exp ut u t t 1 ut u t exp xt x t t 1 xt x t 2 u t t 1 dxt dut exp ut u t t 1 ut u t 2 u t t 1 dut 2 u tt 1 33 neural networks 2013 doi 10 1016 j neunet 2013 01 014 8 the last term is the expected value of the propagation of xt through the stochastic model of 13 back to ut s xt ut xt 1 c ut xt 1 xt xt ut d xt ut exp ut u t t 1 ut u t exp xt x t t 1 xt x t xt t g xt 1 dxt dut exp ut u t t 1 ut u t exp xt x t t 1 xt x t exp xt z 1 t 11 xt z 1 exp xt x t t 1 xt x t exp xt z 2 t 12 xt z 2 exp xt x t t 1 xt x t exp xt zl t 1 l xt zl t t g xt 1 dxt dut exp x t z 1 t 1 1 x t z 1 ut u t t 1 ut u t exp x t z 2 t 2 1 x t z 2 ut u t t 1 ut u t exp x t zl t l 1 x t zl ut u t t 1 ut u t t t g xt 1 dut t g xt 1 34 adding all terms together yields 2 h xt 1 g xt 1 u t t 1 g xt 1 2 u t t 1 t g xt 1 0 35 the solution of this equation cannot be analytically obtained due to the nonlinear nature of hence the controller design is a nonlinear optimization problem which generally leads to a numerical solution the controller network can then be optimized such that the error between optimal control input u t obtained from 35 and estimated control input ut from the neural network is minimized the controller can then generates control signals ut stochastically from a gaussian distribution having a mean u t and a global average covariance calculated as discussed in section ii c iv nonlinear randomized control algorithm based on probabilistic dhp critic methods the exact evaluation of the closed form of optimal controller in fpd methods 7 is nontrivial and computationally very intensive due to its involvement of multivariate integrations these multivariate integrations are only tractable for the linear gaussian case where the mean is linear in both state and control values this motivated the probabilistic dhp adaptive critic approach discussed in section iii as can be seen from 31 the desired critic value can be calculated from neural network models of the forward dynamics of the system nonlinear controller and critic network similarly the control law can be calculated from 35 once the critic network and system dynamic models become available although the probabilistic dhp adaptive critic approach involves multiple computation levels its implementation can be made by means of modular approach constituting of functional modules and algorithmic modules 8 20 12 the key functional modules are the action and critic networks algorithmic modules on the other hand include the computation of the desired critic value 31 computation of the optimal control law 35 and the update of the networks parameters each module in the adaptive critic can be modified independently from other modules thus facilitate fast and reliable implementation the probabilistic dhp adaptive critic approach allows computation of probabilistic control laws from the fpd methods for linear gaussian systems with less computational complexities and more important allows the solution to nonlinear and non gaussian systems the description below is appropriate for direct application to nonlinear control problems of the form stated in section ii 1 estimate the pdf of the stochastic model described by 3 as discussed in section ii 2 design and initialize the weights of the action network 3 design and initialize the weights of the critic network 4 calculate the desired value of the critic network using equation 31 5 use the difference between the desired value of the critic network as calculated from the previous step and the output of the critic to update the parameters of the critic network until it converges 6 use the output of the converged critic in 35 and solve for the optimal control law 7 use this value to update the parameters of the action network 8 calculate the global covariance matrix from the residual error between the output of the action network and optimal control law as calculated in step 6 and update the conditional distribution of the optimal controller 9 repeat steps 4 6 until an acceptable performance is reached the flow chart of implementing the probabilistic dhp adaptive critic method for nonlinear systems is given in figure 1 to summarize the probabilistic dhp adaptive critic training algorithm cycles between a policy improvement routine and a neural networks 2013 doi 10 1016 j neunet 2013 01 014 9 control input determination operation where the optimal control law and the derivative of the value function xt 1 are approximated by the action and critic networks respectively the algorithm terminates when control law and the derivative of the value function have converged to the optimal or suboptimal control law and derivative value function respectively the proof of convergence given in 16 8 is directly applicable to the probabilistic adaptive critic design in this paper a nonlinear control problem example to demonstrate the convergence of the proposed probabilistic critic network is given in section v further discussion on the convergence and speed of convergence of adaptive critic designs can be found in 20 moreover empirical evidence on the convergence of the adaptive critic design can be found in 3 11 19 21 fig 1 implementation of the probabilistic dhp adaptive critic for nonlinear systems v simulation example this section demonstrates the probabilistic dhp adaptive critic method on nonlinear stochastic control system the nonlinear dynamical system is described by the following equation xt sin xt 1 cos 3 xt 1 2 cos xt 1 ut t 36 the unknown nonlinear dynamics are given by h xt 1 sin xt 1 cos 3 xt 1 g xt 1 2 cos xt 1 the noise t is assumed to be sampled from a gaussian distribution n 0 0 01 this system has been used in 7 to illustrate theoretical developments for suboptimal dual adaptive control the plant is initially at time t 0 in state x 0 and the aim is to return the plant state to the origin or a state close to the origin thus a probabilistic dhp critic network that minimizes the cost function 4 is used to design the optimal probabilistic controller and derive optimal control inputs as a first step in the solution the stochastic model of the forward dynamics of the plant described by 36 is estimated by a gaussian density function as discussed in section ii b two rbf networks with 15 and 6 gaussian basis functions are used to estimate the two nonlinear functions h xt 1 and g xt 1 respectively hence the mean of the forward probabilistic model of gaussian density function is given by x t h xt 1 g xt 1 ut and the its global neural networks 2013 doi 10 1016 j neunet 2013 01 014 10 variance 2 0 0098 is computed from the residual error of the system dynamics the weight parameters of the forward gaussian probabilistic model are then kept fixed during the critic and action network training to achieve the control objective of attaining a zero state the distribution of the ideal state of the system dynamics is taken to be is xt ut xt 1 nxt 0 0 0098 similarly the ideal controller distribution is assumed to be ic ut xt 1 nut 0 0 01 the control is then initiated by another rbf network with six neurons in the hidden layer for random values of xt taken uniformly from the interval 4 4 next the critic network was also taken to be an rbf neural network with six neurons in the hidden layer the parameters of the controller and the adaptive critic networks are initialized randomly from a zero mean isotropic gaussian with unit variance scaled by the fan in of the output units the target values of the critic network is then calculated using 31 for the specified range of xt and the critic training is carried out using scaled conjugate gradient method until the weights of the network have converged the termination criterion of the training process is set to f 0 001 and 0 001 both must be satisfied within the limit of 10000 iterations here f and is the absolute difference of the error function defined as the sum of the squares of the errors between target and desired output values and absolute difference of connection weights of the network between two successive iterations respectively during training of the critic network the weights of the action network are kept fixed the output from the converged critic is then used in 35 solving for optimal control values and the action network is then trained for the same number of iterations termination criterion and training method as that of the critic network during training of the action network the weights of the critic network are kept fixed after the action network converged the critic network is trained again by adapting weights of the previously converged critic using the outputs of the converged action network the training of the critic and the action networks are alternated for 3 cycles after which all adaptation is halted and the controller network s ability to return the plant state to the origin is tested the control quality of the controller designed in the above manner is then compared with the conventional dhp adaptive critic technique 31 the same forward neural network model as that used in the above probabilistic design method is used in the conventional dhp critic to represent the forward dynamics of the system however only the deterministic forward model represented by the sum of two rbf networks x t h xt 1 g xt 1 ut is required for implementation of the conventional dhp adaptive critic method moreover for fair comparison same noise sequence initial conditions and same structure of critic and control neural networks were used during the implementation of each control method the ability of the obtained controllers from the conventional and probabilistic dhp adaptive critic methods in returning the system state from its initial value which is taken to be x 0 2 to the origin is then tested note that this initial condition was chosen arbitrarily during testing the optimal control signal ut is generated from the controller network at each time instant t based on previous state value xt 1 this optimal control signal is then forwarded to the plant of equation 36 and the system output xt is measured figure 2 shows histories of the probabilistic and conventional dhp adaptive critic states and control efforts both of the probabilistic and conventional critic methods managed to regularize the state of the system around zero as required the probabilistic dhp critic method however ensures minimal overshoot compared to the conventional dhp critic method this is expected since in the conventional critic method both the critic and controller network parameters have been tuned based on the assumption of the existence of an accurate deterministic forward model in the probabilistic critic method on the other hand optimal control law is derived such that the distance between the joint pdf of the closed loop system and an ideal joint pdf is minimized this allows considering system s uncertainty and improves the performance of the derived optimal control law vi conclusion in this paper the solution to the probabilistic dhp adaptive critic method and randomized control input design have been addressed for a class of dynamic stochastic nonlinear systems using rbf neural networks to approximate the conditional expectations of the pdfs and unknown nonlinear models a randomized control strategy has been developed which minimizes the discrepancy between the joint pdf of the closed loop system and a predetermined ideal joint pdf it has been shown that the controller design is a nonlinear optimization problem and hence need to be solved numerically a simulated example is used to illustrate the use of the randomized control algorithm as derived from the probabilistic critic and compared against its counter part of conventional critic design methods the probabilistic design of critic networks showed minimum overshoot compared to the conventional critic design method references 1 b d o anderson and j b moore linear optimal control prentice hall englewood cliffs nj 1971 2 k j astrom introduction to stochastic control theory new york academic 1970 3 s n balakrishnan and v biega adaptive critic based neural networks for aircraft optimal control journal of guidance control and dynamics 19 4 893 898 july august 1996 4 c m bishop neural networks for pattern recognition oxford university press new york n y 1995 5 l blackmore m ono a bektassov and b c williams a probabilistic particle control approximation of chance constrained stochastic predictive control ieee transactions on robotics 26 3 502 517 2010 6 m h c everdij and h a p blom embedding adaptive jlqg into lq martingale control with a completely observable stochastic control matrix ieee transactions on automatic control 41 3 424 430 1996 neural networks 2013 doi 10 1016 j neunet 2013 01 014 11 20 40 60 80 100 2 1 5 1 0 5 0 0 5 1 1 5 2 time t s ta te x states from conventional critic states from probabilistic critic a 20 40 60 80 100 3 2 1 0 1 2 time t c o n tr o l u control from conventional critic control from probabilistic critic b fig 2 nonlinear stochastic system a probabilistic and conventional critic estimated values for the state b probabilistic and conventional critic values for control 7 s g fabri and v kadirkamanathan functional adaptive control an intelligent systems approach springer verlag february 2001 8 silvia ferrari and robert f stengel model based adaptive critic designs in jennie si andrew g barto warren buckler powell and don wunsch editors handbook of learning and approximate dynamic programming chapter 3 pages 64 94 institute of electrical and electronics engineers inc canada 2004 9 n m filatov and h unbehausen adaptive preditive control policy for nonlinear stochastic systems ieee transactions on automatic control 40 11 1943 1949 1995 10 franklin a graybill matrices with applications in statistics wadsworth international group 1983 11 d han and s n balakrishnan state constrained agile missile control with adaptive critic based neural networks ieee transactions on control systems technology 10 4 481 489 2002 12 r herzallah adaptive critic methods for stochastic systems with input dependent noise automatica 43 1355 1362 august 2007 13 r herzallah and d lowe a bayesian perspective on stochastic neuro control ieee transactions on neural networks 19 5 914 924 may 2008 14 randa herzallah probabilistic control for uncertain systems dynamic systems measurement and control 134 2 021018 2012 15 randa herzallah and miroslav ka arna y fully probabilistic control design in an adaptive critic framework neural networks 24 11 1128 1135 2011 16 r howard dynamic programming and markov processes mit press cambridge massachusetts london england 1960 17 m ka rny and t v guy fully probabilistic control design systems control letters 55 4 259 265 2006 18 miroslav ka rny towards fully probabilistic control design automatica 32 12 1719 1722 1996 19 nilesh v kulkarni and k krishnakumar intelligent engine control using an adaptive critic ieee transactions on control systems technology 11 2 164 173 2003 20 george g lendaris roberto a santiago and michael s carrol proposed framework for applying adaptive critics in real time realm in proceedings of the 2002 international joint conference on neural networks ijcnn 02 pages 1796 1801 honolulu hi usa 2002 21 chuan kai lin radial basis function neural network based adaptive critic control of induction motors applied soft computing 2011 article in press 22 s meyn and p caines a new approach to stochastic adaptive control ieee transactions on automatic control 32 3 220 226 1987 23 yugang niu d w c ho and xingyu wang robust h control for nonlinear stochastic systems a sliding mode approach ieee transactions on automatic control 53 7 1695 1701 2008 24 v peterka bayesian system identification in p eykhoff editor trends and progress in system identification pages 239 304 pergamon press oxford 1981 25 v solo stochastic adaptive control and martingale limit theory ieee transactions on automatic control 35 1 66 71 1990 neural networks 2013 doi 10 1016 j neunet 2013 01 014 12 26 h van trees and k bell a bayesian approach to problems in stochastic estimation and control in bayesian bounds for parameter estimation and nonlinear filtering tracking pages 601 607 wiley ieee press 2007 27 h wang robust control of the output probabolity density functions for multivariable stochastic systems ieee transactions on automatic control 44 21032107 1999 28 h wang minimum entropy control of non gaussian dynamic stochastic systems ieee transactions on automatic control 47 2 398 403 2002 29 h wang and j zhang bounded stochastic distribution control for pseudo armax stochastic systems ieee transactions on automatic control 46 3 486 490 2001 30 hong wang and puya afshar ilc based fixed structure controller design for output pdf shaping in stochastic systems using lmi techniques ieee transactions on automatic control 54 4 760 773 2009 31 p j werbos approximate dynamic programming for real time control and neural modeling in d a white and d a sofge editors handbook of intillegent control chapter 13 pages 493 526 multiscience press inc new york n y 1992 i introduction ii problem formulation and preliminaries ii a model description and control objective ii b pdf of the system dynamics ii c review of the probabilistic dhp adaptive critic method iii solution to the problem iii a basic elements iii b desired value of the critic network iii c probabilistic control iv nonlinear randomized control algorithm based on probabilistic dhp critic methods v simulation example vi conclusion references