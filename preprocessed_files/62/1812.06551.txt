adapting bh to one and two way classified structures of hypotheses shinjini nandi and sanat k sarkar department of statistical science temple university abstract multiple testing literature contains ample research on controlling false discoveries for hypotheses classified according to one criterion which we refer to as one way classified hypotheses although simultaneous classification of hypotheses according to two different criteria resulting in two way classified hypotheses do often occur in scientific studies no such research has taken place yet as far as we know under this structure this article pro duces procedures both in their oracle and data adaptive forms for controlling the overall false discovery rate fdr across all hypotheses effectively capturing the underlying one or two way classification structure they have been obtained by using results associated with weighted benjamini hochberg bh procedure in their more general forms providing guidance on how to adapt the original bh procedure to the underlying one or two way clas sification structure through an appropriate choice of the weights the fdr is maintained non asymptotically by our proposed procedures in their oracle forms under positive regres sion dependence on subset of null p values prds and in their data adaptive forms under independence of the p values possible control of fdr for our data adaptive procedures in certain scenarios involving dependent p values have been investigated through simulations the fact that our suggested procedures can be superior to contemporary practices has been demonstrated through their applications in simulated scenarios and to real life data sets while the procedures proposed here for two way classified hypotheses are new the data adaptive procedure obtained for one way classified hypotheses is alternative to and often more powerful than those proposed in hu et al 2010 keywords one way grouped bh two way grouped bh data adaptive one way grouped bh data adaptive two way grouped bh shinjini nandi is a phd student at department of statistical science temple university email shin jini nandi temple edu sanat k sarkar is professor of department of statistical science temple university philadelphia pa 19122 email sanat temple edu this work is based on nandi s doctoral research sarkar s research was supported by nsf grants dms 1208735 and dms 1309273 1 ar x iv 1 81 2 06 55 1 v 2 st at m e 9 m ar 2 01 9 1 introduction large scale multiple testing problems often involve classifying a set of hypotheses into several groups in some cases the families groups might be formed naturally due to characteristics of the underlying scientific experiment in other situations a certain feature attributable to each hypothesis might serve as the basis of partition grouping of hypotheses due to any well defined argument whether natural or artificial benefits analyses in all such instances since the classifi cation is due to a single criterion we refer to the setup as one way classification of hypotheses multiple testing procedures adapted to such arrangement of hypotheses incorporate the infor mation of similar characteristics within each group consequently they can address problems specific to such structures they usually have more power and better control over false discoveries than their counterparts that ignore group structures one way classified hypotheses have been widely investigated in the literature existing multiple testing procedures have been revamped in pacifico et al 2004 benjamini and heller 2007 etc to accommodate such layout hu et al 2010 introduced a weighted bh procedure for one way grouped hypotheses that assigns weights to each group proportional to the number of null hypotheses in it before applying the bh procedure to the weighted hypotheses pooled together across all groups ignatiadis et al 2016 suggested a data driven weighted procedure to test similarly classified hypotheses any set of weights that depend on external covariates and satisfy some simple constraints can be considered for a testing procedure similar to the method suggested in hu et al 2010 the opti mum set of weights are chosen subject to maximization of power using data based optimization techniques in many situations a set of hypotheses might be classified according to more than one norm of classification just like one way classified hypotheses multiple interesting features or nature of the experiment may determine the norms for example brain imaging studies involving fmri data foygel barber and ramdas 2015 geographical studies involving data collected through satellite remote sensing clements et al 2014 studies in genetics involving microarray time course experiments sun and wei 2011 etc comprise of spatio temporal data the multitude of hypotheses arising out of such data can be clustered into groups formed through aggregation of neighboring spatial units and or related time points other examples can be found in bioinformatics studies involving association between genes and proteins and genomewide association studies that involve analysis of association of snps with different regions of the brain stein et al 2010 examples where more than two types of classification are imposed simultaneously on a set of hypotheses are very rare if a set of hypotheses is classified in exactly two different ways we call it a set of two way classified hypotheses in such cases researchers are most interested in the hypotheses that emerge as significant when effects due to both classifications are factored in the scope of existing multiple testing 2 procedures is limited to one way classified data and such methods are incapable to gauge the simultaneous effect of two way classification some efforts made to study such structures in stein et al 2010 sun and wei 2011 etc involve repetitive application of one way classification multiple testing procedures broadly speaking in the first step one of the two classifications is prioritized over the other considering the hypotheses as classified only due to this factor significant groups and or individual hypotheses are determined in the second step these signif icant elements are further tested for significance due to the second grouping criterion and finally the set of significant hypotheses is determined foygel barber and ramdas 2015 ramdas et al 2017 discuss multi way classification and suggest an algorithm that recursively applies bh procedure to all partitions created and selects the set of hypotheses as significant which are rejected in all partitions the goal of this article is to suggest a new data adaptive multiple testing procedure for one way classified hypotheses and broaden the scope of multiple testing procedures to two way clas sified hypotheses in section 2 we describe existing methodologies that serve as the background for developing our new methods in section 3 this is followed by description of the one way clas sification model the weighted multiple testing procedure and our proposed data adaptive version of it in section 4 we introduce the two way classification model and modify the multiple test ing procedures for one way classified hypotheses to suit to the new layout we also discuss the corresponding data adaptive procedures that can be applied to multiple hypotheses subjected to such classification we establish that our proposed data adaptive methods both one way and two way are adequate for finite sets of hypotheses at least under independence section 5 demonstrates through simulation studies that the performances of our suggested methods are superior to existing practices in most practical scenarios though our suggested data adaptive procedures are proven to control false discoveries for independent hypotheses simulations show that for suitable choices of parameters they are also applicable to positively dependent hypothe ses in certain scenarios involving high density of signals to illustrate its utility our proposed method is applied to a dataset on prevalence of microbial communities involving two way classi fied hypotheses in section 6 and its performance is compared with that of an existing method we end our paper with some concluding remarks in section 7 2 preliminaries and basic methodologies in this section we recall some existing results on weighted and data adaptive weighted p value based fdr controlling procedures for testing a set of hypotheses with no specific group structure and present them in their general forms to set the stage for developing similar procedures in the larger domain of one and two way classified hypotheses the discussions surrounding these 3 results will provide ideas on the basic methodological steps that we will take to develop our proposed newer procedures in the next section consider simultaneous testing of a set of n hypotheses h 1 hn based on their respective p values p 1 pn subject to a control over fdr e vn max rn 1 with rn and vn being the total numbers of rejected and falsely rejected null hypotheses re spectively under the following assumption assumption 1 pi u 0 1 for each i i 0 with i 0 being the set of indexes of null hypotheses regarding dependence among the p values we assume that they are positively regression dependent on subset prds of null p values as defined below generally for any set of random variable x 1 xk condition 1 a set of random variable x 1 xk is said to be positively regression dependent on a particular subset s of these random variables if e x 1 xk xi x is non decreasing in x for each xi s and for any coordinatewise non decreasing function of x 1 xk clearly independent p values are prds for examples of non independent p values satisfying condition 1 the readers are referred to benjamini and yekutieli 2001 and sarkar 2002 sarkar 2008 a weaker form of positive dependence condition with e x 1 xk xi x replaced by e x 1 xk xi x is often assumed in the literature in the context of bh type fdr controlling procedures finner et al 2009 sarkar 2008 this condition could have been used instead of condition 1 in this paper without affecting our results relying on such a condition let us now recall the definition of the bh procedure for a single group of hypotheses in its more general form in terms of weighted p values definition 1 for a set of n hypotheses suppose that the ith p value pi is assigned a non stochastic weight wi 0 for i 1 n the weighted bh procedure at level corresponding to these weights is a stepup procedure with the critical constants i n i 1 n i e it orders the weighted p values pwi wipi i 1 n in increasing order as p w i i 1 n and rejects the hypotheses h 1 h r corresponding to p w 1 pw r where r max 1 j n pw j j n provided the maximum exists otherwise it rejects none 4 result 1 the fdr of the weighted bh procedure based on p values satisfying the prds condi tion is bounded above by n i i 0 1 wi a proof of this result using techniques from sarkar 2002 is provided in appendix result 1 serves as our foundation it leads to systematic development of our proposed proce dures in their oracle forms through appropriate choice of weights suited to either one or two way classification structures levied on the set of hypotheses before we construct their appropriate data adaptive versions more specifically one can determine weights that satisfy i i 0 w 1 i n 1 and appropriately capture the underlying classification structure to develop a weighted bh pro cedure in its oracle form that controls the fdr at across all hypotheses conservatively under prds and exactly under independence before constructing an appropriate data adaptive ver sion of it for instance the choice of weights wi 0 i 0 n for all i 1 n satisfying this condition yields the single group bh procedure in its oracle form a data adaptive version of it is the one that uses the existing data to estimate 0 there are several such data adaptive single group bh procedures that have been put forward in the literature for example benjamini and hochberg 2000 storey et al 2004 sarkar 2008 and blanchard and roquain 2009 the same condition is also satisfied by the weights chosen by hu et al 2010 in their construction of a weighted bh procedure in its oracle form referred to as the one way grouped bh procedure in the context of testing one way classified hypotheses its control over the fdr under prds is also proven and can now be seen to follow from result 1 which is more general it will be revisited in the next section where we introduce a data adaptive version of it that is not only different from the data adaptive procedures originally proposed in hu et al 2010 but also more preferred in a non asymptotic setting where its fdr is theoretically shown to be controlled at least under independence the next section will also contain newer procedures in their oracle as well as data adaptive forms that we introduce in this article for testing two way classified hypotheses the non asymptotic fdr control of all these new data adaptive procedures under independence is estab lished using the following result result 2 the fdr of a data adaptive weighted bh procedure with co ordinate wise non decreasing estimated weight functions w i p 0 i 1 n is bounded above by under independence if e i i 0 1 w i p i 0 n 2 5 where w i p i 0 represents w i as a function of p i p 1 pn pi with pi 0 a proof of this result can be seen in sarkar 2008 we introduce below a newer class of estimates expressing some of the existing ones in a more general form which offers a wider scope of data dependent adaptation of the bh procedure to both one and two way group structures of hypotheses with proven non asymptotic fdr control under independence the following lemma will be useful in checking the inequality in 2 for this larger class of estimates lemma 1 let rn n i 1 i pi vn i i 0 i pi and r i n 1 n j 6 i 1 i pj for a fixed 0 1 then for any non negative real valued function f of rn we have the following result e i i 0 1 f r i n 1 n r i n 1 e f rn 3 proof the inequality in 3 follows from the fact that n 0 vn n rn and so the right hand side of that inequality is greater than or equal to e n 0 vn f rn n rn 1 e i i 0 i pi f r i n 1 i pi n r i n 1 i pi 1 which reduces to the left hand side of 3 since the pi s are independent remark 1 it is important to note as we proceed to use lemma 1 to develop procedures under more complex structures of hypotheses in the next section that r will be subscripted differently under different structural settings since its definition should correctly reflect the number of hypotheses involved 3 one way grouped bh procedure adapting the bh procedure to one way classified hypotheses using the same notations as used in hu et al 2010 let us suppose that the n hypotheses to be simultaneously tested are split into m non overlapping groups according to some criterion with ng pairs of hypothesis and the corresponding p value hgi pgi i 1 ng falling in group g and n m g 1 ng let ng 0 be the number of null hypotheses and ig 0 1 ng be 6 the corresponding set of sub indexes associated with i in group g the set of indexes of all null hypotheses among all hypotheses can then be expressed as i 0 m g 1 ig 0 let g 0 ng 0 ng be the proportion of true nulls in group g so that 0 the proportion of true nulls in the entire set of n hypotheses can be expressed as 0 m g 1 ng g 0 n one way grouped bh shortly one way gbh is an oracle procedure it is defined by hu et al 2010 as a weighted bh procedure with the weights being formulated in terms g 0 for g 1 m assuming they are known in a way that allows the bh procedure to effectively adapt to the present structural setting of the hypotheses we revisit it in the following sub section before developing our newly proposed data adaptive version of it later in this section 3 1 oracle one way gbh procedure it is a weighted bh procedure with wg g 0 1 0 1 g 0 4 being assigned as weight to pgi for each i 1 ng and g 1 m assuming these proportions are all known hu et al 2010 referred to it as simply grouped bh shortly gbh procedure but as said above we will refer to it here as one way gbh procedure since m g 1 i ig 0 w 1 g 1 1 0 m g 1 ng g 0 1 g 0 g 0 1 1 0 m g 1 ng 1 g 0 n 5 the equality in 1 is satisfied by these weights and so we have the following theorem which of course was proved in hu et al 2010 using different arguments theorem 1 one way gbh procedure controls the overall fdr under prds and assumption 1 there is a bayesian justification behind the choice of these weights as articulated by hu et al 2010 however a look at these weights from a different point of view seems to provide further insight into the effectiveness of these weights under the current setting for a group with small proportion of true nulls g 0 would be small at the same time it would have higher odds of being significant relative to other groups as measured by 1 g 0 1 0 consequently the weight associated with that group gets deflated facilitating easier rejection of its members when the weighted bh procedure is applied to all the hypotheses this sort of interpretation for the weights guides us in understanding how to estimate them differently from hu et al 2010 and in constructing a data adaptive version of one way gbh procedure that we will describe below 7 3 2 data adaptive one way gbh procedure we propose this procedure by considering the one way gbh and replacing the weight wg in it by the following w g ng rng 1 n 1 rn m 1 rng g 1 m 6 where for some fixed 0 1 rng rng ng i 1 i pgi and rn m g 1 rng we refer to this procedure as a data adaptive one way gbh procedure the idea of using this type of estimate for each wg came from its alternative interpretation noted above we estimate g 0 by g 0 ng rng 1 ng 1 which is a slight adjustment considered by storey et al 2004 from ng rng to ng rng 1 made in the estimate originally used by storey 2002 for the proportion of true nulls in the context of single group multiple testing to estimate 1 0 1 g 0 we propose estimating 1 g 0 1 0 which is the proportion of false nulls in group g among all false nulls by n rng m 1 ngrn having made a slight adjustment to its natural estimate nrng ng rn and then inverting this estimate when m 1 the w g in expression 6 reduces to that of storey et al 2004 theorem 2 the above data adaptive one way gbh procedure controls the overall fdr under independence among all p values and assumption 1 proof the theorem will follow from result 1 if we can show that the estimated weights treated as functions of all the p values used in adaptive one way gbh satisfy the two conditions in result 2 i w g is non decreasing in pgi for each g and ii the inequality in 2 holds the first condition follows by noting that both ng rng 1 and rn m 1 rng 1 g 6 g rng 1 rng are non increasing in each rng which itself is non increasing in each pgi to show that the second condition is also satisfied let us first express w g as a function of p the set of all p values i e as w g p for each g then note that if we set pgi at 0 for a particular pair g i ig 0 we get w g p g i 0 ng r i ng 1 n 1 r i ng 1 g 6 g rng m r i ng 1 1 g 1 m 8 where r i ng 1 i 6 i i pgi thus we have e m g 1 i ig 0 1 w g p g i 0 ne m g 1 i ig 0 1 f r i ng 1 g 6 g rng ng r i ng 1 7 where f x g 6 g rng x 1 x g 6 g rng m applying lemma 1 to the expectation in the right hand side of equation 7 with respect to the p values in the gth group and completing the expectation with respect to all p values we see that the left hand side of equation 7 is less than or equal to ne m g 1 rng 1 rng g 6 g rng m ne m g 1 rng 1 rn m ne rn m rn m n i e the second condition is also satisfied thus the theorem is proved 4 two way grouped bh procedure adapting the bh method to two way classified hypotheses suppose the n hypotheses can be classified simultaneously according to two criteria and can be laid out in an m n matrix with ngh 1 hypotheses at the intersection of the gth row and the hth column i e in the g h th cell of the matrix we will consider the two different scenarios one involving only one hypothesis per cell i e ngh 1 and the other involving multiple hypotheses per each cell i e ngh 1 separately in the following two sub sections this would give a clearer picture of how our proposed procedures extend from one to multiple hypotheses per cell also in each of these scenarios there is more than one choice of weights to define our proposed procedure in its oracle form before constructing its data adaptive version that captures the underlying two way structure however we will focus on one of them and formally present the corresponding oracle and data adaptive procedures as our proposed ones to use for further evaluation and simply point out the scope of deriving similar procedures using other weights 4 1 one hypothesis per cell ngh 1 let ng 0 be the number of true nulls in the gth row for g 1 m and m 0 h be the number of true nulls in the hth column for h 1 n the subsets of indexes of true nulls associated with 9 h in the gth row and g in the hth column are respectively ig 0 1 n and i 0 h 1 m consequently the set of indexes of true nulls among the entire set of hypotheses can be expressed as i 0 m g 1 ig 0 n h 1 i 0 h the proportion of true nulls in the gth row is defined as g 0 ng 0 n and that in the hth column as 0 h m 0 h m the proportion of true nulls in the entire set of n mn hypotheses is 0 m g 1 g 0 m n h 1 0 h n 4 1 1 oracle two way gbh procedure with one hypothesis per cell the hypothesis hgh at the intersection of the gth row and hth column is affected upon by its both parent row and column which motivates us to consider assigning the following weight to pgh corresponding to hgh assuming all these proportions are known wgh 1 2 1 g 0 1 g 0 1 0 1 0 h 1 0 h 1 0 1 g 1 m h 1 n 8 to simultaneously account for both row and column effects the weighted bh procedure applied to then hypotheses based on the weighted p values pwgh wghpgh for g 1 m h 1 n is one of our proposed procedures in its oracle form which we refer to as an oracle two way gbh 1 procedure this weight is a simple extension of that from one to two way classification setting if the parent row has a low proportion of true nulls g 0 it subsequently has a large odds of being significant relative to other rows as indicated by 1 g 0 1 0 this reduces the weight wgh making hgh more likely to be rejected the weight is similarly affected by the parent column we assume that both classifications have equal impacts on the individual hypothesis and so the weight is a function of the simple mean of contributions from each of parent groups noting that wgh can be expressed as w 1 gh 1 2 w 1 g 1 2 w 1 h with wg along the rows being de fined in expression 4 and wh being defined similarly along the columns as wh 0 h 1 0 1 0 h h 1 n one sees from 5 that m g 1 h ig 0 w 1 gh 1 2 m g 1 h ig 0 w 1 g 1 2 n h 1 g i 0 h w 1 h 1 2 n 1 2 n n 9 since m g 1 h ig 0 n h 1 g i 0 h thus equality in 1 is satisfied for the weights in expres sion 8 and so we can state the following theorem from result 1 without offering a proof theorem 3 oracle two way gbh 1 procedure based on the weights in 8 controls the overall fdr under prds and assumption 1 10 remark 2 the weight in 8 can be customized still satisfying 9 to suit variable influence of the row and column classifications as an example the weight can be adapted to reflect the imbalance between the number of rows and columns as follows wgh 1 m n m g 0 1 g 0 1 0 n 0 h 1 0 h 1 0 1 g 1 m h 1 n 10 these weights additionally account for the proportion of groups along the rows and also along the columns out of the total number of groups clearly if m n they reduce to those in 8 such choice of weights in adapting bh procedure to two way classification structure is not unique and there remains a scope for other choices depending on variable factors or external information 4 1 2 data adaptive two way gbh procedure with one hypothesis per cell we consider the oracle two way gbh 1 procedure in theorem 3 and estimate the weights in it by the following w gh n 1 2 1 n rng 1 rng rn m 1 1 m rmh 1 rmh rn n 1 1 g 1 m h 1 n 11 where rng rng n h 1 i pgh rmh rmh m g 1 i pgh and rn rn m g 1 rng n h 1 rmh for some fixed 0 1 the estimated weight assigned to each p value is similar to that for one way classified hypotheses however it accounts for both parent row and column effects we refer to this procedure as a data adaptive two way gbh 1 we have the following theorem as an extension of theorem 2 from one to two way classifi cation setting theorem 4 the above data adaptive two way gbh 1 procedure controls the overall fdr un der independence among all p values and assumption 1 proof this theorem can be proved based on the same arguments that were used to prove theorem 2 using result 2 first note that w 1 gh 1 2 w 1 g 1 2 w 1 h where w g n rng 1 n 1 rn m 1 rng and w h m rmh 1 n 1 rn n 1 rmh 11 from this we see that w gh is non decreasing in pgh since both w g and w h are non decreasing in pgh which can be proved exactly the way it was proved for the w g in theorem 2 moreover as proved in theorem 2 for w g using lemma 1 we have the following inequalities for w g and w h under the assumption of independence among all p values e m g 1 g ig 0 1 w g p g h 0 n e n h 1 g i 0 h 1 w h p g h 0 n from which we see that e m g 1 h ig 0 1 w gh p g h 0 1 2 e m g 1 h ig 0 1 w g p g h 0 12 e n h 1 g i 0 h 1 w h p g h 0 n i e inequality 2 in result 2 holds thus the theorem is proved remark 3 the estimate of weight considered above is stated in its simplest form like its oracle counterpart it can also be modified as w gh n 1 m n 1 n rng 1 mrng rn m 1 1 m rmh 1 nrmh rn n 1 1 g 1 m h 1 n 12 in addition to accounting for the row and column effects this expression also accounts for the difference in numbers of rows and columns and accordingly emphasizes the corresponding effects on the individual hypothesis theorem 4 can also be stated in terms of adaptive two way gbh with one hypothesis per cell in terms of these alternative weights 4 2 multiple hypothesis per cell ngh 1 let ng n h 1 ngh and n h m g 1 ngh be the total numbers of hypotheses respectively in the gth row and hth column so that n m g 1 ng n h 1 n h m g 1 n h 1 ngh 12 let ngh 0 be the number of true nulls in the g h th cell and igh 0 1 ngh be the corre sponding subset of indexes of true nulls the overall set of indexes of the true nulls is i 0 m g 1 n h 1 igh 0 the proportion of true nulls in the g h th cell of the m n matrix is gh 0 ngh 0 ngh this helps to define g 00 n h 1 ngh gh 0 n h 1 ngh 0 h 0 m g 1 ngh gh 0 m g 1 ngh and n 0 m g 1 ng g 00 n h 1 n h 0 h 0 m g 1 n h 1 ngh gh 0 4 2 1 oracle two way gbh procedure with multiple hypotheses per cell suppose pghk is the kth p value in the g h th cell and hghk is the corresponding hypothesis assuming that all the proportions mentioned above are known we consider assigning the fol lowing weights to pghk for each k 1 ngh to capture the underlying two way classification structure of the hypotheses and refer to the resulting weighted bh procedure as an oracle two waygbh 1 wgh 1 4 1 gh 0 1 gh 0 1 g 00 1 gh 0 1 0 h 0 1 g 00 1 g 00 1 0 1 0 h 0 1 0 h 0 1 0 1 13 expressing wgh as w 1 gh 1 4 w 11 gh 1 4 w 12 gh 1 4 w 1 g 1 4 w 1 h where w 1 gh gh 0 1 g 00 1 gh 0 w 2 gh gh 0 1 0 h 0 1 gh 0 wg g 00 1 0 1 g 00 and wh 0 h 0 1 0 1 0 h 0 one can see that m g 1 n h 1 k igh 0 w 11 gh w 1 2 gh w 1 g w 1 h 4 n that is the equality in 1 is satisfied by the weights in 13 therefore we can state the following from result 1 without a proof theorem 5 two way gbh with multiple hypotheses per cell based on the weights in 13 con trols the overall fdr conservatively under prds and assumption 1 13 remark 4 of course one can consider defining two way gbh procedure with multiple hypothe ses per cell based on other types of weight subject to the equality in 1 for instance following the preceding case of one hypothesis per cell in the two way classification setup a natural choice of weight assigned to hypotheses in the g h th cell would be wgh 1 2 1 g 00 1 g 00 1 0 1 0 h 0 1 0 h 0 1 0 1 14 the choice of weight for the two way gbh procedure in theorem 5 consists of an additional term that depends on the ratio of the proportion of signals in each cell to the same proportions in the parent row and column owing to unequal number of members at the intersections in the two way layout further modifications of the weights would be complicated however if there are an equal number say p 0 hypotheses at each cell we can further edit these weights in 14 as wgh 1 p m n mp g 00 1 g 00 1 0 np 0 h 0 1 0 h 0 1 0 1 15 a and those in the procedure in theorem 5 as wgh 1 p m n p gh 0 1 gh 0 1 g 00 1 gh 0 1 0 h 0 p m 1 g 00 1 g 00 1 0 p n 1 0 h 0 1 0 h 0 1 0 1 15 b 4 2 2 data adaptive two way gbh procedure with multiple hypotheses per cell consider the two waygbh 1 in theorem 5 to replace its weight wgh by w gh 1 4 1 ngh rngh 1 ng rngh rng n 1 n hrngh rn h m 1 n 1 rng ng rng 1 rn m 1 rn h n h rn h 1 rn n 1 1 g 1 m h 1 n 16 where for some fixed rngh rngh ngh k 1 i pghk rng rng n h 1 rngh rn h rn h m g 1 rngh rn m g 1 rng n h 1 rn h m g 1 n h 1 rngh it is referred to as a data adaptive two waygbh 1 14 theorem 6 the above data adaptive two waygbh 1 controls the overall fdr under inde pendence among all p values and assumption 1 proof again this theorem will be proved based on the same arguments that were used to prove theorem 4 by verifying that the conditions in result 2 are satisfied by the weight functions w gh i e it is increasing in each pghk and that the following inequality holds with pghk being set to 0 in it m g 1 n h 1 k igh 0 w 1 gh p g h k 0 n as in proving theorem 4 let us consider w gh in terms of the following representation w 1 gh 1 4 w 11 gh 1 4 w 12 gh 1 4 w 1 g 1 4 w 1 h where w 1 gh ngh rngh 1 ng 1 rng n 1 rngh w 2 gh ngh rngh 1 n h 1 rn h n 1 rngh w g ng rng 1 n 1 rn m 1 rng w h n h rn h 1 n 1 rn n 1 rn h 17 as argued before in proving theorems 2 and 4 each of the four weights in 17 can be shown to satisfy the same two properties that we intend to show for w gh in other words w gh satisfies the desired two conditions in result 2 and hence the theorem is proved remark 5 other choices of weights can be suggested as w gh n 1 2 1 ng rg 1 rg rn m 1 1 n h r h 1 r h rn n 1 1 18 as in the oracle case these weights can be further modified to be more informative if there are an equal number of hypotheses p 0 at each cell the modified choice corresponding to expression 16 would be w gh 1 m n p p 1 ngh rngh 1 ng rngh rng n 1 n hrngh rn h m 1 n 1 p m 1 rng ng rng 1 rn m 1 p m 1 rn h n h rn h 1 rn n 1 1 g 1 m h 1 n 19 and the modified choice corresponding to expression 18 is w gh n 1 m n p mp ng rg 1 rg rn m 1 np n h r h 1 r h rn n 1 1 20 5 simulations studies we carried out extensive simulation studies to investigate the performances of our proposed procedures in theorems 2 6 in terms fdr control and power expected proportion of correctly 15 rejected false nulls among all false nulls against their relevant competitors this section discusses these results 5 1 one way classified hypotheses here our study was designed to compare the performance of the data adaptive two way gbh procedure in theorem 2 with its following three relevant competitors the first two of which were considered in hu et al 2010 as extensions to one way classification setting of the single group data adaptive bh procedures proposed respectively in benjamini and hochberg 2000 and benjamini et al 2006 lsl least slope grouped bh one way gbh procedure with g 0 in equation 4 being esti mated by the following for each g lslg 0 min blg ic 1 n 1 lg i n i 1 1 pg i such that lg i lg i 1 with pg i being the ith minimum ordered p value in the gth group tst two stage grouped bh one way gbh procedure with g 0 in equation 4 being esti mated by the following for each g tstg 0 n rg n with rg being the number of rejections obtained by applying the non adaptive bh procedure to the p values in the gth group at level 1 naive adaptive bh the usual data adaptive bh with the following estimate of 0 0 n rn 1 n 1 with rn m g 1 n i 1 i pg i 21 for some fixed 0 1 applied to all hypotheses 5 1 1 simulation setting the following steps were taken to simulate values of fdr and power for the aforementioned procedures 1 generate g for g 1 m as a random sample from ber 1 2 for each g such that g 1 generate g 1 g n g as a random vector of n i i d ber 1 16 3 given g g g 1 m generate m independent n dimensional random vectors xg xg 1 xg n g 1 m as follows xg g g 1 g zg gzg 0 for some 0 g 1 having generated zg 0 zg zg 1 zgn t as a random vector of n 1 i i d n 0 1 samples for g 1 m 4 apply each procedure at fdr level 0 05 for testing hg i e xg i 0 against kg i e xg i 0 simultaneously for all g 1 m i 1 n in terms of the corresponding p values and note the proportions of false rejections among all rejections and correct rejections among all false nulls 5 repeat steps 1 4 200 times to simulate the values of fdr and power for each procedure by averaging out the corresponding proportions obtained in step 4 remark 6 our modeling of e xg in term of g g allowed us to split the state of each hypothesis at two levels group and individual enabling us to regulate the density of signals in the entire set of hypotheses using the following representation of true nulls among all hypotheses 0 1 1 1 22 5 1 2 simulation findings we fixed m 50 n 100 0 for true null hypotheses and 3 for true signals we have two main objectives in our simulation study regarding the performance of our proposed data adaptive one way gbh procedure in theorem 2 i to investigate how well it performs among all four procedures under independence when all of them are theoretically known to control fdr and ii to investigate if it can possibly control fdr under prds in view of the fact that such control is yet to be theoretically proved figures 1 2 display the findings of the first type of investigation with 0 5 figure 1 considers situations where signals are distributed evenly across all groups with 0 and i e 0 by equation 22 being allowed to vary as seen from this figure our proposed procedure performs better than the lsl and tst gbh procedures it controls fdr less conservatively and is more powerful than its counterparts at all levels of density of true signals however its performance is quite similar to the adaptive bh procedure owing to the signals being uniformly distributed across all groups since signals may potentially be non uniformly distributed across the groups we considered a scenario where only half the groups may contain significant members see figure 2 our proposed procedure is remarkably more powerful in this case than the other methods 17 figure 3 displays the findings of the second type of investigation as seen from it our proposed procedure can potentially control fdr in scenarios where concentration of signals is high and for certain choices of preferably a few such scenarios with varying density of signals uniformly distributed in all groups i e 0 and choices of have been shown in this figure 0 0 0 2 0 4 0 6 0 8 1 0 0 0 0 0 0 2 0 0 4 0 0 6 0 0 8 0 1 0 1 f d r one way adapted bh lsl gbh tst gbh adaptive bh 0 0 0 2 0 4 0 6 0 8 1 0 0 0 0 2 0 4 0 6 0 8 1 0 1 p o w e r one way adapted bh lsl gbh tst gbh adaptive bh figure 1 fdr and power comparisons of the data adaptive one way gbh proposed with other methods under independence m 50 n 100 0 0 0 0 0 2 0 4 0 6 0 8 1 0 0 0 0 0 0 2 0 0 4 0 0 6 0 0 8 0 1 0 1 f d r one way adapted bh lsl gbh tst gbh adaptive bh 0 0 0 2 0 4 0 6 0 8 1 0 0 0 0 2 0 4 0 6 0 8 1 0 1 p o w e r one way adapted bh lsl gbh tst gbh adaptive bh figure 2 fdr and power comparisons of the data adaptive one way gbh with other methods applied to independent one way classified hypotheses when true signals are unevenly distributed m 50 n 100 0 0 5 18 0 00 0 01 0 02 0 03 0 04 0 0 0 0 0 2 0 0 4 0 0 6 0 0 8 0 1 0 1 0 70 f d r one way adapted bh adaptive bh 0 00 0 01 0 02 0 03 0 04 0 0 0 0 0 2 0 0 4 0 0 6 0 0 8 0 1 0 1 0 75 0 00 0 01 0 02 0 03 0 04 0 0 0 0 0 2 0 0 4 0 0 6 0 0 8 0 1 0 1 0 80 0 00 0 01 0 02 0 03 0 04 0 0 0 0 0 2 0 0 4 0 0 6 0 0 8 0 1 0 1 0 90 a fdr comparisons 0 00 0 01 0 02 0 03 0 04 0 0 0 2 0 4 0 6 0 8 1 0 1 0 70 p o w e r one way adapted bh adaptive bh 0 00 0 01 0 02 0 03 0 04 0 0 0 2 0 4 0 6 0 8 1 0 1 0 75 0 00 0 01 0 02 0 03 0 04 0 0 0 2 0 4 0 6 0 8 1 0 1 0 80 0 00 0 01 0 02 0 03 0 04 0 0 0 2 0 4 0 6 0 8 1 0 1 0 90 b power comparisons figure 3 comparison of the data adaptive one way gbh with the naive adaptive bh method under prds condition for varying choices of 0 0 05 m 50 n 100 0 3 0 5 2 two way classified hypotheses one hypothesis per cell this section presents results associated with our simulation study that focused on investigating the performances of our proposed i oracle two way gbh 1 procedure theorem 3 against the usual single group bh procedure and the p filter algorithm foygel barber and ramdas 2015 ramdas et al 2017 in their oracle forms and ii data adaptive two way gbh 1 procedure theorem 4 against the naive data adaptive bh in terms of fdr control and power under normal distributional settings 5 2 1 simulation setting the simulation setting here is a natural extension of that in the above section more specifically it consists of the following steps 1 generate mn as an m n random matrix of i i d ber 1 rc m as a random vector of m i i d ber 1 r and n as a random vector of n i i d ber 1 c 19 2 obtain mn m 1 t n 1 m t n 23 with a b denoting the hadamard product between matrices a and b and 1 a representing the a dimensional vector of 1 s 3 given generate a random m n matrix x xgh as follows x 1 r 1 c zmn 1 r czm 1 tn r 1 c 1 mztn r cz 01 m 1 t n having generated zmn as m n random matrix zm as m dimensional random vector and zn as n dimensional random vector each comprising i i d n 0 1 and z 0 as an additional n 0 1 random variable 4 apply each procedure at fdr level 0 05 for testing hgh e xgh 0 against kgh e xgh 0 simultaneously for all g 1 m h 1 n in terms of the corresponding p values and note the proportions of false rejections among all rejections and correct rejections among all false nulls 5 repeat steps 1 4 200 times to simulate the values of fdr and power for each procedure by averaging out the corresponding proportions obtained in step 4 remark 7 note that vec x nmn vec c r where r 1 r in r 1 n 1 tn r 0 1 and c 1 c im c 1 m 1 t m c 0 1 thus the test statistics are allowed to have different types of dependence structure by appropriately setting the value of r and or c at 0 also as seen from equation 23 the hidden state of each row and each columns in terms of being significant or not has been factored into that of the hypothesis lying at their intersection this enables us to incorporate the true effect of the underlying two way classification structure into our simulation study specifically we can regulate the density of signals in the entire matrix using the following 0 1 1 rc 1 r 1 c representing the proportion of true nulls in the entire set of mn hypotheses in terms of the proportions of rows 1 r and columns 1 c containing signals 20 5 2 2 simulation findings we fixed m 50 n 100 0 for true null hypotheses and 3 for true signals comparison of oracle procedures here we wanted to make two types of investigation of oracle two way gbh 1 s performance under independence as well as under prds compared to the other oracle procedures being considered one in terms of identifying signals and the other in terms of fdr control and power the findings of these are displayed in figures 4 6 for the first type of investigation in the 50 100 matrix we arranged the significant hypothe ses in two 15 15 blocks and along the diagonal of another 15 15 block as shown in figure 4 a this arrangement helps to analyze the performance of a multiple testing procedure when the signals are dense in the two blocks as well as when they are sparse along the diagonal the performance of each method based on one trial is shown in the remaining plots in figure 4 with that being shown in figures 4 b 4 d for the independence case and in figures 4 e 4 g in the prds case when r 0 3 and c 0 4 in either case the proposed oracle two way gbh 1 procedure is seen to be successful in identifying maximum number of clustered signals and almost equally efficient as the bh procedure when the signals are sparse the performances of the p filter algorithm and the bh procedure are comparable the bh better identifies sparse signals although under independence it makes marginally higher number of false rejections than the p filter process for the second type of investigation we varied the density of true signals in the 50 100 blocks we chose different values for r and c to regulate the proportions of significant rows and columns for each choice of r c we varied rc between 0 and 1 to determine the density of signals in the significant rows and columns we evaluated the performance of each of the three methods in terms of simulated fdr and power at each level of 1 rc the results are displayed in figure 5 for the independent case and in figure 6 for the prds case our proposed oracle two way gbh 1 procedure performs better than either p filter algorithm or the bh procedure in terms of both fdr control and power performances of the p filter process and the bh procedure are comparable as the density of true signals increases the proposed method maintains control on fdr at level and is more powerful than the other two procedures 21 a signals b two way gbh c pfilter d bh e two way gbh f pfilter g bh figure 4 comparison of the proposed oracle two way gbh with one hypothesis per cell with other methods for one trial a shows the layout of the significant hypotheses b c and d show the performances of the proposed two way gbh the p filter process and the bh procedure if the hypotheses are independent e f and g show the performances of these methods for the same setup respectively if there is positive dependence among the hypotheses we choose r 0 3 and c 0 4 for the case of dependent hypotheses 22 0 0 0 2 0 4 0 6 0 8 1 0 0 0 0 0 0 2 0 0 4 0 0 6 0 0 8 0 1 0 r 0 c 0 1 rc f d r two way grouped bh p filter bh 0 0 0 2 0 4 0 6 0 8 1 0 0 0 0 0 0 2 0 0 4 0 0 6 0 0 8 0 1 0 r 0 3 c 0 7 1 rc 0 0 0 2 0 4 0 6 0 8 1 0 0 0 0 0 0 2 0 0 4 0 0 6 0 0 8 0 1 0 r 0 5 c 0 5 1 rc 0 0 0 2 0 4 0 6 0 8 1 0 0 0 0 0 0 2 0 0 4 0 0 6 0 0 8 0 1 0 r 0 8 c 0 2 1 rc a fdr comparisons 0 0 0 2 0 4 0 6 0 8 1 0 0 0 0 2 0 4 0 6 0 8 1 0 r 0 c 0 1 rc p o w e r two way grouped bh p filter bh 0 0 0 2 0 4 0 6 0 8 1 0 0 0 0 2 0 4 0 6 0 8 1 0 r 0 3 c 0 7 1 rc 0 0 0 2 0 4 0 6 0 8 1 0 0 0 0 2 0 4 0 6 0 8 1 0 r 0 5 c 0 5 1 rc 0 0 0 2 0 4 0 6 0 8 1 0 0 0 0 2 0 4 0 6 0 8 1 0 r 0 8 c 0 2 1 rc b power comparisons figure 5 comparison of the oracle two way gbh 1 procedure with other methods under inde pendence set of parameters used is m 50 n 100 r 0 c 0 r c rc comparison of data adaptive procedures here our focus had been to investigate the following two questions regarding performance of our proposed data adaptive two way gbh 1 in theorem 4 compared to its natural competitor which is naive data adaptive bh i how well it performs under independence when both are theoretically known to control fdr ii if it can it possibly control fdr under prds in view of the fact that such control is yet to be theoretically proved for both of these procedures figures 7 and 8 display the findings of these investigation figure 7 which summarizes the results associated with answering question i with 0 5 indicates that though both these methods have comparable power when the signals are uniformly distributed in all rows and columns i e when r c 0 our proposed method seems significantly more powerful in these situations we chose r 0 3 and c 0 4 to answer question ii with the related findings being summarized in figure 8 it shows that the proposed data adaptive two way gbh 1 possibly can control fdr under prds when there is a high density of signals across all row and column groups however the choice of seems crucial in such situations and its values should be chosen in the range 0 23 0 0 0 2 0 4 0 6 0 8 1 0 0 0 0 0 0 2 0 0 4 0 0 6 0 0 8 0 1 0 r 0 c 0 1 rc f d r two way grouped bh p filter bh 0 0 0 2 0 4 0 6 0 8 1 0 0 0 0 0 0 2 0 0 4 0 0 6 0 0 8 0 1 0 r 0 3 c 0 7 1 rc 0 0 0 2 0 4 0 6 0 8 1 0 0 0 0 0 0 2 0 0 4 0 0 6 0 0 8 0 1 0 r 0 5 c 0 5 1 rc 0 0 0 2 0 4 0 6 0 8 1 0 0 0 0 0 0 2 0 0 4 0 0 6 0 0 8 0 1 0 r 0 8 c 0 2 1 rc a fdr comparisons 0 0 0 2 0 4 0 6 0 8 1 0 0 0 0 2 0 4 0 6 0 8 1 0 r 0 c 0 1 rc p o w e r two way grouped bh p filter bh 0 0 0 2 0 4 0 6 0 8 1 0 0 0 0 2 0 4 0 6 0 8 1 0 r 0 3 c 0 7 1 rc 0 0 0 2 0 4 0 6 0 8 1 0 0 0 0 2 0 4 0 6 0 8 1 0 r 0 5 c 0 5 1 rc 0 0 0 2 0 4 0 6 0 8 1 0 0 0 0 2 0 4 0 6 0 8 1 0 r 0 8 c 0 2 1 rc b power comparisons figure 6 comparison of the oracle two way gbh 1 procedure for hypotheses with prds property with other methods set of parameters used is m 50 n 100 r 0 3 c 0 4 r c rc 24 0 0 0 2 0 4 0 6 0 8 1 0 0 0 0 0 0 2 0 0 4 0 0 6 0 0 8 0 1 0 r 0 c 0 1 rc f d r two way adaptive grouped bh adaptive bh 0 0 0 2 0 4 0 6 0 8 1 0 0 0 0 0 0 2 0 0 4 0 0 6 0 0 8 0 1 0 r 0 3 c 0 7 1 rc 0 0 0 2 0 4 0 6 0 8 1 0 0 0 0 0 0 2 0 0 4 0 0 6 0 0 8 0 1 0 r 0 5 c 0 5 1 rc 0 0 0 2 0 4 0 6 0 8 1 0 0 0 0 0 0 2 0 0 4 0 0 6 0 0 8 0 1 0 r 0 8 c 0 2 1 rc a fdr comparisons 0 0 0 2 0 4 0 6 0 8 1 0 0 0 0 2 0 4 0 6 0 8 1 0 r 0 c 0 1 rc p o w e r two way adaptive grouped bh adaptive bh 0 0 0 2 0 4 0 6 0 8 1 0 0 0 0 2 0 4 0 6 0 8 1 0 r 0 3 c 0 7 1 rc 0 0 0 2 0 4 0 6 0 8 1 0 0 0 0 2 0 4 0 6 0 8 1 0 r 0 5 c 0 5 1 rc 0 0 0 2 0 4 0 6 0 8 1 0 0 0 0 2 0 4 0 6 0 8 1 0 r 0 8 c 0 2 1 rc b power comparisons figure 7 comparison of the data adaptive two way gbh 1 procedure with the naive adaptive bh method under independence set of parameters used is m 50 n 100 r 0 c 0 r c rc 25 0 00 0 01 0 02 0 03 0 04 0 0 0 0 0 2 0 0 4 0 0 6 0 0 8 0 1 0 1 rc 0 70 f d r two way adaptive grouped bh adaptive bh 0 00 0 01 0 02 0 03 0 04 0 0 0 0 0 2 0 0 4 0 0 6 0 0 8 0 1 0 1 rc 0 75 0 00 0 01 0 02 0 03 0 04 0 0 0 0 0 2 0 0 4 0 0 6 0 0 8 0 1 0 1 rc 0 80 0 00 0 01 0 02 0 03 0 04 0 0 0 0 0 2 0 0 4 0 0 6 0 0 8 0 1 0 1 rc 0 90 a fdr comparisons 0 00 0 01 0 02 0 03 0 04 0 0 0 2 0 4 0 6 0 8 1 0 1 rc 0 70 p o w e r two way adaptive grouped bh adaptive bh 0 00 0 01 0 02 0 03 0 04 0 0 0 2 0 4 0 6 0 8 1 0 1 rc 0 75 0 00 0 01 0 02 0 03 0 04 0 0 0 2 0 4 0 6 0 8 1 0 1 rc 0 80 0 00 0 01 0 02 0 03 0 04 0 0 0 2 0 4 0 6 0 8 1 0 1 rc 0 90 b power comparisons figure 8 comparison of the data adaptive two way gbh 1 procedure for hypotheses with prds property with the naive adaptive bh procedure for varying choices of 0 0 05 set of parameters used is m 50 n 100 r 0 3 c 0 4 r 0 c 0 rc 26 5 3 two way classified hypotheses multiple hypotheses at each in tersection this section presents results from our simulation study carried out to investigate the perfor mances of i oracle two way gbh 1 procedure theorem 5 against the single group bh procedure in its oracle form and ii data adaptive two way gbh 1 theorem 6 against the naive adaptive bh in terms of fdr control and power under normal distributional settings 5 3 1 simulation setting we considered the case where ngh p for all g h so that our data generating process had to be designed to produce a random pair of third order tensors of dimension m n p x consisting of normally distributed test statistics and the bernoulli hidden states of the corresponding hypotheses respectively the following were the steps in that process 1 generate mnp as an m n p dimensional random tensor of i i d ber 1 rc m as a random vector of m i i d ber 1 r and n as a random vector of n i i d ber 1 c 2 obtain mnp m 1 n 1 p 1 m n 1 p with a b denoting the outer product between the vectors a and b 3 given generate x as an m n p dimensional tensor having a tensor normal distribution given below using its vectored form vec x nmnp vec p c r where r 1 r in r 1 n 1 tn r 0 1 c 1 c im c 1 m 1 t m c 0 1 and p 1 p ip p 1 p 1 tp p 0 1 let xghk be the kth layer test statistic in the g h cell they can have different types of positive dependence structures determined through appropriate choices of the correlation coefficients r c and p if there is independence along any dimension of the tensor x the corresponding correlation coefficient is set to 0 we considered the problem of testing hgh e xghk 0 against kghk e xghk 0 simultaneously for all g 1 m h 1 n k 1 p so the next two steps in our simulation study were the following 4 apply each of the aforementioned procedures at fdr level 0 05 and note down each of the the proportions of false rejections among all rejections and correct rejections among all false nulls 27 5 repeat steps 1 4 200 times to simulate the values of fdr and power for each procedure by averaging out the corresponding proportions noted in step 4 5 3 2 simulation findings we considered fixed m 50 n 100 p 10 and set at 0 for true null hypotheses and at 3 for all true signals the rest of the parameters are regulated to generate different situations and analyze the performance of our method in those settings the combination of parameters r c chosen are similar to those in the case of two way classification with one hypothesis per cell for each combination of values for r c 1 rc was varied between 0 and 1 signals are sparse for smaller values of 1 rc and the density increases with its value comparison of oracle procedures we wanted to make two types of investigation for oracle two way gbh 1 in theorem 5 under both independence and prds condition against the usual single group bh how does it perform in terms of fdr control and power the findings of these are displayed in figures 9 for the independent case and 10 for the prds case corresponding to r 0 3 c 0 4 and p 0 2 in either case the proposed method controls fdr as expected and seems to be powerful than the bh comparison of data adaptive procedures as before our focus in this case was to investigate the following two questions regarding the performance of our proposed data adaptive two way gbh 1 in theorem 6 compared to naive adaptive bh i how well it performs under independence when both are theoretically known to control fdr ii can it can possibly control fdr under prds in view of the fact that such control is yet to be theoretically proved for both of these procedures figures 11 and 12 display the findings of these investigation figure 11 which summarizes the results associated with answering question 1 with 0 5 indicates that both methods have similar performance when the signals are uniformly distributed over the m n grid which occurs when r c 0 however our proposed method is more powerful when the signals are not uniformly distributed which is displayed for the other combinations of the r c values figure 12 says as in the case of two way classification with one hypothesis per cell our proposed data adaptive two way gbh 1 can possibly control fdr under prds with choices of with a few instances being shown in the figure when there is a high density of signals across all row and column groups 6 application to microbiome data we apply our two way classified method to a microbial abundance dataset to illustrate its ap plication in real scientific problems we consider the globalpatterns dataset available through 28 0 0 0 2 0 4 0 6 0 8 1 0 0 0 0 0 0 2 0 0 4 0 0 6 0 0 8 0 1 0 r 0 c 0 1 rc f d r two way grouped bh bh 0 0 0 2 0 4 0 6 0 8 1 0 0 0 0 0 0 2 0 0 4 0 0 6 0 0 8 0 1 0 r 0 3 c 0 7 1 rc 0 0 0 2 0 4 0 6 0 8 1 0 0 0 0 0 0 2 0 0 4 0 0 6 0 0 8 0 1 0 r 0 5 c 0 5 1 rc 0 0 0 2 0 4 0 6 0 8 1 0 0 0 0 0 0 2 0 0 4 0 0 6 0 0 8 0 1 0 r 0 8 c 0 2 1 rc a fdr comparisons 0 0 0 2 0 4 0 6 0 8 1 0 0 0 0 2 0 4 0 6 0 8 1 0 r 0 c 0 1 rc p o w e r two way grouped bh bh 0 0 0 2 0 4 0 6 0 8 1 0 0 0 0 2 0 4 0 6 0 8 1 0 r 0 3 c 0 7 1 rc 0 0 0 2 0 4 0 6 0 8 1 0 0 0 0 2 0 4 0 6 0 8 1 0 r 0 5 c 0 5 1 rc 0 0 0 2 0 4 0 6 0 8 1 0 0 0 0 2 0 4 0 6 0 8 1 0 r 0 8 c 0 2 1 rc b power comparisons figure 9 comparison of the oracle two way gbh 1 procedure with the bh method applied to independent hypotheses set of parameters used is m 50 n 100 p 10 r 0 c 0 p 0 r c rc 29 0 0 0 2 0 4 0 6 0 8 1 0 0 0 0 0 0 2 0 0 4 0 0 6 0 0 8 0 1 0 r 0 c 0 1 rc f d r two way grouped bh bh 0 0 0 2 0 4 0 6 0 8 1 0 0 0 0 0 0 2 0 0 4 0 0 6 0 0 8 0 1 0 r 0 3 c 0 7 1 rc 0 0 0 2 0 4 0 6 0 8 1 0 0 0 0 0 0 2 0 0 4 0 0 6 0 0 8 0 1 0 r 0 5 c 0 5 1 rc 0 0 0 2 0 4 0 6 0 8 1 0 0 0 0 0 0 2 0 0 4 0 0 6 0 0 8 0 1 0 r 0 8 c 0 2 1 rc a fdr comparisons 0 0 0 2 0 4 0 6 0 8 1 0 0 0 0 2 0 4 0 6 0 8 1 0 r 0 c 0 1 rc p o w e r two way grouped bh bh 0 0 0 2 0 4 0 6 0 8 1 0 0 0 0 2 0 4 0 6 0 8 1 0 r 0 3 c 0 7 1 rc 0 0 0 2 0 4 0 6 0 8 1 0 0 0 0 2 0 4 0 6 0 8 1 0 r 0 5 c 0 5 1 rc 0 0 0 2 0 4 0 6 0 8 1 0 0 0 0 2 0 4 0 6 0 8 1 0 r 0 8 c 0 2 1 rc b power comparisons figure 10 comparison of the oracle two way gbh 1 procedure with the bh method when the hypotheses satisfy prds condition set of parameters used is m 50 n 100 p 10 r 0 3 c 0 4 p 0 2 r c rc 30 0 0 0 2 0 4 0 6 0 8 1 0 0 0 0 0 0 2 0 0 4 0 0 6 0 0 8 0 1 0 r 0 c 0 1 rc f d r two way adaptive grouped bh adaptive bh 0 0 0 2 0 4 0 6 0 8 1 0 0 0 0 0 0 2 0 0 4 0 0 6 0 0 8 0 1 0 r 0 3 c 0 7 1 rc 0 0 0 2 0 4 0 6 0 8 1 0 0 0 0 0 0 2 0 0 4 0 0 6 0 0 8 0 1 0 r 0 5 c 0 5 1 rc 0 0 0 2 0 4 0 6 0 8 1 0 0 0 0 0 0 2 0 0 4 0 0 6 0 0 8 0 1 0 r 0 8 c 0 2 1 rc a fdr comparisons 0 0 0 2 0 4 0 6 0 8 1 0 0 0 0 2 0 4 0 6 0 8 1 0 r 0 c 0 1 rc p o w e r two way adaptive grouped bh adaptive bh 0 0 0 2 0 4 0 6 0 8 1 0 0 0 0 2 0 4 0 6 0 8 1 0 r 0 3 c 0 7 1 rc 0 0 0 2 0 4 0 6 0 8 1 0 0 0 0 2 0 4 0 6 0 8 1 0 r 0 5 c 0 5 1 rc 0 0 0 2 0 4 0 6 0 8 1 0 0 0 0 2 0 4 0 6 0 8 1 0 r 0 8 c 0 2 1 rc b power comparisons figure 11 comparison of the data adaptive two way gbh 1 procedure with the naive adaptive bh method when the hypotheses are independent set of parameters used is m 50 n 100 p 10 r 0 c 0 p 0 r c rc 31 0 00 0 01 0 02 0 03 0 04 0 0 0 0 0 2 0 0 4 0 0 6 0 0 8 0 1 0 1 rc 0 70 f d r two way adaptive grouped bh adaptive bh 0 00 0 01 0 02 0 03 0 04 0 0 0 0 0 2 0 0 4 0 0 6 0 0 8 0 1 0 1 rc 0 75 0 00 0 01 0 02 0 03 0 04 0 0 0 0 0 2 0 0 4 0 0 6 0 0 8 0 1 0 1 rc 0 80 0 00 0 01 0 02 0 03 0 04 0 0 0 0 0 2 0 0 4 0 0 6 0 0 8 0 1 0 1 rc 0 90 a fdr comparisons 0 00 0 01 0 02 0 03 0 04 0 0 0 2 0 4 0 6 0 8 1 0 1 rc 0 70 p o w e r two way adaptive grouped bh adaptive bh 0 00 0 01 0 02 0 03 0 04 0 0 0 2 0 4 0 6 0 8 1 0 1 rc 0 75 0 00 0 01 0 02 0 03 0 04 0 0 0 2 0 4 0 6 0 8 1 0 1 rc 0 80 0 00 0 01 0 02 0 03 0 04 0 0 0 2 0 4 0 6 0 8 1 0 1 rc 0 90 b power comparisons figure 12 comparison of the data adaptive two way gbh 1 procedure and the naive adaptive bh procedure applied to hypotheses with prds property for varying choices of 0 0 05 set of parameters used is m 50 n 100 p 10 r 0 3 c 0 4 p 0 2 r 0 c 0 rc 32 the bioconductor package phyloseq the data was first studied in caporaso et al 2011 to analyze prevalence of microbial communities in different environments the data consists of 19216 microbes identified by their operational taxonomic otu numbers obtained from 26 samples of 9 different environments which includes a mock environment the environments are characterized by 7 variables classification of the microbes according to their 7 taxonomic ranks is provided along with the phylogenetic tree describing the relationships among the microbes the data records abundance patterns of each microbe across the nine sample environments since microbes closely related at the tips of the phylogenetic tree have similar characteristics it is quite likely that they have similar abundance patterns which renders a positive dependence in the data a smaller subset of this dataset consisting of data on only microbes specific to the chlamydiae bacteria taxon was studied by sankaran and holmes 2014 for their analysis they classified 21 microbes into four groups formed according to their taxonomic families and invoked the grouped bh procedure as suggested by hu et al 2010 to find which particular microbes are significantly abundant across the environments we perform the analysis on a larger scale on the entire globalpatterns dataset a linear regression is fit from data on each microbe s prevalence to the environment types each p value corresponds to a particular microbe and an environment the p value pij corresponding to the ith microbe and jth environment answers the question is the ith microbe abundantly present in the jth environment in contrast to the analysis provided in sankaran and holmes 2014 we consider the p values to be in a two way classified structure considering the microbes as individual groups furnishes m 19216 groups and together with n 9 environments we obtain a two way structure of dimensions 19216 9 instead of considering the microbes by their individual species we classify them according to their taxonomic families while higher taxonomic ranks such as taxonomic class phyla etc can also be utilized for classification of the microbes groups formed as such are larger and members have wider variety of characteristics rendering the effect due to grouping vague after adjusting for missing values and removing hypotheses with missing family labels we obtain n 120942 hypotheses classified into a grid of m 334 families along rows and n 9 environments along columns since there are unequal number of members min 1 and max 1658 in each family we use the data adaptive method for two way classified hypotheses with unequal number of hypotheses in each cell with weights as mentioned in expression 16 the method identified 7584 hypotheses as significant in comparison the adaptive bh procedure applied to the entire set of hypotheses identified 7377 hypotheses as significant 33 a discoveries made in microbial families b number of microbes discovered in each environment figure 13 comparison of the data adaptive procedure for two way classified hypotheses with multiple hypothesis per cell with the adaptive bh procedure when applied to the microbiome dataset 34 7 concluding remarks in this article we have introduced a well founded framework for one and two way classified hy potheses and an effective yet simple multiple testing method to test such hypotheses through simulations and data analysis we have established that existing multiple testing procedures that do not take into consideration the layout of the hypotheses are not sufficiently efficient to study such structures our proposed method in its oracle form controls fdr for indepen dent hypotheses as well as for positively dependent hypotheses that satisfy the prds property the corresponding data adaptive procedure maintains control on fdr non asymptotically for independent hypotheses simulation studies show that it is also capable to control fdr for hypotheses with prds property under certain conditions and when the density of signals is high the method is flexible as it adapts itself to one way or two way classification structures depending on the choice of weights we suggest generic weights suitable for such structures of hypotheses and these weights can be modified to involve additional information appropriate in any particular situation in essence this article explores an underdeveloped area of multiple testing which is adapting standard procedures to structures of hypotheses more complex than what these procedures are initially designed under to gain more efficiency occurrence of hypotheses exhibiting complex structures especially in the form of being classified according to multiple criteria is becoming more and more prevalent in modern statistical investigations with the current boom of big data producing massive amounts of data from various sources however research focused on developing methods efficiently accommodating such structural information has been taking place at a pace that is much slower than one would hope for some advances have indeed been made in one way classification setting hu et al 2010 liu et al 2016 and sarkar and zhao 2017 but there is still scope of making that advancement to a greater extent to provide a fuller coverage of that setting moreover no advancement has been made yet in the direction of adapting methods to two way classification setting and beyond this article makes a significant contribution in this broader domain there remains a scope of improving the proposed method through specific choices of weights suitable to specific scenarios and produce newer methods that can effectively and efficiently be extended possibly to multi way classification settings we conclude this section with some open issues to be resolved in future research in extending the oracle one way gbh from one to two way classification setting before constructing a data adaptive version of it we have proposed using certain specific combinations of the row and column weights see 8 10 13 14 15 a and 15 b however it would be worthwhile to investigate if these weights can be combined in an optimal manner the data adaptive procedures here have been proposed by estimating weights using storey et al 2004 type estimates of proportions of true nulls developing alternative data adaptive procedures using other types of 35 estimates of these proportions would be an important undertaking a appendix a 1 proof of result 1 the fdr of a stepup procedure based on the weighted p values and any set of critical constants c 1 cn can be expressed as follows see e g sarkar 2002 fdr n r 1 i i 0 1 r pr pwi cr r w i r 1 i i 0 pr pwi c 1 n 1 r 1 i i 0 e pr rw i r p w i i pwi cr 1 r 1 i pwi cr r 24 assuming c 0 0 and 0 0 0 with r w i representing the number of rejections in the stepup procedure based on the weighted p values pw 1 p w n p w i and the critical constants ci i 2 n with ci ic 1 i 1 n it is bounded above by i i 0 pr p w i c 1 under prds which can be shown by making use of the following observations for each i i 0 for each r 1 n 1 e pr rw i r p w i i pwi cr 1 r 1 i pwi cr r pr rw i r p w i cr pr pwi cr 1 r 1 pr pwi cr r 0 25 the first inequality in 25 follows from the following two results i pr rw i r p w i e i rw i r p w i is non increasing in pwi since i r w i r is a non increasing function of the weighted p values and the prds condition on the p values translates to that on the weighted p values and ii i pwi cr 1 r 1 i p w i cr r changes sign from to at pwi cr as p w i increases the second inequality follows from the fact that pr pwi cr 1 r 1 pr pwi cr r min r 1 c 1 1 r 1 min rc 1 1 r 0 for r 0 the expectation in 25 equals pr pwi c 1 and so with c 1 n i i 0 pr p w i c 1 i i 0 min nwi 1 n i i 0 1 wi thus result 1 is proved 36 references benjamini y and r heller 2007 false discovery rates for spatial signals journal of the american statistical association 102 480 1272 1281 benjamini y and y hochberg 2000 on the adaptive control of the false discovery rate in multiple testing with independent statistics journal of educational and behavioral statis tics 25 1 60 83 benjamini y a m krieger and d yekutieli 2006 adaptive linear step up procedures that control the false discovery rate biometrika 93 3 491 507 benjamini y and d yekutieli 2001 the control of the false discovery rate in multiple testing under dependency ann statist 29 4 1165 1188 blanchard g and e roquain 2009 adaptive false discovery rate control under independence and dependence j mach learn res 10 2837 2871 caporaso j g c l lauber w a walters d berg lyons c a lozupone p j turnbaugh n fierer and r knight 2011 global patterns of 16 s rrna diversity at a depth of millions of sequences per sample proc natl acad sci u s a 108 suppl 1 4516 4522 201000080 pii clements n s k sarkar z zhao and d y kim 2014 applying multiple testing procedures to detect change in east african vegetation ann appl stat 8 1 286 308 finner h t dickhaus and m roters 2009 04 on the false discovery rate and an asymp totically optimal rejection curve ann statist 37 2 596 618 foygel barber r and a ramdas 2015 december the p filter multi layer fdr control for grouped hypotheses arxiv e prints hu j x h zhao and h h zhou 2010 false discovery rate control with groups journal of the american statistical association 105 491 1215 1227 ignatiadis n b klaus j b zaugg and w huber 2016 data driven hypothesis weighting increases detection power in genome scale multiple testing nature methods 13 577 ep liu y s k sarkar and z zhao 2016 a new approach to multiple testing of grouped hypotheses journal of statistical planning and inference 179 1 14 pacifico m p c genovese i verdinelli and l wasserman 2004 false discovery control for random fields journal of the american statistical association 99 468 1002 1014 37 ramdas a r foygel barber m j wainwright and m i jordan 2017 a unified treatment of multiple testing with prior knowledge using the p filter arxiv e prints sankaran k and s holmes 2014 structssi simultaneous and selective inference for grouped or hierarchically structured data journal of statistical software articles 59 13 1 21 sarkar s k 2002 some results on false discovery rate in stepwise multiple testing procedures ann statist 30 1 239 257 sarkar s k 2008 on methods controlling the false discovery rate sankhya the indian journal of statistics series a 2008 70 2 135 168 sarkar s k and z zhao 2017 local false discovery rate based methods for multiple testing of one way classified hypotheses arxiv e prints stein j l x hua s lee a j ho a d leow a w toga a j saykin l shen t foroud n pankratz m j huentelman d w craig j d gerber a n allen j j corneveaux b m dechairo s g potkin m w weiner and p m thompson 2010 voxelwise genome wide association study vgwas neuroimage 53 3 1160 1174 imaging genetics storey j d 2002 a direct approach to false discovery rates journal of the royal statistical society series b statistical methodology 64 3 479 498 storey j d j e taylor and d siegmund 2004 strong control conservative point estimation and simultaneous conservative consistency of false discovery rates a unified approach journal of the royal statistical society series b statistical methodology 66 1 187 205 sun w and z wei 2011 multiple testing for pattern identification with applications to microarray time course experiments journal of the american statistical association 106 493 73 88 38 1 introduction 2 preliminaries and basic methodologies 3 one way grouped bh procedure adapting the bh procedure to one way classified hypotheses 3 1 oracle one way gbh procedure 3 2 data adaptive one way gbh procedure 4 two way grouped bh procedure adapting the bh method to two way classified hypotheses 4 1 one hypothesis per cell ngh 1 4 1 1 oracle two way gbh procedure with one hypothesis per cell 4 1 2 data adaptive two way gbh procedure with one hypothesis per cell 4 2 multiple hypothesis per cell ngh 1 4 2 1 oracle two way gbh procedure with multiple hypotheses per cell 4 2 2 data adaptive two way gbh procedure with multiple hypotheses per cell 5 simulations studies 5 1 one way classified hypotheses 5 1 1 simulation setting 5 1 2 simulation findings 5 2 two way classified hypotheses one hypothesis per cell 5 2 1 simulation setting 5 2 2 simulation findings 5 3 two way classified hypotheses multiple hypotheses at each intersection 5 3 1 simulation setting 5 3 2 simulation findings 6 application to microbiome data 7 concluding remarks a appendix a 1 proof of result 1