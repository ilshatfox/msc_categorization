sampling conditionally on a rare event via generalized splitting zdravko i botev unsw sydney australia botev unsw edu au pierre l ecuyer universite de montre al canada and inria rennes france lecuyer iro umontreal ca we propose and analyze a generalized splitting method to sample approximately from a distribution condi tional on the occurrence of a rare event this has important applications in a variety of contexts in operations research engineering and computational statistics the method uses independent trials starting from a sin gle particle we exploit this independence to obtain asymptotic and non asymptotic bounds on the total variation error of the sampler our main finding is that the approximation error depends crucially on the relative variability of the number of points produced by the splitting algorithm in one run and that this rel ative variability can be readily estimated via simulation we illustrate the relevance of the proposed method on an application in which one needs to sample approximately from an intractable posterior density in bayesian inference key words conditional distribution monte carlo splitting markov chain monte carlo rare event 1 introduction we consider the problem of generating samples from a conditional distribution when the condi tioning is on the occurrence of an event that has a small probability we have a random variable x defined over a probability space rd b p where b can be taken as the borel sigma field and x has a probability density function pdf f we assume it is easy to sample exactly from the density f the rare event on which we condition can be written in the form b s x b for an appropriately chosen measurable function s rd r called the importance function the conditional pdf is then q x f x i s x x x 1 xd 1 where i is the indicator function and p s x 2 is the appropriate unknown normalizing constant which we assume is so small that estimating it via the naive acceptance rejection method simulate x f until s x is impractical 1 ar x iv 1 90 9 03 56 6 v 1 st at m e 8 s ep 2 01 9 2 sampling from a distribution conditional on a rare event has many applications for example suppose we want to generate x from an arbitrary density proportional to p x for x rd for some known function p and that it is too hard to generate samples directly from this density since p is known we may be able to find a density f such that supx p x f x for some constant then to generate x it suffices to generate a pair of independent random variables x f and u u 0 1 conditional on the event p x f x u which is frequently a rare event kroese et al 2011 section 14 5 this fits our framework by taking s x u p x f x u another application is bayesian lasso regression park and casella 2008 in which inference requires repeated simulation of a vector of model parameters conditional on the regularization constraint 1 we give a detailed example of this in section 5 a third type of application occurs in the setting where we want to estimate the probability of the rare event and to understand under which circumstances the rare event is likely to occur a popular method to estimate is importance sampling and the optimal way to do it is to sample under a density f proportional to the original density conditional on the rare event and then adjust the estimator using a likelihood ratio tuffin et al 2014 botev and ridder 2014 botev et al 2011 this also fits our framework in this context it can be very useful to sample from the conditional density to get insight on how the rare event occurs for instance in a network with unreliable links one may want to sample random configurations of all the links conditionally on a failure of the network to better understand what typically makes the network fail botev et al 2014 2012 the sampling methods examined in this paper are based on the generalized splitting gs algo rithm of botev and kroese 2012 for drawing a collection of random vectors whose distribution converges to a target distribution with pdf of the form 1 to apply gs we first select an increas ing sequence of levels 0 1 for the importance function s this can be done in pilot runs via a run botev and kroese 2012 the algorithm uses a branching process that favors states x having a large value of s x by resampling them conditional on staying above the current threshold thus splitting those states into new copies and then discarding those that do not reach the next level at the end the states that have reached the last level are retained this process is replicated several times independently and all the retained states are collected to form an empirical version of the target conditional distribution there are many ways of choosing the total number of replications or trials for example one can fix them in advance to a constant n or one can repeat the procedure until n trials have provided at least one retained state each or until the total number of retained states is more than t or until a certain computing budget cpu time has elapsed in the latter case one can either complete the current trial or discard it or just take the states retained so far from that trial botev and l ecuyer sampling via splitting 3 there is a large variety of splitting type or interacting particle algorithms to sample the state of a markov chain approximately from its steady state distribution conditional on a rare event see for example glasserman et al 1999 ce rou et al 2005 ce rou et al 2012 l ecuyer et al 2009 andrieu et al 2010 bre hier et al 2016 and the references given there the analysis of these algorithms consists in most cases in proving their unbiasedness when estimating the expectation of a random variable that can be nonzero only when the rare event occurs estimating the probability of the rare event is a special case of this and sometimes showing their asymptotic efficiency when the probability of the rare event decreases toward zero dean and dupuis 2009 in this paper we are interested in the different problem of bounding the difference between the exact conditional distribution and the distribution obtained by picking a state from the sample returned by the splitting algorithm we do this for some variants of the gs method of botev and kroese 2012 l ecuyer et al 2018 proved that this method provides an unbiased estimator of the expected value of a cost function but also showed that a state picked at random from the set of retained states at the last level does not follow the true conditional distribution in general on the other hand the distance between the two distributions converges to zero when the number of replicates increases toward infinity the aim of the present paper is to study how this convergence occurs and to establish explicit non asymptotic risk bounds on the total variation tv error between the two distributions their mean absolute value and the expectation of the tv error in the case when it is a random variable our bounds are expressed in terms of simple mathematical expectations that can be estimated easily from the simulation output we provide convergence results for two versions of the gs algorithm in both we assume that whenever a trial returns no state from the rare event set an empty trial we discard it and try again in the first version we run gs until we have n non empty trials for some fixed n 0 we prove that the tv distance between the true conditional distribution and the distribution of a state picked at random from the retained states from this gs version is bounded by c 1 n where c 1 is an unknown constant that can be estimated from the simulation output in the second version we run gs until the total number of retained states exceeds t for some fixed positive integer t for this version we show that the convergence rate is of the form c 2 t t 3 2 o t 3 2 where the quantity c 2 t is bounded uniformly in t and can be estimated from the simulation output the derivation of these bounds is made possible thanks to the fact that gs produces independent trials each one starting from a single particle and this permits us to use results from renewal theory for our analysis typically approximate simulation from the target pdf 1 is accomplished using markov chain monte carlo mcmc for example jones and hobert 2001 taimre et al 2019 while mcmc sampling can be simple to implement it still poses the challenge of analyzing its output and 4 deciding how close the sampling or empirical distribution is to the desired target distribution jones and hobert 2001 the reason for this difficulty is that mcmc generates a sequence of dependent random vectors y 1 y 2 typical graphical diagnostic tools like autocorrelation plots are heuristics which do not easily provide precise qualitative measure of how close the simulated random variables follow the target distribution also we have to choose from an infinite number of possible one dimensional plots in contrast our bounds on the tv error present a more rigorous and theoretically justified convergence assessment than the autocorrelation plots typically used in mcmc the rest of the paper is organized as follows in section 2 we recall the gs algorithm used in this paper in section 3 we define our versions of gs used for sampling conditional on the rare event in section 4 we state our main new results on the convergence of the distance between the empirical and true conditional distributions and bounds on this distance the proofs are given in the appendix in section 5 we show how our methodology can be applied in a practical setting namely to sample approximately from the posterior density of the bayesian lasso in this example we show how the non asymptotic risk bounds can be used to assess convergence and to estimate the error committed when using gs to sample from the conditional distribution we also compare the simulation accuracy of gs with that of the sequential monte carlo method ce rou et al 2012 2 background on generalized splitting we recall the gs method for estimating the rare event probability in 2 this method is a simple generalization of the classical multilevel splitting technique for rare event simulation kahn and harris 1951 glasserman et al 1999 garvels et al 2002 l ecuyer et al 2009 our background material here is similar to the one given in l ecuyer et al 2018 the idea of gs is to define a discrete time markov chain with state y which evolves via a branching type random mechanism that pushes it toward a state corresponding to y b s y in 1 to estimate the rare event probability 2 via gs we first need to choose 1 an integer s 2 called the splitting factor and 2 an integer 0 and real numbers 0 1 for which l p s y l s y l 1 1 s for l 1 except for which can be larger than 1 s these l s represent the levels of the splitting algorithm in section 5 we give particular choices of s and that are relevant to our examples botev and l ecuyer sampling via splitting 5 for each level l we construct a markov chain whose stationary density is equal to the density of y conditional on s y l a truncated density given by ql y f y i s y l p s y l 3 note that q 0 f and q q we denote by l l the transition kernel of this markov chain l dy x represents the probability that the next state is in dy when the current state is x there are many ways of constructing this markov chain and l a practical example using gibbs sampling will be given in section 5 algorithm 1 gs sampler 1 require s 1 generate a vector y from its unconditional density f if s y 1 then return x and m 0 else x 1 y this state y has reached at least the first level for l 2 to do xl list of states that have reached the level t for all y xl 1 do set y 0 y we will simulate s steps from this state for j 1 to s do sample y j from l 1 dy y j 1 if s y j l then add y j to xl this state has reached the next level return the list y x of retained states and its cardinality m the original gs algorithm is summarized in algorithm 1 and is also given in l ecuyer et al 2018 the algorithm returns a list y of retained states that belong to b y s y as well as the size of this list this list is a multiset in the sense that it may contain the same state more than once the list y can be empty and its cardinality m 0 the o ring symbol in the notation is a reminder that the size of the set can be zero in the remainder of this article we define y and m as the versions of y and m conditional on m 1 let a denote a algebra of borel measurable subsets of rd for some of our results a will be a more restricted class than the borel subsets of rd algorithm 1 can be used to estimate p y a for any a a via the unbiased estimator p a h a s 1 4 6 where h a y a is the number of states y y that belong to a in practice one will replicate this algorithm several times and take the average the unbiasedness is implied by the following lemma proved in l ecuyer et al 2018 lemma 1 l ecuyer et al 2018 for any measurable function rd 7 r and any mea surable subset a b we have egs y y y i y a s 1 e y i y a 5 where the expectation on the left hand side is with respect to y from algorithm 1 and the expectation on the right hand side is with respect to the original density f by taking as the identity function in 5 we obtain that p a in 4 is unbiased for p a egs h a egs y y i y a s 1 p y a and therefore egs p a egs h a s 1 p y a moreover since egs m s 1 p y b and a b we have that egs h a egs m p y a y b p y a p y b 3 sampling conditionally on a rare event when estimating an expectation as in 5 an empty list y poses no problem the unbiased estimator just takes the value 0 in that case but for our purpose of sampling from a conditional distribution we insist that there are no empty sets of retained states to make sure that the set of retained states is non empty we modify the original gs so that each trial returns at least one state whenever a gs run returns an empty list we simply discard it and try again this gives algorithm 2 algorithm 2 gs sampler 2 require s 1 repeat run algorithm 1 until m 0 return the list y x of retained states and its cardinality m y does this algorithm still provide an unbiased estimator an important observation is that if we replace y by y in 5 the equality is no longer true that is we get a biased estimator of the botev and l ecuyer sampling via splitting 7 expectation on the right however our main goal here is not to estimate this expectation but to sample approximately from the conditional distribution and we will analyze methods that use algorithm 2 for this purpose as mentioned earlier there are several ways of doing it in this paper we examine the following two versions a run a fixed number n of iid replicates of algorithm 2 and b perform replicates until there are more than t retained states in total these two approaches are detailed in algorithms 3 and 4 respectively in both cases at the end we collect all the retained states in a multiset y for the first version the cardinality of the returned set y is at least n whereas in the second case it is at least t and n t is the random number of calls to algorithm 2 we summarize these two versions as follows algorithm 3 sampling an empirical distribution from n iid non empty gs replications require s 1 and n for i 1 n do run algorithm 2 to obtain the list yi of size mi return the empirical distribution q n of the states in the set y y 1 yn algorithm 4 sampling an empirical distribution with more than t retained states require s 1 and t i 0 and t 0 0 repeat i i 1 run algorithm 2 to obtain the list yi and its cardinality mi ti ti 1 mi until ti t return n t i and the empirical distribution q n t of the set of states y y 1 yn t note that q n or q n t is a random distribution it is the distribution conditional on y the unconditional distribution of a state obtained by generating y and then selecting one state randomly from y is also of interest this is the a priori distribution of a state sampled from q n or q n t but before we run the gs algorithm to construct y we will denote these two unconditional distributions by qn a e q n a for algorithm 3 and qt a e q n t a for algorithm 4 8 for all a a where the expectation is with respect to the realization of y we saw earlier that e h a e m p y a y b now let h a y a be the number of states returned by algorithm 2 that belong to a we have e h a e h a m 0 e h a p m 0 likewise e m e m p m 0 therefore e h a e m e h a e m p y a y b we also know that q n a and q n t a converge with probability one to e h a e m when n and when t respectively from the strong law of large numbers applied to the numerator and the denominator thus they converge almost surely to the desired conditional probability q a p y a y b 4 convergence analysis we now analyze the convergence of the empirical distribution of the retained states q n or q n t as well as its expected i e unconditional on y version qn or qt to the true conditional distribution q the aim is to obtain non asymptotic or risk bounds on the distance between q and the empirical distribution and its expected unconditional version for a given class a of measurable sets we consider the three error criteria 1 the tv error between the expected unconditional distribution qn and q that is sup a a qn a q a this error measures the size of the bias of q n as an estimator of the true q 2 the worst case mean absolute error of the conditional distribution q n defined as sup a a e q n a q a 3 the random tv error supa a q n a q a of the conditional distribution q n and its expected value e sup a a q n a q a by permuting the positions of the expectation absolute value function and the supremum sup e supe e sup we find that the three error criteria dominate each other as follows expected tv error e sup a a q n a q a sup a a mean absolute error e q n a q a tv error sup a a e q n a q a botev and l ecuyer sampling via splitting 9 in other words the expected tv error is the most stringent of these three errors in fact the expected tv error of the empirical distribution is so stringent that it does not converge unless the class of sets a is restricted to ensure convergence in section 4 2 we will take a to be a restricted class of subsets in contrast the tv and mean absolute errors do not require any restrictions on the class a and for these error criteria we simply take a to be the class of all borel subsets of rd 4 1 convergence of total variation and mean absolute errors let m e m and var m denote the expectation and variance of m which is the output of either algorithm 3 or algorithm 4 in this section we state theorems giving non asymptotic bounds on the tv error and the worst case mean absolute error the proofs of the following results are in the appendix theorem 1 sampling via n iid runs of gs the tv error is bounded as sup a qn a q a c 1 n 1 where c 1 var m var m e m 2 m 2 the worst case mean absolute error is bounded as sup a e q n a q a c 1 n n 1 2 where c 1 n em 2 3 em 4 n m 1 is bounded uniformly in n the terms c 1 and c 1 n in these bounds can be estimated from the simulation output theorem 2 sampling until gs returns t states in this case the tv error is bounded as sup a qt a q a c 2 t t m 3 2 where c 2 t 4 3 e m 3 e m 2 m e m 2 t m 3 is bounded uniformly in t the worst case mean absolute error is bounded as sup a e q n t a q a c 2 t t m 1 2 where c 2 t em 2 1 2 m 1 em 2 m 3 2 t 1 2 is also uniformly bounded in t again the terms c 2 t and c 2 t can be estimated easily by simulation it suffices to estimate em 2 and em 3 by their empirical versions the constant m in t m 3 2 could be absorbed into c 2 t but we choose not to do this because we want to be able to compare qt and qn on a common scale where n the simulation effort of algorithm 3 and t m the average simulation effort of algorithm 4 for large t are the same the key point to notice is that we get a better rate for the bound for qt than for qn 10 in the next result we obtain an improved convergence rate of o 1 t 2 but at the price of introducing in the bound an o exp t term for some 0 which is hard to estimate this term converges exponentially fast in t so it is asymptotically negligible when t but it is not necessarily negligible for a given finite t so we have an asymptotically better bound that we cannot easily estimate in practical settings we may prefer theo t m 3 2 bound from theorem 2 that we can more easily estimate to the o t m 2 bound that we cannot completely estimate theorem 3 sampling until gs returns t states asymptotic version we have sup a qt a q a c 3 t m 2 o exp t where 0 is a typically unknown constant and c 3 e m 2 m 1 2 r 2 m 3 with r em 2 m 2 m this result does not include a statement about the mean absolute error because the bounds of the mean absolute errors in theorems 1 and 2 already converge at the optimal asymptotic rate and thus cannot be improved 4 2 convergence of the empirical conditional distribution q n we now examine the convergence of the tv error between the empirical distribution q n and q when n this distribution is random and any realization is discrete with finite support so obviously it cannot converge to q in tv with a taken as all the borel sets because by taking a as the finite set y we get q n a 1 for any n but q a 0 assuming that q has a density thus as mentioned previously we necessarily have to restrict the class a we start by giving conditions for tv convergence with probability 1 under the following restrictions on the class a assumption 1 suppose that one of the following two conditions holds 1 a is a class with finite vapnik chervonenkis vc dimension or 2 a is the class of all convex sets in rd and the transition kernel in algorithm 1 has a probability density l y x theorem 4 almost sure tv convergence under assumption 1 we have almost sure tv convergence sup a a q n a q a 0 with probability 1 when n botev and l ecuyer sampling via splitting 11 the notion of vc dimension is discussed for example by vapnik 2013 roughly speaking it measures the flexibility of a class of subsets to correctly classify data defined over rd and in our context it measures the complexity of the class of sets a sets with higher vc dimension are more complex note that the class of convex sets has an infinite vc dimension which is why the second option in assumption 1 requires the extra regularity condition on the transition kernel this condition will be satisfied if l is the transition kernel of a gibbs sampler but will not be satisfied for the kernel of a metropolis hastings sampler kroese et al 2011 equation 6 3 page 226 note that the condition does not require that we have a closed form simple formula for the transition density l y x it only requires that it exists our next result proof in appendix a 5 provides bounds on the expected tv error of the empirical distribution where a is a class of sets with a finite vc dimension theorem 5 bound on expected tv for empirical distribution suppose the class a has finite vc dimension v then the expected tv error made by using the empirical distribution q n as an approximation of q is bounded as follows e sup a a q n a q a var m m n 2 v ln 2 n e m 2 lnm m n 1 v n where 1 1 v n ln 2 v v ln 2 n v e m 2 v ln 2 n e m 2 lnm 1 ln 2 n is bounded uniformly in v n as an example let a b y rd a y b represent a rectangle in rd and suppose a is the class of all rectangles in rd then v 2 d sauer 1972 if a that is a as the class of one sided intervals of the form b then v d 1 in this case the previous theorem can provide a bound on the expected value of the kolmogorov smirnov statistic ks n e sup x rd q n x x q x x 6 we will use this type of error bound in section 5 2 when we assess the quality of our approximate sampling from a bayesian posterior using the metric entropy of the class a it is also possible to obtain a bound without the logarithmic growth term ln n ln m in theorem 5 and to get an expected tv bound that depends solely on the relative second moment of m 12 theorem 6 second bound on expected tv for empirical distribution let be the number of levels in algorithm 1 with splitting factor s and suppose that a has vc dimension v then the empirical distribution q n satisfies e sup a a q n a q a var m m n s 1 4 v e m 2 m n 2 v n s where 2 2 v n s d logs ne k 1 1 sk ln 2 2 nv 1 ln v 1 v 1 ln 2 s 2 k 1 2 is bounded uniformly in v n s unfortunately as we shall see in section 5 2 the constant 2 in this bound is much larger than 1 in theorem 5 as a result n has to be impractically large for the above bound to beat the simpler bound in theorem 5 nevertheless the result is still of theoretical interest as it shows that the rate of convergence in expectation of the tv distance can be improved from o ln n n to the canonical rate of o 1 n in addition the term e m 2 lnm m 2 in theorem 5 does not appear in theorem 6 remark 1 simplifications due to existence of a density if the transition density l x y is available in closed form and easily evaluated we can do much better by dropping the restrictions that the class a has a finite vc dimension instead if x y x y is a transition density with stationary pdf q then we can define the empirical density q n x 1 tn y y x y so that we can use sheffe s identity devroye and lugosi 2001 theorem 5 1 to simplify the uniform deviation over the class b of borel measurable sets 2 sup a b a q n x dx q a rd q n x q x dx therefore the bound on the expected tv distance simplifies as follows 2 e sup a b a q n x dx q a e rd 1 nm n y y x y 1 nm y y x y dx e rd 1 nm y y x y q x dx 1 m n var m rd var x y dx thus provided the integrated variance var x y dx can be estimated easily this bound can be used as a simpler alternative to theorem 5 we do not pursue this possibility further in this article botev and l ecuyer sampling via splitting 13 5 numerical example bayesian lasso in this section we consider an application of the splitting sampler in algorithm 2 to the problem of posterior simulation in bayesian inference we estimate the bounds in theorems 1 to 6 in order to assess the convergence of algorithms 3 and 4 this convergence assessment can be used to either assess whether any bayesian credible intervals are reliably estimated from the simulation output or to rank the performance of implementations that use different markov chain kernels l the markov chain that yields the smallest tv error will be the preferred one 5 1 approximate posterior simulations via splitting one of the simplest and most widely used linear regression models for data y y 1 yn is the bayesian lasso park and casella 2008 in which the point estimator of the regression coefficient 1 d rd is defined as the minimizer of the constrained least squares problem min y x 22 subject to 1 where 1 x is a matrix with d columns predictors 2 the term 1 1 d is the least absolute shrinkage and selection operator lasso and 3 0 is the lasso regularization parameter in a bayesian linear regression one wishes to estimate the posterior distribution of the parameters 2 that is the distribution of 2 conditional on the data y and the constraint 1 since this posterior distribution is intractable one typically approximates it by sampling random pairs from the posterior pdf q y y x 2 i 2 i 1 d 2 d 7 where a x denotes the multivariate normal pdf with mean zero and covariance matrix evaluated at x b the factor 2 results from using an uninformative prior for the scale and c i 1 d 2 d is the prior of uniform over the feasible set note that unlike the more common laplace prior used in the bayesian lasso park and casella 2008 here the prior enforces the constraint on directly to sample a new state k k during the course of splitting we need to simulate from a transition density l k k k 1 k 1 which is stationary with respect to the density 3 we simulate a move from k 1 k 1 to k k as follows given k 1 we sample 1 2 k gamma n 1 2 y x k 1 2 2 2 which is the gamma distribution with mean n 1 y x k 1 22 and shape parameter n 1 2 given k k 1 we simulate k via a hit and run gibbs sampler kroese et al 2011 page 240 14 in other words the new state is k k 1 d where d is a point uniformly distributed on the surface of the d dimensional unit hyper sphere and the scalar is simulated according to d k k 1 d k k 1 q k 1 d k y q k d k y d the conditional pdf d k 1 is a univariate truncated normal which can be simulated easily botev and l ecuyer 2017 as a concrete illustration we use the diabetes dataset park and casella 2008 consisting of n 442 patients for each patient we have a record of d 10 predictor variables age sex body mass index and 7 blood serum measurements so that x is a matrix of size 442 10 and a response variable which measures the severity of nascent diabetes we fix 1200 which corresponds to the lasso regularization parameter value used by park and casella 2008 to simulate from the bayesian posterior 7 we ran algorithm 2 with splitting factor s 100 and n 104 using the following 4 levels 1 2 3 4 1907 1368 1230 1200 to obtain the multiset y the first three levels were chosen so that j 0 01 for j 1 3 the values for 1 were selected by running the adaptive pilot algorithm in botev et al 2012 algorithm 4 the marginal empirical distribution of each coefficient j is illustrated in figure 1 as a boxplot age sex bmi bp tc ldl hdl tch ltg glu 200 0 200 400 600 figure 1 empirical marginal distributions of the ten coefficients j corresponding to the ten predictors sampled approximately from 7 for comparison the unconstrained ordinary least squares solution for each j is displayed as a circle botev and l ecuyer sampling via splitting 15 5 2 convergence assessment via theoretical bounds using the output of algorithm 2 from the previous section we calculated point estimates of the unknown terms c 1 c 1 n c 2 t c 2 t c 3 1 2 appearing in theorems 1 through 6 note that all the unknown terms depend on moments of m for example some of the point estimates of the moments of m are em em 2 5 9 71 figure 2 shows the estimates of c 1 n c 2 t t m 3 2 and c 3 t m 2 which bound the tv error see theorems 1 to 3 on a common scale with t n 5 9 since m e m 5 9 101 102 103 104 105 106 10 12 10 10 10 8 10 6 10 4 10 2 100 figure 2 comparison of three bounds on the tv error c 1 n c 2 t t m 3 2 and c 3 t m 2 where t n m there is one major take home message from figure 2 namely that algorithm 4 sampling to exceed t states simulates more closely in terms of tv error from the target distribution q than algorithm 3 n iid non empty replications of course the downside of using algorithm 4 is that the number of trials n t is random with expectation t m for large t in addition reading off from figure 2 we can see that if we run algorithm 4 with t 5 9 103 then the tv error between qt and q is estimated as less than 10 3 using the non asymptotic bound c 2 t t m 3 2 and as less than 10 5 using the asymptotic bound c 3 t m 2 it is asymptotic because we ignored the asymptotically negligible o exp t term in theorem 3 as for the mean absolute error the left pane of figure 3 shows the estimated bounds c 1 n n 1 2 and c 2 t t m 1 2 given in theorems 1 and 2 respectively using t n m it is clear that the bound c 2 t t m 1 2 is always smaller note that both bounds are asymp totically equivalent to first order as n becomes larger the two bounds converge to each other 16 101 102 103 104 105 106 10 3 10 2 10 1 100 101 102 104 106 108 1010 10 4 10 3 10 2 10 1 100 101 figure 3 left estimates of the worst case mean absolute error right estimates of the expected tv error based on the mean absolute error in this example we again conclude that algorithm 4 sample more than t m n states is a better performing sampler than algorithm 3 n iid non empty runs next we apply the results of theorems 5 and 6 to bound the expectation of the kolmogorov smirnov statistic ks n given in 6 let b 5 n and b 6 n be the upper bounds on 6 derived in theorems 5 and 6 respectively here v d 1 11 the right pane of figure 3 shows the estimated bounds on the value of ks n there are a number of observations to be made first we can see that for the range of the plot b 5 n o ln n n yields a better risk bound than b 6 n o 1 n despite the superior convergence rate of b 6 this is because as mentioned previously the constant 2 in theorem 6 is much larger than 1 in theorem 5 in fact the cross over for which ultimately b 6 n b 5 n happens for n 10 19 not shown on figure 3 second from the right pane of figure 3 we can see that the expectation of the kolmogorov smirnov statistic is indeed the most stringent error criteria because we need a very large n to guarantee an acceptably small error at least n 107 to make b 5 n smaller than 10 2 third we observe that since the transition kernel l has a density it is the transition pdf of a gibbs markov chain theorem 4 ensures the almost sure convergence of the empirical tv uniformly over the class a of all convex subsets that is supa a q n a q a 0 with probability one finally we note that our convergence results do not theoretically quantify the speed of conver gence of the markov chains induced by the kernels l this dynamics is captured by the moments of m which we estimate empirically but not theoretically to analyze theoretically the growth of the moments of m will require an analysis of the speed of convergence of all markov chains used in algorithm 1 botev and l ecuyer sampling via splitting 17 5 3 comparison with sequential monte carlo for rare event estimation in the bayesian context the rare event probability p 1 is the normalizing constant of the posterior 7 also called the model evidence or marginal likelihood which is of importance in model selection and inference from equation 4 above we can see that an estimator of using n 104 independent runs of algorithm 1 is m 1 m n ns 1 with relative error var m n we obtained the estimate of 2 4 10 8 with estimated relative error of 3 6 for completeness and as a benchmark to our results we compared the performance of algo rithm 1 with the popular sequential monte carlo smc method for rare event estimation of ce rou et al 2012 as described on top of page 798 column 1 for the smc we used the same intermediate thresholds 1 2 3 4 1907 1368 1230 1200 in the notation on page 798 we have ak 1 k and a total simulation effort of 6 106 particles to estimate this is roughly twice the average simulation effort for n runs of algorithm 1 which is approximately n k 1 1 k 3 4 106 despite this the relative error of the smc estimator of was estimated as 12 or about three times larger than the relative error of the observation that the gs algorithm can under certain conditions perform better than sequential monte carlo methods is known and is already explained in botev and kroese 2012 briefly the gs sampler is expected to outperform standard smc methods when the markov chain induced by l converges slowly to its stationary pdf 3 conversely when the markov chain at each level l mixes fast the particles follow the law of 3 almost exactly then smc methods are to be preferred as previously explained botev and kroese 2012 unlike standard smc methods the gs sampler does not have a bootstrap resampling step which is advantageous when the tran sition kernel l fails to create enough diversity in the samples bootstrap resampling reduces the diversity this advantage however disappears if the markov chains at each level are mixing fast and as a result using a fixed number of particles at each level ce rou et al 2012 page 798 leads to superior accuracy compared to using a random number of particles as in the gs algorithm 1 6 summary and conclusions we presented two different implementations of the generalized splitting method that can be used to simulate approximately from a conditional density in high dimensions in the first implementation we construct an empirical distribution q n from n iid non empty replications of the gs sampler algorithm 1 in the second implementation we construct an empirical distribution q n t by running algorithm 2 until we have more than t states in total in both implementations q n and q n t and their respective expectations qn and qt aim to approximate the true distribution q to assess the quality of the approximations we derived non asymptotic bounds on three different error criteria 1 the total variation errors of qn and qt widely used in mcmc convergence 18 analysis 2 the mean absolute errors of q n and q n t and 3 the expected total variation error of q n the main take away messages are as follows first the gs sampler in algorithm 4 which samples until we have more than t states in total converges faster than the gs sampler in algorithm 3 which samples n iid non empty replications second the proposed splitting samplers provide a simple qualitative method for assessing whether they are sampling accurately from the target distribution any unknown constants and terms in the theoretical error estimates depend only on moments of the number m of particles which can be readily estimated from the simulation output this allows us to make qualitative statements such as choose n 103 to approximately obtain a total variation error of less than 10 3 or to rank the performance of different implementations of the algorithms finally we have confirmed that under certain conditions generalized splitting can be more effi cient than sequential monte carlo in estimating rare event probabilities this observation extends not just to estimation but approximate sampling as well because if an algorithm is not the most efficient in estimating a rare event probability then it will also not be the most efficient algorithm to simulate conditional on the rare event appendix a proof of the theorems we first recall the working notation let a be a class of measurable sets for any a a and i 1 let mi and hi a be the cardinalities of yi and of yi a these are the realizations of m and h a for replication i of algorithm 2 let m n and h n a be the respective averages of these n realizations and let m egs m so that the target distribution is q a egs h a m for simplicity of notation unless there is ambiguity we henceforth drop the gs subscripts from egs when we draw an y from q n it belongs to a with probability h n a m n since y is not empty m n 0 note that h a m for all a a and that mi and hi take their values in 1 s 1 in particular in algorithm 3 we obtain the independent sets y 1 y 2 yn of states y we can re label all the states y such that y 1 y 1 y t 1 yn y tn 1 1 y tn in this way y t t 1 2 is a discrete time regenerative process with regeneration times 0 t 0 tn and tour lengths mi ti ti 1 j 1 2 n with stationary measure q a with this notation we have that n t min n tn t in algorithm 4 moreover if we define the number of renewals in 0 t as n t n t 1 max n tn t with n 0 0 then n t t 0 is a renewal process asmussen 2008 chapter 5 botev and l ecuyer sampling via splitting 19 since n t n t 1 is a stopping time with respect to the filtration generated by the sequence of iid random variables mi i 1 by the wald identity we have e tn t e n t e mi we define q n a h n a m n and q n t a 1 tn t n t i 1 hi a with zi a hi a miq a wald s identity also gives e n t i 1 zi a e n t e zi a 0 8 remark 2 elapsed time process note that the autocorrelation plot of the age or current lifetime process e t t tn t may be used as a graphical tool to diagnose the convergence of y t t 1 2 to its stationary distribution q a because asmussen 2008 page 170 proposition 1 3 sup a p y t a q a 2 sup a p e t a p e a in other words ensuring the convergence of the markov process e t t 0 to its stationary measure is sufficient to ensure the convergence of y t t 1 2 to its stationary measure a 1 proof of theorem 1 first we prove the bound on the tv error using the identity meketon and heidelberger 1982 page 180 x y x y y 2 2 x y 2 x y 2 9 with 0 we have that e h n a m n h a m e z n a m e z n a m n m n m 2 m 2 cov z n a m n m 2 z a m was used e m n m 2 m 2 cov z n a m n m 2 var m cov z 1 a m 1 nm 2 hence using the fact that cov z 1 a m 1 2 var m 1 var z 1 a var m 1 em 2 we obtain sup a qn a q a var m supa cov z 1 a m 1 nm 2 var m var m em 2 nm 2 we can thus clearly see that the convergence of qn a depends on the relative error of m next we prove the bound for the mean absolute value first note that the term e z n a v n 2 where vk mk m can be bounded using the independence of the pairs zi a vi and ezi a evi 0 as follows ez 2 n a v 2 n i j k l e zizjvkvl n 4 3 n 2 2 n n 4 max i j k l e zizjvkvl 3 em 4 n 2 therefore using the triangle inequality we have me q n a q a e z n a z n a m n m m n m n 1 e z n a e z n a m n m ez 2 n a e z n a m n m 2 z a m em 2 n 3 em 4 n 20 a 2 proof of theorem 2 recall that n t n t 1 is a stopping time let r t tn t 1 t so that r t er t me n t t using wald s identity 8 we can write qt a q a e n t k 1 hk a mkq a tn t e n t k 1 zk a tn t e 1 t n t k 1 zk a 1 r t t e 1 1 r t t 1 z t a where z t a 1 t n t k 1 zk a then using the fact that 1 1 r t t 1 we obtain the uniform bound qt a q a 1 t e r t 1 r t t z t a 1 t e r t z t a er 2 t e z 2 t a t er 2 t t e n t e z 2 a t 2 e r 2 t t 3 2 e z 2 a e n t t e r 2 t t 3 2 em 2 m 1 r t t where in the third last line we used wald s second moment identity see 10 below to finish the proof we apply lorden s moment inequalities e r t e m 2 m and e r 2 t 4 e m 3 3 m see lorden 1970 to obtain sup a qt a q a 4 3 e m 3 e m 2 m e m 2 t m 3 t m 3 2 to prove the bound for the mean absolute value we proceed as follows again using 1 1 r t t 1 we have e qt a q a e 1 t n t k 1 zk a 1 r t t e 1 t n t k 1 zk a 2 e n t ez 2 a t ez 2 a tm e m 2 e z 2 a t 2 m 2 em 2 tm em 2 tm where in the second last line we used cauchy s inequality and wald s second moment identity and in the last line we used lorden s inequality and the sub additivity of the square root a 3 proof of theorem 3 denote r t er t and r em 2 m 2 m and note that under the condition emp 5 for some p 0 we have glynn 2006 r t r o 1 tp 3 botev and l ecuyer sampling via splitting 21 using 0 1 1 x 1 x x 2 for x 0 we have the error bound qt a q a e 1 1 r t t 1 z t a triangle ineq er t z t a t e 1 1 r t t 1 r t t z t a er t z t a t er 2 t z t a t 2 er t n t k 1 zk a t 2 e r 4 t e z 2 t a t 2 since em 5 by lorden s inequality we have er 4 t and the second term is o t 5 2 because by wald s second moment identity e z 2 t a e n t t 2 e z 21 a 1 r t t e m 2 t o 1 t 10 for the first term we verify that ea t er t n t k 1 zk a satisfies the renewal equation ea t u va t with va t e r t z 1 a e r t r z 1 a see awad and glynn 2007 page 25 the latter is bounded uniformly in a va t e r t r z 1 a m 1 t e r t r z 1 a m 1 t e m 1 r z 1 a m 1 t e r t m 1 r z 1 a m 1 t e m 1 r m 1 m 1 t e r t m 1 r m 1 m 1 t for the first term we obtain e m 1 r m 1 m 1 t o e mp 5 m t tp 3 o 1 tp 3 for the second term e r t m r m m t e r t m r m m t 2 e r t m r m m t 2 sup s t 2 r s r e m sup s t 2 r s r e m m t 2 o 1 tp 3 o 1 tp 4 hence we have the convergence uniformly in a ea t e m 1 1 2 r m 1 z 1 a 2 m o 1 tp 2 e m 1 1 2 r m 21 2 m o 1 tp 2 putting it all together we obtain sup a qt a q a e m 1 2 r m 2 2 mt 2 o t 5 2 o 1 tp 4 where r em 2 m 2 m the exponential convergence comes from the fact that emp for all p 0 because m s 1 is always bounded this completes the proof notational setup for proofs of theorems 4 and 5 we now introduce some working notation that will apply to both the proofs of theorem 4 and 5 define f y b 1 btn 0 1 tn there exists an a a bi i xi a xi y 11 22 to be a class of binary functions on 0 1 tn such that each element of f corresponds to an intersection of y with a set a in a without any conditions on the class of sets a the cardinality of f y grows exponentially in tn and we have f y 2 tn for any n let sa yi n i 1 max y 1 yn a y 1 yn a a denote the vapnik chervonenkis shatter coefficient vapnik 2013 loosely speaking the shatter coefficient sa y is the maximum number of distinct ways in which the point set y can intersect with elements of a sauer s lemma sauer 1972 tells us that if a is a class of sets with vapnik chervonenkis dimension v then the shatter coefficient eventually grows polynomially in n instead of exponentially sa yi n i 1 ne v v n v 12 let 1 n be iid random variables with marginal distribution p 1 1 2 let y be a sample independent from y that can in principle be obtained from another n independent calls to algorithm 1 the y sample is a ghost sample gine and zinn 1984 that does not need to be constructed but is only used in symmetrization inequalities we denote quantities computed using y by h i y i m i t i etc for example h is an independent ghost copy of h we will make use of two symmetrization inequalities by gine and zinn 1984 the first will be used in theorem 5 e sup a a h n a eh a e sup a a 1 n n i 1 i hi a h i a 13 the second will be used in theorem 4 p sup a a h a eh a 2 p sup a a h a h a 2 for 8 sup a a var h a 14 a 4 proof of theorem 4 if we can show that with gn o n limn gn n 0 p sup a a q n a q a c 1 exp c 2 n 2 o n 15 for some constants c 1 c 2 0 then the fact that n 1 p supa a q n a q a for any 0 implies the almost sure convergence result of the theorem to show 15 we will use the symmetrization inequality 14 and the simple union bound p x y p x p y 1 0 1 16 using these two inequalities we have p sup a a q n a q a 16 p m n m m 2 p supa a h n a eh a m 2 hoeffding s with m s 2 exp nm 2 2 2 s 2 p supa a h n a eh a m 2 thus in order to show 15 we only need an exponentially decaying bound on the second term with 1 m 2 p sup a a h n a eh a 1 14 2 p sup a a h n a h n a 1 2 for 1 8 em 2 n n 8 em 2 21 botev and l ecuyer sampling via splitting 23 recall that 1 n is an iid random sample with p 1 1 2 and that each h i is an independent ghost copy of hi by symmetry each hi a h i a has the same distribution as i hi a h i a using this observation we obtain with 2 1 2 and for n 2 em 2 22 p sup a a h n a h n a 2 p sup a a 1 n n i 1 i hi a h i a 2 16 p sup a a 1 n n i 1 ihi a 22 p sup a a 1 n n i 1 ih i a 22 2 p sup a a 1 n n i 1 ihi a 22 the proof will be complete if we show that 3 2 2 p supa a 1 n n i 1 ihi a 3 c 1 exp c 2 n 23 o n for some constants c 1 c 2 0 let na y a y 1 y tn a a be the number of different subsets of the points in y that can be picked out by the class a so that by definition the shatter coefficient is sa tn maxy na y similarly let na y a y a a where y y 1 y ns 1 is the collection of all ns 1 potential states from n independent runs of splitting l ecuyer et al 2018 section 3 1 in practice only a small fractions of these trajectories survive till the final level of splitting clearly na y na y a well known result see rao 1962 and devroye et al 2013 theorem 13 13 asserts that when the y s have a density and a is the class of all convex sets then ena y 2 o n 17 thus by conditioning on y we can write p sup a a 1 n n i 1 ihi a 3 e p sup a a 1 n n i 1 ihi a 3 y union bound e na y sup a a p 1 n n i 1 ihi a 3 y hoeffding s with ihi a s e na y sup a a 2 exp 2 n 23 2 s 2 using y y ns 1 2 exp n 23 2 s 2 e na y 17 2 exp n 23 2 s 2 o n this completes the proof 24 a 5 proof of theorem 5 our proof follows as closely as possible the proof of the classical vc inequalities as described in devroye and lugosi 2001 theorems 3 1 3 2 applying the triangle inequality and then the symmetrization inequality 13 yields e sup a a q n a q a e sup a a h n a m n h n a m e sup a a h n a m q a 1 m e m n m 1 mn e sup a a n i 1 i hi a h i a var m m n 1 mn e y k y k where we define the conditional expectation y k y k e sup a a n i 1 i hi a h i a y y and the last expectation is with respect to let a a be the collection of sets such that all intersections with the pointset y 1 y tn y 1 y tn are represented once and any two sets in a are different observe that y k y k e sup a a n i 1 i hi a h i a y y and that a sa tn t n let x g denote the sub gaussian coefficient of the random variable x in other words the moment generating function of x satisfies e exp tx exp t 2 x 2 g 2 t we shall next use the maximal inequality emax k k xk 2 ln 2 k max k k xk g 18 for a finite index set k which holds even if the xk s are dependent we will also make use of the property that k wkxk 2 g k w 2 k xk 2 g 19 whenever x 1 x 2 are independent conditioning on all y k y k and taking expectation over we obtain y k y k e sup a a n k 1 k hk a h k a maximal ineq 18 2 ln 2 sa tn t n sup a a n k 1 k hk a h k a g sauer s lemma 12 19 2 ln 2 tn t n e v v sup a a n k 1 k hk a h k a 2 g 2 ln 2 tn t n e v v sup a a n k 1 hk a h k a 2 2 ln 2 tn t n e v v n k 1 mi m i 2 botev and l ecuyer sampling via splitting 25 therefore using the bound ri mi m i r 2 n 1 n i r 2 i er 2 n ln tn t n ln 2 n er 2 n e 1 n i r 2 i ln 1 n i ri cauchy schwartz ln 2 n er 2 n e 1 n i r 2 i 1 2 ln 1 n i r 2 i jensen s on x ln x ln 2 n er 2 n e 1 2 n i r 2 i ln r 2 i ln 2 n er 2 er 2 ln r 2 ln 2 n em 2 2 em 2 ln m we obtain e sup a a q n a q a var m m n e 2 ln 2 v ln tn t n v v ln v r 2 n m n var m m n 2 ln 2 v v ln 2 n v em 2 vem 2 lnm m n var m m n 2 v ln 2 n e m 2 lnm m n 1 v n where 1 v n ln 2 v v ln 2 n v em 2 v ln 2 n em 2 lnm 1 ln 2 n this completes the proof of the theorem a 6 proof of theorem 6 we need to introduce more working notation first recall a number of standard definitions define the weighted lp p metric on the probability space rd b p via the norm x p rd x pdp 1 p p 1 let f be a class of functions an cover of f under the lp p metric is a finite set c f 1 f c with cardinality c such that for every f f there exists an fk c that satisfies f fk p let c be the cover with the smallest cardinality the cardinality of the smallest cover of f under the metric lp p is called the covering number and is denoted by n f lp p we will write n f lp p n f if the metric is clear from the context recall that y with tn nm n y is the agglomeration of all the final states from n independent runs of algorithm 1 since the splitting factor is s we have m s denote 2 n 1 n n j 1 m 2 j we know that n s for each index k 0 1 k dlogs s n e we define a cover as follows conditional on y we let c k be the smallest ns k cover of the set of functions f y h 1 a hn a a a under the weighted metric with norm h 2 1 n n j 1 h 2 j observe that the zero vector is within ns 0 radius of all elements of f y and that c 0 0 is an minimal ns 0 cover that is n ns 0 f y 1 further the minimal cover for 0 1 n contains all the elements of f y that is n ns k f y f y c k conditional on y we let h h 1 hn be the vector with components hj a k yj i y k a each hj is a conditional version of hj for a given 1 n let h correspond to the vector maximizing sup a a n k 1 khk a n k 1 kh k h 26 then for k 0 k let hk be the vector in the minimal cover c k which is closest to h that is hk h 2 infh c k h h 2 ns k it follows that h hk k k 1 hk hk 1 by the triangle inequality we have hk hk 1 2 hk h 2 hk 1 h 2 s 1 ns k hence h k k 1 hk hk 1 k k 1 hk hk 1 k k 1 max h c k h c k 1 h h 2 s 1 ns k h h 20 taking expectation with respect to and using the maximal inequality 18 we thus obtain e max h c k h c k 1 h h 2 s 1 ns k h h 2 ln 2 c k 1 c k s 1 ns k therefore taking expectation over y e h s 1 k k 1 s ke n 2 ln 2 c k 2 s 1 k k 1 s k 2 e ln 2 c k 2 2 n finally from the triangle inequality and symmetrization inequality 13 we have e sup a a q n a q a e sup a a h n a m n h n a m e sup a a h n a m q a 1 m e m n m 2 mn e sup a b n i 1 ihi a var m m n s 1 2 2 mn k k 1 s k e 2 n ln 2 n 2 ns k f y it thus remains to bound the metric entropy lnn n f y for a fixed y let c 1 c n be minimal covers corresponding to each of the n binary function classes j 1 n f yj b 1 bmj a a bi i y i a y i yj this implies that for any bj f yj there exists an sj c j such that bj sj 2 1 mj mj k 1 b k j s k j 2 then the set s 1 j s mj j sj c j j 1 n is an n cover of f y to see this note that for any h f y we have hj b 1 j b mj j bj f yj j 1 n and by the cauchy schwartz inequality h m 1 k 1 s k 1 mnk 1 s k n 2 2 1 n n j 1 hj mj k 1 s k j 2 1 n n j 1 m 2 j 1 mj mj k 1 b k j s k j 2 1 n n j 1 m 2 j 1 mj mj k 1 b k j s k j 2 1 n n j 1 m 2 j 1 mj mj k 1 b k j s k j 2 2 n 2 botev and l ecuyer sampling via splitting 27 using the inequality of haussler 1995 lnn f yj ln e v 1 v ln 2 e 2 0 1 21 for the cover number of a class of sets a with vc dimension v we thus have the bound on the metric entropy of f y lnn n f y n j 1 lnn f yj 21 n ln e v 1 v ln 2 e 2 0 1 hence combining all the results so far we obtain the upper bound for e supa a q n a q a var m m n s 1 2 2 mn k k 1 e 2 n ln 2 n 2 ns k f y sk s 1 4 vem 2 m n k k 1 ln 2 2 nv ln e v 1 v ln 2 es 2 k sk s 1 4 vem 2 m n 2 v n hence the result of the theorem follows references andrieu c doucet a holenstein r 2010 particle markov chain monte carlo methods journal of the royal statistical society series b 72 1 33 asmussen s 2008 applied probability and queues volume 51 springer science business media awad hp glynn pw 2007 on the theoretical comparison of low bias steady state simulation estimators acm transactions on modeling and computer simulation 17 1 4 issn 1049 3301 url http dx doi org http doi acm org 10 1145 1189756 1189760 botev zi kroese dp 2012 efficient monte carlo simulation via the generalized splitting method statistics and computing 22 1 1 16 botev zi l ecuyer p 2017 simulation from the normal distribution truncated to an interval in the tail 10 th eai international conference on performance evaluation methodologies and tools valuetools 2016 23 29 acm url http dx doi org doi 10 4108 eai 25 10 2016 2266879 botev zi l ecuyer p tuffin b 2011 an importance sampling method based on a one step look ahead density from a markov chain proceedings of the 2011 winter simulation conference wsc 528 539 ieee botev zi l ecuyer p tuffin b 2012 dependent failures in highly reliable static networks proceedings of the 2012 winter simulation conference wsc 1 12 ieee url http dx doi org 10 1109 wsc 2012 6465033 botev zi ridder a 2014 variance reduction wiley statsref statistics reference online 1 6 botev zi vaisman s rubinstein ry l ecuyer p 2014 reliability of stochastic flow networks with contin uous link capacities proceedings of the 2014 winter simulation conference 543 552 ieee press 28 bre hier ce gazeau m goudene ge l lelie vre t rousset m 2016 unbiasedness of some generalized adaptive multilevel splitting algorithms the annals of applied probability 26 6 3559 3601 ce rou f legland f del moral p lezaud p 2005 limit theorems for the multilevel splitting algorithm in the simulation of rare events m e kuhl fba n m steiger joines ja eds proceedings of the 2005 winter simulation conference 682 691 ieee press ce rou f moral pd furon t guyader a 2012 sequential monte carlo for rare event estimation statistics and computing 22 3 795 808 dean t dupuis p 2009 splitting for rare event simulation a large deviation approach to design and analysis stochastic processes and their applications 119 562 587 devroye l la szlo g ga bor l 2013 a probabilistic theory of pattern recognition new york springer verlag devroye l lugosi g 2001 combinatorial methods in density estimation springer new york garvels mj ommeren jkv kroese dp 2002 on the importance function in splitting simulation trans actions on emerging telecommunications technologies 13 4 363 371 gine e zinn j 1984 some limit theorems for empirical processes the annals of probability 12 4 929 989 glasserman p heidelberger p shahabuddin p zajic t 1999 multilevel splitting for estimating rare event probabilities operations research 47 4 585 600 glynn pw 2006 simulation algorithms for regenerative processes henderson sg nelson bl eds simula tion 477 500 handbooks in operations research and management science amsterdam the nether lands elsevier chapter 16 haussler d 1995 sphere packing numbers for subsets of the boolean n cube with bounded vapnik chervonenkis dimension journal of combinatorial theory series a 69 2 217 232 jones gl hobert jp 2001 honest exploration of intractable probability distributions via markov chain monte carlo statistical science 16 4 312 334 kahn h harris te 1951 estimation of particle transmission by random sampling national bureau of standards applied mathematics series 12 27 30 kroese dp taimre t botev zi 2011 handbook of monte carlo methods volume 706 john wiley sons l ecuyer p botev zi kroese dp 2018 on a generalized splitting method for sampling from a conditional distribution proceedings of the 2018 winter simulation conference 1694 1705 ieee press l ecuyer p legland f lezaud p tuffin b 2009 splitting techniques rubino g tuffin b eds rare event simulation using monte carlo methods 39 62 wiley chapter 3 lorden g 1970 on excess over the boundary the annals of mathematical statistics 41 2 520 527 meketon ms heidelberger p 1982 a renewal theoretic approach to bias reduction in regenerative simula tions management science 26 173 181 botev and l ecuyer sampling via splitting 29 park t casella g 2008 the bayesian lasso journal of the american statistical association 103 482 681 686 rao rr 1962 relations between weak and uniform convergence of measures with applications the annals of mathematical statistics 33 2 659 680 sauer n 1972 on the density of families of sets journal of combinatorial theory series a 13 1 145 147 taimre t kroese dp botev zi 2019 monte carlo methods wiley statsref statistics reference online doi 10 1002 9781118445112 stat 03619 pub 2 tuffin b saggadi s l ecuyer p 2014 an adaptive zero variance importance sampling approximation for static network dependability evaluation computers and operations research 45 51 59 vapnik v 2013 the nature of statistical learning theory springer verlag