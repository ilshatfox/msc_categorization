localglmnet interpretable deep learning for tabular data ronald richman mario v wu thrich version of july 26 2021 abstract deep learning models have gained great popularity in statistical modeling because they lead to very competitive regression models often outperforming classical statistical models such as generalized linear models the disadvantage of deep learning models is that their solutions are difficult to interpret and explain and variable selection is not easily possible because deep learning models solve feature engineering and variable selection internally in a nontransparent way inspired by the appealing structure of generalized linear models we propose a new network architecture that shares similar features as generalized linear models but provides superior predictive power benefiting from the art of representation learning this new architecture allows for variable selection of tabular data and for interpretation of the calibrated deep learning model in fact our approach provides an additive decomposition in the spirit of shapley values and integrated gradients keywords deep learning neural networks generalized linear model regression model variable selection explainable deep learning attention layer tabular data exponential dis persion family shapley values shapley additive explanations shap integrated gradients 1 introduction deep learning models celebrate great success in statistical modeling because they often provide superior predictive power over classical regression models this success is based on the fact that deep learning models perform representation learning of features which means that they bring features into the right structure to be able to extract maximal information for the prediction task at hand this feature engineering is done internally in a nontransparent way by the deep learning model for this reason deep learning solutions are often criticized to be non explainable and interpretable in particular because this process of representation learning is performed in high dimensional spaces analyzing bits and pieces of the feature information recent research has been focusing on interpreting machine learning predictions in retrospect see e g friedman s partial dependence plot pdp 10 the accumulated local effects ale method of apley zhu 4 the locally interpretable model agnostic explanation lime introduced by ribeiro et al 23 the shapley additive explanations shap of lundberg lee 18 or the marginal attribution by conditioning on quantiles macq method proposed by merz et al 20 pdp ale lime and shap can be used for any machine learning method such as random forests boosting or university of the witwatersrand ronaldrichman gmail com risklab department of mathematics eth zurich mario wuethrich math ethz ch 1 ar x iv 2 10 7 11 05 9 v 1 cs l g 2 3 ju l 20 21 neural networks whereas macq requires differentiability of the regression function which is the case for neural networks under differentiable activation functions for a review of more gradient based methods we refer to merz et al 20 we follow a different approach here namely we propose a new network architecture that has an internal structure that directly allows for interpreting and explaining moreover this internal structure also allows for variable selection of tabular feature data and to extract interactions between feature components the starting point of our proposal is the framework of general ized linear models glms introduced by nelder wedderburn 21 and mccullagh nelder 19 glms are characterized by the choice of a link function that maps the regression function to a linear predictor and thus leading to a linear functional form that directly describes the in fluence of each predictor variable on the response variable of course this generalized linear form is both transparent and interpretable to some extent our architecture preserves this lin ear structure of glms but we make the coefficients of the linear predictors feature dependent too such an approach follows a similar strategy as the resnet proposal of he et al 12 that considers a linear term and then builds the network around this linear term the lassonet of lemhadri et al 16 follows a similar philosophy too by performing lasso regularization on network features both proposals have in common that they use a so called skip connection in the network architecture that gives a linear modeling part around which the network model is built our proposal uses such a skip connection too which provides the linear modeling part and we weight these linear terms with potentially non linear weights this allows us to generate non linear regression functions with arbitrary interactions in spirit our non linear weights are similar to the attention layers recently introduced by bahdanau et al 6 and vaswani et al 28 attention layers are a rather successful new way of building powerful networks by extracting more important feature components from embeddings by giving more weight attention to them from this viewpoint we construct network regression attention weights that provide us with a local glm for tabular data and we therefore call our proposal localglmnet these regression attention weights also provide us with a possibility of explicit variable selection which is a novel and unique property within network regression models moreover we can explicitly explore in teractions between feature components we mention that a similar approach is studied by ahn et al 3 in bayesian credibility theory where the credibility weights are modeled by attention weights there is another stream of literature that tries to choose regression structures that have inter pretable features e g the explainable neural networks xnn and the neural additive models nam make restrictions to the structure of the network regression function by running differ ent subsets of feature components through separated parallel networks see vaughan et al 29 and agarwal et al 2 the drawback of these proposals is that representation learning can only occur within the parallel networks our proposal overcomes this issue as it allows for gen eral interactions we also mention richman 24 who extends the xnn approach by explicitly including linear features to a combined model called caxnn another interpretable network approach is the tabnet proposal of arik pfister 5 tabnet uses networks to create attention to important features for the regression task at hand however this proposal has the drawback that it may lead to heavy computational burden our localglmnet approach overcomes the limitations of these explainable network approaches as we will see below our proposal is computationally efficient and it leads to a nice explanation 2 in the sense that we can also interpret our model in terms of shapley 25 values we refer to lundberg lee 18 and sundararajan najmi 26 for shap in fact we could also argue that our idea makes the shap interpretation to a regression model assumption this will be further explored in section 2 4 below organization of this manuscript in the next section we introduce and discuss the local glmnet we therefore first recall the glm framework which will give us the right starting point and intuition for the localglmnet in section 2 2 we extend glms to feed forward neu ral networks that form the basis of our regression attention weight construction and section 2 3 presents our localglmnet proposal that combines glms with regression attention weights section 2 4 discusses the localglmnet and it relates our proposal to shap section 3 presents two examples a synthetic data example and a real data example the former will give us a proof of concept a verification is obtained because we know the true data generating mechanism in the synthetic data example moreover in section 3 2 we discuss how the localglmnet allows for variable selection which is a novel and unique property within network regression modeling section 3 3 explains how we can find interactions in section 3 4 we present a real data example section 3 5 discusses variable importance and in section 3 6 we discuss how categorical feature components can be treated within our proposal finally in section 4 we conclude 2 model architecture 2 1 generalized linear model the starting point of our proposal is a glm which typically is based on the exponential disper sion family edf glms have been introduced by nelder wedderburn 21 and mccullagh nelder 19 and the edf has been analyzed in detail by barndorff nielsen 7 and j rgensen 14 the present paper uses the notation and terminology of wu thrich merz 31 and for a detailed treatment of glms and the edf we also refer to chapters 2 and 5 of that latter reference assume we have a datum y x v with a given exposure v 0 a vector valued feature x rq and a response variable y following a member of the single parameter linear edf having density w r t to a finite measure on r y f y v exp y v a y v 2 1 with dispersion parameter 0 canonical parameter where the effective domain r is a non empty interval with cumulant function r and with normalizing function a by construction of the edf the cumulant function is a smooth and convex function on the interior of the effective domain this then implies that y has first and second moments we refer to chapter 2 in wu thrich merz 31 e y and var y v 0 a glm is obtained by making a specific regression assumption on the mean of y namely choose a strictly monotone and continuous link function g r r and assume that 3 the mean of y given x satisfies x 7 g g x 0 x 0 q j 1 jxj 2 2 with glm regression parameter 1 q rq bias intercept 0 r and where denotes the scalar product in the euclidean space rq this glm assumption implies that the canonical parameter takes the following form on the canonical scale of the edf 1 g 1 0 x where 1 is the canonical link of the chosen edf 2 1 the glm regression function 2 2 is very appealing because it leads to a linear predictor x 0 x after applying the link function g to the mean x and the regression parameter j directly explains how the individual feature component xj influences the linear predictor x and the expected value x of y respectively our goal is to benefit from this transparent structure as far as possible 2 2 fully connected feed forward neural network the neural network extension of a glm can be obtained rather easily by allowing for feature engineering before considering the scalar product in the linear predictor 2 2 a fully connected feed forward neural ffn network builds upon engineering feature information x through non linear transformations before entering the scalar product a composition of ffn layers performs these non linear transformations choose a non linear activation function m r r and integers dimensions qm 1 qm n the m th ffn layer of a deep ffn network is defined by the mapping z m rqm 1 rqm 2 3 x 7 z m x z m 1 x z m qm x having neurons z m j x 1 j qm for x x 1 xqm 1 rqm 1 z m j x m w m 0 j w m j x m w m 0 j qm 1 l 1 w m l j xl for given network weights w m j w m l j 1 l qm 1 r qm 1 and bias w m 0 j r a ffn network of depth d n is obtained by composing d ffn layers 2 3 to provide a deep learned representation we set input dimension q 0 q z d 1 rq rqd 2 4 x 7 z d 1 x z d z 1 x this qd dimensional learned representation z d 1 x rqd then enters a glm of type 2 2 providing ffn network regression function x 7 g g x 0 z d 1 x 2 5 4 with glm regression output parameter 1 qd rqd and bias 0 r from 2 5 we see that the raw feature x is first suitably transformed before entering the glm structure the standard reference for neural networks is goodfellow et al 11 for more insight interpretation and model fitting we refer to section 7 2 of wu thrich merz 31 2 3 local generalized linear model network the disadvantage of deep representation learning 2 4 is that we can no longer track how individual feature components xj of x influence regression function 2 5 because the composition of ffn layers acts rather as a black box e g in general it is not clear how each feature component xj influences the response x whether a certain component xj needs to be included in the regression function or whether it could be dropped because it does not contribute this is neither clear for an individual example x locally nor at a global level the key idea of our localglmnet proposal is to retain the glm structure 2 2 as far as possible but to let the regression parameters j j x become feature x dependent we call regression parameter if it does not depend on x and we call x regression attention if it is x dependent our proposal of the localglmnet architecture can be interpreted as a local glm with network learned regression attention as we are going to model the regression attentions j x r by networks strictly speaking we typically lose the linearity if we let j x be feature dependent however if this dependence is smooth we have a sort of a local glm parameter which justifies our terminology see also section 2 4 below assumptions 2 1 localglmnet choose a ffn network architecture of depth d n with input and output dimensions being equal to q 0 qd q to model the attention weights rq rq 2 6 x 7 x z d 1 x z d z 1 x the localglmnet is defined by the additive decomposition x 7 g g x 0 x x 2 7 network architecture 2 7 is a ffn network architecture with a skip connection firstly feature x is processed through the deep ffn network providing us with learned representation x rq and secondly x has a direct link to the output layer skipping all ffn layers providing an untransformed linear term x the localglmnet then scalar multiplies these two different components see 2 7 in the next section we give extended remarks and interpretation this model can be fitted to data by state of the art stochastic gradient descent sgd methods using training and validation data for performing early stopping to not over fit to the training data for details we refer to goodfellow et al 11 and section 7 2 in wu thrich merz 31 2 4 interpretation and extension of localglmnet we call 2 7 a localglmnet because in a small environment b x around x we may approx imate regression attention x x b x by a constant regression parameter giving us the interpretation of a local glm network architecture 2 7 can also be interpreted as an attention mechanism because j x decides how much attention should be given to feature value xj 5 yet another interpretation of 2 7 is given in terms of shapley 25 values we briefly discuss shap to make this link for references on shap we refer to lundberg lee 18 sundararajan najmi 26 and aas et al 1 shapley 25 values have their orgin in cooperative game theory by providing a fair allocation of a common gain to individual players this concept has been translated to deep learning models by aiming at attributing a joint response x to individual feature components xj so that we receive an additive decomposition x 0 q j 1 jxj 2 8 where j describes the contribution of component xj of x to response x this attribution is required to fulfill certain axioms of fairness see lundberg lee 18 a critical issue in the cal culation of these attributions is the combinatorial complexity which can be very computational for this reason approximations have been proposed e g under the assumption of independence between feature components a fair allocation in 2 8 can be approximated efficiently not sur prisingly these approximations have also been criticized as not being suitable and giving wrong interpretations see aas et al 1 the localglmnet solves the explanation problem 2 8 dif ferently namely instead of fitting a complex model to data that needs to be interpreted in a subsequent step our localglmnet directly postulates an additive decomposition 2 5 in response after applying the link function g thus we could also say that we make the interpretation an integral part our model assumptions and we naturally obtain the regression attentions j x playing the role of j by model fitting we also mention the similarity to integrated gradients of sundararajan et al 27 remarks 2 2 formula 2 7 defines the localglmnet if we replace the scalar product in 2 7 by a hadamard product component wise product we receive a localglm layer x 7 1 x x 1 1 x x 1 1 q x xq rq a deep localglmnet can be received by composing such localglm layers for instance if we compose two such layers we receive a regression function x 7 g g x 2 0 2 1 x x x such an architecture may lead to increased predictive power and interpretable intermediate steps above we have emphasized that the localglmnet will lead to an interpretable regression model and the verification of this statement will be done in the examples below al ternatively if one wants to rely on a plain vanilla deep ffn network one can still fit a localglmnet to the deep ffn network as an interpretable surrogate model the localglmnet has been introduced for tabular data as we try to mimic a glm that acts on a design matrix which naturally is in tabular form if we extend the localglmnet to unstructured data time series or image recognition it requires that this data is first encoded into tabular form e g by using a convolutional module that extracts from spatial data relevant feature information and transforms this into tabular structure that is it requires the paradigm of representation learning by first bringing raw inputs into a suitable form before encoding this information by the localglmnet for prediction 6 before we study the performance of the localglmnet we would like to get the right interpre tation and intuition for regression function 2 7 we select one component 1 j q which provides us on the linear scale after applying the link g with terms j x xj 2 9 we mention specific cases in the following remarks and how they should be interpreted remarks 2 3 1 a glm term is obtained in component xj if j x j is not feature dependent providing jxj we refer to glm 2 2 2 condition j x 0 proposes that the term xj should not be included in section 3 2 below we are going to present an empirical method to test for the null hypothesis of dropping a term 3 property j x j xj says that we have a term j xj xj that does not interact with other terms in general we can analyze j x over different features x with the j th component being constantly equal to a fixed value xj if this j x does not show any sensitivity in the components different from j then we do not have interactions and otherwise we do below we extract this information by considering the gradients j x x 1 j x xq j x rq 2 10 the j th component of this gradient j x explores whether we have a linear term in xj and the components different from j quantify the interaction strengths 4 one has to be a bit careful with these interpretations as we do not have full identifiability in model calibration as e g we could also receive the following structure j x xj xj by learning a regression attention j x xj xj however our tests on different config urations have not manifested any such issues as sgd fitting seems rather pre determined by the localglmnet functional form 2 7 3 examples 3 1 synthetic data example we start with a synthetic data example because this has the advantage of knowing the true data generating model this allows us to verify that we draw the right conclusions we choose q 8 feature components x x 1 x 8 r 8 we generate two data sets learning data l and test data t the learning data will be used for model fitting and the test data for an out of sample generalization analysis we choose for both data sets n 100 000 randomly generated independent features x n 0 being centered and having unit variance moreover we assume that all components of x are independent except between x 2 and x 8 we assume a correlation of 50 based on these features we choose regression function x r 8 7 x 1 2 x 1 1 4 x 22 1 2 x 3 sin 2 x 3 1 2 x 4 x 5 1 8 x 25 x 6 3 1 7 thus neither x 7 nor x 8 run into the regression function x 7 is independent from the remaining components and x 8 has a 50 correlation with x 2 based on this regression function we generate independent gaussian observations y n x 1 3 2 this gives us the two data sets with all observations being independent l yi xi 1 i n and t yt xt n 1 t 2 n the gaussian model 3 2 belongs to the edf with cumulant function 2 2 effective domain r exposure v 1 and dispersion parameter 1 thus we can apply the theory of section 2 we start with the glm as link function g we choose the identity function which is the canonical link of the gaussian model this provides us with linear predictor in the glm case x 7 x x 0 x 3 3 with regression parameter r 8 and bias 0 r this model is fit to the learning data l using maximum likelihood estimation mle which in the gaussian case is equivalent to minimizing the mean squared error mse loss function for regression parameter 0 mle 0 mle arg min 0 1 n n i 1 yi xi 2 for this fitted model we calculate the in sample mse on l and the out of sample mse on t we compare these losses to the mses of the true model xi which is available here and the corresponding mses of the null model which only includes a bias 0 these figures are given in table 1 on lines a c mse losses in sample on l out of sample on t a true regression function 1 0023 0 9955 b null model bias 0 only 1 7907 1 7916 c glm case 1 5241 1 5274 d localglmnet 1 0023 1 0047 table 1 in sample and out of sample mses in synthetic data example the mses under the true regression function are roughly equal to 1 which exactly corresponds to the fact that the responses y have been simulated with unit variance see 3 2 the small differences to 1 correspond to the randomness implied by simulating the loss figures of the glm are between the null model homogeneous model and the correct model still these loss figures are comparably large because the true model 3 1 has a rather different functional form compared to what we can capture by the linear function 3 3 this is also verified by figure 1 lhs which compares the glm estimated means xt to the true means xt for different instances xt a perfect model would provide points on the diagonal orange line and we see rater big differences between the glm and the true regression function 8 4 2 0 2 4 4 2 0 2 4 glm estimated means vs true means true means mu g l m e st im a to r 4 2 0 2 4 4 2 0 2 4 localglmnet estimated means vs true means true means mu l o ca lg l m n e t e st im a to r figure 1 estimated means xt vs true means xt lhs fitted glm 3 3 and rhs fitted localglmnet of 5 000 randomly selected out of sample instances xt from t we could now start to improve 3 3 e g by including a quadratic term we refrain from doing so but we fit the localglmnet architecture 2 7 using the identity link for g a network of depth d 4 having q 0 q 1 q 2 q 3 q 4 8 20 15 10 8 neurons and as activation functions m we choose the hyperbolic tangent function for m 1 2 3 and the linear function for m 4 this architecture is illustrated in listing 1 in the appendix this localglmnet is fitted using the nadam version of sgd early stopping is tracked by using 20 of the learning data l as validation data v and the remaining 80 as training data u and the network calibration with the smallest mse validation loss on v is selected note that l u v is disjoint from the test data t this fitting approach is state of the art for more details we refer to section 7 2 3 in wu thrich merz 31 the results are given on line d of table 1 we observe that the mses in sample and out of sample are very close to 1 and the mses of the true model which indicates that the localglmnet is able to find the true regression structure 3 3 this is verified by figure 1 rhs which plots the estimated means xt against the true means xt out of sample for 5 000 randomly selected instances xt from t the fitted localglmnet estimators lie on the diagonal which says that we have very good accuracy we are now in the situation where we can benefit from the localglmnet architecture this al lows us to study the estimated regression attentions and the resulting terms in the localglmnet regression function x 7 j x and x 7 j x xj the interpretation to these terms has been given in remarks 2 3 we use the code of listing 2 to extract x these estimated regression attentions j x are illustrated in figure 2 for all components 1 j q 8 we interpret figure 2 regression attention 1 x is concentrated around 1 2 which describes the first term in 3 1 the regression attentions 2 x 6 x are quite different from 0 red horizontal line which indicates that x 2 x 6 are important in the description of the true regression function finally 7 x and 8 x are concentrated around zero which indicates that feature information x 7 and x 8 may not be important for our regression function thus the 9 4 2 0 2 1 0 0 5 0 0 0 5 1 0 regression attentions feature x 1 feature values x 1 re g re ss io n a tt e n tio n b e ta x beta x zero line 99 9 significance level 2 0 2 4 1 0 0 5 0 0 0 5 1 0 regression attentions feature x 2 feature values x 2 re g re ss io n a tt e n tio n b e ta x beta x zero line 99 9 significance level 4 2 0 2 4 1 0 0 5 0 0 0 5 1 0 regression attentions feature x 3 feature values x 3 re g re ss io n a tt e n tio n b e ta x beta x zero line 99 9 significance level 2 0 2 4 1 0 0 5 0 0 0 5 1 0 regression attentions feature x 4 feature values x 4 re g re ss io n a tt e n tio n b e ta x beta x zero line 99 9 significance level 3 2 1 0 1 2 3 4 1 0 0 5 0 0 0 5 1 0 regression attentions feature x 5 feature values x 5 re g re ss io n a tt e n tio n b e ta x beta x zero line 99 9 significance level 2 0 2 4 1 0 0 5 0 0 0 5 1 0 regression attentions feature x 6 feature values x 6 re g re ss io n a tt e n tio n b e ta x beta x zero line 99 9 significance level 3 2 1 0 1 2 3 1 0 0 5 0 0 0 5 1 0 regression attentions feature x 7 feature values x 7 re g re ss io n a tt e n tio n b e ta x beta x zero line 99 9 significance level 3 2 1 0 1 2 3 1 0 0 5 0 0 0 5 1 0 regression attentions feature x 8 feature values x 8 re g re ss io n a tt e n tio n b e ta x beta x zero line 99 9 significance level figure 2 regression attentions j xt 1 j q 8 of 5 000 randomly selected out of sample instances xt from t the y scale is identical in all plots and on the x scale we have xj last two variables could be dropped from the model unless they play an important role in x this can be checked by just refitting the model without these variables 3 2 variable selection in the previous example we have just said that we should drop variables x 7 and x 8 from the localglmnet regression because regression attentions 7 x and 8 x spread around zero obviously these two estimators should be identically equal to zero because they do not appear in the true regression function but the noise in the data yi is letting their estimators fluctuate around zero this fluctuation is of comparable size for both x 7 which is independent of all other variables and x 8 which is correlated with x 2 the main question is how much fluctuation around zero is still acceptable for allowing to drop a variable i e does not reject the null hypothesis h 0 of setting 7 x 0 or how much fluctuation reveals real regression structure in glms this question is answered by either the wald test or the likelihood ratio 10 test lrt which use asymptotic normality results of mles see section 2 2 2 in fahrmeir tutz 9 here we cannot rely on an asymptotic theory for mles because early stopping implies that we do not consider the mle an analysis of the results also shows that the volatility in 7 x is bigger than the magnitudes used in the wald test and the lrt for these reason we propose an empirical way of determining the rejection region of the null hypothesis h 0 7 x 0 if we are given a statistical problem with features x x 1 xq rq we propose to extend these features by an additional variable xq 1 which is completely random independent of x and which of course does not enter the true unknown regression function x but is only included within the network this additional random component xq 1 will quantify the resulting fluctuations in q 1 x of an independent component that does not enter the regression function in order to successfully apply this empirical test we need to normalize all feature components xj 1 j q 1 to have zero empirical mean and unit variance i e they should all live on the same scale note that such a normalization should already have been done for successful sgd fitting thus this does not impose an additional step here we then fit a localglmnet 2 6 2 7 to the learning data l with extended features x x xq 1 rq 1 which gives us the estimated regression attentions 1 x i q 1 x i using these estimated regression attentions we receive empirical mean and standard deviation for the additional component b q 1 1 n n i 1 q 1 x i and s q 1 1 n 1 n i 1 q 1 x i b q 1 2 3 4 since this additional component xq 1 does not enter the true regression function we expect b q 1 0 and s q 1 quantifies the expected fluctuation around zero the null hypothesis h 0 j x 0 for component j on significance level 0 1 2 can then be rejected if the coverage ratio of the following centered interval i for j x i 1 i n i qn 2 s q 1 qn 1 2 s q 1 qn 2 s q 1 qn 2 s q 1 3 5 is substantially smaller than where qn p denotes the quantile of the standard gaussian distribution on quantile level p 0 1 we come back to our figure 2 we do not add an additional component xq 1 but we directly use component x 7 to test the null hypotheses h 0 j x 0 for the remaining components j 6 7 in our synthetic data example we have b 7 0 0068 0 and s 7 0 0461 we choose significance level 0 1 which provides us with qn 0 05 3 2905 the cyan lines in figure 2 show the resulting interval i given in 3 5 for our example only for x 8 the black dots 8 xt are within these confidence bounds i which implies that we should drop this component and keep components x 1 x 6 in the regression model in a final step the model with dropped components should be re fitted and the out of sample loss should not substantially change this re fitting step verifies that the dropped components also do not play a significant role in the regression attentions j x of the remaining feature components j i e contribute by interacting with other variables figure 3 gives the resulting feature contributions j xt xt j 1 j q 8 to the localglmnet estimated regression function xt we clearly see the linear term in x 1 the quadratic term in 11 4 2 0 2 2 1 0 1 2 feature contribution feature x 1 feature values x 1 co n tr ib u tio n x 1 b e ta 1 x 2 0 2 4 2 1 0 1 2 feature contribution feature x 2 feature values x 2 co n tr ib u tio n x 2 b e ta 2 x 4 2 0 2 4 2 1 0 1 2 feature contribution feature x 3 feature values x 3 co n tr ib u tio n x 3 b e ta 3 x 2 0 2 4 2 1 0 1 2 feature contribution feature x 4 feature values x 4 co n tr ib u tio n x 4 b e ta 4 x 3 2 1 0 1 2 3 4 2 1 0 1 2 feature contribution feature x 5 feature values x 5 co n tr ib u tio n x 5 b e ta 5 x 2 0 2 4 2 1 0 1 2 feature contribution feature x 6 feature values x 6 co n tr ib u tio n x 6 b e ta 6 x 3 2 1 0 1 2 3 2 1 0 1 2 feature contribution feature x 7 feature values x 7 co n tr ib u tio n x 7 b e ta 7 x 3 2 1 0 1 2 3 2 1 0 1 2 feature contribution feature x 8 feature values x 8 co n tr ib u tio n x 8 b e ta 8 x figure 3 feature contributions j xt xt j 1 j q 8 to the localglmnet estimated regression function xt of 5 000 randomly selected out of sample instances xt from t the y scale is identical in all plots and on the x scale we have xj x 2 and the sine term in x 3 first line of figure 3 see also 3 1 for the true regression function the second line of figure 3 shows the interacting feature components x 4 x 5 and x 6 and the last line those that should be dropped 3 3 interactions in the next and final step we explore interactions between different feature components this is based on analyzing the gradients j x for 1 j q see 2 10 the j th component of this gradient j x explores whether we have a linear term in xj or not if there are no interactions of the j th component with other components i e j x xj j xj xj it will exactly provide us with the right functional form of j x since in that case j x xj 0 for all j 6 j in relation to figure 2 this means that the scatter plot resembles a line that does not have any lateral dilation in figure 2 this is the case for components x 1 x 2 x 7 x 8 for component x 3 this 12 is not completely clear from the scatter plot and x 4 x 5 x 7 show lateral extensions indicating interactions in the latter general case we have j x xj 6 0 for some j 6 j 4 2 0 2 4 0 4 0 2 0 0 0 2 0 4 interactions of feature component x 1 feature values x 1 in te ra ct io n s tr e n g th s x 1 x 2 x 3 x 4 x 5 x 6 x 7 x 8 feature x 1 feature x 2 feature x 3 feature x 4 feature x 5 feature x 6 feature x 7 feature x 8 4 2 0 2 4 0 4 0 2 0 0 0 2 0 4 interactions of feature component x 2 feature values x 2 in te ra ct io n s tr e n g th s x 1 x 2 x 3 x 4 x 5 x 6 x 7 x 8 feature x 1 feature x 2 feature x 3 feature x 4 feature x 5 feature x 6 feature x 7 feature x 8 4 2 0 2 4 0 5 0 0 0 5 interactions of feature component x 3 feature values x 3 in te ra ct io n s tr e n g th s x 1 x 2 x 3 x 4 x 5 x 6 x 7 x 8 feature x 1 feature x 2 feature x 3 feature x 4 feature x 5 feature x 6 feature x 7 feature x 8 4 2 0 2 4 0 4 0 2 0 0 0 2 0 4 interactions of feature component x 4 feature values x 4 in te ra ct io n s tr e n g th s x 1 x 2 x 3 x 4 x 5 x 6 x 7 x 8 feature x 1 feature x 2 feature x 3 feature x 4 feature x 5 feature x 6 feature x 7 feature x 8 4 2 0 2 4 0 4 0 2 0 0 0 2 0 4 interactions of feature component x 5 feature values x 5 in te ra ct io n s tr e n g th s x 1 x 2 x 3 x 4 x 5 x 6 x 7 x 8 feature x 1 feature x 2 feature x 3 feature x 4 feature x 5 feature x 6 feature x 7 feature x 8 4 2 0 2 4 0 4 0 2 0 0 0 2 0 4 interactions of feature component x 6 feature values x 6 in te ra ct io n s tr e n g th s x 1 x 2 x 3 x 4 x 5 x 6 x 7 x 8 feature x 1 feature x 2 feature x 3 feature x 4 feature x 5 feature x 6 feature x 7 feature x 8 figure 4 spline fits to the sensitivities xk j xi 1 j k 6 over all instances i 1 n we calculate the gradients j x 1 j q of the fitted model these can be obtained 13 by the r code of listing 3 this provides us for fixed j with vectors j xi for all instances i 1 n in order to analyze these gradients we fit a spline to these observations by regressing xk j xi xk j xi xi j 3 6 this studies the derivative of regression attention j x w r t xk as a function of the corre sponding feature component xj that is considered in the feature contribution j x xj see 2 7 the code for these spline fits is also provided in listing 3 on lines 12 15 and it gives us the results illustrated in figure 4 figure 4 studies the spline regressions 3 6 only of the significant components x 1 x 6 that enter regression function see 3 1 we interpret these plots plot x 1 shows that all gradients are roughly zero which means that 1 x const which indeed is the case in the true regression function plots x 2 and x 3 show one term that is significantly different from 0 for the x 2 plot it is x 2 2 x and for the x 3 plot it is x 3 3 x this says that these two terms do not have any interactions with other variables and that the right functional form is not the linear one but j x xj j xj xj is non linear for j 2 3 in fact we have x 2 2 x const which says that we have a quadratic term in x 2 and x 3 3 x shows a sine like behavior plot x 4 shows a linear interaction with x 5 because x 5 4 x const plot x 5 shows a linear interaction with x 4 because x 4 5 x const and it shows an interaction with x 6 plot x 6 does not show any significant terms as they have already been captured by the previous plots note that this comes from the fact that terms x 25 x 6 8 do not lead to an identifiable decomposition but this can be allocated either to x 5 or to x 6 or could even be split among the two 3 4 real data example as a second example we consider a real data example in this real data example we also discuss how categorical feature components should be pre processed for our localglmnet approach we consider the french motor third party liability mtpl claims frequency data fremtpl 2 freq which is available through the r package casdatasets of dutang charpentier 8 this data is described in appendix a of wu thrich merz 31 and in the tutorials of noll et al 22 and lorentzen mayer 17 we apply the data cleaning of listing b 1 of wu thrich merz 31 to this data after data cleaning we have observations yi vi xi i with claim counts yi n 0 time exposures vi 0 1 and feature information xi we have 6 continuous feature components called area code bonus malus level density driver s age vehicle age vehicle power 1 binary component called vehicle gas and 2 categorical components with more then two levels called vehicle brand and region we pre process these components as follows we center and normalize to unit variance the 6 continuous and the binary components we apply one hot encoding to the 2 categorical variables we emphasize that we do not use dummy coding as it is 14 usually done in glms below in section 3 6 we are going to motivate this one hot encoding choice which does not lead to full rank design matrices for one hot encoding vs dummy coding we refer to formulas 5 21 and 7 29 in wu thrich merz 31 as a control variable we add two random feature components that are i i d distributed centered and with unit variance the first one having a uniform distribution and the second one having a standard normal distribution we call these two additional feature components randu and randn we consider two additional independent components to understand whether the dis tributional choice influences the results of hypothesis testing using the empirical interval i see 3 5 altogether and using one hot encoding we receive q 42 dimensional tabular feature variables xi rq this includes the two additional components randu and randn we fit a poisson network regression model to this french mtpl data note that the poisson distribution belongs to the edf with cumulant function exp on the effective domain r the canonical link is given by the log link this motivates link choice g log we then start by fitting a plain vanilla ffn network 2 5 to this data this ffn network will give us the benchmark in terms of predictive power we choose a network of depth d 3 having q 1 q 2 q 3 20 15 10 ffn neurons the r code for this ffn architecture is given in listing 7 1 of wu thrich merz 31 but we replace input dimension 40 by 42 on line 3 of that listing in order to do a proper out of sample generalization analysis we partition the data randomly into a learning data set l and a test data set t the learning data l contains n 610 206 instances and the test data set t contains 67 801 instances we use exactly the same split as in table 5 2 of wu thrich merz 31 the learning data l will be used to learn the network parameters and the test data t is used to perform an out of sample generalization analysis as loss function for parameter fitting and generalization analysis we choose the poisson deviance loss which is a distribution adapted and strictly consistent loss function for the mean within the poisson model for details we refer to section 4 1 3 in wu thrich merz 31 we fit this ffn network using the nadam version of sgd on batches of size 5 000 over 100 epochs and we retrieve the network calibration that provides the smallest validation loss on a training validation partition u and v of the learning data l the results are presented on line b of table 2 the ffn network provides clearly better results than the null model only using a bias 0 this justifies regression modeling here poisson deviance losses in 10 2 in sample on l out of sample on t a null model bias 0 only 25 213 25 445 b ffn network 23 764 23 873 c localglmnet 23 728 23 945 d reduced localglmnet 23 714 23 912 table 2 in sample and out of sample losses on the real mtpl data example next we fit the localglmnet architecture using exactly the same set up as in the ffn network but having a depth of d 4 with numbers of neurons q 0 q 1 q 2 q 3 q 4 42 20 15 10 42 the results on line c of table 2 show that we sacrifice a bit of predictive power out of sample for receiving our interpretable network architecture we now analyze the resulting estimated regression attentions j x we start by studying the regression attentions j x of the continuous and binary feature compo 15 1 2 3 4 5 6 0 5 0 0 0 5 regression attention area code area code re g re ss io n a tt e n tio n beta x zero line 0 1 significance level 60 80 100 120 140 0 5 0 0 0 5 regression attention bonus malus level bonus malus level re g re ss io n a tt e n tio n beta x zero line 0 1 significance level 2 4 6 8 10 0 5 0 0 0 5 regression attention density density re g re ss io n a tt e n tio n beta x zero line 0 1 significance level 20 30 40 50 60 70 80 90 0 5 0 0 0 5 regression attention driver s age driver s age re g re ss io n a tt e n tio n beta x zero line 0 1 significance level 0 5 10 15 20 0 5 0 0 0 5 regression attention vehicle age vehicle age re g re ss io n a tt e n tio n beta x zero line 0 1 significance level diesel regular 0 5 0 0 0 5 regression attention vehicle gas vehicle gas re g re ss io n a tt e n tio n beta x zero line 0 1 significance level 4 6 8 10 12 14 0 5 0 0 0 5 regression attention vehicle power vehicle power re g re ss io n a tt e n tio n beta x zero line 0 1 significance level 1 5 1 0 0 5 0 0 0 5 1 0 1 5 0 5 0 0 0 5 regression attention randu randu re g re ss io n a tt e n tio n beta x zero line 0 1 significance level 4 2 0 2 0 5 0 0 0 5 regression attention randn randn re g re ss io n a tt e n tio n beta x zero line 0 1 significance level figure 5 attention weights j xt of the continuous and binary feature components area code bonus malus level density driver s age vehicle age vehicle gas vehicle power randu and randn for 5 000 randomly selected instances xt of t the cyan lines show the boundary of the rejection area ic for dropping the term xj on significance level 0 1 nents area code bonus malus level density driver s age vehicle age vehicle gas vehicle power randu and randn first we calculate the empirical standard deviations s j that we receive from randu and randn see 3 4 s randu 0 052 and s randn 0 048 thus these standard deviation estimates are rather similar and in this case the specific distri butional choice of the control variable xq 1 does not influence the results we calculate interval i for significance level 0 1 see 3 5 the resulting confidence bounds are illustrated by the cyan lines in figure 5 we observe that for the variables bonus malus level density driver s age vehicle age and vehicle gas we clearly reject the null hypothesis h 0 j x 0 on the chosen significance level 0 1 and area code and vehicle power need further anal 16 ysis for these two variables i provides a coverage ratio of 97 1 and 98 1 thus strictly speaking these numbers are below 1 99 9 and we should keep these variables in the model nevertheless we further analyze these two variables from the empirical analysis in noll et al 22 we know that area code and density are highly correlated figure 6 lhs shows the boxplot of density vs area code and this plot highlights that density almost fully explains area code therefore it is sufficient to include the density variable and we drop area code 2 4 6 8 1 0 boxplot density vs area code area code d e n si ty lo g sc a le 1 2 3 4 5 6 5 0 6 0 7 0 8 0 9 0 1 0 0 1 1 0 1 2 0 boxplot bonus malus vs driver s age driver s age b o n u s m a lu s l e ve l 1 8 1 9 2 0 2 1 2 2 2 3 2 4 2 5 2 6 3 5 3 6 4 5 4 6 5 5 5 6 6 5 6 6 7 5 7 6 figure 6 lhs boxplots of density vs area code and rhs bonus malus vs driver s age thus we drop the variables area code and vehpower and we also drop the control variables randu and randn because these are no longer needed this gives us reduced input dimension q 0 q 38 and we run the same localglmnet sgd fitting again line d of table 2 gives the in sample and out of sample results of this reduced localglmnet model we observe a small out of sample improvement compared to line c which confirms that we can drop area code and vehpower without losing predictive performance in fact the small improvement indicates that a smaller model less likely over fits and we can consider more sgd steps before over fitting i e we receive a later early stopping point figure 7 shows the feature contributions j xt xj t of the selected continuous and binary feature components bonus malus level density driver s age vehicle age and vehicle gas of 5 000 randomly selected instances xt and the magenta line shows a spline fit to these feature contri butions the y scale is the same in all plots we observe that all these components contribute substantially to the regression function the bonus malus variable being the most important one and vehicle gas being the least important one bonus malus and density have in average an increasing trend and vehicle age has in average a decreasing trend density being close to a linear function and the remaining continuous variables are clearly non linear the explanation of driver s age is more difficult as can be seen from the spline fit magenta color figure 6 rhs shows the boxplot of bonus malus level vs driver s age we observe that new young drivers enter the bonus malus system at 100 and every year of driving without an accident decreases the bonus malus level therefore the lowest bonus malus level can only be reached after multiple years of accident free driving this can be seen from figure 6 rhs and it implies that the bonus malus level and the driver s age variables interact we are going to verify this 17 60 80 100 120 140 1 5 1 0 0 5 0 0 0 5 1 0 1 5 feature contribution bonus malus level bonus malus level fe a tu re c o n tr ib u tio n beta x zero line spline fit 2 4 6 8 10 1 5 1 0 0 5 0 0 0 5 1 0 1 5 feature contribution density density fe a tu re c o n tr ib u tio n beta x zero line spline fit 20 30 40 50 60 70 80 90 1 5 1 0 0 5 0 0 0 5 1 0 1 5 feature contribution driver s age driver s age fe a tu re c o n tr ib u tio n beta x zero line spline fit 0 5 10 15 20 1 5 1 0 0 5 0 0 0 5 1 0 1 5 feature contribution vehicle age vehicle age fe a tu re c o n tr ib u tio n beta x zero line spline fit diesel regular 1 5 1 0 0 5 0 0 0 5 1 0 1 5 feature contribution vehicle gas vehicle gas fe a tu re c o n tr ib u tio n beta x zero line figure 7 feature contributions j xt xj t of the continuous and binary feature components bonus malus level density driver s age vehicle age and vehicle gas of 5 000 randomly selected instances xt of t the y scale is the same in all plots and the magenta color gives a spline fit to the feature contributions by studying the gradients j x of the regression attributions figure 8 shows the spline fits to the gradients xk j x of the continuous variables bonus malus level density driver s age and vehicle age firstly we observe that bonus malus level and driver s age have substantial non linear terms xj j x xj vehicle age shows some non linearity and density seems to be pretty linear since xj j x xj 0 this verifies the findings of figure 7 of the magenta spline fits next we focus on interactions which requires the study of xk j x for k 6 j in figure 8 the most significant interactions can clearly be observed between bonus malus level and driver s age but also between the bonus malus level and density we encounter an interaction term saying that a higher bonus malus level at a lower density leads to a higher prediction which intuitively makes sense as in less densely populated areas we expect less claims for vehicle age we do not find substantial interactions it only weakly interacts with bonus malus level and driver s age by entering the corresponding regression attributions j x of these two feature components there remains the discussion of the categorical feature components vehicle brand and region this is going to be done in section 3 6 below 18 60 80 100 120 140 2 1 0 1 2 interactions of feature component bonus malus level bonus malus level in te ra ct io n s tr e n g th s vehage drivage bonusmalus vehgas density vehicle age driver s age bonus malus level vehicle gas density 0 2 4 6 8 10 2 1 0 1 2 interactions of feature component density density in te ra ct io n s tr e n g th s vehagedrivage bonusmalus vehgasdensity vehicle age driver s age bonus malus level vehicle gas density 20 30 40 50 60 70 80 90 2 1 0 1 2 interactions of feature component driver s age driver s age in te ra ct io n s tr e n g th s vehage drivage bonusmalus vehgasdensity vehicle age driver s age bonus malus level vehicle gas density 0 5 10 15 20 2 1 0 1 2 interactions of feature component vehicle age vehicle age in te ra ct io n s tr e n g th s vehage drivagebonusmalusvehgasdensity vehicle age driver s age bonus malus level vehicle gas density figure 8 spline fits to the gradients xk j xi of the continuous variables bonus malus level density driver s age and vehicle age over all instances i 1 n 3 5 variable importance the estimated regression attentions j x 1 j q allow us to quantify variable importance coming back to the shap additive decomposition 2 8 a popular way of quantifying variable importance is obtained by aggregating the absolute values of the attention weights a simple measure of variable importance can thus be defined by vij 1 n n i 1 j xi for 1 j q and where we aggregate over all instances 1 i n typically the bigger these values vij the more component xj influences the regression function note that all feature components xj have been centered and normalized to unit variance i e they live on the same scale otherwise such a comparison of vij across different j would not make sense figure 9 gives the variable importance results which emphasizes that area code and vehicle power are the least important variables which in fact have been dropped in a second step above 19 randu randn area code vehicle power vehicle gas vehicle age density driver s age bonus malus variable importance 0 0 0 1 0 2 0 3 0 4 0 5 0 6 0 7 figure 9 variable importance vij 1 j q 3 6 categorical feature components in this section we discuss how categorical feature components can be considered note that at the beginning of section 3 4 we have emphasized that we use one hot encoding and not dummy coding for categorical variables the reason for this choice can be seen in figure 7 namely if the feature value is xj 0 then the corresponding feature contribution gives j x xj 0 this provides the calibration of the regression model i e it gives the reference level which is determined by the bias 0 r since in glms we do not allow the components to interact in the linear predictor x all instances that have the same level xj receive the same contribution jxj see 2 2 in the localglmnet we allow the same level xj to have different contributions j x xj through interactions in the regression attention x if we want to carry this forward to categorical feature components it requires that these components receive an encoding that is not identically equal to zero this is the case for one hot encoding but not for dummy coding where the reference level is just identical to the bias 0 for this reason we recommend to use one hot encoding for the localglmnet figure 10 shows the feature contributions j x of the categorical feature components note that each box corresponds to one level of the chosen categorical variable firstly different medians between the boxes indicate different parameter sizes j x for different levels j note that in one hot encoding j describes the different levels of the categorical variable secondly the larger the box the more interaction this level has with other feature components because j xi is more volatile over different instances i from figure 10 we observe that vehicle brands b 11 and b 14 are the two most extreme vehicle brands w r t claims frequency b 11 having the highest expected frequency and b 14 the lowest from the french regions r 74 limousin and r 82 rho ne alpes seem outstanding having a higher frequency than elsewhere this finishes our example in fact figure 10 provides contextualized embeddings for the different levels of the categorical features attention based embedding models exactly try to do such a contextualized embedding we refer to kuo richman 15 in an actuarial context and to huang et al 13 for general tabular data 20 b 1 b 3 b 5 b 10 b 12 b 14 1 5 1 0 0 5 0 0 0 5 1 0 1 5 feature contribution vehicle brand vehicle brand fe a tu re c o n tr ib u tio n r 11 r 23 r 26 r 42 r 53 r 73 r 83 r 94 1 5 1 0 0 5 0 0 0 5 1 0 1 5 feature contribution french regions french regions fe a tu re c o n tr ib u tio n figure 10 boxplot of the feature contributions j x of the categorical feature components vehicle brand and french regions the y scale is the same as in figure 7 we could add the learned categorical regression attentions j x to the variable importance plot of figure 9 this requires some care firstly if categorical variables have many levels then showing individual levels will not result in clear plots secondly one hot encoding is not normalized and centered to unit variance thus these one hot encoded variables live on a different scale compared to the standardized ones and a direct comparison is not sensible 4 conclusions we have introduced the localglmnet which is inspired by classical generalized linear models making the regression parameters of a generalized linear model feature dependent allows us to receive a flexible regression model that shares representation learning and the predictive performance of classical fully connected feed forward neural networks and at the same time it remains interpretable this appealing structure allows us to perform variable selection it allows us to study variable importance and it also allows us to determine interactions thus it provides us with a fully transparent network model that brings out the internal structure of the data to the best of our knowledge this is rather unique in network regression modeling since our proposal does not share the shortcomings of similar proposals like computational burden or a loss of predictive power above we have mentioned possible extensions e g localglm layers can be composed to receive deeper interpretable networks and the localglmnet can serve as a surrogate model to shed more light into many other deep learning models whereas our architecture is most suitable for tabular input data the question about optimal consideration of non tabular data or of categorical variables with many levels is one point that should be further explored references 1 aas k jullum m l land a 2020 explaining individual predictions when features are de pendent more accurate approximations to shapley values arxiv 1903 10464 v 3 21 2 agarwal r frosst n zhang x caruana r hinton g e 2020 neural additive models interpretable machine learning with neural nets arxiv 2004 13912 v 1 3 ahn j lu y oh r park k zhu d 2021 neural credibility conference presentation virtual 24 th international congress on insurance mathematics and economics july 5 10 2021 4 apley d w zhu j 2020 visualizing the effects of predictor variables in black box supervised learning models journal of the royal statistical society series b 82 4 1059 1086 5 arik s o pfister t 2019 tabnet attentive interpretable tabular learning arxiv 1908 07442 v 5 6 bahdanau d cho k bengio y 2014 neural machine translation by jointly learning to align and translate arxiv 1409 0473 7 barndorff nielsen o 2014 information and exponential families in statistical theory john wiley sons 8 dutang c charpentier a 2018 casdatasets r package vignette reference manual version 1 0 8 packaged 2018 05 20 9 fahrmeir l tutz g 1994 multivariate statistical modelling based on generalized linear mod els springer 10 friedman j h 2001 greedy function approximation a gradient boosting machine annals of statistics 29 5 1189 1232 11 goodfellow i bengio y courville a 2016 deep learning mit press http www deeplearningbook org 12 he k zhang x ren s sun j 2016 deep residual learning for image recognition 2016 ieee conference on computer vision and pattern recognition 1 770 778 13 huang x khetan a cvitkovic m karnin z 2020 tabtransformer tabular data modeling using contextual embeddings arxiv 2012 00678 14 j rgensen b 1997 the theory of dispersion models chapman hall 15 kuo k richman r 2021 embeddings and attention in predictive modeling arxiv 2104 03545 v 1 16 lemhadri i ruan f abraham l tibshirani r 2021 lassonet a neural network with feature sparsity journal of machine learning research 22 1 29 17 lorentzen c mayer m 2020 peeking into the black box an actuarial case study for inter pretable machine learning ssrn manuscript id 3595944 version may 7 2020 18 lundberg s m lee s i 2017 a unified approach to interpreting model predictions in ad vances in neural information processing systems 30 guyon i luxburg u v bengio s wal lach h fergus r vishwanathan s garnett r eds 4765 74 montreal curran associates 19 mccullagh p nelder j a 1983 generalized linear models chapman hall 20 merz m richman r tsanakas a wu thrich m v 2021 interpreting deep learning models with marginal attribution by conditioning on quantiles ssrn manuscript id 3809674 21 nelder j a wedderburn r w m 1972 generalized linear models journal of the royal statis tical society series a 135 3 370 384 22 noll a salzmann r wu thrich m v 2018 case study french motor third party liability claims ssrn manuscript id 3164764 version march 4 2020 22 http www deeplearningbook org http www deeplearningbook org 23 ribeiro m t singh s guestrin c 2016 why should i trust you explaining the predictions of any classifier in proceedings of the 22 nd acm sigkdd international conference on knowledge discovery and data mining kdd 16 new york association for computing machinery 1135 1144 24 richman r 2021 mind the gap safely incorporating deep learning models into the actuarial toolkit ssrn manuscript id 3857693 25 shapley l s 1953 a value for n person games in contributions to the theory of games am 28 vol ii kuhn h w tucker a w eds princeton university press 307 318 26 sundararajan m najmi a 2020 the many shapley values for model explanation arxiv 1908 08474 v 2 27 sundararajan m taly a yan q 2017 axiomatic attribution for deep networks in proceed ings of the 34 th international conference on machine learning proceedings of machine learning research pmlr international convention centre sydney australia 70 3319 3328 28 vaswani a shazeer n parmar n uszkoreit j jones l gomez a n kaiser l polosukhin i 2017 attention is all you need arxiv 1706 03762 v 5 29 vaughan j sudjianto a brahimi e chen j nair v n 2018 explainable neural networks based on additive index models arxiv 1806 01933 v 1 30 wang q li b xiao t zhu j li c wong d f chao l s 2019 learning deep trans former models for machine translation arxiv 1906 01787 31 wu thrich m v merz m 2021 statistical foundations of actuarial learning and its applications ssrn manuscript id 3822407 23 a r code listing 1 code to implement localglmnet of depth d 4 for the synthetic gaussian case 1 library keras 2 3 design layer input shape c 8 dtype float 32 4 5 attention design 6 layer dense units 20 activation tanh 7 layer dense units 15 activation tanh 8 layer dense units 10 activation tanh 9 layer dense units 40 activation linear name attention 10 11 response list design attention layer dot axes 1 12 layer dense units 1 activation linear name response 13 14 model keras model inputs c design outputs c response 15 model compile loss mse optimizer nadam listing 2 extraction of the estimated weights x 1 zz keras model inputs model input outputs get layer model attention output 2 3 beta x data frame zz predict list xx xx denotes design feature matrix 4 5 our architecture still requires a scaling coming from dense layer response which 6 we add to have intercept beta 0 in our localglmnet architecture 7 beta x beta x as numeric get weights model 9 listing 3 extraction of the gradients j x and code for spline fit 1 j 1 select the feature component 2 3 beta j attention layer lambda function x x j 4 model j keras model inputs c design outputs c beta j 5 6 grad beta j layer lambda function x k gradients model j outputs model j inputs 7 model grad keras model inputs c design outputs c grad 8 9 grad beta data frame model grad predict as matrix xx 10 11 12 k 4 select component for interaction j k 13 14 library locfit 15 predict locfit grad beta k beta x j alpha 0 1 deg 2 newdata c 400 400 100 24 1 introduction 2 model architecture 2 1 generalized linear model 2 2 fully connected feed forward neural network 2 3 local generalized linear model network 2 4 interpretation and extension of localglmnet 3 examples 3 1 synthetic data example 3 2 variable selection 3 3 interactions 3 4 real data example 3 5 variable importance 3 6 categorical feature components 4 conclusions a r code