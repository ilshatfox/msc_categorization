can we leverage predictive uncertainty to detect dataset shift and adversarial examples in android malware detection can we leverage predictive uncertainty to detect dataset shift and adversarial examples in android malware detection deqiang li nanjing university of science and technology nanjing china lideqiang njust edu cn tian qiu nanjing university of science and technology nanjing china qiutian njust edu cn shuo chen riken saitama japan shuo chen ya riken jp qianmu li nanjing university of science and technology nanjing china qianmu njust edu cn shouhuai xu university of colorado colorado springs colorado springs colorado usa sxu uccs edu abstract the deep learning approach to detecting malicious software mal ware is promising but has yet to tackle the problem of dataset shift namely that the joint distribution of examples and their labels associated with the test set is different from that of the training set this problem causes the degradation of deep learning models with out users notice in order to alleviate the problem one approach is to let a classifier not only predict the label on a given example but also present its uncertainty or confidence on the predicted label whereby a defender can decide whether to use the predicted label or not while intuitive and clearly important the capabilities and limitations of this approach have not been well understood in this paper we conduct an empirical study to evaluate the quality of predictive uncertainties of malware detectors specifically we re design and build 24 android malware detectors by transforming four off the shelf detectors with six calibration methods and quan tify their uncertainties with nine metrics including three metrics dealing with data imbalance our main findings are i predictive uncertainty indeed helps achieve reliable malware detection in the presence of dataset shift but cannot cope with adversarial evasion attacks ii approximate bayesian methods are promising to cali brate and generalize malware detectors to deal with dataset shift but cannot cope with adversarial evasion attacks iii adversarial evasion attacks can render calibration methods useless and it is an open problem to quantify the uncertainty associated with the predicted labels of adversarial examples i e it is not effective to use predictive uncertainty to detect adversarial examples also with wuyi university permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page copyrights for components of this work owned by others than acm must be honored abstracting with credit is permitted to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and or a fee request permissions from permissions acm org acsac 21 december 6 10 2021 virtual event usa 2021 association for computing machinery acm isbn 978 1 4503 8579 4 21 12 15 00 https doi org 10 1145 3485832 3485916 ccs concepts security and privacy malware and its mitigation math ematics of computing probabilistic inference problems keywords malware detection predictive uncertainty deep learning dataset shift adversarial malware examples acm reference format deqiang li tian qiu shuo chen qianmu li and shouhuai xu 2021 can we leverage predictive uncertainty to detect dataset shift and adversarial examples in android malware detection in annual computer security applications conference acsac 21 december 6 10 2021 virtual event usa acm new york ny usa 13 pages https doi org 10 1145 3485832 3485916 1 introduction malware is a big threat to cybersecurity despite tremendous efforts communities still suffer from this problem because the number of malware examples consistently increases for example kaspersky 24 detected 21 6 million unique malware in 2018 24 6 million in 2019 and 33 4 million in 2020 this highlights the necessity of au tomating malware detection via machine learning techniques 48 however a fundamental assumption made by machine learning is that the training data distribution and the test data distribution are identical in practice this assumption is often invalid because of the dataset shift problem 37 note that dataset shift is related to but different from the concept drift problem which emphasizes that the conditional distribution of the labels conditioned on the input associated with the test data is different from its counterpart associated with the training data 46 while some people use these two terms interchangeably 28 50 we choose to use dataset shift because it is a broader concept than concept drift several approaches have been proposed for alleviating the dataset shift problem such as periodically retraining malware detectors 10 47 extracting invariant features 49 and detecting example anomalies 20 one fundamental open problem is to quantify the uncertainty that is inherent to the outcomes of malware detectors or the confidence a detector has in its prediction a well calibrated uncertainty indicates the potential risk of the accuracy decrease ar x iv 2 10 9 09 65 4 v 2 cs c r 2 0 o ct 2 02 1 https doi org 10 1145 3485832 3485916 https doi org 10 1145 3485832 3485916 https doi org 10 1145 3485832 3485916 acsac 21 december 6 10 2021 virtual event usa d li t qiu s chen q li and s xu and enables malware analysts to conduct informative decisions i e using the predicted label or not one may argue that a deep learn ing model associates its label space with a probability distribution however this as is method is poorly calibrated and causes poor uncertainty estimates 18 this problem has motivated researchers to propose multiple methods to calibrate the probabilities such as variational bayesian inference 6 monte carlo dropout 15 stochastic gradient mcmc 45 and non bayesian methods such as ensemble 25 quantifying the uncertainty associated with pre dicted labels i e predictive uncertainty in the presence of dataset shift has received a due amount of attention in the context of image classification 6 25 medical diagnoses 26 and natural language processing 39 but not in the context of malware detection this motivates us to answer the question in the title our contributions in this paper we empirically quantify the pre dictive uncertainty of 24 deep learning based android malware detectors these detectors correspond to combinations of four mal ware detectors which include two multiple layer perceptron based methods i e deepdrebin 17 and multimodalnn 22 and one convolutional neural network based method deepdroid 30 and the recurrent neural network based method droidetec 29 and six calibration methods which are vanilla no effort made for cali bration temperature scaling 18 monte carlo mc dropout 15 variational bayesian inference vbi 39 deep ensemble 25 and its weighted version the vanilla and temperature scaling calibra tion methods belong to the post hoc strategy while the others are ad hoc and require us to transform the layers of an original neural network in a principled manner e g sampling parameters from a learned distribution in order to evaluate the quality of predictive uncertainty on imbalanced datasets we propose useful variants of three standard metrics by applying the aforementioned 24 malware detectors to three android malware datasets we draw the following insights i we can leverage predictive uncertainty to achieve reliable malware de tection in the presence of dataset shift to some extent while noting that a defender should trust the predicted labels with uncertainty below a certain threshold ii approximate bayesian methods are promising to calibrate and generalize malware detectors to deal with dataset shift iii adversarial evasion attacks can render cali bration methods useless and thus the predictive uncertainty we have made the code of our framework publicly available at https github com deqangss malware uncertainty it is worth mentioning that after the present paper is accepted we became aware of a preprint 32 which investigates how to leverage predic tive uncertainty to deal with false positives of windows malware detectors rather than dealing with dataset shift issues 2 problem statement 2 1 android apps and malware detection since android malware is a major problem and deep learning is a promising technique our empirical study focuses on android malware detection recall that an android package kit apk is a zipped file that mainly contains i androidmanifest xml which de clares various kinds of attributes about the apk e g package name required permissions activities services hardware ii classes dex which contains the apk s functionalities that can be understood by the java virtual machines e g android runtime iii res folder and resources arsc which contain the resources used by an apk iv lib folder which contains the native binaries compatible to different central processing unit cpu architectures e g arm and x 86 v meta inf folder which contains the signatures of an apk for analysis purposes one can unzip an apk to obtain its files in the binary format or disassemble an apk by using an appropriate tool e g apktool 42 and androguard 13 to obtain human readable codes and manifest data e g androidmanifest xml a malware detector is often modeled as a supervised binary classifier that labels an example as benign 0 or malicious 1 let z denote the example space i e consisting of benign and malicious software and y 0 1 denote the label space let denote the underlying joint distribution where z and y the task of malware detection deals with the conditional distribution specifically given a software sample z we consider deep neural network dnn 1 which uses the sigmoid function in its output layer to model where represents the learnable parameters a detector denoted by z y which consists of dnns and is learned from the training set returns 1 if 1 0 5 and 0 otherwise we obtain 0 1 1 moreover let denote the underlying distribution of test dataset 2 2 problem statement there are two kinds of uncertainty associated with machine learn ing epistemic vs aleatoric 39 the epistemic uncertainty tells us about which region of the input space is not perceived by a model 5 that is a data sample in the dense region will get a low epis temic uncertainty and get a high epistemic uncertainty in the sparse region on the other hand the aleatoric uncertainty is triggered by data noises and is not investigated in this paper it is widely assumed that in malware detec tion and in the broader context of machine learning however this assumption does not hold in the presence of dataset shift which re flects non stationary environments e g data distribution changed over time or the presence of adversarial evasion attacks 37 most dataset shifts possibly incur changes in terms of epistemic un certainty excluding label flipping or concept of input changed thoroughly we consider three settings that potentially trigger the out of source the and are drawn from different sources 12 temporal covariate shift the test data or evolves over time 35 adversarial evasion attack the test data is manipulated ad versarially i e 1 1 is perturbed from 1 1 where and have the same functionality and denotes is sampled from 27 one approach to coping with these kinds of dataset shifts is to make a malware detector additionally quantify the uncertainty associ ated with a prediction so that a decision maker decides whether to use the prediction 25 39 44 this means that a detector should be able to model well while predicting examples of with high uncertainties when where denotes does not obey the distribution of specifically https github com deqangss malware uncertainty can we leverage predictive uncertainty to detect dataset shift and adversarial examples in android malware detection acsac 21 december 6 10 2021 virtual event usa the quality of prediction uncertainty can be assessed by their con fidence scores this can be achieved by leveraging the notion of calibration 25 a malware detector is said to be well calibrated if the detector returns a same confidence score 0 1 for a set of test examples z in which the malware examples are dis tributed as 43 formally let pr 1 denote the proportion of malware examples in the set that are indeed malicious we have definition 1 well calibrated malware detector adapted from 43 a probabilistic malware detector z 0 1 is well calibrated if for each confidence 0 1 and 1 z it holds that pr 1 note that definition 1 means that for a well calibrated detector the fraction of malware examples in example set is indeed this means that we can use as a confidence score for quantifying un certainty when assessing the trustworthiness of a detector s predic tions this also implies that detection accuracy and well calibration are two different concepts this is so because an accurate detector is not necessarily well calibrated e g when correct predictions with confidence scores near 0 5 moreover a well calibrated malware detector is also not necessarily accurate it would be ideal if we can rigorously quantify or prove the un certainty or bounds associated with a malware detector however this turns out to be a big challenge that has yet to be tackled this motivates us to conduct an empirical study to characterize the un certainty associated with android malware detectors hopefully the empirical findings will contribute to theoretical breakthrough in the near future specifically our empirical study is centered at the question in title which is further disintegrated as four research questions rqs as follows rq 1 what is the predictive uncertainty of malware detec tors in the absence of dataset shift rq 2 what is the predictive uncertainty of malware detec tors with respect to out of source examples rq 3 what is the predictive uncertainty of malware detec tors under temporal covariate shift rq 4 what is the predictive uncertainty of malware detec tors under adversarial evasion attacks towards answering these questions we need to empirically study the predictive distribution of malware detectors in a num ber of scenarios 3 empirical analysis methodology in order to design a competent methodology we need to select malware detector that are accurate in detecting malware select the calibration methods that are appropriate for these detectors and metrics this is important because a blindly designed method ology would suffer from incompatibility issues e g integrating different feature extractions modularly or integrating post and ad hoc calibration methods together the methodology will be de signed in a modular way so that it can be extended to accommodate other models or calibration methods in a plug and play fashion 3 1 selecting candidate detectors we focus on deep learning based android malware detectors and more specifically choose the following four android malware de tectors deepdrebin 17 it is a multiple layer perceptron mlp based malware detector learned from the drebin features 4 which are extracted from the androidmanifest xml file and the classes dex file reviewed above these features are represented by binary vectors with each element indicating the presence or absence of a feature multimodalnn 22 it is a multimodal detector that contains five headers and an integrated part all of which are realized by mlp the 5 headers respectively learn from 5 kinds of features i permission component environment features extracted from the manifest file ii strings e g ip address iii system apis iv dalvik opcode and v arm opcodes from native binaries these features are represented by their occurrence frequencies these 5 headers produce 5 pieces of high level representations which are concatenated to pass through the integrated part for classification deepdroid 30 it is convolutional neural network cnn based and uses the textcnn architecture 23 the features are dalvik opcode sequences of smali codes droidetec 29 is an rnn based malware detector with the archi tecture of bi directional long short term memory bi lstm 41 droidetec partitions a function call graph fcg into sequences according to the caller callee relation and then concatenates these sequences for passing through the bi lstm model these detectors leverage several types of deep learning models indeed we also implement an end to end method r 2 d 2 19 and find it ineffectiveness due to the over fitting issue therefore we eliminate it from our study 3 2 selecting calibration methods in order to select calibration methods to calibrate the malware detectors the following two criteria can be used i they are known to be effective and ii they are scalable for learning a deep learning model in particular the preceding highlights the importance of the computational complexity of a calibration method based on a previous study 39 these criteria lead us to select the following six methods vanilla it serves as a baseline and means that no effort is made to calibrate a model 1 temperature scaling temp scaling 18 it is a post processing method that learns extra parameters to scale the logits of deep learning models on the validation set where logits are the input of the activation of sigmoid monte carlo dropout mc dropout 15 it technically adds a dropout layer 40 before the input of every layer contained in a model this dropout operation is performed in both the training and test phases different from the normal usage that turns dropout on in the training phase and off in the test phase in theory mc dropout is an approximate bayesian inference which takes as input an example and marginalizes the parameters out for returning the predictive probability 1 1 1 acsac 21 december 6 10 2021 virtual event usa d li t qiu s chen q li and s xu due to the intricate neural networks an analytical solution to ob taining is absent one alternative is to approximate via a known functional form distribution with variables leading to e specifi cally let w 1 be the set of parameters of a neural network mc dropout defines as w m v with v bernoulli 2 where m is learnable variables entities of v are sampled from a bernoulli distribution with the probability i e dropout rate and m 1 in the training phase variational learning is leveraged to look for m 1 6 16 which minimizes the kullback leibler kl divergence between and in the test phase eq 1 is degraded by averaging 0 models 1 each of which is sampled from namely 1 1 1 1 3 eq 3 says 1 is obtained just by keeping the dropout switched and averaging the results of times predictions variational bayesian inference vbi 39 it is also an approxi mate bayesian method distinguishing from mc dropout the pa rameters of neural network are directly sampled from a known form distribution with variables that is w with w 4 the training and test manner is the same as mc dropout deep ensemble 25 it learns independent neural networks which are diversified by randomly initialized parameters the intu ition behind this idea is that dropout itself is an ensemble 40 weighted deep ensemble wensemble it has the same setting as deep ensemble except for the weighted voting 1 1 5 with 0 and 1 1 3 3 calibrating detectors figure 1 highlights our methodology in calibrating deep malware detectors for answering the research questions mentioned above i e rq 1 rq 4 each calibration method is calibrated into each of the select detectors the methodology has a training phase and a testing phase each phase has five modules preprocessing layers customization deep neural network ensemble wrapper and model post processing which are described below the preprocessing module transforms program files into the data formats that can be processed by deep learning models including feature extraction and low level feature representation the layers customization module modifies the layers of standard deep learn ing models to incorporate appropriate calibration methods such as placing a dropout layer before the input of the fully connected layer the convolutional layer or the lstm layer sampling param eters from learnable distributions the deep neural network module constructs the deep learning models with the customized layers mentioned above to process the preprocessed data for training or testing purposes the ensemble wrappermodule uses an ensemble of malicious benign files 1 layers customization deep neural network ensemble wrapper probabilities w weights new file predicting 1 preprocessing model post processing training testing figure 1 our methodology for calibrating deep malware detectors to answer the aforementioned rq 1 rq 4 where dashed boxes indicate that the modules may not be neces sary for some calibrationmethods in the training phase we learn the calibratedmalware detectors in the test phase pre dicted probabilities withweights if applicable are obtained deep learning models in the training and testing phases according to the incorporated calibration method in this module we load basic block models sequentially in the training and test phases for relieving thememory complexity themodel post processingmodule copes with the requirements of post hoc calibration methods the input to this module is the detector s output i e predicted prob ability that a file belongs to which class and a validation dataset which is a fraction of data sampled from the same distribution as the training set this means that this module does not affect the parameters of neural networks 3 4 selecting metrics in order to quantify the predictive uncertainty of a calibrated de tector we need to use a test dataset denoted by and some metrics in order to make the methodology widely applicable we consider two scenarios the ground truth labels of testing dataset are available vs are not available it is important to make this dis tinction is important because ground truth labels when available can be used to validate the trustworthiness of detectors predic tive uncertainties however ground truth labels are often costly to obtain which motivates us to accommodate this more realis tic scenario this is relevant because even if the detector trainer may have access to ground truth labels when learning detectors these ground truth labels may not be available to those that aim to quantify the detectors uncertainties in making predictions 3 4 1 selectingmetricswhenground truth labels are given there are standard metrics that can be applied for this purpose however these metrics treat each example as equally important and are in sensitive to data imbalance which is often encountered in malware detection this prompts us to propose variants of standard metrics to deal with the issue of data imbalance specifically we use the following three predictive uncertainty metrics which are applicable when ground truth labels are known the first standard metric is known as negative log likelihood nll which are commonly used as a loss function for training a model and intuitively measure the goodness of a model fitting the dataset 9 a smaller nll value means a better calibration can we leverage predictive uncertainty to detect dataset shift and adversarial examples in android malware detection acsac 21 december 6 10 2021 virtual event usa formally this metric is defined as e log 1 1 log 1 1 in order to deal with imbalanced data we propose using the follow ing variant dubbed balanced nll bnll which is formally defined as 1 y y 0 nll where nll is the expectation of negative log likelihood on the test set of class 0 1 bnll treats each class equally important while nll treats each sample equally the second standard metric is known as brier score error bse which measures the accuracy of probabilistic predictions 7 39 a smaller bse value means a better calibration this metric is formally defined as e 1 2 in order to deal with imbalanced data we propose using the following vari ant dubbed balanced bse bbse which is formally defined as 1 y y 0 brier where brier is the expectation of bse on the test set of class 0 1 the third standardmetric is known as expected calibration error ece which also measures accuracy of predicted probabilities yet in a fine grained manner 31 a smaller ece value means a better calibration formally this metric is defined as follows given buckets corresponding to quantiles of the probabilities 1 the ece is defined as ece 1 pr 1 conf 6 where with a little abuse of notation 1 1 is the number of examples in bucket pr 1 1 1 is the fraction of ma licious examples conf 1 1 and the ece metric suffers from imbalanced data because the majority class dominates some bins owing to the weights in order to deal with imbalanced data we propose using the fol lowing variant dubbed unweighted ece uece which is formally defined as follows uece 1 1 pr 1 conf 3 4 2 selecting metrics when ground truth labels are not given there are three metrics 21 25 34 that can be applied to quantify predictive uncertainty in the absence of ground truth labels these metrics are applied to a point i e expectation is not considered which indicates these metrics do not suffer from the imbalanced dataset the first metric is known as entropy which intuitively measure a state of disorder in a physical system 21 a larger entropy value means a higher uncertainty formally this metric is defined as log 1 log 1 7 where denotes the model output 1 or eq 3 the second metric is known as standard deviation sd which intuitively measures the inconsistency between the base classi fiers and the ensemble one 34 a larger sd value means a higher uncertainty formally this metric is defined as 1 1 2 where denotes the th dnn model which has a weight ref eq 5 or 1 the third metric is known as the kl divergence which is an alternative to sd 25 a larger kl value means a higher uncertainty formally this metric is defined as 1 kl where kl denotes the kullback leibler divergence 3 5 answering rqs at this point one can apply the calibrated detectors to quantify their predictive uncertainties it should be clear that this methodology can be adopted or adapted by other researchers to conduct empirical studies with more kinds of detectors and more metrics 4 experimental results and analysis 4 1 experimental setup we implement the framework using tensorflow 2 and tensorflow probability libraries 1 and run experiments on a cuda enabled gtx 2080 ti gpu we below detail datasets and hyperparameters 4 1 1 datasets we use 3 widely used android datasets drebin 4 virusshare 11 and androzoo 3 drebin the drebin dataset is built before the year of 2013 and is prepossessed by a recent study 27 which relabels the apks using the virustotal service 38 that contains more than 70 antivirus scanners an apk is treated as malicious if four or more scanners say it is malicious and benign if no scanners say it is malicious theoretical justification of such heuristic but widely used practice has yet to be made 14 the resultant drebin dataset contains 5 560 malicious apks and 42 333 benign apks virusshare virusshare is a repository of potential malware we chose the apks collected in 2013 and treat this dataset as out of source in regards to the drebin dataset these apks are labeled using the same fashion as the drebin dataset producing 12 383 malicious apks and 340 benign apks while throwing away the 20 14 0 1 20 14 0 2 20 14 0 3 20 14 0 4 20 14 0 5 20 14 0 6 20 14 0 7 20 14 0 8 20 14 0 9 20 14 1 0 20 14 1 1 20 14 1 2 20 15 0 1 20 15 0 2 20 15 0 3 20 15 0 4 20 15 0 5 20 15 0 6 20 15 0 7 20 15 0 8 20 15 0 9 20 15 1 0 20 15 1 1 20 15 1 2 20 16 0 1 20 16 0 2 20 16 0 3 20 16 0 4 20 16 0 5 20 16 0 6 20 16 0 7 20 16 0 8 20 16 0 9 20 16 1 0 20 16 1 1 20 16 1 20 2000 4000 6000 8000 10000 o f e xa m pl es 34 40 30 67 34 85 41 01 50 81 60 66 87 45 47 88 41 76 63 45 13 05 14 44 15 64 12 31 1 88 8 18 38 19 53 20 98 25 21 27 68 30 77 29 32 30 10 32 89 34 78 39 59 58 18 63 68 40 52 28 06 30 27 48 81 13 77 75 8 19 0 6738 3 26 3 38 1 48 5 60 8 72 4 10 72 49 9 39 9 59 1 14 5 14 7 14 4 12 9 21 5 18 3 22 1 21 6 27 5 27 2 35 4 31 3 37 4 36 9 34 4 47 6 63 5 61 2 45 2 27 8 35 2 56 4 14 8 81 23 8 benware malware figure 2 the androzoo examples of apks with time 35 acsac 21 december 6 10 2021 virtual event usa d li t qiu s chen q li and s xu 469 apks in the grey area i e at least one but at most three scanners say they are malicious androzoo androzoo is an apk repository including over 10 mil lion examples alongwith their virustotal reports these apkswere crawled from the known markets e g google play appchina following a previous study 35 we use a subset of these apks spanning from january 2014 to december 2016 which includes 12 735 malicious examples and 116 993 benign examples figure 2 plots the monthly distribution of these examples with time 35 4 1 2 hyper parameters wepresent the hyper parameters for mal ware detectors and then for calibration methods deepdrebin 17 is an mlp consisting of two fully connected hidden layers each with 200 neurons multimodalnn 22 has five headers and an integrated part where each header consists of two fully connected layers of 500 neurons the integrated part consists of two fully connected layers of 200 neurons deepdroid 30 has an embedding layer followed by a convolu tional layer and two fully connected layers the vocabulary of the embedding layer has 256 words which correspond to 256 dalvik opcodes the embedding dimension is 8 the convolutional layer has the kernels of size 8 8 with 64 kernels the fully connected layer has 200 neurons limited by the gpu memory deepdroid can only deal with a maximum sequence of length 700 000 meaning that apks with longer opcode sequences are truncated and apks with shorter opcode sequences are padded with 0 s which correspond to nop droidetec 29 has an embedding layerwith vocabulary size 100 000 and embedding dimension 8 the bi directional lstm layer with 64 units and a fully connected hidden layer with 200 neurons droide tec allows the maximum length of api sequence 100 000 we further clip the gradient values into the range of 100 100 for droidetec in case of gradient explosion all models mentioned above use the relu activation function we also place a dropout layer with a dropout rate 0 4 before the last fully connected layer i e the output layer we implement the four malware detectors by ourselves the hyperparameters of calibration methods are detailed below vanilla and temp scaling we have the same settings as the mal ware detectors mentioned above mc dropout we use a dropout layer with a dropout rate 0 4 we add the dropout layer into the fully connected layer convolutional layer and the lstm layer respectively following a recent study 39 we neglect the 2 regularization that could decline the detec tion accuracy in the test phase we sample 10 predictions for each example vbi we sample the parameters of the fully connected layer or the convolutional layer i e weights and bias from gaussian dis tributions a gaussian distribution has the variables mean and standard deviation which are learned via back propagation using the reparameterization technique 6 we do not implement vbi for bi lstm due to the effectiveness issue 39 44 this means only the last layer of droidetec is calibrated by vbi in the test phase we sample 10 predictions for each example ensemble and wensemble we learn 10 base instances for each ensemble based method we learn these models using the adam optimizer with 30 epochs batch size 16 and learning rate 0 001 a model is selected for evalu ation when it achieves the highest accuracy on the validation set in the training phase in addition we calculate the validation accuracy at the end of each epoch 4 2 answering rq 1 in order to quantify the predictive uncertainty of malware detectors in the absence of dataset shift we learn the aforementioned 24 malware detectors on the drebin dataset by splitting it into three disjoint sets of 60 for training 20 for validation and 20 for testing table 1 summarizes the results including detection estimation us ing the metrics false negative rate fnr false positive rate fpr accuracy acc or percentage of detecting benign and malicious samples correctly balanced accuracy bacc 8 and f 1 score 36 and uncertainty evaluation using the metrics nll bnll bse bbse ece and uece we make four observations first temp scaling achieves the same detection accuracy as its vanilla model because it is a post processing method without changing the learned parame ters on the other hand mc dropout ensemble and wensemble im prove detection accuracy but vbi degrades detection accuracy some what when compared with the vanilla model in terms of balanced accuracy the calibration methods do not always improve detection accuracy because the vanilla multimodalnn actually achieves the highest balanced accuracy 98 61 among all those detectors the reason may be that multimodalnn itself is an ensemble model e g 5 headers are equipped second ensemble methods i e ensemble and wensemble re duce the calibration error when compared with the respective vanilla models moreover the two ensemble methods exceed the other calibration methods in terms of the nll bse and bbse met rics except for deepdrebin suggesting mc dropout is best for calibration third the measurements of the balanced metrics are notably larger than their imbalanced counterparts e g bnll vs nll because benign examples dominate the test set and malware detectors predict benign examples more accurately than predicting malicious ones fourth uece shows inconsistent results in terms of bnll and bbse in order to understand the reasons we plot the reliability dia gram 33 which demonstrates the difference between the fraction of malicious examples in each bin namely the difference between the pr 1 in eq 6 and the mean of the predicted confi dence figure 3 plots the results of the vanilla malware detectors along with the number of examples in the bins figure 3 a shows that most examples belong to bins 1 and 5 figure 3 b says deepdroid achieves the lowest error because it is closest to the diagonal than others and shall be best calibrated which contracts the ece values in table 1 demonstrating that multimodalnn is best instead this is because as shown in figure 3 a most benign examples belong to bin 1 and most malicious examples belong to bin 5 as a comparison uece does not suffer from this issue insight 1 calibration methods reduce malware detection uncer tainty variational bayesian inference degrades detection accuracy and f 1 score in the absence of dataset shift balanced metrics i e can we leverage predictive uncertainty to detect dataset shift and adversarial examples in android malware detection acsac 21 december 6 10 2021 virtual event usa table 1 detection estimation and uncertainty evaluation of calibrated malware detectors in the absence of dataset shift malware detector calibration method detection estimation uncertainty evaluation fnr fpr acc bacc f 1 nll bnll bse bbse ece uece deepdrebin vanilla 3 90 0 31 99 28 97 90 96 84 0 100 0 329 0 007 0 020 0 006 0 104 temp scaling 3 90 0 31 99 28 97 90 96 84 0 052 0 109 0 006 0 018 0 007 0 062 mc dropout 3 45 0 32 99 32 98 12 97 04 0 033 0 094 0 006 0 015 0 002 0 056 vbi 3 36 0 83 98 88 97 91 95 22 0 054 0 094 0 009 0 016 0 012 0 102 ensemble 3 99 0 19 99 37 97 91 97 24 0 063 0 211 0 005 0 018 0 005 0 160 wensemble 3 99 0 20 99 36 97 90 97 20 0 058 0 190 0 005 0 018 0 004 0 095 multimodalnn vanilla 2 16 0 63 99 20 98 61 96 58 0 087 0 207 0 007 0 013 0 007 0 162 temp scaling 2 16 0 63 99 20 98 61 96 58 0 053 0 086 0 007 0 012 0 010 0 182 mc dropout 2 97 0 39 99 31 98 32 97 03 0 077 0 225 0 005 0 014 0 003 0 072 vbi 8 45 0 33 98 73 95 61 94 35 0 073 0 253 0 010 0 036 0 004 0 078 ensemble 2 52 0 39 99 36 98 55 97 26 0 063 0 188 0 005 0 012 0 004 0 144 wensemble 2 88 0 26 99 44 98 43 97 56 0 046 0 153 0 005 0 013 0 002 0 045 deepdroid vanilla 8 53 0 69 98 41 95 39 92 99 0 097 0 311 0 013 0 039 0 009 0 059 temp scaling 8 53 0 69 98 41 95 39 92 99 0 076 0 220 0 013 0 038 0 002 0 023 mc dropout 7 62 0 66 98 54 95 86 93 57 0 078 0 239 0 012 0 035 0 004 0 055 vbi 12 7 0 35 98 22 93 47 91 88 0 084 0 305 0 014 0 052 0 010 0 092 ensemble 7 44 0 11 99 05 96 23 95 73 0 049 0 171 0 008 0 029 0 006 0 162 wensemble 4 99 0 27 99 18 97 37 96 41 0 050 0 131 0 007 0 022 0 008 0 066 droidetec vanilla 4 14 1 53 98 17 97 17 92 30 0 119 0 208 0 016 0 026 0 014 0 205 temp scaling 4 14 1 53 98 17 97 17 92 30 0 101 0 167 0 016 0 026 0 015 0 180 mc dropout 3 03 1 40 98 41 97 78 93 32 0 088 0 142 0 014 0 020 0 013 0 207 vbi 3 22 1 67 98 15 97 55 92 29 0 118 0 202 0 015 0 022 0 015 0 262 ensemble 3 13 0 75 98 98 98 06 95 60 0 055 0 107 0 009 0 016 0 010 0 143 wensemble 3 49 0 59 99 07 97 96 95 98 0 046 0 101 0 007 0 016 0 008 0 116 b 1 b 2 b 3 b 4 b 5 benware 0 e 0 2 e 3 4 e 3 6 e 3 8 e 3 o f e xa m pl es b 1 b 2 b 3 b 4 b 5 malware deepdrebin multimodalnn deepdroid droidetec a of examples per bin 0 0 0 2 0 4 0 6 0 8 1 0 mean of predicted value 0 0 0 2 0 4 0 6 0 8 1 0 ra tio o f p os iti ve s well calibrated b reliability diagram figure 3 reliability diagram of vanilla malware detectors there are 5 bins 1 5 and benware denotes the benign software bnll bbse and uece are more sensitive than their imbalanced counterparts i e nll bse and ece when data imbalance is present 4 3 answering rq 2 in order to quantify the predictive uncertainty of malware detec tors with respect to out of source examples we apply the drebin malware detectors to the virusshare dataset we assess predictive distribution and report the accuracy of malware detectors on the datasets obtained after removing the examples for which the de tectors are uncertain i e with an entropy value above a threshold this corresponds to the real world usefulness of quantifying predictive uncertainty i e discarding prediction results for which detector is uncertain table 2 summarizes the uncertainty evaluation and the cor responding detection accuracy we make three observations i malware detectors achieve low accuracy with out of source test examples nevertheless deepdrebin incorporating vbi obtain an accuracy of 82 69 which notably outperforms other detectors it is reminding that vbi hinders the detection accuracy in the absence of dataset shift ii calibration methods e g vbi or ensemble reduce the uncertainty in terms of bnll and bbse when compared with the vanilla models except for the multimodalnn model incorporat ing mc dropout iii deepdrebin incorporating vbi also achieves the best calibration results suggesting that vbi benefits from both regularization and calibration on the other hand deepdroid and droidetec suffer from the setting of out of source both models han dle the very long sequential data that would be truncated due to the limited gpu memory leading to the inferior results figure 4 illustrates the density of predictive entropy figure 4 b further shows the accuracy on the examples after removing the ones for which the detectors are uncertain about their predictions we make the following observations i the vanilla models return zero acsac 21 december 6 10 2021 virtual event usa d li t qiu s chen q li and s xu 0 5 0 0 0 5 1 0 entropy values 0 2 4 6 8 10 d en si ty deepdrebin 0 5 0 0 0 5 1 0 entropy values multimodalnn 0 5 0 0 0 5 1 0 entropy values deepdroid vanilla temp scaling mc dropout vbi ensemble wensemble 0 5 0 0 0 5 1 0 entropy values droidetec a 0 0 0 2 0 4 0 6 0 8 1 0 threshold 0 5 0 6 0 7 0 8 0 9 1 0 ac cu ra cy o n e xa m pl es w e nt ro py deepdrebin 0 0 0 2 0 4 0 6 0 8 1 0 threshold multimodalnn 0 0 0 2 0 4 0 6 0 8 1 0 threshold deepdroid 0 0 0 2 0 4 0 6 0 8 1 0 threshold droidetec b figure 4 predictive entropy see eq 7 of malware detectors trained on the drebin dataset and tested on the virusshare a histogram of predictive entropy b accuracy on the dataset after excluding the examples for which the detector has high uncertainties i e the examples for which the predictive entropy is above a pre determined threshold which corresponds to the real world use of the quantified predictive uncertainty table 2 predictive uncertainty ofmalware detectors that are learned on the drebin dataset and tested on the virusshare calibration method detection uncertainty evaluation acc bacc nll bnll bse bbse ece uece d e e p d r e b i n vanilla 63 96 77 59 5 52 3 58 0 35 0 21 0 359 0 483 temp scaling 63 96 77 59 1 65 1 39 0 31 0 19 0 363 0 468 mc dropout 74 39 83 53 1 48 0 95 0 20 0 13 0 274 0 463 vbi 82 69 87 07 0 64 0 52 0 13 0 10 0 210 0 434 ensemble 61 76 78 04 3 43 2 15 0 32 0 19 0 394 0 466 wensemble 59 49 76 59 3 08 1 79 0 32 0 19 0 397 0 469 m u l t i m o d a l n n vanilla 69 02 80 48 4 05 2 59 0 29 0 18 0 306 0 463 temp scaling 69 02 80 48 1 45 1 13 0 25 0 17 0 303 0 464 mc dropout 64 38 78 38 4 61 2 58 0 32 0 18 0 361 0 473 vbi 58 17 77 21 2 32 1 25 0 33 0 18 0 414 0 478 ensemble 72 66 82 20 2 24 1 34 0 21 0 14 0 279 0 450 wensemble 61 73 77 74 2 21 1 26 0 30 0 17 0 379 0 471 d e e p d r o i d vanilla 52 85 70 02 3 44 2 11 0 42 0 27 0 463 0 481 temp scaling 52 85 70 02 2 09 1 31 0 39 0 25 0 460 0 477 mc dropout 65 50 74 22 1 54 1 10 0 26 0 20 0 338 0 465 vbi 56 57 72 65 2 44 1 46 0 40 0 25 0 476 0 475 ensemble 56 57 72 65 1 78 1 12 0 33 0 20 0 435 0 475 wensemble 64 11 74 22 1 22 1 00 0 24 0 19 0 350 0 461 d r o i d e t e c vanilla 59 98 70 04 2 22 1 59 0 34 0 253 0 389 0 476 temp scaling 59 98 70 04 1 66 1 20 0 32 0 235 0 390 0 476 mc dropout 64 99 72 61 1 57 1 33 0 27 0 222 0 344 0 472 vbi 65 30 74 21 2 14 1 85 0 27 0 210 0 315 0 473 ensemble 63 83 72 45 1 33 0 94 0 24 0 185 0 343 0 470 wensemble 62 26 71 64 1 50 1 23 0 28 0 219 0 375 0 465 entropy value for many examples but calibration methods relieve 0 0 0 2 0 4 0 6 0 8 kl d iv er ge nc e k l vbi 0 0 0 2 0 4 0 6 0 8 sd vbi 0 0 0 2 0 4 0 6 0 8 1 0 entropy 0 0 0 2 0 4 0 6 0 8 kl d iv er ge nc e k l ensemble 0 0 0 2 0 4 0 6 0 8 1 0 entropy 0 0 0 2 0 4 0 6 0 8 sd ensemble figure 5 scatter points of the randomly selected 2 000 test examples from the virusshare dataset with paired values entropy kl and entropy sd that are obtained by apply ing deepdrebin incorporating vbi or ensemble this situation notably considering that the higher entropy deliv ers more uncertainty vanilla model is poorly calibrated regarding the out of source examples this is further confirmed that vanilla models exhibit a limited change along with increasing thresholds in figure 4 b ii ensemble and wensemble increase the robustness of deep learning models in detecting out of source examples for example the multimodalnn deepdroid and droidetec models can be enhanced by ensemble and wensemble to some extent espe cially when applied to predicting the examples with entropy values below 0 3 i e the detectors are relatively certain about their pre dictions iii deepdrebin incorporating either vbi or mc dropout make a significant achievement by comparing with ensemble based can we leverage predictive uncertainty to detect dataset shift and adversarial examples in android malware detection acsac 21 december 6 10 2021 virtual event usa 0 50 0 60 0 70 0 80 0 90 1 00 ba cc deepdrebin multimodalnn deepdroid droidetec 0 0 2 0 4 0 6 0 8 0 10 0 bn ll vbi ensemble wensemble te st s et 20 15 0 2 20 15 0 4 20 15 0 6 20 15 0 8 20 15 1 0 20 15 1 2 20 16 0 2 20 16 0 4 20 16 0 6 20 16 0 8 20 16 1 0 20 16 1 20 00 0 10 0 20 0 30 0 40 0 50 bb se te st s et 20 15 0 2 20 15 0 4 20 15 0 6 20 15 0 8 20 15 1 0 20 15 1 2 20 16 0 2 20 16 0 4 20 16 0 6 20 16 0 8 20 16 1 0 20 16 1 2 te st s et 20 15 0 2 20 15 0 4 20 15 0 6 20 15 0 8 20 15 1 0 20 15 1 2 20 16 0 2 20 16 0 4 20 16 0 6 20 16 0 8 20 16 1 0 20 16 1 2 vanilla temp scaling mc dropout te st s et 20 15 0 2 20 15 0 4 20 15 0 6 20 15 0 8 20 15 1 0 20 15 1 2 20 16 0 2 20 16 0 4 20 16 0 6 20 16 0 8 20 16 1 0 20 16 1 2 figure 6 illustration of balanced accuracy bacc balanced nll bnll balanced bse bbse under temporal covariate shift 0 92 0 94 0 96 0 98 1 00 ac cu ra cy o n e xa m pl es w e nt ro py deepdrebin multimodalnn deepdroid droidetec 0 0 0 2 0 4 0 6 0 8 1 0 threshold 0 50 0 60 0 70 0 80 0 90 ba cc ur ac y on e xa m pl es w e nt ro py 0 0 0 2 0 4 0 6 0 8 1 0 threshold 0 0 0 2 0 4 0 6 0 8 1 0 threshold 0 0 0 2 0 4 0 6 0 8 1 0 threshold a 0 4 8 12 16 20 d en si ty deepdrebin multimodalnn vanilla temp scaling mc dropout vbi ensemble wensemble 0 5 0 0 0 5 1 0 entropy values 0 2 4 6 8 10 d en si ty deepdroid 0 5 0 0 0 5 1 0 entropy values droidetec b figure 7 predictive entropy see eq 7 of malware detectors on androzoo dataset a accuracy upper row and baccuracy bottom row on the androzoo test set after excluding the examples for which the detectors have high uncertainties i e the examples forwhich the predictive entropy is above a pre determined threshold b test sample density of predictive entropy calibrations because vbi requires suitable prior distributions it is challenging to generalize this calibration to all models effectively 6 iv temp scaling demonstrates an un intuitive phenomenon that it achieves almost 100 accuracy at the start of the curves when applied to deepdrebin multimodalnn and droidetec but degrades the accuracy of deepdroid the is because temp scaling tends to over approximate the predicted probabilities resulting in high con fidence score for examples some of which are mis classified how ever in addition the balanced accuracy demonstrates the similar experimental results cf the appendix materials for details figure 5 plots the relationship between the entropy and the kl divergence kl and the relationship between the entropy and the standard deviation sd a scatter point represents a test example based on the paired value we observe that these three measure ments are closely related which explains why we use the entropy to characterize the predictive uncertainty solely we only report the results for the calibrated deepdrebin with vbi and ensemble because similar phenomena are observed for the other models note that vanilla and temp scaling do not apply to kl divergence and standard deviation insight 2 deep ensemble benefits calibration of malware detec tors against out of source test examples but a carefully tuned vbi model could achieve a higher quality of uncertainty than ensemble based methods measurements of entropy kl divergence and standard deviation are closely related 4 4 answering rq 3 in order to quantify the predictive uncertainty of malware detectors under temporal covariate shift we use androzoo dataset specifi cally we train malware detectors upon the apks collected in the year of 2014 and test these malware detectors upon apks collected in the year of 2015 and 2016 at the month granularity we also split the apks in the year of 2014 into three disjoint datasets 83 4 for acsac 21 december 6 10 2021 virtual event usa d li t qiu s chen q li and s xu table 3 effectiveness of calibrated malware detectors under adversarial evasion attacks malware detector calibration method no attack max pgds gdkde attack mimicry attack acc nll bse ece acc nll bse ece acc nll bse ece deepdrebin vanilla 96 09 0 629 0 037 0 039 0 00 33 22 1 000 1 000 66 09 4 778 0 317 0 334 temp scaling 96 09 0 184 0 033 0 042 0 00 7 015 0 985 0 992 66 09 1 427 0 266 0 332 mc dropout 96 55 0 186 0 029 0 040 0 00 33 22 1 000 1 000 69 18 1 639 0 245 0 317 vbi 96 27 0 142 0 025 0 051 0 00 33 22 1 000 1 000 69 91 1 034 0 211 0 320 ensemble 96 00 0 403 0 034 0 042 0 00 33 22 1 000 1 000 64 82 3 296 0 295 0 363 wensemble 96 00 0 362 0 034 0 042 0 00 33 22 1 000 1 000 64 64 2 944 0 296 0 362 multimo dalnn vanilla 97 82 0 368 0 020 0 023 0 00 33 22 1 000 1 000 87 64 1 530 0 107 0 119 temp scaling 97 82 0 129 0 019 0 025 0 00 8 871 0 996 0 998 87 64 0 562 0 094 0 122 mc dropout 97 18 0 399 0 024 0 030 0 00 33 22 1 000 1 000 85 64 1 822 0 121 0 152 vbi 96 82 0 166 0 026 0 042 0 00 33 22 1 000 1 000 89 64 0 506 0 080 0 119 ensemble 97 45 0 355 0 021 0 026 0 00 33 22 1 000 1 000 88 09 1 148 0 091 0 129 wensemble 97 09 0 295 0 025 0 035 0 00 33 22 1 000 1 000 84 27 1 124 0 123 0 187 deepdroid vanilla 91 55 0 587 0 073 0 095 85 45 0 773 0 116 0 148 86 09 0 786 0 110 0 142 temp scaling 91 55 0 404 0 069 0 113 85 45 0 536 0 105 0 165 86 09 0 538 0 101 0 158 mc dropout 92 55 0 451 0 066 0 097 93 55 0 273 0 048 0 074 90 18 0 529 0 083 0 126 vbi 87 27 0 592 0 102 0 151 84 00 0 592 0 117 0 180 82 00 0 705 0 136 0 200 ensemble 92 55 0 329 0 058 0 099 90 64 0 366 0 068 0 129 89 55 0 433 0 079 0 142 wensemble 95 00 0 237 0 040 0 069 93 00 0 309 0 057 0 111 92 82 0 348 0 061 0 111 droidetec vanilla 98 08 0 123 0 016 0 028 66 03 2 331 0 298 0 341 88 80 0 656 0 099 0 126 temp scaling 98 08 0 113 0 017 0 039 66 03 1 717 0 285 0 345 88 80 0 514 0 095 0 138 mc dropout 98 81 0 063 0 009 0 018 67 30 2 066 0 272 0 330 93 17 0 268 0 052 0 090 vbi 98 54 0 095 0 012 0 016 71 31 1 996 0 250 0 292 93 08 0 396 0 060 0 078 ensemble 99 18 0 060 0 008 0 014 80 87 0 657 0 138 0 215 96 17 0 175 0 030 0 068 wensemble 99 00 0 048 0 008 0 015 80 05 0 776 0 151 0 232 95 90 0 156 0 029 0 066 training 8 33 for validation 8 33 is the average percentage of apks emerging in each month of 2014 and 8 33 for testing figure 6 plots the balanced accuracy baccuracy balanced nll bnll and balanced bse bbse under temporal covariate shift more results are presented in the appendix materials we make the following observations i malware detectors encounter a signifi cantly decreasing of accuracy and increasing of bnll and bbsewith newer test data this can be attributed to the natural software evolu tion that google gradually updates android apis and practitioners upgrade their apks to support new services in particular droide tec suffer a lot from temporal covariate shift and exhibits a low detection accuracy as mentioned earlier this may be that droidetec is permitted to learn from a limited number of apis which inhibits handling the apks with a broad range of apis ii temp scaling has the same effect as the vanilla model in terms of baccuracy en semble enhances the vanilla models deepdrebin multimodalnn and deepdroid at the start of several months but then this en hancement diminishes vbi makes multimodalnn to achieve the highest robustness under data evolution but only achieves 80 baccuracy iii ensemble methods benefit calibration in terms of bnll and bbse when compared with the vanilla model vbi in corporating deepdrebin or multimodalnn achieves an impressive result figure 7 a plots the accuracy at the upper half and the balanced accuracy at the lower half after excluding the examples for which the detectors have entropy values greater than a threshold fig ure 7 b plots the sample density of predictive entropy we observe that i either accuracy or balanced accuracy decreases dramati cally when the entropy increases which is particularly true for deepdroid and droidetec ii multimodalnn incorporating vbi seems to work very well in terms of accuracy but not necessary for balanced accuracy this is because the model classifies most benign samples correctly but not malicious ones until the threshold value is approach 0 9 moreover it is interesting to see that multimodalnn incorporating vbi achieves the best baccuracy without consider ing uncertainty cf figure 6 which is in sharp contrast to figure 7 a the reason behind this is that multimodalnn incorporating vbi correctly classifies a portion of examples with high entropy value as shown in figure 7 b iii deepdrebin incorporating vbi outperforms the other drebin based models which resonates the results obtained in our second group of experiments cf figure 4 b in section 4 3 iv figure 7 b says that for all of the malware detectors except multimodalnn incorporating vbi and deepdrebin incorporating vbi most examples tend to have a small entropy this suggests ineffective calibrations of malware detectors under temporal covariate shifts and a lack of good calibration method can we leverage predictive uncertainty to detect dataset shift and adversarial examples in android malware detection acsac 21 december 6 10 2021 virtual event usa insight 3 calibrated malware detectors cannot cope with tempo ral datashit shift effectively but vbi is promising for calibration and generalization under temporal covariate shift 4 5 answering rq 4 in order to quantify the predictive uncertainty of malware detectors under adversarial evasion attacks we wage transfer attacks and generate adversarial apks via a surrogatedeepdrebin model we do not include adversarial apks with respect to multimodalnn deep droid and droidetec because we do not find effective solutions the surrogate deepdrebin model consists of two fully connected layers of 160 neurons with the relu activation function we learn the model using the adam optimizer with learning rate 0 001 batch size 128 and 150 epochs we then generate adversarial examples against the surrogate model to perturb the 1 112 malicious apks in the test dataset specifically by following a recent study 27 we first perturb the feature vectors of the apks using the max pgds gdkde attack and the mimicry attack and then obtain ad versarial apks by using obfuscation techniques in total we obtain 1100 perturbed apk files for both attacks respectively table 3 summarizes the results of the malware detectors under the max pgds gdkde attack and the mimicry attack because the test dataset contains malware samples solely we consider the accuracy nll bse and ece rather than their balanced versions we observe that i the max pgds gdkde attack renders deep drebin and multimodalnn models useless regardless of the calibra tion methods nevertheless deepdroid is robust against this attack because opcode are not used by the deepdrebin and thus is unfo cused by the attacker however deepdroid still suffers somewhat from this attack because of the opcode manipulations is leveraged for preserving the malicious functionality ii under the mimicry attack vbi makes deepdrebin and multimodalnn achieve the best accuracy and the lowest calibration error in terms of nll and bse while weighted ensemble makes both obtain the worst re sults however this situation is changed in regards to deepdroid and droidetec this might be that deepdrebin and multimodalnn are more sensitive to mimicry attack than deepdroid and droide tec leading to that an ensemble of vulnerable models decreases the robustness against the attack insight 4 adversarial evasion attacks can render calibrated mal ware detectors and therefore the quantified predictive uncertainty useless but heterogeneous feature extraction does improve the robust ness of malware detectors against the transfer attacks 5 conclusion we empirically quantified the predictive uncertainty of four deep malware detectors with six calibration strategies i e 24 detectors in total we found that the predictive uncertainty of calibrated malware detectors is useful except for adversarial examples we hope this study will motivate and inspire more research in quanti fying the uncertainty of malware detectors which is of paramount importance in practice but it is currently little understood acknowledgments q li is supported in part by the national key r d program of china under grants 2020 yfb 1804604 and 2020 yfb 1804600 the 2020 industrial internet innovation and development project from ministry of industry and information technology of china the fundamental research fund for the central universities under grants 30918012204 and 30920041112 the 2019 industrial internet innovation and development project fromministry of industry and information technology of china s xu is supported in part by nsf grants 2122631 1814825 and 2115134 aro grant w 911 nf 17 1 0566 and colorado state bill 18 086 references 1 mart n abadi ashish agarwal and et al 2015 tensorflow large scale machine learning on heterogeneous systems https www tensorflow org software available from tensorflow org 2 mart n abadi paul barham et al 2016 tensorflow a system for large scale machine learning in osdi 16 usenix association savannah ga usa 265 283 3 kevin allix tegawend f bissyand et al 2016 androzoo collecting millions of android apps for the research community in international conference on msr austin texas acm ny usa 468 471 https doi org 10 1145 2901739 2903508 4 daniel arp michael spreitzenbarth et al 2014 drebin effective and explainable detection of android malware in your pocket in ndss vol 14 the internet society san diego california usa 23 26 5 umang bhatt yunfeng zhang and et al 2020 uncertainty as a form of transparency measuring communicating and using uncertainty corr abs 2011 07586 2020 https arxiv org abs 2011 07586 6 charles blundell julien cornebise koray kavukcuoglu and daan wierstra 2015 weight uncertainty in neural network in proceedings of the 32 nd international conference on machine learning vol 37 pmlr lille france 1613 1622 https proceedings mlr press v 37 blundell 15 html 7 glenn w brier 1950 verification of forecasts expressed in terms of probability monthly weather review 78 1 1950 1 3 8 k h brodersen c s ong k e stephan and j m buhmann 2010 the balanced accuracy and its posterior distribution in 2010 20 th international conference on pattern recognition ieee computer society istanbul turkey 3121 3124 9 joaquin qui onero candela carl edward rasmussen fabian h sinz olivier bousquet and bernhard sch lkopf 2005 evaluating predictive uncertainty challenge in machine learning challenges evaluating predictive uncertainty visual object classification and recognizing textual entailment first pascal machine learning challenges workshop vol 3944 springer southampton uk 1 27 10 lingwei chen yanfang ye and thirimachos bourlai 2017 adversarial machine learning in malware detection arms race between evasion attack and defense in eisic 2017 ieee computer society athens greece 99 106 11 forensics corvus 2020 virusshare https virusshare com 12 ambra demontis marco melis et al 2017 yes machine learning can be more secure a case study on android malware detection ieee tdsc 16 4 2017 711 724 13 anthony desnos 2020 androguard https github com androguard androguard 14 pang du zheyuan sun huashan chen jin hee cho and shouhuai xu 2018 statistical estimation of malware detection metrics in the absence of ground truth ieee trans inf forensics secur 13 12 2018 2965 2980 15 yarin gal and zoubin ghahramani 2016 dropout as a bayesian approximation representing model uncertainty in deep learning in international conference on machine learning jmlr org ny usa 1050 1059 16 alex graves 2011 practical variational inference for neural networks in advances in neural information processing systems 24 25 th annual conference on neural information processing systems 2011 curran associates inc granada spain 2348 2356 17 kathrin grosse nicolas papernot et al 2017 adversarial examples for malware detection in esorics springer oslo norway 62 79 18 chuan guo geoff pleiss yu sun and kilian q weinberger 2017 on calibration of modern neural networks in proceedings of the 34 th international conference on machine learning icml proceedings of machine learning research vol 70 doina precup and yee whye teh eds pmlr sydney nsw australia 1321 1330 19 t h huang and h kao 2018 r 2 d 2 color inspired convolutional neural network cnn based android malware detections in 2018 ieee international conference on big data big data ieee seattle wa usa 2633 2642 20 roberto jordaney kumar sharad et al 2017 transcend detecting concept drift in malware classification models in usenix security 17 usenix association vancouver bc 625 642 https www usenix org conference usenixsecurity 17 technical sessions presentation jordaney 21 alex kendall and yarin gal 2017 what uncertainties do we need in bayesian deep learning for computer vision in neurips curran associates inc long https www tensorflow org https doi org 10 1145 2901739 2903508 https doi org 10 1145 2901739 2903508 https arxiv org abs 2011 07586 https proceedings mlr press v 37 blundell 15 html https proceedings mlr press v 37 blundell 15 html https virusshare com https github com androguard androguard https www usenix org conference usenixsecurity 17 technical sessions presentation jordaney https www usenix org conference usenixsecurity 17 technical sessions presentation jordaney acsac 21 december 6 10 2021 virtual event usa d li t qiu s chen q li and s xu beach ca usa 5574 5584 22 t kim b kang et al 2019 a multimodal deep learning method for android malware detection using various features ieee trans info forensics and sec 14 3 2019 773 788 23 yoon kim 2014 convolutional neural networks for sentence classification in proceedings of the 2014 conference on empirical methods in natural language processing emnlp alessandro moschitti bo pang and walter daelemans eds acl doha qatar 1746 1751 24 kaspersky lab 2020 kaspersky https www kaspersky com 25 balaji lakshminarayanan alexander pritzel and charles blundell 2017 simple and scalable predictive uncertainty estimation using deep ensembles in neurips curran associates inc long beach ca usa 6402 6413 26 christian leibig vaneeda allken murat se kin ayhan philipp berens and siegfried wahl 2017 leveraging uncertainty information from deep neural networks for disease detection scientific reports 7 1 2017 1 14 27 deqiang li and qianmu li 2020 adversarial deep ensemble evasion attacks and defenses for malware detection ieee trans info forensics and sec 15 2020 3886 3900 28 jie lu anjin liu fan dong feng gu jo o gama and guangquan zhang 2019 learning under concept drift a review ieee trans knowl data eng 31 12 2019 2346 2363 29 zhuo ma haoran ge zhuzhu wang yang liu and ximeng liu 2020 droidetec androidmalware detection andmalicious code localization through deep learning corr abs 2002 03594 2020 https arxiv org abs 2002 03594 30 niall mclaughlin jesus martinez del rincon et al 2017 deep android malware detection in codaspy 17 scottsdale arizona usa acm ny usa 301 308 https doi org 10 1145 3029806 3029823 31 mahdi pakdaman naeini gregory cooper and milos hauskrecht 2015 obtain ing well calibrated probabilities using bayesian binning in twenty ninth aaai conference on artificial intelligence aaai press austin texas usa 2901 2907 32 andr t nguyen edward raff charles nicholas and james holt 2021 leverag ing uncertainty for improved static malware detection under extreme false pos itive constraints corr abs 2108 04081 2021 https arxiv org abs 2108 04081 33 alexandru niculescu mizil and rich caruana 2005 predicting good probabilities with supervised learning in icml acm bonn germany 625 632 34 tim pearce felix leibfried et al 2020 uncertainty in neural networks approx imately bayesian ensembling in aistats pmlr online palermo sicily italy 234 244 35 feargus pendlebury fabio pierazzi et al 2019 tesseract eliminating experi mental bias in malware classification across space and time in usenix security 19 usenix association santa clara ca 729 746 https www usenix org conference usenixsecurity 19 presentation pendlebury 36 marcus pendleton richard garcia lebron jin hee cho and shouhuai xu 2016 a survey on systems security metrics acm comput surv 49 4 dec 2016 1 35 37 joaquin quionero candela masashi sugiyama anton schwaighofer and neil d lawrence 2009 dataset shift in machine learning the mit press cambridge ma 38 hispasec sistemas 2020 virustotal alphabet inc https www virustotal com 39 jasper snoek yaniv ovadia emily fertig balaji lakshminarayanan sebastian nowozin d sculley joshua dillon jie ren and zachary nado 2019 can you trust your model s uncertainty evaluating predictive uncertainty under dataset shift in advances in neural information processing systems curran associates inc vancouver bc canada 13969 13980 40 nitish srivastava geoffrey hinton alex krizhevsky ilya sutskever and ruslan salakhutdinov 2014 dropout a simple way to prevent neural networks from overfitting the journal of machine learning research 15 1 2014 1929 1958 41 trias thireou and martin reczko 2007 bidirectional long short term mem ory networks for predicting the subcellular localization of eukaryotic proteins ieee acm transactions on computational biology and bioinformatics 4 3 2007 441 446 42 connor tumbleson and ryszard wi niewski 2020 apktool https ibotpeaches github io apktool 43 juozas vaicenavicius davidwidmann carl r andersson fredrik lindsten jacob roll and thomas b sch n 2019 evaluating model calibration in classification in the 22 nd international conference on artificial intelligence and statistics aistats vol 89 pmlr naha okinawa japan 3459 3467 44 cheng wang carolin lawrence and mathias niepert 2021 uncertainty estima tion and calibration with finite state probabilistic rnns in 9 th international conference on learning representations openreview net virtual event austria 45 max welling and yee w teh 2011 bayesian learning via stochastic gradient langevin dynamics in icml omnipress madison wi usa 681 688 46 gerhard widmer and miroslav kubat 1996 learning in the presence of concept drift and hidden contexts mach learn 23 1 1996 69 101 47 li xu zhenxin zhan shouhuai xu and keying ye 2014 an evasion and counter evasion study in malicious websites detection in ieee conference on communi cations and network security cns 2014 ieee san francisco ca usa 265 273 48 yanfang ye tao li and et al 2017 a survey on malware detection using data mining techniques acm comput surv 50 3 2017 41 1 41 40 49 xiaohan zhang yuan zhang and et al 2020 enhancing state of the art clas sifiers with api semantics to detect evolved android malware in ccs 2020 virtual event usa association for computing machinery new york usa 757 770 50 indre liobaite mykola pechenizkiy and jo o gama 2016 an overview of concept drift applications springer international publishing cham 91 114 a experimental results on the virusshare dataset figure 8 plots the balanced accuracy on the virusshare dataset with decision referral we observe that figure 8 exhibit the trends that are similar to what are exhibited by figure 4 b except for temp scaling on deepdrebin and multimodalnn this is because the model predicts benign examples accurately but do not predict malicious examples accurately b experimental results on the androozoo dataset figure 9 plots the accuracy nll and bse of malware detectors under temporal covariate shifts we observe that the accuracy nll and bse are smaller than their balanced counterparts plotted in figure 6 owing to the data imbalance exhibited by the androzoo dataset despite that they all exhibit a similar trend https www kaspersky com https arxiv org abs 2002 03594 https doi org 10 1145 3029806 3029823 https arxiv org abs 2108 04081 https www usenix org conference usenixsecurity 19 presentation pendlebury https www usenix org conference usenixsecurity 19 presentation pendlebury https www virustotal com https ibotpeaches github io apktool https ibotpeaches github io apktool can we leverage predictive uncertainty to detect dataset shift and adversarial examples in android malware detection acsac 21 december 6 10 2021 virtual event usa 0 0 0 2 0 4 0 6 0 8 1 0 threshold 0 7 0 8 0 9 1 0 ba cc ur ac y on e xa m pl es w e nt ro py deepdrebin 0 0 0 2 0 4 0 6 0 8 1 0 threshold multimodalnn 0 0 0 2 0 4 0 6 0 8 1 0 threshold deepdroid 0 0 0 2 0 4 0 6 0 8 1 0 threshold droidetec vanilla temp scaling mc dropout vbi ensemble wensemble figure 8 the balanced accuracy on the virusshare dataset after excluding the examples for which the detector has high uncertainties i e the examples for which the predictive entropy is above a pre determined threshold for each curve a shadow region is obtained from the 95 confidence interval using a bootstrapping with 103 repetitions and sampling size being the number of examples in the virusshare dataset 0 80 0 85 0 90 0 95 1 00 ac cu ra cy deepdrebin multimodalnn deepdroid droidetec 0 00 1 00 2 00 3 00 nl l vbi ensemble wensemble te st s et 20 15 0 2 20 15 0 4 20 15 0 6 20 15 0 8 20 15 1 0 20 15 1 2 20 16 0 2 20 16 0 4 20 16 0 6 20 16 0 8 20 16 1 0 20 16 1 20 00 0 05 0 10 0 15 0 20 bs e te st s et 20 15 0 2 20 15 0 4 20 15 0 6 20 15 0 8 20 15 1 0 20 15 1 2 20 16 0 2 20 16 0 4 20 16 0 6 20 16 0 8 20 16 1 0 20 16 1 2 vanilla temp scaling mc dropout te st s et 20 15 0 2 20 15 0 4 20 15 0 6 20 15 0 8 20 15 1 0 20 15 1 2 20 16 0 2 20 16 0 4 20 16 0 6 20 16 0 8 20 16 1 0 20 16 1 2 te st s et 20 15 0 2 20 15 0 4 20 15 0 6 20 15 0 8 20 15 1 0 20 15 1 2 20 16 0 2 20 16 0 4 20 16 0 6 20 16 0 8 20 16 1 0 20 16 1 2 figure 9 illustration of accuracy nll bse under temporal covariate shift on the androzoo dataset a shadow region is ob tained from the 95 confidence interval using a bootstrapping with 103 repetitions and sampling size being the number of apks in per month cf figure 2 abstract 1 introduction 2 problem statement 2 1 android apps and malware detection 2 2 problem statement 3 empirical analysis methodology 3 1 selecting candidate detectors 3 2 selecting calibration methods 3 3 calibrating detectors 3 4 selecting metrics 3 5 answering rqs 4 experimental results and analysis 4 1 experimental setup 4 2 answering rq 1 4 3 answering rq 2 4 4 answering rq 3 4 5 answering rq 4 5 conclusion acknowledgments references a experimental results on the virusshare dataset b experimental results on the androozoo dataset